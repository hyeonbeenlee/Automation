A. Zelinsky, "Welcome Message from the General Chair," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1-2.
doi: 10.1109/ICRA.2018.8461171
Abstract: On behalf of the ICRA 2018 Organising Committee we extend a warm welcome to the world's foremost conference in robotics & automation, where you will be in the company of the best and brightest researchers and engineers from around our planet! ICRA started in 1984 and has become the leading international conference attended by thousands. The conference has played a leading role in shaping the future of robotics and automation. There has never been a better time than now to be working in robotics and automation field. Today we are witnessing explosive growth in the field with significant opportunities for both research and industry. ICRA is the meeting place where science, technology, innovation comes together to understand the latest advances in order to push for the next frontiers of development. As our technology matures and takes its place amongst the everyday lives of people it is important that this is done in a considered, safe and ethical manner.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461171&isnumber=8460178

P. Corke, "ICRA 2018 Program Chair Report," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1-3.
doi: 10.1109/ICRA.2018.8461126
Abstract: This year a record number of papers were submitted directly to ICRA (1981) and to RA-L with the ICRA option (605). This represents an increase of 4% and 48% over last year respectively - clearly the RA-L/ICRA option is growing in popularity. The long-term average is a growth rate of around 60 papers per year. The submission process accommodated, as much as possible, the hardships inflicted on authors by hurricanes and earthquakes in the days prior to the deadline.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461126&isnumber=8460178

"Organizing Committee," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1-12.
doi: 10.1109/ICRA.2018.8460932
Abstract: Provides a listing of current committee members and society officers.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460932&isnumber=8460178

"Conference Editorial Committee," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1-48.
doi: 10.1109/ICRA.2018.8460808
Abstract: Provides a listing of current committee members and society officers.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460808&isnumber=8460178

"Plenary and Keynote Talks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1-20.
doi: 10.1109/ICRA.2018.8460801
Abstract: Provides an abstract for each of the keynote presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460801&isnumber=8460178

"Awards," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1-8.
doi: 10.1109/ICRA.2018.8460803
Abstract: Lists the ICRA 2018 awards that will be supported and award finalists.
keywords: {Awards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460803&isnumber=8460178

"ICRA 2018 Youtube Channel," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1-1.
doi: 10.1109/ICRA.2018.8461158
Abstract: ICRA 2018 Youtube Channel
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461158&isnumber=8460178

"Workshops & Tutorials," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1-3.
doi: 10.1109/ICRA.2018.8460509
Abstract: Full Day Workshops & Tutorials
keywords: {Conferences;Tutorials;Service robots;Machine learning;Soft robotics;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460509&isnumber=8460178

"Sponsors and Exhibitors," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1-7.
doi: 10.1109/ICRA.2018.8460540
Abstract: We thank all sponsors for their generous support and contribution.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460540&isnumber=8460178

A. Favaro, L. Cerri, S. Galvan, F. R. Y. Baena and E. De Momi, "Automatic Optimized 3D Path Planner for Steerable Catheters with Heuristic Search and Uncertainty Tolerance," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 9-16.
doi: 10.1109/ICRA.2018.8461262
Abstract: In this paper, an automatic planner for minimally invasive neurosurgery is presented. The solution provides the neurosurgeon with the best path to connect a user-defined entry point with a target in accordance with a specific cost function. The approach guarantees the avoidance of obstacles which can be found along the insertion pathway. The method is tailored to the EDEN2020* programmable bevel-tip needle, a multisegment steerable probe intended to be used to perform drug delivery for the treatment of glioblastomas. A sample-based heuristic search inspired by the BIT* algorithm is used to define the asymptotically-optimal solution in terms of path length, followed by a smoothing phase to meet the required kinematic constraints of the needle. To account for inaccuracies in catheter modeling, which could determine unexpected control errors over the insertion procedure, an uncertainty margin is defined in order to increase the algorithm's safety. The feasibility of the proposed solution was demonstrated by testing the method in simulated neurosurgical scenarios with different degrees of obstacle occupancy and against other sample-based algorithms present in literature: RRT, RRT* and an enhanced version of the RRT-Connect.
keywords: {Neurosurgery;Catheters;Three-dimensional displays;Kinematics;Needles;Planning;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461262&isnumber=8460178

N. Liu, M. E. M. K. Abdelaziz, M. Shen and G. -Z. Yang, "Design and kinematics characterization of a laser-profiled continuum manipulator for the guidance of bronchoscopic instruments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 25-31.
doi: 10.1109/ICRA.2018.8460849
Abstract: Bronchoscopic intervention, as a minimally invasive method for the diagnosis and treatment of lung diseases, has attracted more and more attention in recent years. However, existing endobronchial instruments lack the steerability accessing the peripheral airways with difficult bifurcations. This paper presents a novel wire-driven dexterous manipulator for the guidance of such instruments. Precision laser profiling is used to cut a stainless steel tube into multiple interlocked segments with revolute joints. The outer diameter of the manipulator is 2.20 mm which is small enough to be inserted into the working channels of most commercial bronchoscopes and distal airways, while keeping a large inner lumen with a diameter of 1.44 mm for passing various bronchoscopic instruments. The small bending radius provides enough flexibility to navigate inside the complex bronchial tree. Two kinematic models are proposed to predict the manipulator configuration from the translation of actuation wires. The former model is geometrically derived with the assumption of constant curvature bending and the latter one is statistically driven by capturing the motion trajectories of manipulator joints. A prototype of our low-cost add-on instrument guidance robot for bronchoscopic intervention is presented which can be easily integrated into current clinical routine.
keywords: {Manipulators;Wires;Instruments;Electron tubes;Surgery;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460849&isnumber=8460178

Y. Chitalia, X. Wang and J. P. Desai, "Design, Modeling and Control of a 2-DoF Robotic Guidewire," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 32-37.
doi: 10.1109/ICRA.2018.8462694
Abstract: In most cases of peripheral arterial disease (PAD), the operating surgeon must use a variety of catheters riding on a thin wire known as a `guidewire'. This guidewire must be manually navigated through a tortuous pathway of arteries to arrive at the diseased area. Automation of the guidewire therefore reduces surgeon effort and minimizes the time required for a PAD procedure, but is restricted by the size constraints of a standard guidewire. This work presents the design of a robotically actuated 2 degree-of-freedom (DoF) guidewire tip comprised of joints laser micro-machined into a 0.78 mm (<; 2.4 Fr) Nitinol tube. We present an analysis of the notch joint used as a building block in the robot and a control strategy for this type of a joint. The experimental results show that tendon force is an important observable quantity that can be used as a shape sensing mechanism for this type of a joint in practical control applications.
keywords: {Tendons;Electron tubes;Arteries;Catheters;Robot kinematics;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462694&isnumber=8460178

H. Tsukagoshi, K. Terashima and Y. Takai, "A Self-propelled Catheter Capable of Generating Travelling Waves with Steering Function by Mono-Line Drive," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 38-43.
doi: 10.1109/ICRA.2018.8461159
Abstract: This paper discusses the design method of a self-propelled catheter with thin diameter of 2.6mm, aimed for moving and steering in the bronchi. As the basic configuration, the proposed catheter is composed of an inner tube and McKibben artificial muscles. It can propel by generating travelling waves by a single supply line driven by pneumatics. Since the inner tube equips with orifices of different size, several McKibben chambers can deform with the time delay. We also propose the method to steer the direction at the branch pipe, whose angle can be adjusted by PWM control of pressuring. Besides, we also introduce the design method of how to deal with the pipes with different diameters. The validity of these proposed methods are verified by the prototype through the experiments in the bronchial model.
keywords: {Electron tubes;Propulsion;Muscles;Actuators;Catheters;Prototypes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461159&isnumber=8460178

E. H. Murai, S. Homer-Vanniasinkam, P. G. Silveira, J. S. Dai, D. Martins and H. A. Wurdemann, "Towards a Modular Suturing Catheter for Minimally Invasive Vascular Surgery," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 44-49.
doi: 10.1109/ICRA.2018.8460823
Abstract: Endovascular aneurysm repair (EVAR) is a minimally invasive approach for abdominal aortic aneurysm (AAA) treatment. Compared to open surgery, the benefits of EVAR include faster recovery and shorter time in hospital as well as no general anesthesia (in most cases). Though EVAR has become a preferred way to treat AAA with an increasing number of procedures, there are persisting complications, e.g. stent graft migration. Suturing the stent graft to the aorta increases the displacement force necessary to move the implant. This paper describes the design of a suturing catheter for EVAR. The suturing device consist of two modules which can be inserted through the femoral arteries into the abdominal aorta where both join using an electro-magnetic connector. The positioning module provides an anchor inside the aorta for the suturing module and new sequential positions for each stitch. Our large-scale prototype is validated inside a phantom vessel made of silicone material. We are able to successfully prove the concept of this novel single-sided suturing catheter for EVAR.
keywords: {Catheters;Needles;Arteries;Surgery;Prototypes;Yarn;Shafts},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460823&isnumber=8460178

A. Denasi et al., "An Observer-Based Fusion Method Using Multicore Optical Shape Sensors and Ultrasound Images for Magnetically-Actuated Catheters," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 50-57.
doi: 10.1109/ICRA.2018.8462695
Abstract: Minimally invasive surgery involves using flexible medical instruments such as endoscopes and catheters. Magnetically actuated catheters can provide improved steering precision over conventional catheters. However, besides the actuation method, an accurate tip position is required for precise control of the medical instruments. In this study, the tip position obtained from transverse 2D ultrasound images and multicore optical shape sensors are combined using a robust sensor fusion algorithm. The tip position is tracked in the ultrasound images using a template-based tracker and a convolutional neural network based tracker, respectively. Experimental results for a rhombus path are presented, where data obtained from both tracking sources are fused using Luenberger and Kalman state estimators. The mean and standard deviation of the Euclidean error for the Luenberger observer is 0.2 ± 0.11 [mm] whereas for the Kalman filter it is 0.18 ± 0.13 [mm], respectively.
keywords: {Catheters;Fiber gratings;Optical sensors;Shape;Multicore processing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462695&isnumber=8460178

I. An, M. Son, D. Manocha and S. -E. Yoon, "Reflection-Aware Sound Source Localization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 66-73.
doi: 10.1109/ICRA.2018.8461268
Abstract: We present a novel, reflection-aware method for 3D sound localization in indoor environments. Unlike prior approaches, which are mainly based on continuous sound signals from a stationary source, our formulation is designed to localize the position instantaneously from signals within a single frame. We consider direct sound and indirect sound signals that reach the microphones after reflecting off surfaces such as ceilings or walls. We then generate and trace direct and reflected acoustic paths using inverse acoustic ray tracing and utilize these paths with Monte Carlo localization to estimate a 3D sound source position. We have implemented our method on a robot with a cube-shaped microphone array and tested it against different settings with continuous and intermittent sound signals with a stationary or a mobile source. Across different settings, our approach can localize the sound with an average distance error of 0.8 m tested in a room of 7 m by 7 m area with 3 m height, including a mobile and non-line-of-sight sound source. We also reveal that the modeling of indirect rays increases the localization accuracy by 40% compared to only using direct acoustic rays.
keywords: {Acoustics;Ray tracing;Microphone arrays;Three-dimensional displays;Robots;Indoor environments},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461268&isnumber=8460178

W. He, P. Motlicek and J. Odobez, "Deep Neural Networks for Multiple Speaker Detection and Localization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 74-79.
doi: 10.1109/ICRA.2018.8461267
Abstract: We propose to use neural networks for simultaneous detection and localization of multiple sound sources in human-robot interaction. In contrast to conventional signal processing techniques, neural network-based sound source localization methods require fewer strong assumptions about the environment. Previous neural network-based methods have been focusing on localizing a single sound source, which do not extend to multiple sources in terms of detection and localization. In this paper, we thus propose a likelihood-based encoding of the network output, which naturally allows the detection of an arbitrary number of sources. In addition, we investigate the use of sub-band cross-correlation information as features for better localization in sound mixtures, as well as three different network architectures based on different motivations. Experiments on real data recorded from a robot show that our proposed methods significantly outperform the popular spatial spectrum-based approaches.
keywords: {Encoding;Delays;Robots;Artificial neural networks;Microphones;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461267&isnumber=8460178

P. Misra, A. A. Kumar, P. Mohapatra and P. Balamuralidhar, "DroneEARS: Robust Acoustic Source Localization with Aerial Drones," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 80-85.
doi: 10.1109/ICRA.2018.8461223
Abstract: Micro aerial vehicles (MAVs), an emerging class of aerial drones, are fast turning into high value mobile sensing assets. While MAVs have a large sensory gamut at their disposal; vision continues to dominate the external sensing scene, with limited usability in scenarios that offer acoustic clues. Therefore, we endeavor to provision a MAV auditory system (i.e., ears); and as part of this goal, our preliminary aim is to develop a robust acoustic localization system for detecting sound sources in the physical space-of-interest. However, devising this capability is extremely challenging due to strong ego-noise from the MAV propeller units, which is both wideband and non-stationary. It is well known that beamformers with large sensor arrays can overcome high noise levels; but in an attempt to cater to the platform (i.e., space, payload and computation) constraints of a MAV, we propose DroneEARS: a binaural sensing system for geo-locating sound sources. It combines the benefits of sparse (two elements) sensor array design (for meeting the platform constraints), and our proposed mobility-aided beamforming (for overcoming the severe ego-noise and its other complex characteristics) to significantly enhance the received signal-to-noise ratio (SNR). We demonstrate the efficacy of DroneEARS by empirical evaluations, and show that it provides a SNR improvement of 15-18 dB compared to many conventional and widely used techniques. This SNR gain translates to a source localization accuracy of approximately 40 cm within a scan region of 6m × 3m , that is, one order of magnitude better than competing methodologies.
keywords: {Acoustics;Robot sensing systems;Sensor arrays;Signal to noise ratio;Array signal processing;Propellers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461223&isnumber=8460178

F. Cunha and K. Youcef-Toumi, "Ultra-Wideband Radar for Robust Inspection Drone in Underground Coal Mines," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 86-92.
doi: 10.1109/ICRA.2018.8461191
Abstract: Coal mines pose a high safety risk for human workers. An autonomous inspection drone would enable a coal mine operation to reduce this risk by minimizing the time spent by workers inside the mine. This inspection drone must be highly robust to the harsh and dangerous environment of an underground coal mine, with high levels of coal dust and humidity that can obstruct many conventional sensing methods. For high functionality, the drone must sense and avoid potential obstacles and as well as inspect and map the mining wall face. The objective of this paper is to present ultra-wideband (UWB) radar as a robust sensing solution to this challenging environment and validate its performance experimentally in the typical coal mine environment, both statically and dynamically.
keywords: {Coal mining;Ultra wideband radar;Robustness;Drones;Coal;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461191&isnumber=8460178

J. Windau and L. Itti, "Inertial Machine Monitoring System for Automated Failure Detection," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 93-98.
doi: 10.1109/ICRA.2018.8461266
Abstract: Smart manufacturing technologies are emerging which combine industrial equipment with Internet-of-Things (IoT) sensors to monitor and improve productivity of manufacturing. This allows for new opportunities to explore algorithms for predicting machine failures from attached sensor data. This paper presents a solution to non-invasively upgrade an existing machine with an Inertial Machine Monitoring System (IMMS) to detect and classify equipment failure or degraded state. We also provide a strategy to optimize the amount, placement locations, and efficiency of the sensors. In experiments, the system collected data from 36 inertial sensors placed at multiple locations on a 3D printer. Normal operation vs. 10 types of realworld abnormal equipment behavior (loose belt, failures of machine components) were detected and classified by Support Vector Machines and Neural Networks. Using under 1 minute of recording while running a test print, a recursively discovered best subset of 4 to 9 sensors yielded 11-way classification accuracy over 99%. Our results suggest that even a small sensor network and short test program can yield effective detection of machine degraded state and can facilitate early remediation.
keywords: {Feature extraction;Robot sensing systems;Vibrations;Monitoring;Accelerometers;Databases;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461266&isnumber=8460178

B. Wei, N. Trigoni and A. Markham, "iMag: Accurate and Rapidly Deployable Inertial Magneto-Inductive Localisation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 99-106.
doi: 10.1109/ICRA.2018.8460804
Abstract: Localisation is of importance for many applications. Our motivating scenarios are short-term construction work and emergency rescue. Not only is accuracy necessary, these scenarios also require rapid setup and robustness to environmental conditions. These requirements preclude the use of many traditional methods e.g. vision-based, laser-based, Ultra-wide band (UWB) and Global Positioning System (GPS)-based localisation systems. To solve these challenges, we introduce iMag, an accurate and rapidly deployable inertial magneto-inductive (MI) localisation system. It localises monitored workers using a single MI transmitter and inertial measurement units with minimal setup effort. However, MI location estimates can be distorted and ambiguous. To solve this problem, we suggest a novel method to use MI devices for sensing environmental distortions, and use these to correctly close inertial loops. By applying robust simultaneous localisation and mapping (SLAM), our proposed localisation method achieves excellent tracking accuracy, and can improve performance significantly compared with only using an inertial measurement unit (IMU) and MI device for localisation.
keywords: {Transmitters;Robustness;Simultaneous localization and mapping;Magnetic resonance imaging;Distortion;Trajectory;Magneto-inductive device;Inertial measurements;Localisation;SLAM},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460804&isnumber=8460178

J. Zhang, M. Salehizadeh and E. Diller, "Parallel Pick and Place Using Two Independent Untethered Mobile Magnetic Microgrippers," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 123-128.
doi: 10.1109/ICRA.2018.8462861
Abstract: Untethered mobile microgrippers exhibit flexibility and agility in small and constrained environments as precise and accurate robotic end-effectors, with promising potential applications in cell manipulation and microassembly. Here, we propose the first scheme to independently and simultaneously position two microgrippers on a horizontal plane for parallel targeted cargo delivery using a single global input. The separation and orientation of the two-microgripper pair are modulated by the local magnetic interactions between the two microgrippers, which are governed by a global magnetic field. The microgripper action of grasping or releasing cargoes is fully controlled by the global magnetic field without requiring additional thermal, chemical, or other stimuli. Thus, the proposed strategy only requires a single input, i.e., a global magnetic field, to control two microgrippers and therefore is simple to implement and fast-acting. As a demonstration, two microgrippers are maneuvered by a global magnetic field to pick up two cargoes and deliver them to their respective destinations. The parallel operation of two microgrippers can potentially double the overall throughput and enable the tasks that require team cooperations. The two 3D microgrippers configuration is intuitive in teleoperations, since it imitates the two-hand case of human beings.
keywords: {Grippers;Magnetic separation;Barium;Magnetic hysteresis;Magnetoelasticity;Micromagnetics;Task analysis;magnetic microgripper;multi-agent control at microscales;soft robotics;targeted cargo delivery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462861&isnumber=8460178

J. Smits et al., "Development and Experimental Validation of a Combined FBG Force and OCT Distance Sensing Needle for Robot-Assisted Retinal Vein Cannulation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 129-134.
doi: 10.1109/ICRA.2018.8460983
Abstract: Retinal Vein Occlusion is a common retinal vascular disorder which can cause severe loss of vision. Retinal vein cannulation followed by injection of an anti-coagulant into the affected vein is a promising treatment. However, given the scale and fragility of the surgical workfield, this procedure is considered too high-risk to perform manually. A first successful robot-assisted procedure has been demonstrated. Even though successful, the procedure remains extremely challenging. This paper aims at providing a solution for the limited perception of instrument-tissue interaction forces as well as depth estimation during retinal vein cannulation. The development of a novel combined force and distance sensing cannulation needle relying on Fiber Bragg grating (FBG) and Optical Coherence Tomography (OCT) A-scan technology is reported. The design, the manufacturing process, the calibration method, and the experimental characterization of the produced sensor are discussed. The functionality of the combined sensing modalities and the real-time distance estimation algorithm are validated respectively on in-vitro and ex-vivo models.
keywords: {Retina;Robot sensing systems;Force;Needles;Instruments;Veins},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460983&isnumber=8460178

A. Mablekos-Alexiou, S. Ourselin, L. Da Cruz and C. Bergeles, "Requirements Based Design and End-to-End Dynamic Modeling of a Robotic Tool for Vitreoretinal Surgery," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 135-141.
doi: 10.1109/ICRA.2018.8460921
Abstract: Despite several robots having been proposed for vitreoretinal surgery, there is limited information on their dynamic modeling. This gap leads to sub-optimal motor selection and hinders the application of advanced control schemes that would fulfill the goal of micro-precise surgery. This paper presents the design process and a dynamics study of a multi-Degree of Freedom (DoF) robotic system, which is inspired by established co-manipulation architectures. A rigorous kinematics and dynamics analysis of the robot's part that is responsible for manipulating the surgical tool during the retinal surgery phase is provided. In particular, the Euler-Lagrange equations of motion, which describe the dynamics of the 3-link surgical manipulator, are combined with novel analytical models of each link's corresponding transmission mechanism, including an anti-backlash lead screw assembly and a worm drive. The resulting models, transferable to existing manipulators, provide a meticulous analysis of the robot's performance that can be used both for mechanical design and control purposes.
keywords: {Surgery;Manipulator dynamics;Tools;Mathematical model;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460921&isnumber=8460178

T. J. C. O. Vrielink, M. Zhao, A. Darzi and G. P. Mylonas, "ESD CYCLOPS: A New Robotic Surgical System for GI Surgery," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 150-157.
doi: 10.1109/ICRA.2018.8462698
Abstract: Gastrointestinal (GI) cancers account for 1.5 million deaths worldwide. Endoscopic Submucosal Dissection (ESD) is an advanced therapeutic endoscopy technique with superior clinical outcome due to the minimally invasive and en bloc removal of tumours. In the western world, ESD is seldom carried out, due to its complex and challenging nature. Various surgical systems are being developed to make this therapy accessible, however, these solutions have shown limited operational workspace, dexterity, or low force exertion capabilities. The current paper shows the ESD CYCLOPS system, a bimanual surgical robotic attachment that can be mounted at the end of any flexible endoscope. The system is able to achieve forces of up to 46N, and showed a mean error of 0.217mm during an elliptical tracing task. The workspace and instrument dexterity is shown by pre-clinical ex vivo trials, in which ESD is successfully performed by a GI surgeon. The system is currently undergoing pre-clinical in vivo validation.
keywords: {Instruments;Endoscopes;Electrostatic discharges;Surgery;Tendons;Robots;Cancer},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462698&isnumber=8460178

C. Zhang, W. Wang, N. Xi, Y. Wang and L. Liu, "Differentiation of C2C12 Myoblasts and Characterization of Electro-Responsive Beating Behavior of Myotubes Using Circularly Distributed Multiple Electrodes for Bio-Syncretic Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 158-163.
doi: 10.1109/ICRA.2018.8461225
Abstract: Micro-robots have a great application prospect in the biomedical field due to the feature of small size. To solve the issues of energy supply and bio-compatibility of micro-robots, bio-syncretic micro-robots composed of biological materials and electromechanical systems have been studied widely. The skeletal muscle is a potential material to develop bio-actuator for the bio-syncretic robots on account of the great contraction force and the controllability. However, the low differentiation quality of C2C12s and the control of the bio-syncretic robots are the two of the main challenges for the development of the bio-syncretic robots based on the skeleton muscle. In this paper, an approach based on circularly distributed multiple electrodes (CDMEs) was proposed to improve the differentiation of C2C12 myoblast cells and characterize the electro-responsive beating behavior of myotubes for the development of bio-syncretic robots. Three groups of C2C12 blasts were used to fulfill the differentiation experiments without electrical stimulation and with electrical stimulation using parallel electrodes and CDMEs respectively, for evaluating the effect of CDMEs on C2C12 differentiation. It was demonstrated that electrical field through CDMEs can improve the differentiation quality of C2C12 blasts into myotubes in terms of intensity, length, and widths. Then, the effect of electrical stimulation on the beating behaviors of myotubes was also investigated with CDMEs, and it was shown that the beating amplitudes of myotubes were significantly affected by the frequencies, amplitude and direction of electrical stimulation with respect to the myotubes, which is fundamental for the control of the micro-robot based on skeletal muscle cells. The proposed approach is useful for not only the development of the bio-syncretic robots, but also the study of muscle tissue engineering.
keywords: {Electrodes;Electrical stimulation;Muscles;Robots;Electric fields;Biological materials;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461225&isnumber=8460178

T. Matsuno, T. Shirakawa, T. Watanabe and M. Minami, "String Untying Planning Based on Knot Theory and Proposal of Algorithms to Generate the Motion of a Manipulator," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 180-186.
doi: 10.1109/ICRA.2018.8460477
Abstract: Recently, the demand to manipulate deformable objects such as a string and cloth by robots is growing. The reason is that it has the possibility of making our lives more convenient in many domains. The manipulation of deformable objects, however, is more difficult than that of rigid objects, because deformable objects have diversity of shape and behavior. Therefore, our research group has been focusing on the string shape operation. This paper describes planning method of string untying operation based on knot theory and algorithms to generate the motion of a manipulator. The novel contribution of our planning method is automatic selection of optimal shape operation based on cost function. At final, the results of string untying experiments are reported.
keywords: {Shape;Planning;Manipulators;Robot motion;Three-dimensional displays;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460477&isnumber=8460178

O. A. Araromi, S. Castellanos, C. J. Walsh and R. J. Wood, "Compliant Low Profile Multi-Axis Force Sensors," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 187-192.
doi: 10.1109/ICRA.2018.8460189
Abstract: The development of soft, compliant force sensors is greatly sought after in areas such as soft robotics and prosthetics. Nevertheless, solutions for measuring forces in multiple axes, while being mechanically compliant, have been few and far between. Here we present a compliant sensor able to detect forces tangential and normal to the sensor surface. The transduction mechanism is based on the deformation of laser-machined carbon fiber composite (CFC) micro-scale meanders, encapsulated within elastomers layers. Strains in the elastomer are transmitted to the meanders, causing changes in the electrical resistance of the sensor contact mechanics. Configuring the meanders in a radial pattern, segmenting them into quadrants (two antagonist pairs) and biasing the center of the sensor out-of-plane enables detection of forces in multiple axis via differential measurement. Sensors were manufactured using a custom fabrication process and exhibited high mechanical compliance with a very low form factor. The sensors were experimentally characterized and demonstrated large differential changes in resistance (up to 26 kΩ for tangential forces applied to the sensor surface). We integrated our sensor onto a soft robotic gripper finger and demonstrated the ability to detect changes in friction at the actuator surface, thus demonstrating their potential for real world applications.
keywords: {Robot sensing systems;Resistance;Fabrication;Geometry;Force sensors;Contacts;Carbon;Soft Material Robotics;Wearable Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460189&isnumber=8460178

A. Di Lallo, M. Catalano, M. Garabini, G. Grioli, M. Gabiccini and A. Bicchi, "A Novel Approach to Under-Actuated Control of Fluidic Systems," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 193-199.
doi: 10.1109/ICRA.2018.8460859
Abstract: Thanks to the growing interest in soft robotics, hydropneumatics and inflatable system dynamics are attracting renewed attention from the scientific community. Typical fluidic systems are composed of several chambers and require a complex and bulky network of active components for their control. This paper presents a novel approach to fluidic actuation, which consists in the co-design of both the mechanical parameters of the system and of custom input signals, to enable the elicitation of different behaviors of the system with fewer control components. The principle is presented in theory and simulation and then experimentally validated through the application to a case study, an in-pipe inchworm-like robot. It is shown that it is possible to obtain forward and backward movements by modulating a unique input.
keywords: {Robots;Pneumatic systems;Valves;Pistons;Damping;Task analysis;Inspection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460859&isnumber=8460178

F. S. Farimani and S. Misra, "Introducing PneuAct: Parametrically-Designed MRI-Compatible Pneumatic Stepper Actuator," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 200-205.
doi: 10.1109/ICRA.2018.8462697
Abstract: Pneumatic stepper motors are one of the promising alternative actuation methods for motion control in environments where electromagnetic (EM) motors cannot be used. Due to the lack of commercial off-the-shelf products, researchers working on MR compatible robotics have to develop their own pneumatic actuators. This imposes extensive costs and delays on the development process. Additionally, the current solutions are limited in their range of specifications and are difficult to manufacture. In this paper, proof-of-concept-prototypes for a family of parametrically designed, electromagnetically stealth, rotational pneumatic stepper motors are presented. The main objective of the paper is to demonstrate a general purpose non-electromagnetic actuation method, which can be customized and integrated into any design. Customizability, miniaturization, safety and affordability are some of the key features of the presented work. The developed prototypes are entirely 3D-printed and contain no sealing, bearing or lubrication. Thanks to the low production cost, the motor can be used as a disposable part in surgical applications. Experiments demonstrate effectiveness of the design in terms of cost-efficiency, versatility, MRI-compatibility, speed and performance. In order to optimize the design and control algorithm, empirical equations are presented describing response time of a pneumatic system to sequential pressure signals. A rotational speed of 800 rpm, total volume of 4.6 cm3 and resolution of 3° are some of the design attributes. The effects of clearance on stick-slip effect and leakage in a 3D printed cylinder-piston are also presented.
keywords: {Pistons;Synchronous motors;Electron tubes;Pneumatic systems;Force;Actuators;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462697&isnumber=8460178

C. Guan, W. Vega-Brown and N. Roy, "Efficient Planning for Near-Optimal Compliant Manipulation Leveraging Environmental Contact," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 215-222.
doi: 10.1109/ICRA.2018.8462696
Abstract: Path planning classically focuses on avoiding environmental contact. However, some assembly tasks permit contact through compliance, and such contact may allow for more efficient and reliable solutions under action uncertainty. But, optimal manipulation plans that leverage environmental contact are difficult to compute. Environmental contact produces complex kinematics that create difficulties for planning. This complexity is usually addressed by discretization over state and action space, but discretization quickly becomes computationally intractable. To overcome the challenge, we use the insight that only actions on configurations near the contact manifold are likely to involve complex kinematics, while segments of the plan through free space do not. Leveraging this structure can greatly reduce the number of states considered and scales much better with problem complexity. We develop an algorithm based on this idea and show that it performs comparably to full MDP solutions at a fraction of the computational cost.
keywords: {Aerospace electronics;Uncertainty;Kinematics;Mathematical model;Manifolds;Task analysis;Complexity theory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462696&isnumber=8460178

J. Huh, B. Lee and D. D. Lee, "Constrained Sampling-Based Planning for Grasping and Manipulation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 223-230.
doi: 10.1109/ICRA.2018.8461265
Abstract: This paper presents a novel constrained, sampling-based motion planning method for grasp and transport tasks with a redundant robotic manipulator. We utilize a planning margin for grasping with constraints that allow the best grasp configuration and approach direction to be determined automatically. For manipulators with many degrees of freedom, our method efficiently chooses the optimal grasp pose when there are many redundant solutions. The method also introduces a parameterized intermediate pose that is optimized to determine the approach direction, increasing robustness under sensor uncertainty and execution errors. Our method also considers transporting the grasped object to the desired target position using a Rapidly-exploring Random Tree (RRT) algorithm that incorporates soft constraints via appropriate cost penalties. We demonstrate the effectiveness and efficiency of our algorithms on a number of simulated and experimental applications. Our experimental results show a marked improvement in computational efficiency in comparison to previously studied approaches.
keywords: {Planning;Grasping;Task analysis;Manipulators;Jacobian matrices;Robustness;Manifolds},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461265&isnumber=8460178

B. Sundaralingam and T. Hermans, "Geometric In-Hand Regrasp Planning: Alternating Optimization of Finger Gaits and In-Grasp Manipulation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 231-238.
doi: 10.1109/ICRA.2018.8460496
Abstract: This paper explores the problem of autonomous, in-hand regrasping-the problem of moving from an initial grasp on an object to a desired grasp using the dexterity of a robot's fingers. We propose a planner for this problem which alternates between finger gaiting, and in-grasp manipulation. Finger gaiting enables the robot to move a single finger to a new contact location on the object, while the remaining fingers stably hold the object. In-grasp manipulation moves the object to a new pose relative to the robot's palm, while maintaining the contact locations between the hand and object. Given the object's geometry (as a mesh), the hand's kinematic structure, and the initial and desired grasps, we plan a sequence of finger gaits and object reposing actions to reach the desired grasp without dropping the object. We propose an optimization based approach and report in-hand regrasping plans for 5 objects over 5 in-hand regrasp goals each. The plans generated by our planner are collision free and guarantee kinematic feasibility.
keywords: {Planning;Robots;Optimization;Task analysis;Thumb;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460496&isnumber=8460178

B. Jia, Z. Hu, J. Pan and D. Manocha, "Manipulating Highly Deformable Materials Using a Visual Feedback Dictionary," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 239-246.
doi: 10.1109/ICRA.2018.8461264
Abstract: The complex physical properties of highly deformable materials such as clothes pose significant challenges for autonomous robotic manipulation systems. We present a novel visual feedback dictionary-based method for manipulating deformable objects towards a desired configuration. Our approach is based on visual servoing and we use an efficient technique to extract key features from the RGB sensor stream in the form of a histogram of deformable model features. These histogram features serve as high-level representations of the state of the deformable material. Next, we collect manipulation data and use a visual feedback dictionary that maps the velocity in the high-dimensional feature space to the velocity of the robotic end-effectors for manipulation. We have evaluated our approach on a set of complex manipulation tasks and human-robot manipulation tasks on different cloth pieces with varying material characteristics.
keywords: {Visualization;Dictionaries;Feature extraction;Task analysis;Visual servoing;Deformable models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461264&isnumber=8460178

F. R. Hogan, E. R. Grau and A. Rodriguez, "Reactive Planar Manipulation with Convex Hybrid MPC," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 247-253.
doi: 10.1109/ICRA.2018.8461175
Abstract: This paper presents a reactive controller for planar manipulation tasks that leverages machine learning to achieve real-time performance. The approach is based on a Model Predictive Control (MPC) formulation, where the goal is to find an optimal sequence of robot motions to achieve a desired object motion. Due to the multiple contact modes associated with frictional interactions, the resulting optimization program suffers from combinatorial complexity when tasked with determining the optimal sequence of modes. To overcome this difficulty, we formulate the search for the optimal mode sequences offline, separately from the search for optimal control inputs online. Using tools from machine learning, this leads to a convex hybrid MPC program that can be solved in real-time. We validate our algorithm on a planar manipulation experimental setup where results show that the convex hybrid MPC formulation with learned modes achieves good closed-loop performance on a trajectory tracking problem.
keywords: {Task analysis;Force;Schedules;Friction;Predictive control;Manipulators;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461175&isnumber=8460178

N. Chavan-Dafle and A. Rodriguez, "Stable Prehensile Pushing: In-Hand Manipulation with Alternating Sticking Contacts," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 254-261.
doi: 10.1109/ICRA.2018.8461243
Abstract: This paper presents an approach to in-hand manipulation planning that exploits the mechanics of alternating sticking contact. Particularly, we consider the problem of manipulating a grasped object using external pushes for which the pusher sticks to the object. Given the physical properties of the object, frictional coefficients at contacts and a desired regrasp on the object, we propose a sampling-based planning framework that builds a pushing strategy concatenating different feasible stable pushes to achieve the desired regrasp. An efficient dynamics formulation allows us to plan in-hand manipulations 100-1000 times faster than our previous work which builds upon a complementarity formulation. Experimental observations for the generated plans show that the object precisely moves in the grasp as expected by the planner.
keywords: {Planning;Dynamics;Grippers;Friction;Robots;Geometry;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461243&isnumber=8460178

W. Yuan, J. A. Stork, D. Kragic, M. Y. Wang and K. Hang, "Rearrangement with Nonprehensile Manipulation Using Deep Reinforcement Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 270-277.
doi: 10.1109/ICRA.2018.8462863
Abstract: Rearranging objects on a tabletop surface by means of nonprehensile manipulation is a task which requires skillful interaction with the physical world. Usually, this is achieved by precisely modeling physical properties of the objects, robot, and the environment for explicit planning. In contrast, as explicitly modeling the physical environment is not always feasible and involves various uncertainties, we learn a nonprehensile rearrangement strategy with deep reinforcement learning based on only visual feedback. For this, we model the task with rewards and train a deep Q-network. Our potential field-based heuristic exploration strategy reduces the amount of collisions which lead to suboptimal outcomes and we actively balance the training set to avoid bias towards poor examples. Our training process leads to quicker learning and better performance on the task as compared to uniform exploration and standard experience replay. We demonstrate empirical evidence from simulation that our method leads to a success rate of 85%, show that our system can cope with sudden changes of the environment, and compare our performance with human level performance.
keywords: {Planning;Task analysis;Robots;Tools;Cameras;Visualization;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462863&isnumber=8460178

P. Culbertson and M. Schwager, "Decentralized Adaptive Control for Collaborative Manipulation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 278-285.
doi: 10.1109/ICRA.2018.8461263
Abstract: This paper presents a design for a decentralized adaptive controller that allows a team of agents to manipulate a common payload in $\mathbb{R}^{2}$ or $\mathbb{R}^{3}$. The controller requires no communication between agents and requires no a priori knowledge of agent positions or payload properties. The agents can control the payload to track a reference trajectory in linear and angular velocity with center-of-mass measurements, in angular velocity using only local measurements and a common frame, and can stabilize its rotation with only local measurements. The controller is designed via a Lyapunov-style analysis and has proven stability and convergence. The controller is validated in simulation and experimentally with four robots manipulating an object in the plane.
keywords: {Payloads;Robots;Collaboration;Angular velocity;Velocity measurement;Task analysis;Stability analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461263&isnumber=8460178

P. R. Giordano, Q. Delamare and A. Franchi, "Trajectory Generation for Minimum Closed-Loop State Sensitivity," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 286-293.
doi: 10.1109/ICRA.2018.8460546
Abstract: In this paper we propose a novel general method to let a dynamical system fulfil at best a control task when the nominal parameters are not perfectly known. The approach is based on the introduction of the novel concept of closed-loop sensitivity, a quantity that relates parameter variations to deviations of the closed-loop trajectory of the system/controller pair. This new definition takes into account the dependency of the control inputs from the system states and nominal parameters as well as from the controller dynamics. The reference trajectory to be tracked is taken as optimization variable, and the dynamics of both the sensitivity and of its gradient are computed analytically along the system trajectories. We then show how this computation can be effectively exploited for solving trajectory optimization problems aimed at generating a reference trajectory that minimizes a norm of the closed-loop sensitivity. The theoretical results are validated via an extensive campaign of Monte Carlo simulations for two relevant robotic systems: a unicycle and a quadrotor UAV.
keywords: {Trajectory;Sensitivity;Task analysis;Optimization;Uncertainty;Robots;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460546&isnumber=8460178

N. Dehio et al., "Modeling and Control of Multi-Arm and Multi-Leg Robots: Compensating for Object Dynamics During Grasping," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 294-301.
doi: 10.1109/ICRA.2018.8462872
Abstract: We consider a virtual manipulator in grasping scenarios which allows us to capture the effect of the object dynamics. This modeling approach turns a multi-arm robot into an underactuated system. We observe that controlling floating-base multi-leg robots is fundamentally similar. The Projected Inverse Dynamics Control approach is employed for decoupling contact consistent motion generation and controlling contact wrenches. The proposed framework for underactuated robots has been evaluated on an enormous robot hand composed of four KUKA LWR IV+ representing fingers cooperatively manipulating a 9kg box with total 28 actuated DOF and six virtual DOF representing the object as additional free-floating robot link. Finally, we validate the same approach on ANYmal, a floating-base quadruped with 12 actuated DOF. Experiments are performed both in simulation and real world.
keywords: {Grasping;Dynamics;Task analysis;Jacobian matrices;Manipulator dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462872&isnumber=8460178

E. M. Hoffman, A. Laurenzi, L. Muratore, N. G. Tsagarakis and D. G. Caldwell, "Multi-Priority Cartesian Impedance Control Based on Quadratic Programming Optimization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 309-315.
doi: 10.1109/ICRA.2018.8462877
Abstract: In this work we introduced a prioritized Cartesian impedance control under the framework of the Quadratic Programming (QP) optimization. In particular, we present a formulation which is simpler than full inverse dynamics, avoids any matrix pseudo-inversion, inverse kinematics computation and considers strict priorities among tasks. Our formulation is based on QP optimization permitting to take into account also explicit inequality constraints. We compare in simulation the tracking results obtained with a classical algebraic implementation against those derived from the proposed QP implementation taking into account joint torque limits. We consider the classical Cartesian impedance controller and a simplified version, also known as Virtual Model Control. Finally the proposed method was implemented and validated on a humanoid upper-body torque controlled robot. Experimental trials involving various physical interaction conditions were executed to demonstrate the performance of the proposed method.
keywords: {Task analysis;Impedance;Robots;Force;Torque;Optimization;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462877&isnumber=8460178

F. Beuke, S. Alatartsev, S. Jessen and A. Verl, "Responsive and Reactive Dual-Arm Robot Coordination," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 316-322.
doi: 10.1109/ICRA.2018.8462868
Abstract: The need for temporal and spatial coordination of two robot arms moving independently in a shared workspace frequently arises in industrial and service-oriented robotics alike. Today, this problem is often solved manually, leading to a negative impact on user experience as well as on execution performance. In this paper, we present an algorithm that is able to automatically coordinate independently planned motions of a dual-arm manipulator during execution. In addition, the algorithm is capable of refining the plan upon receiving new motion commands during the robot motion. We demonstrate the effectiveness and efficiency of the proposed approach on an ABB YuMi robot working on an industrial palletizing task.
keywords: {Robot kinematics;Trajectory;Collision avoidance;Task analysis;Service robots;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462868&isnumber=8460178

A. Zwiener, C. Geckeler and A. Zell, "Contact Point Localization for Articulated Manipulators with Proprioceptive Sensors and Machine Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 323-329.
doi: 10.1109/ICRA.2018.8462869
Abstract: A model-based Machine Learning (ML) approach is presented to detect and localize external contacts on a 6 degree of freedom (DoF) serial manipulator. This approach only requires the use of proprioceptive sensors (joint positions, velocities and one-dimensional (ID) joint torques already available in the robot arm). Good results are obtained with Random Forests (RFs) and Multi-Layer-Perceptrons (MLPs) leading to a precise localization of the contact link and its orientation. Apart from the link in contact and the orientation of the force, RFs and MLPs are also able to differentiate between contact points on the same link and orientation but with different distances to the joint axis. We experimentally verify this approach on simulated and real data obtained from the Kinova Jaco 2 manipulator and compare it to an optimization based approach.
keywords: {Force;Torque;Three-dimensional displays;Robot sensing systems;Manipulator dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462869&isnumber=8460178

J. H. Kim, S. -m. Hur and Y. Oh, "$L_{1}$ Robustness of Computed Torque Method for Robot Manipulators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 330-335.
doi: 10.1109/ICRA.2018.8461170
Abstract: This paper revisits computed torque method for robot manipulators and aims at developing its new framework based on the L1 robustness, in which the L∞ norm together with its induced norm is employed to characterize model uncertainties and a performance measure. More precisely, we consider the L1 robust stability and performance for a given robot manipulator with a computed torque controller. We first show that the modelling errors in the computed torque method can be divided into an exogenous disturbance and a multiplicative model uncertainty, which are bounded in terms of the L∞ norm and its induced norm, respectively. It is next shown that the robot manipulator with the computed torque controller can be equivalently represented by an interconnection of a continuous-time linear time-invariant (LTI) nominal plant and a stabilizing controller together with the L∞-induced norm bounded model uncertainty. Based on the interconnected representation, the L1 robust stability condition and an upper bound of the L1 performance against the exogenous disturbance with respect to all model uncertainties in a class of a bounded L∞-induced norm are dealt with by using the small-gain theorem. Finally, the effectiveness of the theoretical results is demonstrated through some experiment results.
keywords: {Torque;Manipulator dynamics;Computational modeling;Uncertainty;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461170&isnumber=8460178

F. Gao, W. Wu, Y. Lin and S. Shen, "Online Safe Trajectory Generation for Quadrotors Using Fast Marching Method and Bernstein Basis Polynomial," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 344-351.
doi: 10.1109/ICRA.2018.8462878
Abstract: In this paper, we propose a framework for online quadrotor motion planning for autonomous navigation in unknown environments. Based on the onboard state estimation and environment perception, we adopt a fast marching-based path searching method to find a path on a velocity field induced by the Euclidean signed distance field (ESDF) of the map, to achieve better time allocation. We generate a flight corridor for the quadrotor to travel through by inflating the path against the environment. We represent the trajectory as piecewise Bézier curves by using Bernstein polynomial basis and formulate the trajectory generation problem as typical convex programs. By using Bézier curves, we are able to bound positions and higher order dynamics of the trajectory entirely within safe regions. The proposed motion planning method is integrated into a customized light-weight quadrotor platform and is validated by presenting fully autonomous navigation in unknown cluttered indoor and outdoor environments. We also release our code for trajectory generation as an open-source package.
keywords: {Resource management;Planning;Trajectory optimization;Safety;Autonomous robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462878&isnumber=8460178

M. Wei and V. Isler, "Coverage Path Planning Under the Energy Constraint," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 368-373.
doi: 10.1109/ICRA.2018.8462867
Abstract: In the coverage path planning problem, a common assumption is that the robot can fully cover the environment without recharging. However, in reality most mobile robot systems operate under battery limitations. To incorporate this constraint, we consider the problem when the working environment is large and the robot needs to recharge multiple times to fully cover the environment. We focus on a geometric version where the environment is represented as a polygonal grid with a single charging station. Energy consumption throughout the environment is assumed to be uniform and proportional to the distance traveled. We first present a constant-factor approximation algorithm for contour-connected environments. We then extend the algorithm for general environments. We also validate the results in experiments performed with an aerial robot.
keywords: {Robots;Charging stations;Approximation algorithms;Path planning;Batteries;Partitioning algorithms;Energy consumption},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462867&isnumber=8460178

P. Váňa, J. Sláma and J. Faigl, "The Dubins Traveling Salesman Problem with Neighborhoods in the Three-Dimensional Space," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 374-379.
doi: 10.1109/ICRA.2018.8460957
Abstract: We introduce an extension of the Dubins Traveling Salesman Problem with Neighborhoods into the 3D space in which a fixed-wing aerial vehicle is requested to visit a set of target regions while the vehicle motion constraints are satisfied, i.e., the minimum turning radius and maximum climb and dive angles. The primary challenge is to address both the combinatorial optimization part of finding the sequence of target visits and the continuous optimization part of the final trajectory determination. Due to its high complexity, we propose to address both parts of the problem separately by a decoupled approach in which the sequence is determined by a new distance function designed explicitly for the utilized 3D Dubins Airplane model. The final trajectory is then found by a local optimization which improves the solution quality. The proposed approach provides significantly better solutions than using Euclidean distance in the sequencing part of the problem. Moreover, the found solutions are of the competitive quality to the sampling-based algorithm while its computational requirements are about two orders of magnitude lower.
keywords: {Three-dimensional displays;Trajectory;Atmospheric modeling;Airplanes;Solid modeling;Two dimensional displays;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460957&isnumber=8460178

D. Balkcom, A. Furtuna and W. Wang, "The Dubins Car and Other Arm-Like Mobile Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 380-386.
doi: 10.1109/ICRA.2018.8461017
Abstract: This paper investigates the connection between the kinematics of robots arms and the shortest paths for mobile robots. Lagrange multipliers are used to show that the shortest paths are equivalent to arms in configurations that balance an external force, while applying equal torques and forces at each joint. Analysis of the arm Jacobian yields a further geometric interpretations of optimal paths, constraining the locations of rotation centers and the directions of translations that may occur along optimal paths.
keywords: {Kinematics;Mobile robots;Trajectory;Automobiles;Manipulators;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461017&isnumber=8460178

D. Fridovich-Keil, S. L. Herbert, J. F. Fisac, S. Deglurkar and C. J. Tomlin, "Planning, Fast and Slow: A Framework for Adaptive Real-Time Safe Trajectory Planning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 387-394.
doi: 10.1109/ICRA.2018.8460863
Abstract: Motion planning is an extremely well-studied problem in the robotics community, yet existing work largely falls into one of two categories: computationally efficient but with few if any safety guarantees, or able to give stronger guarantees but at high computational cost. This work builds on a recent development called FaSTrack in which a slow offline computation provides a modular safety guarantee for a faster online planner. We introduce the notion of “meta-planning” in which a refined offline computation enables safe switching between different online planners. This provides autonomous systems with the ability to adapt motion plans to a priori unknown environments in real-time as sensor measurements detect new obstacles, and the flexibility to maneuver differently in the presence of obstacles than they would in free space, all while maintaining a strict safety guarantee. We demonstrate the meta-planning algorithm both in simulation and in hardware using a small Crazyflie 2.0 quadrotor.
keywords: {Planning;Trajectory;Safety;Real-time systems;Robustness;Navigation;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460863&isnumber=8460178

Y. Lee and J. Park, "Reactive Bipedal Walking Method for Torque Controlled Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 395-402.
doi: 10.1109/ICRA.2018.8460668
Abstract: Reactivity to unexpected situations is one of the most important characteristics of walking for real world applications. In this study, we introduce a reactive biped robot walking method that reflects only the current state of the robot. Therefore, time plan and trajectory tracking control are not required for robot walking, and this enables reactive behavior to unexpected contact or disturbance. The walking algorithm is realized through a whole-body control algorithm based on the operational space control framework, that possesses the capability to command the required force for tasks and also implement compliant task behavior by adjusting corresponding task gains. The performance of the proposed method is verified by experiments with a 12-DoF torque controlled biped robot. Robust walking is demonstrated when the foot is stopped by an unexpected obstacle or when the lateral motion is unexpectedly blocked and released by a human.
keywords: {Legged locomotion;Foot;Acceleration;Trajectory tracking;Humanoid robots;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460668&isnumber=8460178

M. Kim, J. H. Kim, S. Kim, J. Sim and J. Park, "Disturbance Observer Based Linear Feedback Controller for Compliant Motion of Humanoid Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 403-410.
doi: 10.1109/ICRA.2018.8460618
Abstract: Actuator modules of humanoid robots have relatively higher joint elasticity than those of industrial robots. Such joint elasticity could lead to negative effects on both the tracking performance and stability for walking. Especially, unstable contact between the foot and ground caused by joint elasticity is a critical problem, as it decreases the stability of position-controlled humanoid robots. To address this problem, this paper introduces a novel control scheme for position-controlled humanoid robots by which we can obtain not only enhance compliance capability for unknown contact but also suppress the vibration caused by joint elasticity. To estimate the disturbance caused by external forces and modeling errors between the actual system and nominal system, a disturbance observer based estimator is designed at each joint. Furthermore, a linear feedback controller for the flexible joint model and a gravity compensator is considered to reduce vibration and deflection due to the joint elasticity. The proposed control scheme was implemented on our humanoid robot, DYROS-JET, and its performance was demonstrated by improved stability during dynamic walking and stepping on objects.
keywords: {Elasticity;Legged locomotion;Humanoid robots;Gravity;Vibrations;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460618&isnumber=8460178

N. Rotella, S. Schaal and L. Righetti, "Unsupervised Contact Learning for Humanoid Estimation and Control," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 411-417.
doi: 10.1109/ICRA.2018.8462864
Abstract: This work presents a method for contact state estimation using fuzzy clustering to learn contact probability for full, six-dimensional humanoid contacts. The data required for training is solely from proprioceptive sensors - endeffector contact wrench sensors and inertial measurement units (IMUs) - and the method is completely unsupervised. The resulting cluster means are used to efficiently compute the probability of contact in each of the six endeffector degrees of freedom (DoFs) independently. This clustering-based contact probability estimator is validated in a kinematics-based base state estimator in a simulation environment with realistic added sensor noise for locomotion over rough, low-friction terrain on which the robot is subject to foot slip and rotation. The proposed base state estimator which utilizes these six DoF contact probability estimates is shown to perform considerably better than that which determines kinematic contact constraints purely based on measured normal force.
keywords: {Friction;Sensors;Force;Foot;State estimation;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462864&isnumber=8460178

F. Fan and I. R. Manchester, "Robust Control of Dynamic Walking Robots Using Transverse H∞," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 418-425.
doi: 10.1109/ICRA.2018.8460744
Abstract: The control of walking robots has been a long-studied problem as researchers attempt to bring robots out of the lab and into unstructured environments. In particular, there is significant interest in dynamic walkers: a class of walking robots that exhibit highly efficient gaits, but are sensitive to disturbances. This paper develops robust controllers for dynamic walkers in transverse coordinates using H∞ control, with a focus on rejecting disturbances at foot impact. The optimization objective is a measure of disturbance rejection known as the gait sensitivity norm. The controller was used to stabilise a compass gait walker in simulation for various disturbances. Simulation results demonstrate the advantages of phase-tracking and H∞ control for robustness compared to time-varying and LQR controllers.
keywords: {Legged locomotion;Robot kinematics;Robustness;Sensitivity;Robot sensing systems;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460744&isnumber=8460178

A. Blom and A. Patel, "Investigation of a Bipedal Platform for Rapid Acceleration and Braking Manoeuvres," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 426-432.
doi: 10.1109/ICRA.2018.8462879
Abstract: Rapid acceleration manoeuvres have been avoided by researchers due to the aperiodicity and complexities of this motion. With the recent improvements in optimal control, this paper presents the first examination of a biped completing a time optimal sprint, starting and ending in rest, to provide insight for parameter choices of a robotic platform. In particular, a realistic linkage morphology is used with the limitation of a pre-specified actuator to choose the nominal leg length and gear ratio. Due to the size of the optimisation problem, a brute force approach is used rather than including these parameters as free variables. The results provided unique motion trajectories for time optimal behaviour with the models reaching near steady state motion and performing manoeuvres that are seen in a biped's biological counterpart. We then show that access to a higher mass-specific force does not improve the rapid acceleration manoeuvres, rather the friction coefficient and keeping the feet near the ground act as the limiting factor given sufficiently powerful actuators. A parabolic relationship emerged for sprint time versus linkage lengths providing valuable insight into the parameters to use for the platform design. To the authors knowledge, no prior research has focused on rapid acceleration and braking manoeuvres of a biped in one optimisation problem, let alone providing insight for the physical bipedal robotic platform.
keywords: {Legged locomotion;Couplings;Mathematical model;Actuators;Acceleration;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462879&isnumber=8460178

W. Hu, I. Chatzinikolaidis, K. Yuan and Z. Li, "Comparison Study of Nonlinear Optimization of Step Durations and Foot Placement for Dynamic Walking," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 433-439.
doi: 10.1109/ICRA.2018.8461101
Abstract: This paper studies bipedal locomotion as a nonlinear optimization problem based on continuous and discrete dynamics, by simultaneously optimizing the remaining step duration, the next step duration and the foot location to achieve robustness. The linear inverted pendulum as the motion model captures the center of mass dynamics and its low-dimensionality makes the problem more tractable. We first formulate a holistic approach to search for optimality in the three-dimensional parametric space and use these results as baseline. To further improve computational efficiency, our study investigates a sequential approach with two stages of customized optimization that first optimizes the current step duration, and subsequently the duration and location of the next step. The effectiveness of both approaches is successfully demonstrated in simulation by applying different perturbations. The comparison study shows that these two approaches find mostly the same optimal solutions, but the latter requires considerably less computational time, which suggests that the proposed sequential approach is well suited for real-time implementation with a minor trade-off in optimality.
keywords: {Optimization;Foot;Legged locomotion;Robustness;Lips;Dynamics;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461101&isnumber=8460178

J. Englsberger, G. Mesesan, A. Werner and C. Ott, "Torque-Based Dynamic Walking - A Long Way from Simulation to Experiment," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 440-447.
doi: 10.1109/ICRA.2018.8462862
Abstract: This paper presents methods that facilitate the implementation of dynamic walking on torque-controlled robots in real world experiments. The work uses the Divergent Component of Motion (DCM) for walking trajectory generation and control. The DCM controller is embedded into a whole-body controller (WBC) that produces a full-body walking behavior. While in simulation the combination of DCM and WBC is sufficient for achieving sophisticated walking gaits, during our initial experiments several real-world issues, detailed in this paper, prevented the original control framework from functioning. This work presents the improvements to the original control framework that enabled a breakthrough on the way to achieving torque-based dynamic walking on a real robot.
keywords: {Legged locomotion;Task analysis;Foot;Trajectory;Force;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462862&isnumber=8460178

R. Subburaman, J. Lee, D. G. Caldwell and N. G. Tsagarakis, "Online Falling-Over Control of Humanoids Exploiting Energy Shaping and Distribution Methods," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 448-454.
doi: 10.1109/ICRA.2018.8462880
Abstract: This paper proposes a novel fall control technique based on energy concepts, which can be applied online to mitigate the impact forces incurred during the falling over of humanoids. The technique reduces the total energy using a nonlinear control tool, called energy shaping (ES), and further distributes the reduced energy over multiple contacts by means of energy distribution polygons (EDP). We also include an effective orientation control to safeguard the end-effectors in the event of ground impacts. The performance of the proposed method is numerically evaluated by dynamic simulations under the sudden falling over scenario of the humanoid robot for both lateral and sagittal falls. The effectiveness of the proposed ES and EDP concepts are verified by diverse comparative simulations with total energy, distribution, and impact forces.
keywords: {Force;Numerical models;Energy conversion;Robot kinematics;Position control;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462880&isnumber=8460178

M. Karpelson, R. Peña and R. J. Wood, "Low-Cost Electromechanical Actuator Arrays for Tactile Display Applications," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 471-476.
doi: 10.1109/ICRA.2018.8460909
Abstract: Dynamic tactile displays represent a class of haptic devices of particular interest to the blind and visually impaired. Despite many years of research and development efforts, the low-cost, low-power, compact tactile display remains elusive. This paper describes a low-cost electromechanical actuator array based on low-force, low-displacement bistable actuators that can be realized using inexpensive, commercially available components and high-volume manufacturing processes. The array is applicable to several types of tactile displays; as an initial proof of concept, we demonstrate a 6-dot Braille cell with a 3mm pitch that requires less than 50mJ per actuator per transition.
keywords: {Actuators;Force;Ball bearings;Inductors;Magnetic levitation;Prototypes;Magnetic flux;haptics;tactile display;actuator array;low cost;Braille;visually impaired;assistive device},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460909&isnumber=8460178

L. Roche and L. Saint-Bauzel, "High Stiffness in Teleoperated Comanipulation: Necessity or Luxury?," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 477-483.
doi: 10.1109/ICRA.2018.8461005
Abstract: The present paper investigates if and in which conditions does the implementation of high stiffness controllers increase the performances of human dyads during comanipulative tasks in physical Human-Human Interaction (pHHI) settings. Two experiments are conducted which cover two fundamental aspects of pHHI: low-level interactions allowing interpersonal coordination, and high-level interactions allowing common decision-making and negotiation of strategies. The results of these experiments show that high stiffness is not necessary for good performances when the task only requires low-level interactions. On the contrary, when dealing with high-level interactions, higher stiffness increases task performance. The results presented highlight the importance of the quality of teleoperated control in setups used for the study of pHHI.
keywords: {Task analysis;Force;Haptic interfaces;Visualization;Impedance;Measurement;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461005&isnumber=8460178

J. M. Suchoski, S. Martinez and A. M. Okamura, "Scaling Inertial Forces to Alter Weight Perception in Virtual Reality," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 484-489.
doi: 10.1109/ICRA.2018.8462874
Abstract: As the field of haptics in virtual reality expands, wearable devices are being explored as alternatives to traditional kinesthetic force feedback devices, which are often limited in workspace. Skin deformation feedback offers a user-grounded feedback modality that mimics cutaneous interactions with the real world but can suffer from force-output saturation due to the actuation constraints required to achieve a small form factor. Saturation of haptic devices limits the mechanical properties and interactions that can be rendered in a virtual environment, specifically the weight that can be rendered when a user manipulates a virtual object. We use scaled inertial forces to alter virtual weight perception during a dynamic grasp-lift-and-place task in a virtual environment with haptic feedback via two wearable skin deformation feedback devices. A study was conducted, beginning with an open response exercise to assess how participants interpreted scaled inertial forces when interacting with virtual blocks. Participants then performed a series of trials to measure the Point of Subjective Equality of virtual weight with scaled inertial forces, using a reference of 200 g under the normal (no scaling) condition. PSEs for inertial scaling factors of 2 and 3 were 171 g and 151 g, respectively. These results demonstrate the effectiveness of a unique haptic rendering algorithm that can convey larger weights without saturating the force output of the haptic device.
keywords: {Skin;Haptic interfaces;Strain;Force;Virtual environments;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462874&isnumber=8460178

Z. A. Zook, A. M. Okamura and Y. Kamikawa, "Effects of Latency and Refresh Rate on Force Perception via Sensory Substitution by Force-Controlled Skin Deformation Feedback," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 506-511.
doi: 10.1109/ICRA.2018.8462883
Abstract: Latency and refresh rate are known to adversely affect human force perception in bilateral teleoperators and virtual environments using kinesthetic force feedback, motivating the use of sensory substitution of force. The purpose of this study is to quantify the effects of latency and refresh rate on force perception using sensory substitution by skin deformation feedback. A force-controlled skin deformation feedback device was attached to a 3-degree-of-freedom kinesthetic force feedback device used for position tracking and gravity support. A human participant study was conducted to determine the effects of latency and refresh rate on perceived stiffness and damping with skin deformation feedback. Participants compared two virtual objects: a comparison object with stiffness or damping that could be tuned by the participant, and a reference object with either added latency or reduced refresh rate. Participants modified the stiffness or damping of the tunable object until it resembled the stiffness or damping of the reference object. We found that added latency and reduced refresh rate both increased perceived stiffness but had no effect on perceived damping. Specifically, participants felt significantly different stiffness when the latency exceeded 300 ms and the refresh rate dropped below 16.6 Hz. The impact of latency and refresh rate on force perception via skin deformation feedback was significantly less than what has been previously shown for kinesthetic force feedback.
keywords: {Skin;Strain;Force;Force feedback;Damping;Delay effects},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462883&isnumber=8460178

M. Beetz, D. Beßler, A. Haidu, M. Pomarlan, A. K. Bozcuoğlu and G. Bartels, "Know Rob 2.0 — A 2nd Generation Knowledge Processing Framework for Cognition-Enabled Robotic Agents," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 512-519.
doi: 10.1109/ICRA.2018.8460964
Abstract: In this paper we present KnowRob2, a second generation knowledge representation and reasoning framework for robotic agents. KnowRob2 is an extension and partial redesign of KnowRob, currently one of the most advanced knowledge processing systems for robots that has enabled them to successfully perform complex manipulation tasks such as making pizza, conducting chemical experiments, and setting tables. The knowledge base appears to be a conventional first-order time interval logic knowledge base, but it exists to a large part only virtually: many logical expressions are constructed on demand from data structures of the control program, computed through robotics algorithms including ones for motion planning and solving inverse kinematics problems, and log data stored in noSQL databases. Novel features and extensions of KnowRob2 substantially increase the capabilities of robotic agents of acquiring open-ended manipulation skills and competence, reasoning about how to perform manipulation actions more realistically, and acquiring commonsense knowledge.
keywords: {Robots;Cognition;Data structures;Ontologies;Task analysis;Knowledge based systems;Physics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460964&isnumber=8460178

L. Halt, F. Nagele, P. Tenbrock and A. Pott, "Intuitive Constraint-Based Robot Programming for Robotic Assembly Tasks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 520-526.
doi: 10.1109/ICRA.2018.8462882
Abstract: Recent intuitive robot programming approaches operate on task level, enabling programmers to intuitively arrange or compose encapsulating robot capabilities (skills). This paper presents an approach to intuitively create (sub-)skills. General guidelines for assembly process descriptions #2860 provided by the Association of German Engineers VDI are applied to robot programming, in particular addressing assembly applications. The guidelines are exemplarily applied to the constraint-based approach iTaSC (instantaneous Task Specification using Constraints), presenting a procedure to hierarchically combine elementary processes to (sub-)skills. Six elementary processes are identified to be sufficient to implement a wide variety of assembly tasks. An iTaSC implementation was developed and two exemplarily assembly tasks were realized to evaluate the approach.
keywords: {Task analysis;Robot sensing systems;Robot programming;Guidelines;Robotic assembly},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462882&isnumber=8460178

A. Munawar et al., "MaestROB: A Robotics Framework for Integrated Orchestration of Low-Level Control and High-Level Reasoning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 527-534.
doi: 10.1109/ICRA.2018.8462870
Abstract: This paper describes a framework called MaestROBe It is designed to make the robots perform complex tasks with high precision by simple high-level instructions given by natural language or demonstration. To realize this, it handles a hierarchical structure by using the knowledge stored in the forms of ontology and rules for bridging among different levels of instructions. Accordingly, the framework has multiple layers of processing components; perception and actuation control at the low level, symbolic planner and Watson APIs for cognitive capabilities and semantic understanding, and orchestration of these components by a new open source robot middleware called Project Intu at its core. We show how this framework can be used in a complex scenario where multiple actors (human, a communication robot, and an industrial robot) collaborate to perform a common industrial task. Human teaches an assembly task to Pepper (a humanoid robot from SoftBank Robotics) using natural language conversation and demonstration. Our framework helps Pepper perceive the human demonstration and generate a sequence of actions for UR5 (collaborative robot arm from Universal Robots), which ultimately performs the assembly (e.g. insertion) task.
keywords: {Task analysis;Service robots;Natural languages;Robot kinematics;Middleware;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462870&isnumber=8460178

J. A. Castano, P. Kryczka, B. Delhaisse, C. Zhou and N. G. Tsagarakis, "Ctrl-MORE: A Framework to Integrate Controllers of Multi-DoF Robot for Developers and Users," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 543-549.
doi: 10.1109/ICRA.2018.8460947
Abstract: In recent years, many different feedback controllers for robotic applications have been proposed and implemented. However, the high coupling between the different software modules made their integration into one common architecture difficult. Consequently, this has hindered the ability of a user to employ the different controllers into a single, general and modular framework. To address this problem, we present Ctrl-MORE, a software architecture developed to fill the gap between control developers and other users in robotic applications. On one hand, Ctrl-MORE aims to provide developers with an opportunity to integrate easily and share their controllers with other roboticists working in different areas. For example, manipulation, locomotion, vision and so on. On the other hand, it provides to end-users a tool to apply the additional control strategies that guarantee the execution of desired behaviors in a transparent, yet efficient way. The proposed control architecture allows an easier integration of general purpose feedback controllers, such as stabilizers, with higher control layers such as trajectory planners, increasing the robustness of the overall system.
keywords: {Robots;Documentation;Software;Task analysis;Computer architecture;Hardware;Tools},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460947&isnumber=8460178

F. Fei et al., "Cross-Layer Retrofitting of UAVs Against Cyber-Physical Attacks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 550-557.
doi: 10.1109/ICRA.2018.8462886
Abstract: As a rapidly growing cyber-physical platform, unmanned aerial vehicles are facing more security threats as their capabilities and applications continue to expand. Adversaries with detailed knowledge about the vehicle could orchestrate sophisticated attacks that are not easily detected or handled by the vehicle's control system. In this work, we purpose a generic security framework, termed BlueBox, capable of detecting and handling a variety of cyber-physical attacks. To demonstrate an application of BlueBox in practice, we retrofitted an off-the-shelf quadcopter. A series of attacks were then launched by embedding malicious code in the control software and by altering the vehicle's hardware with the specific targeting of sensors, controller, motors, vehicle dynamics, and operating system. Experimental results verified that BlueBox was capable of both detecting a variety of cyber-physical attacks, while also providing the means in which to recover from such attacks.
keywords: {Software;Hardware;Security;Sensor fusion;Vehicle dynamics;Control systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462886&isnumber=8460178

F. Nägele, L. Halt, P. Tenbrock and A. Pott, "A Prototype-Based Skill Model for Specifying Robotic Assembly Tasks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 558-565.
doi: 10.1109/ICRA.2018.8462885
Abstract: In recent years, a number of publications described approaches for model-based manipulation skills and their applicability to a variety of robot tasks-be it assembly, industrial robotics in general, or service robotics. These approaches roughly follow the same pattern: They model robot task description based on the Task Frame Formalism, the Task Function Approach, or iTaSC. They model coordination mechanisms in form of statecharts or Petri nets. And almost all models are accompanied by domain-specific languages (DSLs) that facilitate creating applications based on those models. While one advantage of using models is their reusability across applications, how to explicitly model the reuse itself has not been fully addressed by these publications. Our paper contributes to this field of research by investigating how reuse can be explicitly modeled using prototype-based inheritance. We base our model on iTaSC and provide a simple yet effective DSL for populating the model and creating applications. We demonstrate our approach by creating a comprehensive library of skills, and by showing the use, reuse and incremental refinement of skills for diverse industrial assembly applications.
keywords: {Task analysis;Robot kinematics;Kinematics;DSL;Libraries;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462885&isnumber=8460178

J. Ramos, B. Katz, M. Y. M. Chuah and S. Kim, "Facilitating Model-Based Control Through Software-Hardware Co-Design," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 566-572.
doi: 10.1109/ICRA.2018.8460575
Abstract: This paper exemplifies the design process for legged machines capable of dynamic behaviors. In order to achieve high performance robots, it is crucial to guarantee harmonious integration between software and hardware. Hence, the development of such capable robotic platforms must address design requirements that meet the assumptions of typical model-based controllers but also respect the physical limitations of a real system. First, we show that proper hardware design choices can greatly aid the control algorithm by approximating the physical robot to the template assumptions. We include actuation and sensing design examples that allows a simple model to capture a major portion of the natural dynamic behavior of the physical machine. Results are applied to a real robot (Figure 1) and we show that the adopted methodology is able to address typical problems in legged robots such as high bandwidth force control and robustness to impact. Finally, a simple model-based balance controller that takes advantage of the fidelity of the template model to the real machine is implemented. These are examples of software-hardware codesign processes that vastly facilitate robotic control.
keywords: {Legged locomotion;Robot sensing systems;Actuators;Hardware;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460575&isnumber=8460178

A. Murai and M. Tada, "Multilayered Kinodynamics Simulation for Detailed Whole-Body Motion Generation and Analysis," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 581-587.
doi: 10.1109/ICRA.2018.8460719
Abstract: This study generates and analyzes unsafe human motions that cannot be measured experimentally in laboratories with dynamic consistency. Detailed whole-body motions are generated by a multilayered kinodynamics simulation (MLKD Sim) that uses a detailed digital whole-body human model and a simple motion-representation model that parametrically represents human motion mechanisms. First, we develop the simple motion-representation model that represents human motion and contact force data that are experimentally measured in a laboratory, and we identify this model's parameters based on these experimental data. Forward dynamics computation of this motion-representation model with changing model and/or environmental parameters simulates motion modification as well as a contact force with dynamic consistency. Finally, the mapping function from the motion-representation model's motion to the detailed motion identified from the experimental data is used to reconstruct the detailed whole-body motion. MLKD Sim reconstructs a vertical contact force with average error of 2.18E+02 N, center of mass trajectory with average error of 3.31E-02 m, ankle joint angle with average error of 1.11E-01 rad (2.95E+00%), and ankle joint torque with average error of 6.13E+01 Nm (1.93E+01%). Unsafe motion simulation results show that the physical load on the hip, knee, and ankle joints increases by 9.23E+01%, 5.42E+02%, and 1.45E+02% respectively with 0.5-m level difference in a running surface. These results imply that when sprinting in an unknown environment, we need to protect, in order, the knee ankle, and hip joints. This study conducts detailed dynamics and kinematics analysis of unsafe human motions that cannot be measured experimentally in laboratories to prevent injuries, falls, and fatigue, and these results should find applications in the fields of medicine and welfare.
keywords: {Dynamics;Computational modeling;Force;Legged locomotion;Kinematics;Data models;Analytical models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460719&isnumber=8460178

U. Acharya, S. Kunde, L. Hall, B. A. Duncan and J. M. Bradley, "Inference of User Qualities in Shared Control," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 588-595.
doi: 10.1109/ICRA.2018.8461193
Abstract: Users play an integral role in the performance of many robotic systems, and robotic systems must account for differences in users to improve collaborative performance. Much of the work in adapting to users has focused on designing teleoperation controllers that adjust to extrinsic user indicators such as force, or intent, but do not adjust to intrinsic user qualities. In contrast, the Human-Robot Interaction community has extensively studied intrinsic user qualities, but results may not rapidly be fed back into autonomy design. Here we provide foundational evidence for a new strategy that augments current shared control, and provide a mechanism to directly feed back results from the HRI community into autonomy design. Our evidence is based on a study examining the impact of the user quality “locus of control” on telepresence robot performance. Our results support our hypothesis that key user qualities can be inferred from human-robot interactions (such as through path deviation or time to completion) and that switching or adaptive autonomies might improve shared control performance.
keywords: {Robots;Telepresence;Collision avoidance;Task analysis;Force;Human-robot interaction;System performance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461193&isnumber=8460178

R. Pinsler, R. Akrour, T. Osa, J. Peters and G. Neumann, "Sample and Feedback Efficient Hierarchical Reinforcement Learning from Human Preferences," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 596-601.
doi: 10.1109/ICRA.2018.8460907
Abstract: While reinforcement learning has led to promising results in robotics, defining an informative reward function is challenging. Prior work considered including the human in the loop to jointly learn the reward function and the optimal policy. Generating samples from a physical robot and requesting human feedback are both taxing efforts for which efficiency is critical. We propose to learn reward functions from both the robot and the human perspectives to improve on both efficiency metrics. Learning a reward function from the human perspective increases feedback efficiency by assuming that humans rank trajectories according to a low-dimensional outcome space. Learning a reward function from the robot perspective circumvents the need for a dynamics model while retaining the sample efficiency of model-based approaches. We provide an algorithm that incorporates bi-perspective reward learning into a general hierarchical reinforcement learning framework and demonstrate the merits of our approach on a toy task and a simulated robot grasping task.
keywords: {Robots;Grasping;Task analysis;Trajectory;Learning (artificial intelligence);Context modeling;Customer relationship management},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460907&isnumber=8460178

B. A. Duncan, E. Beachly, A. Bevins, S. Elbaum and C. Detweiler, "Investigation of Communicative Flight Paths for Small Unmanned Aerial Systems," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 602-609.
doi: 10.1109/ICRA.2018.8462871
Abstract: This project seeks to generate small Unmanned Aerial System (sUAS) flight paths that are broadly understood by the general population and can communicate states about both the sUAS and its understanding of the world. Previous work in sUAS flight paths has sought to communicate intent, destination, or emotion of the system without focusing on concrete states (e.g., low battery, landing, etc.). This work leverages biologically-based flight paths and experimental methodologies from human-human and human-humanoid robot interactions to assess the understanding of avian flight paths to communicate sUAS states to novice users. If successful, this work should inform: the human-robot interaction community about the perception of flight paths, sUAS manufacturers on how their systems could communicate with both operators and bystanders, and end users on ways to communicate with others when flying systems in public spaces. General design implications and future directions of work are suggested to build on the results here, which suggest that novice users gravitate towards labels they understand (draw attention and landing) while avoiding more technical labels (lost sensor).
keywords: {Biology;Humanoid robots;Stakeholders;Batteries;Aerospace electronics;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462871&isnumber=8460178

K. Li, M. Rath and J. W. Burdick, "Inverse Reinforcement Learning via Function Approximation for Clinical Motion Analysis," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 610-617.
doi: 10.1109/ICRA.2018.8460563
Abstract: This paper introduces a new method for inverse reinforcement learning in large state spaces, where the learned reward function can be used to control high-dimensional robot systems and analyze complex human movement. To avoid solving the computationally expensive reinforcement learning problems in reward learning, we propose a function approximation method to ensure that the Bellman Optimality Equation always holds, and then estimate a function to maximize the likelihood of the observed motion. The time complexity of the proposed method is linearly proportional to the cardinality of the action set, thus it can handle large state spaces efficiently. We test the proposed method in a simulated environment on reward learning, and show that it is more accurate than existing methods and significantly better in scalability. We also show that the proposed method can extend many existing methods to large state spaces. We then apply the method to evaluating the effect of rehabilitative stimulations on patients with spinal cord injuries based on the observed patient motions.
keywords: {Learning (artificial intelligence);Mathematical model;Trajectory;Function approximation;Spinal cord injury;Markov processes;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460563&isnumber=8460178

N. Wilde, D. Kulić and S. L. Smith, "Learning User Preferences in Robot Motion Planning Through Interaction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 619-626.
doi: 10.1109/ICRA.2018.8460586
Abstract: In this paper we develop an approach for learning user preferences for complex task specifications through human-robot interaction. We consider the problem of planning robot motion in a known environment, but where a user has specified additional spatial and temporal constraints on allowable robot motions. To illustrate the impact of the user's constraints on performance, we iteratively present users with alternative solutions on an interface. The user provides a ranking of alternate paths, and from this we learn about the importance of different constraints. This allows for an accessible method for specifying complex robot tasks. We present an algorithm that iteratively builds a set of constraints on the relative importance of each user constraint, and prove that with sufficient interaction, the algorithm determines a user-optimal path. We demonstrate the practical performance by simulating realistic material transport scenarios in industrial facilities.
keywords: {Task analysis;Service robots;Roads;Robot motion;Planning;Shortest path problem},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460586&isnumber=8460178

C. Wang, H. K. Galoogahi, C. Lin and S. Lucey, "Deep-LK for Efficient Adaptive Object Tracking," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 627-634.
doi: 10.1109/ICRA.2018.8460815
Abstract: In this paper, we present a new approach for efficient regression-based object tracking. Our approach is closely related to the Generic Object Tracking Using Regression Networks (GOTURN) framework [1]. We make the following contributions. First, we demonstrate that there is a theoretical relationship between Siamese regression networks like GOTURN and the classical Inverse Compositional Lucas & Kanade (IC-LK) algorithm. Further, we demonstrate that unlike GOTURN, IC-LK adapts its regressor to the appearance of the current tracked frame. We argue that the lack of such property in GOTURN attributes to its poor performance on unseen objects and/or viewpoints. Second, we propose a novel framework for object tracking inspired by the IC-LK framework, which we refer to as Deep-LK. Finally, we show impressive results demonstrating that Deep-LK substantially outperforms GOTURN and demonstrate comparable tracking performance against current state-of-the-art deep trackers on high frame-rate sequences whilst being an order of magnitude (100 FPS) computationally efficient.
keywords: {Object tracking;Mathematical model;Robustness;Feature extraction;Linear regression;Videos;Strain},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460815&isnumber=8460178

D. Frossard and R. Urtasun, "End-to-end Learning of Multi-sensor 3D Tracking by Detection," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 635-642.
doi: 10.1109/ICRA.2018.8462884
Abstract: In this paper we propose a novel approach to tracking by detection that can exploit both cameras as well as LIDAR data to produce very accurate 3D trajectories. Towards this goal, we formulate the problem as a linear program that can be solved exactly, and learn convolutional networks for detection as well as matching in an end-to-end manner. We evaluate our model in the challenging KITTI dataset and show very competitive results.
keywords: {Trajectory;Three-dimensional displays;Laser radar;Tracking;Cameras;Neural networks;Radar tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462884&isnumber=8460178

C. Rauch, T. Hospedales, J. Shotton and M. Fallon, "Visual Articulated Tracking in the Presence of Occlusions," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 643-650.
doi: 10.1109/ICRA.2018.8462873
Abstract: This paper focuses on visual tracking of a robotic manipulator during manipulation. In this situation, tracking is prone to failure when visual distractions are created by the object being manipulated and the clutter in the environment. Current state-of-the-art approaches, which typically rely on model-fitting using Iterative Closest Point (ICP), fail in the presence of distracting data points and are unable to recover. Meanwhile, discriminative methods which are trained only to distinguish parts of the tracked object can also fail in these scenarios as data points from the occlusions are incorrectly classified as being from the manipulator. We instead propose to use the per-pixel data-to-model associations provided from a random forest to avoid local minima during model fitting. By training the random forest with artificial occlusions we can achieve increased robustness to occlusion and clutter present in the scene. We do this without specific knowledge about the type or location of the manipulated object. Our approach is demonstrated by using dense depth data from an RGB-D camera to track a robotic manipulator during manipulation and in presence of occlusions.
keywords: {Manipulators;Data models;Visualization;Robot sensing systems;Training;Radio frequency},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462873&isnumber=8460178

P. Liang, Y. Wu, H. Lu, L. Wang, C. Liao and H. Ling, "Planar Object Tracking in the Wild: A Benchmark," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 651-658.
doi: 10.1109/ICRA.2018.8461037
Abstract: Planar object tracking is an actively studied problem in vision-based robotic applications. While several benchmarks have been constructed for evaluating state-of-the-art algorithms, there is a lack of video sequences captured in the wild rather than in constrained laboratory environment. In this paper, we present a carefully designed planar object tracking benchmark containing 210 videos of 30 planar objects sampled in the natural environment. In particular, for each object, we shoot seven videos involving various challenging factors, namely scale change, rotation, perspective distortion, motion blur, occlusion, out-of-view, and unconstrained. The ground truth is carefully annotated semi-manually to ensure the quality. Moreover, eleven state-of-the-art algorithms are evaluated on the benchmark using two evaluation metrics, with detailed analysis provided for the evaluation results. We expect the proposed benchmark to benefit future studies on planar object tracking.
keywords: {Object tracking;Benchmark testing;Cameras;Target tracking;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461037&isnumber=8460178

T. Wang, H. Ling, C. Lang, S. Feng, Y. Jin and Y. Li, "Constrained Confidence Matching for Planar Object Tracking," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 659-666.
doi: 10.1109/ICRA.2018.8460680
Abstract: Tracking planar objects has a wide range of applications in robotics. Conventional template tracking algorithms, however, often fail to observe fast object motion or drift significantly after a period of time, due to drastic object appearance change. To address such challenges, we propose a novel constrained confidence matching algorithm for motion estimation and a robust Kalman filter for template updating. Integrated with an accurate occlusion detector, our approach achieves accurate motion estimation in presence of partial occlusion, by excluding occluded pixels from computation of motion parameters. Furthermore, the proposed Kalman filter employs a novel control-input model to handle the object appearance change, which brings our tracker high robustness against sudden illumination change and heavy motion blur. For evaluation, we compare the proposed tracker with several state-of-the-art planar object trackers on two public benchmark datasets. Experimental results show that our algorithm achieves robust tracking results against various environmental variations, and outperforms baseline algorithms remarkably on both datasets.
keywords: {Robustness;Lighting;Perturbation methods;Object tracking;Kalman filters;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460680&isnumber=8460178

A. Lambert, A. Shaban, A. Raj, Z. Liu and B. Boots, "Deep Forward and Inverse Perceptual Models for Tracking and Prediction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 675-682.
doi: 10.1109/ICRA.2018.8461050
Abstract: We consider the problems of learning forward models that map state to high-dimensional images and inverse models that map high-dimensional images to state in robotics. Specifically, we present a perceptual model for generating video frames from state with deep networks, and provide a framework for its use in tracking and prediction tasks. We show that our proposed model greatly outperforms standard deconvolutional methods and GANs for image generation, producing clear, photo-realistic images. We also develop a convolutional neural network model for state estimation and compare the result to an Extended Kalman Filter to estimate robot trajectories. We validate all models on a real robotic system.
keywords: {Predictive models;Inverse problems;Robot sensing systems;Kinematics;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461050&isnumber=8460178

D. Saldaña, B. Gabrich, G. Li, M. Yim and V. Kumar, "ModQuad: The Flying Modular Structure that Self-Assembles in Midair," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 691-698.
doi: 10.1109/ICRA.2018.8461014
Abstract: We introduce ModQuad, a novel flying modular robotic structure that is able to self-assemble in midair and cooperatively fly. The structure is composed by agile flying modules that can easily move in a three dimensional environment. The module is based on a quadrotor platform within a cuboid frame which allows it to attach to other modules by matching vertical faces. Using this mechanism, a ModQuad swarm is able to rapidly assemble flying structures in midair using the robot bodies as building units. In this paper, we focus on two important tasks for modular flying structures. First, we propose a decentralized modular attitude controller to allow a team of physically connected modules to fly cooperatively. Second, we develop a docking method that drives pairs of structures to be attached in midair. Our method precisely aligns, and corrects motion errors during the docking process. In our experiments, we tested and analyzed the performance of the cooperative flying method for multiple configurations. We also tested the docking method with successful results.
keywords: {Robot kinematics;Rotors;Buildings;Payloads;Shape;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461014&isnumber=8460178

É. Barrett et al., "Autonomous Battery Exchange of UAVs with a Mobile Ground Base," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 699-705.
doi: 10.1109/ICRA.2018.8460201
Abstract: This paper presents the autonomous battery exchange operation for small scale UAVs, using a mobile ground base that carries a robotic arm and a service station containing the battery exchange mechanism. The goal of this work is to demonstrate the means to increase the autonomy and persistence of robotic systems without requiring human intervention. The design and control of the system and its components are presented in detail, as well as the collaborative software framework used to plan and execute complex missions. Finally, the results of autonomous outdoor experiments are presented, in which the ground rover successfully localizes, retrieves, services, and deploys the landed UAV, proving its capacity to extend and enhance autonomous operations.
keywords: {Batteries;Task analysis;Actuators;Robot kinematics;Planning;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460201&isnumber=8460178

J. A. Castano, E. M. Hoffman, A. Laurenzi, L. Muratore, M. Karnedula and N. G. Tsagarakis, "A Whole Body Attitude Stabilizer for Hybrid Wheeled-Legged Quadruped Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 706-712.
doi: 10.1109/ICRA.2018.8462875
Abstract: This work presents a new attitude balancing strategy implemented and validated on a quadrupedal robot equipped with a custom hybrid wheel-legged mobility system. The proposed method uses an inverse kinematics solution scheme based on Quadratic Programming optimization to generate full body motions that ensure the desired balancing performances. The strategy generates a compliant behaviour to cope with the applied external forces resulting in a stable and smooth reaction response. Furthermore, the method takes advantage of the robot hybrid wheeled-legged mobility system to provide new motion capabilities and balancing reactions as it will be shown through the paper. Extensive simulation studies on the Centauro robot are presented. Results show the efficiency of the propose method demonstrating significant contribution in the rejection of the applied external disturbances.
keywords: {Wheels;Legged locomotion;Task analysis;Stability analysis;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462875&isnumber=8460178

Z. Fan, L. Meng, T. Q. Chen, J. Li and I. M. Mitchell, "Learning Motion Predictors for Smart Wheelchair Using Autoregressive Sparse Gaussian Process," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 713-718.
doi: 10.1109/ICRA.2018.8460502
Abstract: Constructing a smart wheelchair on a commercially available powered wheelchair (PWC) platform avoids a host of seating, mechanical design and reliability issues but requires methods of predicting and controlling the motion of a device never intended for robotics. Analog joystick inputs are subject to black-box transformations which may produce intuitive and adaptable motion control for human operators, but complicate robotic control approaches; furthermore, installation of standard axle mounted odometers on a commercial PWC is difficult. In this work, we present an integrated hardware and software system for predicting the motion of a commercial PWC platform that does not require any physical or electronic modification of the chair beyond plugging into an industry standard auxiliary input port. This system uses an RGB-D camera and an Arduino interface board to capture motion data, including visual odometry and joystick signals, via ROS communication. Future motion is predicted using an autoregressive sparse Gaussian process model. We evaluate the proposed system on real-world short-term path prediction experiments. Experimental results demonstrate the system's efficacy when compared to a baseline neural network model.
keywords: {Cameras;Gaussian processes;Robot sensing systems;Wheelchairs;Mobile robots;Hardware},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460502&isnumber=8460178

P. Wolf, T. Ropertz, M. Oswald and K. Berns, "Local Behavior-Based Navigation in Rough Off-Road Scenarios Based on Vehicle Kinematics," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 719-724.
doi: 10.1109/ICRA.2018.8460631
Abstract: This paper describes a novel behavior-based local navigation approach for rough off-road scenarios. Trajectory candidates are generated based on vehicle kinematics and dynamics as well as the desired global trajectory. In contrast to on-road local navigation approaches, the work at hand proposes the use of a shiftable elevation grid map instead of occupancy maps since traversability in rough terrains does not only depend on location, but also on the robot's orientation. The traversability is evaluated by determining tire contact points with the terrain to take various different safety and efficiency aspects like underbody collisions and rollover risk into account. By exploiting the behavior-based control paradigm, the navigation approach can be easily extended and its robustness is shown in experimental evaluations using an Unimog U5023.
keywords: {Wheels;Navigation;Trajectory;Robot sensing systems;Axles;Three-dimensional displays;robotics;off-road navigation;behavior-based control;tentacles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460631&isnumber=8460178

M. Mashali, L. Wu, R. Alqasemi and R. Dubey, "Controlling a Non-Holonomic Mobile Manipulator in a Constrained Floor Space," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 725-731.
doi: 10.1109/ICRA.2018.8462866
Abstract: Robotic manipulators that are attached to mobile platforms are often used in workspaces that require the end-effector to mobilize beyond the manipulator's limited reach, such as in warehouse shelf stacking and similar applications. However, such assistive robots fall short of completing tasks that require the end-effector to be situated in a specific configuration at a critical time during the task. Traditionally, users control the mobile base to situate the arm such that the task can be completed through continuous operation. This requires an experienced operator who can predict the needed end-effector workspace, and can operate the base accordingly to maximize the likelihood of a successful task while avoiding any floor obstacles. In this work, we propose a straightforward control method that provides sufficient freedom to the end-effector to complete a task that is bound by time-dependent constraints. This is achieved by relaxing the time constraints on the mobile base trajectory in a floor space obstructed by obstacles. The trajectory of the platform is determined by sensor-assisted obstacle avoidance algorithm such that a single degree of freedom mobility can be represented through a safe obstacle-free time-independent path. The proposed control method is implemented in simulation and on physical hardware built in our labs. The simulation included a 5-DoF redundant Planar Mobile Manipulator (PMM). The hardware implementation and testing utilized a 9-DoF redundant mobile manipulator. The implementation results demonstrate the effectiveness of the control method in adjusting the mobile platform motion along its allowed obstacle-free path to enable the end-effector to follow its trajectory for task completion that would otherwise fail to complete when conventional control methods are used.
keywords: {Manipulators;Task analysis;Trajectory;Hardware;Kinematics;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462866&isnumber=8460178

P. Glotfelter and M. Egerstedt, "A Parametric MPC Approach to Balancing the Cost of Abstraction for Differential-Drive Mobile Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 732-737.
doi: 10.1109/ICRA.2018.8461234
Abstract: When designing control strategies for differential-drive mobile robots, one standard tool is the consideration of a point at a fixed distance along a line orthogonal to the wheel axis instead of the full pose of the vehicle. This abstraction supports replacing the non-holonomic, three-state unicycle model with a much simpler two-state single-integrator model (i.e., a velocity-controlled point). Yet this transformation comes at a performance cost, through the robot's precision and maneuverability. This work contains derivations for expressions of these precision and maneuverability costs in terms of the transformation's parameters. Furthermore, these costs show that only selecting the parameter once over the course of an application may cause an undue loss of precision. Model Predictive Control (MPC) represents one such method to ameliorate this condition. However, MPC typically realizes a control signal, rather than a parameter, so this work also proposes a Parametric Model Predictive Control (PMPC) method for parameter and sampling horizon optimization. Experimental results are presented that demonstrate the effects of the parameterization on the deployment of algorithms developed for the single-integrator model on actual differential-drive mobile robots.
keywords: {Mobile robots;Wheels;Robot kinematics;Predictive control;Measurement;Parametric statistics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461234&isnumber=8460178

H. Yang et al., "Dynamic Simulation of Planetary Rovers with Terrain Property Mapping," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 738-743.
doi: 10.1109/ICRA.2018.8460755
Abstract: Simulation of planetary rovers moving on complex terrains is critical for Mars exploration. Equivalent stiffness is proposed and used to characterize the pressure-sinkage property of terrain, while friction angle to characterize the shearing property. Terramechanics model for calculating forces between rigid wheel and soil is proved to be the same with that contact model for calculating forces between rigid wheel and rock. A Digital Elevation Map with Physical Properties is developed and applied to simulate terrain physical properties along with its geometry information. The established methods are validated using simulation and experimental tests with a three-wheel-rover.
keywords: {Soil;Mathematical model;Wheels;Stress;Computational modeling;Shearing;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460755&isnumber=8460178

S. H. Pyo, H. S. Lee, B. M. Phu, S. J. Park and J. W. Yoon, "Development of an Fast-Omnidirectional Treadmill (F-ODT) for Immersive Locomotion Interface," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 760-766.
doi: 10.1109/ICRA.2018.8460669
Abstract: To achieve immersive and natural navigation in a virtual environment through human locomotion, it is necessary to generate a 2-dimensional infinite ground for omnidirectional walking. However, the existing omnidirectional treadmills are heavy, complex and exhibit low acceleration due to power transmission inefficiency. In this paper, we present a novel fast-omnidirectional treadmill (F-ODT) with a new power transmission mechanism called the Geared Omni-pulley. This mechanism ensures higher power transmission efficiency for driving the belts of the multiple transversal treadmills for independent Y-axis motion. Due to the improved power transmission performance combined with a simpler and relatively light-weight structure, the proposed 2D treadmill can generate a maximum speed of 3m/sec with an acceleration of 3m/sec2. Based on the improved performance, the F-ODT system can be used as a locomotion interface platform in various virtual reality environments such as training of soldiers, gaming/educational experiences and gait rehabilitation.
keywords: {Belts;Motion segmentation;Power transmission;Torque;Synchronous motors;Angular velocity;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460669&isnumber=8460178

C. Abah, A. L. Orekhov and N. Simaan, "Design Considerations and Redundancy Resolution for Variable Geometry Continuum Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 767-774.
doi: 10.1109/ICRA.2018.8460722
Abstract: Current multi-backbone continuum robots are limited to a constant cross-sectional diameter. This paper proposes a design alternative that overcomes this limitation. The ability to change the diameter of a continuum robot expands the repertoire of kinematic redundancy and enables kinematic parameter adaptation to optimize performance. A continuum robot design based on the angulated scissor mechanism is presented along with its position analysis. An exploration of admissible design parameter values for a given continuum robot segment with a desired maximum curvature while maintaining an open bore along its center is also carried out. A design presenting how this mechanism can be incorporated into a continuum robot is shown and a strategy for minimizing joint forces and avoiding joint limits is formulated as a gradient descent redundancy resolution problem in a simulation case study. The simulation results show that varying the diameter can significantly reduce joint forces while preserving the workspace and avoiding joint limits. This work is a first step towards continuum robots with situational awareness that will use their sensing capabilities to adapt their structure in order to optimize task execution performance.
keywords: {Couplings;Kinematics;Elbow;Robot sensing systems;Redundancy;Fasteners;Continuum robots;variable geometry robots;redundancy;angulated scissor mechanism;kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460722&isnumber=8460178

S. Wolf and M. Iskandar, "Extending a Dynamic Friction Model with Nonlinear Viscous and Thermal Dependency for a Motor and Harmonic Drive Gear," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 783-790.
doi: 10.1109/ICRA.2018.8460613
Abstract: In robotic actuation a well identified and modeled friction behavior of the actuator components helps to significantly improve friction compensation, output torque estimation, and dynamic simulations. The friction of two components, i.e. a brush-less DC motor and a harmonic drive gear (HD) is investigated in order to build an accurate dynamic model of the main actuator of the arms of the humanoid David namely the DLR Floating Spring Joint (FSJ). A dedicated testbed is built to precisely identify input and output torques, temperatures, positions, and elasticities of the investigated components at a controlled environment temperature. Extensive test series are performed in the full velocity operating range in a temperature interval from 24 to 50 °C. The nonlinear influences of velocity and temperature are identified to be dominant effects. It is proposed how to include these nonlinear velocity and temperature dependencies into a static and a dynamic friction model, e.g. LuGre. Dynamic models of the motor and HD are built with the proposed method and experimentally evaluated. The new models are compared to friction models with linear dependencies and show a significant improvement of correspondence with reality.
keywords: {Friction;Mathematical model;Torque;Gears;Robots;Harmonic analysis;Springs},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460613&isnumber=8460178

F. Chen, H. Zhao and H. Ding, "Eddy Current Damper Design for Vibration Suppression in Robotic Milling Process," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 799-804.
doi: 10.1109/ICRA.2018.8460693
Abstract: This paper presents a novel eddy current damper design for chatter suppression in robotic milling process. The designed eddy current dampers are installed on a milling spindle to damp the tool tip vibrations. The structural design of the eddy current dampers and the working principle of the proposed vibration attenuation method are explained. Finite element method is used to analyze the magnetic flux density and the magnetic force generated by the designed eddy current. The dynamics of the robotic milling system without and with eddy current dampers are modeled, and the damping performance of the proposed method is verified through simulations in both frequency and time domains. The results show that the peaks of the tool tip frequency response function caused by the spindle and milling tool modes are damped by 3.2 dB and 5.3 dB, respectively, and the chatter stability is improved by about 43% in the high spindle speed zone, compared to the case without eddy current dampers.
keywords: {Robots;Milling;Damping;Tools;Force;Copper;Vibrations;Robotic milling;eddy current damper;vibration suppression;chatter},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460693&isnumber=8460178

R. Gomez-Ojeda, Z. Zhang, J. Gonzalez-Jimenez and D. Scaramuzza, "Learning-Based Image Enhancement for Visual Odometry in Challenging HDR Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 805-811.
doi: 10.1109/ICRA.2018.8462876
Abstract: One of the main open challenges in visual odometry (VO) is the robustness to difficult illumination conditions or high dynamic range (HDR) environments. The main difficulties in these situations come from both the limitations of the sensors and the inability to perform a successful tracking of interest points because of the bold assumptions in VO, such as brightness constancy. We address this problem from a deep learning perspective, for which we first fine-tune a deep neural network with the purpose of obtaining enhanced representations of the sequences for VO. Then, we demonstrate how the insertion of long short term memory allows us to obtain temporally consistent sequences, as the estimation depends on previous states. However, the use of very deep networks enlarges the computational burden of the VO framework; therefore, we also propose a convolutional neural network of reduced size capable of performing faster. Finally, we validate the enhanced representations by evaluating the sequences produced by the two architectures in several state-of-art VO algorithms, such as ORB-SLAM and DSO.
keywords: {Robustness;Cameras;Brightness;Lighting;Training;Decoding;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462876&isnumber=8460178

G. Caron and F. Morbidi, "Spherical Visual Gyroscope for Autonomous Robots Using the Mixture of Photometric Potentials," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 820-827.
doi: 10.1109/ICRA.2018.8460761
Abstract: In this paper, we present a new direct omnidirectional visual gyroscope for mobile robotic platforms. The gyroscope estimates the 3D orientation of a camera-robot by comparing the current spherical image with that acquired at a reference pose. By transforming pixel intensities into a Mixture of Photometric Potentials, we introduce a novel image-similarity measure which can be seamlessly integrated into a classical nonlinear least-squares optimization scheme, offering an extended convergence domain. Our method provides accurate and robust attitude estimates, and it is easy-to-use since it involves a single tuning parameter, the width of the photometric potentials (Gaussian functions, in this work) controlling the power of attraction of each pixel. The visual gyroscope has been successfully tested on spherical image sequences generated by a twin-fisheye camera mounted on the end-effector of a robot arm and on a fixed-wing UAV.
keywords: {Cameras;Visualization;Gyroscopes;Robot vision systems;Three-dimensional displays;Convergence},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460761&isnumber=8460178

N. Zhang, M. Warren and T. D. Barfoot, "Learning Place-and-Time-Dependent Binary Descriptors for Long-Term Visual Localization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 828-835.
doi: 10.1109/ICRA.2018.8460674
Abstract: Vision-based navigation is extremely susceptible to natural scene changes. This can result in localization failures in less than a few hours after map creation. To combat short-term illumination changes as well as long-term seasonal variations, we propose using a place-and-time-dependent binary descriptor that adapts to different scenarios in an online fashion. This is achieved by extending the GRIEF [6] evolution algorithm in two ways: correspondence generation using a known pose change and the inclusion of LATCH triplets in addition to BRIEF comparisons for descriptor generation. We show the adaptive descriptor outperforms a single descriptor scheme for localization within a single-experience Visual Teach and Repeat (VT&R) system while maintaining the efficiency of binary descriptors. By adapting the description function to different environmental conditions, it allows the system to operate for a longer period before a new experience is required. In the presence of extreme illumination changes from day to night, we obtain 40% more inlier matches compared to SURF. In the case of seasonal variations, a 70% increase is demonstrated. The increased correspondences result in more localizable sections along the paths, amounting to a 25% and 150% increase in the lighting and seasonal cases, respectively.
keywords: {Lighting;Visualization;Latches;Navigation;Robustness;Measurement;Evolutionary computation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460674&isnumber=8460178

C. Wang, T. Ji, T. -M. Nguyen and L. Xie, "Correlation Flow: Robust Optical Flow Using Kernel Cross-Correlators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 836-841.
doi: 10.1109/ICRA.2018.8460569
Abstract: Robust velocity and position estimation is crucial for autonomous robot navigation. The optical flow based methods for autonomous navigation have been receiving increasing attentions in tandem with the development of micro unmanned aerial vehicles. This paper proposes a kernel cross-correlator (KCC) based algorithm to determine optical flow using a monocular camera, which is named as correlation flow (CF). Correlation flow is able to provide reliable and accurate velocity estimation and is robust to motion blur. In addition, it can also estimate the altitude velocity and yaw rate, which are not available by traditional methods. Autonomous flight tests on a quadcopter show that correlation flow can provide robust trajectory estimation with very low processing power. The source codes are released based on the ROS framework.
keywords: {Kernel;Optical sensors;Optical imaging;Correlation;Correlators;Robustness;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460569&isnumber=8460178

M. Huber, T. Hinzmann, R. Siegwart and L. H. Matthies, "Cubic Range Error Model for Stereo Vision with Illuminators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 842-848.
doi: 10.1109/ICRA.2018.8461150
Abstract: Use of low-cost depth sensors, such as a stereo camera setup with illuminators, is of particular interest for numerous applications ranging from robotics and transportation to mixed and augmented reality. The ability to quantify noise is crucial for these applications, e.g., when the sensor is used for map generation or to develop a sensor scheduling policy in a multi-sensor setup. Range error models provide uncertainty estimates and help weigh the data correctly in instances where range measurements are taken from different vantage points or with different sensors. Such a model is derived in this work. We show that the range error for stereo systems with integrated illuminators is cubic and validate the proposed model experimentally with an off-the-shelf structured light stereo system. The experiments confirm the validity of the model and simplify the application of this type of sensor in robotics.
keywords: {Cameras;Robot sensing systems;Uncertainty;Lighting;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461150&isnumber=8460178

D. Martins, K. Van Hecke and G. De Croon, "Fusion of Stereo and Still Monocular Depth Estimates in a Self-Supervised Learning Context," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 849-856.
doi: 10.1109/ICRA.2018.8461116
Abstract: We study how autonomous robots can learn by themselves to improve their depth estimation capability. In particular, we investigate a self-supervised learning setup in which stereo vision depth estimates serve as targets for a convolutional neural network (CNN) that transforms a single still image to a dense depth map. After training, the stereo and mono estimates are fused with a novel fusion method that preserves high confidence stereo estimates, while leveraging the CNN estimates in the low-confidence regions. The main contribution of the article is that it is shown that the fused estimates lead to a higher performance than the stereo vision estimates alone. Experiments are performed on the KITTI dataset, and on board of a Parrot SLAMDunk, showing that even rather limited CNNs can help provide stereo vision equipped robots with more reliable depth maps for autonomous navigation.
keywords: {Estimation;Stereo vision;Robot sensing systems;Cameras;Training;Self-supervised learning;monocular depth estimation;stereo vision;convolutional neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461116&isnumber=8460178

J. Kim, Y. Cho and A. Kim, "Exposure Control Using Bayesian Optimization Based on Entropy Weighted Image Gradient," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 857-864.
doi: 10.1109/ICRA.2018.8462881
Abstract: Under- and oversaturation can cause severe image degradation in many vision-based robotic applications. To control camera exposure in dynamic lighting conditions, we introduce a novel metric for image information measure. Measuring an image gradient is typical when evaluating its level of image detail. However, emphasizing more informative pixels substantially improves the measure within an image. By using this entropy weighted image gradient, we introduce an optimal exposure value for vision-based approaches. Using this newly invented metric, we also propose an effective exposure control scheme that covers a wide range of light conditions. When evaluating the function (e.g., image frame grab) is expensive, the next best estimation needs to be carefully considered. Through Bayesian optimization, the algorithm can estimate the optimal exposure value with minimal cost. We validated the proposed image information measure and exposure control scheme via a series of thorough experiments using various exposure conditions.
keywords: {Entropy;Measurement;Cameras;Optimization;Bayes methods;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462881&isnumber=8460178

S. Sharma, M. Suomalainen and V. Kyrki, "Compliant Manipulation of Free-Floating Objects," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 865-872.
doi: 10.1109/ICRA.2018.8462889
Abstract: Compliant motions allow alignment of workpieces using naturally occurring interaction forces. However, free-floating objects do not have a fixed base to absorb the reaction forces caused by the interactions. Consequently, if the interaction forces are too high, objects can gain momentum and move away after contact. This paper proposes an approach based on direct force control for compliant manipulation of free-floating objects. The objective of the controller is to minimize the interaction forces while maintaining the contact. The proposed approach achieves this by maintaining small constant force along the motion direction and an apparent reduction of manipulator inertia along remaining Degrees of Freedom (DOF). Simulation results emphasize the importance of relative inertia of the robotic manipulator with respect to the free-floating object. The experiments were performed with KUKA LWR4+ manipulator arm and a two-dimensional micro-gravity emulator (object floating on an air bed), which was developed in-house. It was verified that the proposed control law is capable of controlling the interaction forces and aligning the tools without pushing the object away. We conclude that direct force control works better with a free-floating object than implicit force control algorithms, such as impedance control.
keywords: {Manipulators;Force;Force control;Impedance;Damping;Aerospace electronics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462889&isnumber=8460178

K. Seweryn et al., "Validation of the Robot Rendezvous and Grasping Manoeuvre Using Microgravity Simulators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 873-880.
doi: 10.1109/ICRA.2018.8460475
Abstract: Robots mounted on an unmanned chaser satellite could be used for performing rendezvous and grasping manoeuvres in order to repair satellites or remove space debris from orbit. Use of manipulators for such purposes is challenging, since the performed task need to be done autonomously, accurately and with high level of robustness. During manoeuvres high disturbances might appear e.g. due to contact between the manipulator arm end-effector and the target spacecraft. In this paper an approach for validation of the robotic subsystem during chaser rendezvous and grasping manoeuvre has been shown. Two type of testbed systems were used: planar air-bearing microgravity simulators and a test-bed system with industrial robots. The proposed approach took advantage of possible replacement of particular subsystem in reference model or reference hardware in specified test-bed system. The list of tests performed are included in the paper.
keywords: {Manipulators;Satellites;Orbits;Space vehicles;Service robots;Control systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460475&isnumber=8460178

H. Kato, D. Hirano and J. Ota, "Collision-Based Contact Mode Estimation for Dynamic Rigid Body Capture," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 881-888.
doi: 10.1109/ICRA.2018.8460806
Abstract: This paper proposes real-time collision-based contact mode estimation with only a force-torque sensor for capturing a moving rigid body. The contact modes are defined for determining when to generate the signal to close the robotic hand for establishing object closure. In our particle filter approach, collision-triggered filter is used to determine the contact mode with the least amount of computation. Brach's collision model is used for our collision model-based approach for a rigid body because it is computationally light-weighted and enables the sampling of three collision properties for the particle filter. The validity of our method is experimentally demonstrated by achieving the highest success rate using the reasonable computation resources required (average of 3.9 milliseconds and worst of 6.1 milliseconds with our setup), and verifying each computation resource (or number of particles) based on the size of motion estimation error in the pre-capture phase.
keywords: {Estimation;Robot sensing systems;Computational modeling;Collision avoidance;Predictive models;Bayes methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460806&isnumber=8460178

A. M. Giordano, D. Calzolari and A. Albu-Schäffer, "Workspace Fixation for Free-Floating Space Robot Operations," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 889-896.
doi: 10.1109/ICRA.2018.8460478
Abstract: When a space robot accidentally or voluntarily comes in contact with a target object, a workspace shift happens due to exchange of momentum between the objects. The problem of workspace adjustment is addressed herein. A novel controller is derived to simultaneously adjust the workspace and control the end-effector pose. The controller is based on a center-of-mass (CoM) regulation which fixes the workspace in the inertial space while leaving the base free to move, resulting in fuel efficiency. The control is validated on hardware using a robotic simulator composed of a seven degree-of-freedom (DOF) arm mounted on a 6DOF moving base.
keywords: {Manipulators;Symmetric matrices;Fuels;Robot kinematics;Satellites},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460478&isnumber=8460178

S. Chiodini, R. G. Reid, B. Hockman, I. A. D. Nesnas, S. Debei and M. Pavone, "Robust Visual Localization for Hopping Rovers on Small Bodies," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 897-903.
doi: 10.1109/ICRA.2018.8462865
Abstract: We present a collaborative visual localization method for rovers designed to hop and tumble across the surface of small Solar System bodies, such as comets and asteroids. In a two-phase approach, an orbiting primary spacecraft first maps the surface of a body by capturing images from various poses and illumination angles; these images are processed to create a prior map of 3D landmarks. In the second phase, a hopping rover is deployed to the surface where it uses a camera to relocalize to the prior map and to perform onboard visual simultaneous localization and mapping (SLAM). Small bodies present several unique challenges to existing visual SLAM algorithms, such as high-contrast shadows that move quickly over the surface due to the short (e.g. 1-12 hour) rotational periods, and large changes in visual appearance between orbit and the surface, where image scale varies by many orders of magnitude (kilometers to centimeters). In this work, we describe how to augment ORB-SLAM2-a state of the art visual SLAM implementation-to handle large variations in illumination by fusing prior images with varying illumination angles. We demonstrate how a hopping rover can use a wide field of view (FOV) camera to relocalize to prior maps captured by an orbiting spacecraft with a narrow FOV camera, and how the growth of pose and scale errors can be bounded by periodic loop closures during large hops. The proposed method is evaluated with sequences of images captured around a mock asteroid; it is shown to be robust to varying illumination angles, scene scale changes, and off-nadir camera pointing angles.
keywords: {Cameras;Space vehicles;Visualization;Simultaneous localization and mapping;Optimization;Lighting;Solar system},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462865&isnumber=8460178

K. -J. Kim, B. -S. Sim, S. -H. Kim and K. -H. Yu, "Wheel Design Methodology for a Lunar Exploration Rover in Order to Improve Trafficability Considering Operation Environment," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 904-909.
doi: 10.1109/ICRA.2018.8460824
Abstract: For achieving a successful mission in lunar exploration, not only traversability of exploration rover should be predicted but also operation environment should be considered under the limited power condition. Therefore, an optimal design of rover wheel for minimizing power consumption and maximizing tractive performance is required by conducting conceptual design stage. This paper describes settlement of requirements at system level and modeling of operation environment such as power acquisition and terrain characteristics in the lunar simulant. Using the wheel-terrain interaction model, a wheel design methodology was proposed to obtain an optimal wheel dimension, which meet the limited power condition along with maximal trafficability according to the each landing site. In addition, the results from the above approach have been validated with the experimental results using a single wheel test bed on the lunar simulant.
keywords: {Wheels;Moon;Mathematical model;Stress;Design methodology;Power demand;Azimuth},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460824&isnumber=8460178

K. Bussmann, A. Dietrich and C. Ott, "Whole-Body Impedance Control for a Planetary Rover with Robotic Arm: Theory, Control Design, and Experimental Validation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 910-917.
doi: 10.1109/ICRA.2018.8460533
Abstract: Future planetary rovers will gain the ability to manipulate their environment in addition to the maneuverability of current systems. For dedicated contact interaction, Cartesian impedance control is a well-established approach from numerous terrestrial applications. In this paper we will present a whole-body Cartesian impedance controller for a planetary rover equipped with a robotic arm. In contrast to classical terrestrial whole-body controllers, the issue of proper wheel force distribution will be addressed within the control framework. A global optimization solves this redundancy in the over-actuation of the mobile base while additionally handling the kinematic redundancy in the serial kinematic sub-chain of the robot. The approach is experimentally validated on the DLR Lightweight Rover Unit. It can be used for versatile manipulation in rough terrain such as encountered in planetary exploration or terrestrial search-and-rescue scenarios.
keywords: {Wheels;Manipulators;Impedance;Mobile robots;Robot kinematics;Null space},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460533&isnumber=8460178

A. Kuntz et al., "Kinematic Design Optimization of a Parallel Surgical Robot to Maximize Anatomical Visibility via Motion Planning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 926-933.
doi: 10.1109/ICRA.2018.8461135
Abstract: We introduce a method to optimize on a patient-specific basis the kinematic design of the Continuum Reconfigurable Incisionless Surgical Parallel (CRISP) robot, a needle-diameter medical robot based on a parallel structure that is capable of performing minimally invasive procedures. Our objective is to maximize the ability of the robot's tip camera to view tissue surfaces in constrained spaces. The kinematic design of the CRISP robot, which greatly influences its ability to perform a task, includes parameters that are fixed before the procedure begins, such as entry points into the body and parallel structure connection points. We combine a global stochastic optimization algorithm, Adaptive Simulated Annealing (ASA), with a motion planner designed specifically for the CRISP robot. ASA facilitates exploration of the robot's design space while the motion planner enables evaluation of candidate designs based on their ability to successfully view target regions on a tissue surface. By leveraging motion planning, we ensure that the evaluation of a design only considers motions which do not collide with the patient's anatomy. We analytically show that the method asymptotically converges to a globally optimal solution and demonstrate our algorithm's ability to optimize kinematic designs of the CRISP robot on a patient-specific basis.
keywords: {Electron tubes;Kinematics;Collision avoidance;Robot kinematics;Cameras;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461135&isnumber=8460178

G. Wu, "Workspace, Transmissibility and Dynamics of a New 3T3R Parallel Pick-and-place Robot with High Rotational Capability," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 942-947.
doi: 10.1109/ICRA.2018.8460888
Abstract: This paper presents a six-limb high-speed parallel robot for pick-and-place operations that is based on two Delta robots, where the two sub-platforms are connected by a gearbox. Unlike the current 6-axis Delta-type robot, all the actuators of the robot are mounted on a base platform, allowing to reduce the inertia for high dynamic performance. Besides the 3-axis translations, the three rotations of the robot end-effector are realized by the differential motions of the two sub-platforms in three directions for large orientational workspace, but without significantly increased structural complexity of gearbox, compared to the existing one. The kinematic problems are studied to reveal that the workspace volume of the robot is similar to the commercial Delta-type robots. The simplified dynamic model is established and the simulation results show that the robot can reach up to a 20G acceleration subject to the commercial actuation combination.
keywords: {Robot kinematics;Manipulators;Actuators;Kinematics;Service robots;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460888&isnumber=8460178

G. Pittiglio, A. Kogkas, J. O. Vrielink and G. Mylonas, "Dynamic Control of Cable Driven Parallel Robots with Unknown Cable Stiffness: a Joint Space Approach," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 948-955.
doi: 10.1109/ICRA.2018.8460822
Abstract: In the present paper we discuss a novel dynamic controller for Cable Driven Parallel Robots, based on the Backstepping technique. The main challenge in controlling these robots, is expressing the dynamic equilibrium with respect to the joint variables. This drawback makes the definition of closed-loop controllers more challenging, in comparison with their serial counterparts. The problem is tackled by considering redundant dynamics, expressed in both task and joints space and solved through the method of quasi-velocity. We propose the usage of the observer linearization to estimate the end effector pose and stiffness, by just measuring the motor position, velocity and torque. These variables are used in the feedback loop to control the pose of the end effector. A 3-tendon planar platform is used for the experimental analysis.
keywords: {Observers;Kinematics;Position measurement;Velocity measurement;Jacobian matrices;Parallel robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460822&isnumber=8460178

C. Tian, Y. Fang and Q. J. Ge, "New Kinematic Structures for Two-Loop Generalized Parallel Mechanism Designs," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 956-961.
doi: 10.1109/ICRA.2018.8460503
Abstract: The moving platform of a conventional parallel mechanism is typically connected to the ground link via serial kinematic chains or limbs. When interconnections are created among the limbs, they form coupling sub-chains that can provide additional constraints to the motion of the platform. The resulting complex mechanism offers the potential for improved performance and functionality of the overall mechanism. The basic building block of the parallel mechanism with coupling sub-chain is found to be a two-loop mechanism. This paper presents a screw theory based general method for synthesizing two-loop mechanism by adding an open chain on top of an existing closed chain for a specified combination of rotational and translational degrees of freedom of the end-effector. A comprehensive set of two-loop mechanisms have been presented for various combinations of rotational and translational degrees of freedom.
keywords: {Kinematics;Couplings;Fasteners;Manipulators;Force;Mechanical engineering;Periodic structures},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460503&isnumber=8460178

T. Rasheed, P. Long, D. Marquez-Gamez and S. Caro, "Available Wrench Set for Planar Mobile Cable-Driven Parallel Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 962-967.
doi: 10.1109/ICRA.2018.8461199
Abstract: Cable-Driven Parallel Robots (CDPRs) have several advantages over conventional parallel manipulators most notably a large workspace. CDPRs whose workspace can be further increased by modification of the geometric architecture are known as Reconfigurable Cable Driven Parallel Robots(RCDPRs). A novel concept of RCDPRs, known as Mobile CDPR (MCDPR) that consists of a CDPR carried by multiple mobile bases, is studied in this paper. The system is capable of autonomously navigating to a desired location then deploying to a standard CDPR. In this paper, we analyze the Static equilibrium (SE) of the mobile bases when the system is fully deployed. In contrast to classical CDPRs we show that the workspace of the MCDPR depends, not only on the tension limits, but on the SE constraints as well. We demonstrate how to construct the Available Wrench Set (AWS) for a planar MCDPR wih a point-mass end-effector using both the convex hull and Hyperplane shifting methods. The obtained results are validated in simulation and on an experimental platform consisting of two mobile bases and a CDPR with four cables.
keywords: {Task analysis;Parallel robots;Power cables;Collision avoidance;Prototypes;Wheels},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461199&isnumber=8460178

S. Schulz, A. Seibel and J. Schlattmann, "Closed-form Solution for the Direct Kinematics Problem of the Planar 3-RPR Parallel Mechanism," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 968-973.
doi: 10.1109/ICRA.2018.8460544
Abstract: In general, it is not possible to determine the actual manipulator platform's pose of a parallel mechanism from its active joints' coordinates. This problem is usually solved by using additional numerical procedures or by additional system information from auxiliary sensors, providing several weaknesses including initial pose estimations, reference drives, or workspace limitations. In this paper, we therefore introduce a closed-form solution for the direct kinematics problem of the planar 3-RPR parallel mechanism by using only the orientations of two active joints and the manipulator platform, where P denotes active prismatic joints and R passive revolute joints.
keywords: {Manipulators;Kinematics;Actuators;Sensors;Closed-form solutions;Legged locomotion;Conferences},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460544&isnumber=8460178

J. M. Porta and F. Thomas, "Yet Another Approach to the Gough-Stewart Platform Forward Kinematics," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 974-980.
doi: 10.1109/ICRA.2018.8460900
Abstract: The forward kinematics of the Gough-Stewart platform, and their simplified versions in which some leg endpoints coalesce, has been typically solved using variable elimination methods. In this paper, we cast doubts on whether this is the easiest way to solve the problem. We will see how the indirect approach in which the length of some extra virtual legs is first computed leads to important simplifications. In particular, we provide a procedure to solve 30 out of 34 possible topologies for a Gough-Stewart platform without variable elimination.
keywords: {Legged locomotion;Topology;Kinematics;Distance measurement;Conferences;Automation;Australia},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460900&isnumber=8460178

L. Toohey, O. Pizarro and S. B. Williams, "Bounding Drift in Cooperative Localisation Through the Sharing of Local Loop Closures," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 981-987.
doi: 10.1109/ICRA.2018.8460820
Abstract: Handling loop closures and intervehicle observations in cooperative robotic scenarios remains a challenging problem due to data consistency, bandwidth limitations and increased computation requirements. This paper develops a general cooperative localisation and single vehicle Visual SLAM framework that includes direct intervehicle observations and pose to pose loop closures on each vehicle with states shared as required. This fuses single vehicle SLAM with cooperative localisation and avoids data association of map data across limited communication networks. The base problem is developed as a factor graph with each vehicle solving local subgraphs that are split based on intervehicle observations. We modify the order of variable elimination in subgraphs through manipulation of the square-root of the Information matrix to extract updates that include the historic states involved in the loop closures and do not require transmission of other states not involved in the measurement or retransmission of previously shared states. We demonstrate the effect on localisation accuracy and bandwidth using data captured from a set of five robots observing each other and landmarks compared to both single vehicle SLAM, pure cooperative localisation and a centralised solution.
keywords: {Simultaneous localization and mapping;Bandwidth;Jacobian matrices;Visualization;Message systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460820&isnumber=8460178

X. Wang, H. Zhang, X. Yin, M. Du and Q. Chen, "Monocular Visual Odometry Scale Recovery Using Geometrical Constraint," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 988-995.
doi: 10.1109/ICRA.2018.8462902
Abstract: Scale recovery is one of the essential problems for monocular visual odometry. The camera height is usually used as an absolute reference to recover the scale. In this case, the precision of scale recovery depends on the accuracy of the road region detection and road geometrical model calculation. In previous works, road detection and road geometrical model calculation are solved sequentially: the road geometrical model calculation is based on the road detection and the road region detection is based on the color information. However, the color information of a road is not stable enough. In the proposed method, the estimated road geometrical model is taken into consideration to detect the road region as a feedback. Therefore, the road region detection and road geometrical model estimation can benefit each other. Delaunay Triangulation method is used to segment an input image to many triangles with the matched feature points as vertices. Every triangle region is classified as a road region or not by comparing their geometrical model with that of the road and the road geometrical model is updated online. We evaluate our visual odometry scale recovery method on the KITTI dataset and the results show that our method is achieving the best performance among all existing monocular visual odometry scale recovery methods without additional sensors.
keywords: {Roads;Cameras;Visual odometry;Three-dimensional displays;Robot vision systems;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462902&isnumber=8460178

B. P. W. Babu, D. Cyganski, J. Duckworth and S. Kim, "Detection and Resolution of Motion Conflict in Visual Inertial Odometry," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 996-1002.
doi: 10.1109/ICRA.2018.8460870
Abstract: In this paper, we present a novel method to detect and resolve motion conflicts in visual-inertial odometry. Recently, it has been common to integrate an IMU sensor with visual odometry in order to improve localization accuracy and robustness. However, when a disagreement between the two sensor modalities occurs, the localization accuracy reduces drastically and leads to irreversible errors. In such conditions, multiple motion estimates based on the set of observations used are possible. This creates a conflict (motion conflict) in determining which observations to use for accurate ego-motion estimation. Therefore, we present a method to detect motion conflicts based on per-frame positional estimate discrepancy and per-landmark reprojection errors. Additionally, we also present a method to resolve motion conflicts by eliminating inconsistent IMU and landmark measurements. Finally, we implement Motion Conflict aware Visual Inertial Odometry (MC-VIO) by combining both detection and resolution of motion conflicts. We perform quantitative and qualitative evaluation of MC-VIO on visually and inertially challenging datasets. Experimental results indicate that the MC-VIO algorithm reduces the increase in absolute trajectory error by 80% and the relative pose error by 60% for scenes with motion conflict, in comparison to the state-of-the-art reference VIO algorithm.
keywords: {Visualization;Cameras;Estimation;Robustness;Simultaneous localization and mapping;Hidden Markov models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460870&isnumber=8460178

S. Nobili, G. Tinchev and M. Fallon, "Predicting Alignment Risk to Prevent Localization Failure," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1003-1010.
doi: 10.1109/ICRA.2018.8462890
Abstract: During localization and mapping the success of point cloud registration can be compromised when there is an absence of geometric features or constraints in corridors or across doorways, or when the volumes scanned only partly overlap, due to occlusions or constrictions between subsequent observations. This work proposes a strategy to predict and prevent laser-based localization failure. Our solution relies on explicit analysis of the point cloud content prior to registration. A model predicting the risk of a failed alignment is learned by analysing the degree of spatial overlap between two input point clouds and the geometric constraints available within the region of overlap. We define a novel measure of alignability for these constraints. The method is evaluated against three real-world datasets and compared to baseline approaches. The experiments demonstrate how our approach can help improve the reliability of laser-based localization during exploration of unknown and cluttered man-made environments.
keywords: {Three-dimensional displays;Cloud computing;Robot sensing systems;Measurement;Iterative closest point algorithm;Octrees},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462890&isnumber=8460178

H. Porav, W. Maddern and P. Newman, "Adversarial Training for Adverse Conditions: Robust Metric Localisation Using Appearance Transfer," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1011-1018.
doi: 10.1109/ICRA.2018.8462894
Abstract: We present a method of improving visual place recognition and metric localisation under very strong appearance change. We learn an invertable generator that can transform the conditions of images, e.g. from day to night, summer to winter etc. This image transforming filter is explicitly designed to aid and abet feature-matching using a new loss based on SURF detector and dense descriptor maps. A network is trained to output synthetic images optimised for feature matching given only an input RGB image, and these generated images are used to localize the robot against a previously built map using traditional sparse matching approaches. We benchmark our results using multiple traversals of the Oxford RobotCar Dataset over a year-long period, using one traversal as a map and the other to localise. We show that this method significantly improves place recognition and localisation under changing and adverse conditions, while reducing the number of mapping runs needed to successfully achieve reliable localisation.
keywords: {Generators;Detectors;Measurement;Feature extraction;Computer architecture;Training;Pipelines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462894&isnumber=8460178

F. Yang and N. Chakraborty, "Algorithm for Optimal Chance Constrained Knapsack Problem with Applications to Multi-Robot Teaming," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1043-1049.
doi: 10.1109/ICRA.2018.8461040
Abstract: Motivated by applications in multirobot team selection, in this paper, we present a novel algorithm for computing optimal solution of chance-constrained 0-1 knapsack problem. In this variation of the knapsack problem, the objective function is deterministic but the weights of the items are stochastic and therefore the knapsack constraint is stochastic. We convert the chance-constrained knapsack problem to a two-dimensional discrete optimization problem on the variance-mean plane, where each point on the plane can be identified with an assignment of items to the knapsack. By exploiting the geometry of the non-convex feasible region of the chance-constrained knapsack problem in the variance-mean plane, we present a novel deterministic technique to find an optimal solution by solving a sequence of deterministic knapsack problems (called risk-averse knapsack problem). We apply our algorithm to a multirobot team selection problem to cover a given route, where the length of the route is much larger than the length each individual robot can fly and the length that an individual robot can fly is a random variable (with known mean and variance). We present simulation results on randomly generated data to demonstrate that our approach is scalable with both the number of robots and increasing uncertainty of the distance an individual robot can travel.
keywords: {Robots;Optimization;Random variables;Task analysis;Batteries;Linear programming;Approximation algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461040&isnumber=8460178

G. Best, M. Forrai, R. R. Mettu and R. Fitch, "Planning-Aware Communication for Decentralised Multi-Robot Coordination," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1050-1057.
doi: 10.1109/ICRA.2018.8460617
Abstract: We present an algorithm for selecting when to communicate during online planning phases of coordinated multi-robot missions. The key idea is that a robot decides to request communication from another robot by reasoning over the predicted information value of communication messages over a sliding time-horizon, where communication messages are probability distributions over action sequences. We formulate this problem in the context of the recently proposed decentralised Monte Carlo tree search (Dec-MCTS) algorithm for online, decentralised multi-robot coordination. We propose a particle filter for predicting the information value, and a polynomial-time belief-space planning algorithm for finding the optimal communication schedules in an online and decentralised manner. We evaluate the benefit of informative communication planning for a multi-robot information gathering scenario with 8 simulated robots. Our results show reductions in channel utilisation of up to four-fifths with surprisingly little impact on coordination performance.
keywords: {Planning;Robot kinematics;Prediction algorithms;Probability distribution;Australia;Cognition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460617&isnumber=8460178

D. Şenel, H. I. Bozma and F. Öztürk, "Multi-Robot Realization Based on Goal Adjacency Constraints," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1058-1063.
doi: 10.1109/ICRA.2018.8460830
Abstract: This paper considers the problem of multi-robot realization. A realization is a set of robot positions where pairwise distances are either bounded from above or from below by a given adjacency threshold - depending on whether the respective robot pairs are to be adjacent or not. In the realization problem, unlike the related coordinated navigation or formation control problems, exact goal positions or relative distances need not be specified. Rather, only pairwise adjacency constraints are given and the robots' positions are required to satisfy these constraints. Applications of realization problem include multi-robots involved in team games (playing soccer, etc), patrolling and area coverage. We present a novel solution to this problem in which the robots simultaneously navigate to find a realization of a given adjacency matrix without colliding with each other along the way. In this solution, complete information about pairwise distances and free configuration space are encoded using an artificial potential function over the cross product space of the robots' simultaneous positions and proximity variables. The closed-loop dynamics governing the motion of each velocity-controlled robot take the form of the appropriate projection of the gradient of this function while pairwise distances are adjusted accordingly. Our extensive simulations demonstrate that the proposed approach has considerably higher realization percentage and shorter movement distances in comparison to a standard 2-stage approach.
keywords: {Conferences;Automation;Australia},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460830&isnumber=8460178

Z. Wang, S. Singh, M. Pavone and M. Schwager, "Cooperative Object Transport in 3D with Multiple Quadrotors Using No Peer Communication," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1064-1071.
doi: 10.1109/ICRA.2018.8460742
Abstract: We present a framework to enable a fleet of rigidly attached quadrotor aerial robots to transport heavy objects along a known reference trajectory without inter-robot communication or centralized coordination. Leveraging a distributed wrench controller, we provide exponential stability guarantees for the entire assembly, under a mild geometric condition. This is achieved by each quadrotor independently solving a local optimization problem to counteract the biased torque effects from each robot in the assembly. We rigorously analyze the controllability of the object, design a distributed compensation scheme to address these challenges, and show that the resulting strategy collectively guarantees full group control authority. To ensure feasibility for online implementation, we derive bounds on the net desired control wrench, characterize the output wrench space of each quadrotor, and perform subsequent trajectory optimization under these input constraints. We thoroughly validate our method in simulation with eight quadrotors transporting a heavy object in a cluttered environment subject to various sources of uncertainty, and demonstrate the algorithm's resilience.
keywords: {Robot kinematics;Trajectory;Torque;Three-dimensional displays;Payloads;Unmanned aerial vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460742&isnumber=8460178

M. De Stefano, R. Balachandran, A. M. Giordano, C. Ott and C. Secchi, "An Energy-Based Approach for the Multi-Rate Control of a Manipulator on an Actuated Base," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1072-1077.
doi: 10.1109/ICRA.2018.8460497
Abstract: In this paper we address the problem of controlling a robotic system mounted on an actuated floating base for space applications. In particular, we investigate the stability issues due to the low rate of the base control unit. We propose a passivity-based stabilizing controller based on the time domain passivity approach. The controller uses a variable damper regulated by a designed energy observer. The effectiveness of the proposed strategy is validated on a base-manipulator multibody simulation.
keywords: {Manipulators;Satellites;Jacobian matrices;Stability analysis;Delays;Time-domain analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460497&isnumber=8460178

J. Liu and R. K. Williams, "Optimal Intermittent Deployment and Sensor Selection for Environmental Sensing with Multi-Robot Teams," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1078-1083.
doi: 10.1109/ICRA.2018.8460215
Abstract: In this paper, we formulate an environmental sensing problem for multi-robot teams that couples intermittent deployments with the selection of team composition and sensor type over time. We suppose that a multi-robot team needs to autonomously sense an environmental process and find the optimal policy for deploying heterogeneous robots. In addition, heterogeneous robot teams can be composed in various ways by selecting different mobility and sensor types which have varying accuracies and costs, resulting in a more complex problem. The question is then how to find an optimal intermittent deployment and sensor selection policy that captures both cost and estimation accuracy based on partial environmental information. By utilizing structural results from partially observable Markov decision processes (POMDP) and exploiting submodularity, an optimal policy, which minimizes cost while maintaining a high accuracy, can be achieved in this paper. The effectiveness of this method is demonstrated by simulation results and comparisons with naive policies.
keywords: {Robot sensing systems;Robot kinematics;Markov processes;Computational modeling;Delays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460215&isnumber=8460178

M. Lippi and A. Marino, "Cooperative Object Transportation by Multiple Ground and Aerial Vehicles: Modeling and Planning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1084-1090.
doi: 10.1109/ICRA.2018.8460778
Abstract: In this paper the modeling and planning problems of a system composed of multiple ground and aerial robots involved in a transportation task are considered. The ground robots rigidly grasp a load, while the aerial vehicles are attached to the object through non-rigid inextensible cables. The idea behind such a heterogeneous multi-robot system is to benefit of the advantages of both types of robots that might be the precision of ground robots, the increased payload of multiple aerial vehicles and their larger workspace. The overall model of the system is derived and its expression and redundancy are exploited by setting a general constrained optimal planning problem. The problem is herein solved by dynamic programming and simulation results validated the proposed scheme.
keywords: {Vehicle dynamics;Manipulators;Load modeling;Unmanned aerial vehicles;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460778&isnumber=8460178

P. Bechon, M. Barbier, C. Grand, S. Lacroix, C. Lesire and C. Praiet, "Integrating Planning and Execution for a Team of Heterogeneous Robots with Time and Communication Constraints," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1091-1097.
doi: 10.1109/ICRA.2018.8461024
Abstract: Field multi-robot missions face numerous unavoidable disturbances, such as delays in executing tasks and intermittent communications. Coping with such disturbances requires to endow the robots with high-level decision skills. We present a distributed decision architecture based first on a hybrid planner that can manage decentralized repairs with partial communication, and secondly on a distributed execution algorithm that efficiently propagates delays. This architecture has been successfully experimented on the field for the achievement of surveillance missions involving eight (8) real autonomous aerial and ground robots.
keywords: {Maintenance engineering;Planning;Computer architecture;Robot kinematics;Surveillance;Delays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461024&isnumber=8460178

Y. Jiang and C. K. Liu, "Data-Driven Approach to Simulating Realistic Human Joint Constraints," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1098-1103.
doi: 10.1109/ICRA.2018.8461010
Abstract: Modeling realistic human joint limits is important for applications involving physical human-robot interaction. However, setting appropriate human joint limits is challenging because it is pose-dependent: the range of joint motion varies depending on the positions of other bones. The paper introduces a new technique to accurately simulate human joint limits in physics simulation. We propose to learn an implicit equation to represent the boundary of valid human joint configurations from real human data. The function in the implicit equation is represented by a fully connected neural network whose gradients can be efficiently computed via back-propagation. Using gradients, we can efficiently enforce realistic human joint limits through constraint forces in a physics engine or as constraints in an optimization problem.
keywords: {Joints;Mathematical model;Physics;Robots;Neural networks;Elbow;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461010&isnumber=8460178

F. Chao et al., "Generative Adversarial Nets in Robotic Chinese Calligraphy," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1104-1110.
doi: 10.1109/ICRA.2018.8460787
Abstract: Conventional approaches of robotic writing of Chinese character strokes often suffer from limited font generation methods, and thus the writing results often lack of diversity. This has seriously restricted the high quality writing ability of robots. This paper proposes a generative adversarial nets-based calligraphic robotic framework, which enables a robot to learn writing fundamental Chinese strokes with rich diversity and good originality. In particular, the framework considers the learning process of robotic writing as an adversarial procedure which is implemented by three interactive modules including a stroke generation module, a stroke discriminative module and a training module. Noting that the stroke generative module included in the conventional generative adversarial nets cannot solve the non-differentiable problem, the policy gradient commonly used in reinforcement learning is thus adapted in this work to train the generative module by regarding the outputs from the discriminative module as rewards. Experimental results demonstrate that the proposed framework allows a calligraphic robot to successfully write fundamental Chinese strokes with good quality in various styles. The experiment also suggests the proposed approach can achieve human-level stroke writing quality without the requirement of a performance evaluation system. This approach therefore significantly boosts the robotic autonomous creation ability.
keywords: {Writing;Trajectory;Training;Gallium nitride;Manipulators;Probability distribution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460787&isnumber=8460178

L. Tai, J. Zhang, M. Liu and W. Burgard, "Socially Compliant Navigation Through Raw Depth Inputs with Generative Adversarial Imitation Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1111-1117.
doi: 10.1109/ICRA.2018.8460968
Abstract: We present an approach for mobile robots to learn to navigate in dynamic environments with pedestrians via raw depth inputs, in a socially compliant manner. To achieve this, we adopt a generative adversarial imitation learning (GAIL) strategy, which improves upon a pre-trained behavior cloning policy. Our approach overcomes the disadvantages of previous methods, as they heavily depend on the full knowledge of the location and velocity information of nearby pedestrians, which not only requires specific sensors, but also the extraction of such state information from raw sensory input could consume much computation time. In this paper, our proposed GAIL-based model performs directly on raw depth inputs and plans in real-time. Experiments show that our GAIL-based approach greatly improves the safety and efficiency of the behavior of mobile robots from pure behavior cloning. The real-world deployment also shows that our method is capable of guiding autonomous vehicles to navigate in a socially compliant manner directly through raw depth inputs. In addition, we release a simulation plugin for modeling pedestrian behaviors based on the social force model.
keywords: {Force;Navigation;Cloning;Sensors;Mobile robots;Learning (artificial intelligence);Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460968&isnumber=8460178

Y. Liu, A. Gupta, P. Abbeel and S. Levine, "Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1118-1125.
doi: 10.1109/ICRA.2018.8462901
Abstract: Imitation learning is an effective approach for autonomous systems to acquire control policies when an explicit reward function is unavailable, using supervision provided as demonstrations from an expert, typically a human operator. However, standard imitation learning methods assume that the agent receives examples of observation-action tuples that could be provided, for instance, to a supervised learning algorithm. This stands in contrast to how humans and animals imitate: we observe another person performing some behavior and then figure out which actions will realize that behavior, compensating for changes in viewpoint, surroundings, object positions and types, and other factors. We term this kind of imitation learning “imitation-from-observation,” and propose an imitation learning method based on video prediction with context translation and deep reinforcement learning. This lifts the assumption in imitation learning that the demonstration should consist of observations in the same environment configuration, and enables a variety of interesting applications, including learning robotic skills that involve tool use simply by observing videos of human tool use. Our experimental results show the effectiveness of our approach in learning a wide range of real-world robotic tasks modeled after common household chores from videos of a human demonstrator, including sweeping, ladling almonds, pushing objects as well as a number of tasks in simulation.
keywords: {Task analysis;Robots;Context modeling;Learning (artificial intelligence);Visualization;Tools;Cloning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462901&isnumber=8460178

R. A. Gutierrez, V. Chu, A. L. Thomaz and S. Niekum, "Incremental Task Modification via Corrective Demonstrations," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1126-1133.
doi: 10.1109/ICRA.2018.8461215
Abstract: In realistic environments, fully specifying a task model such that a robot can perform a task in all situations is impractical. In this work, we present Incremental Task Modification via Corrective Demonstrations (ITMCD), a novel algorithm that allows a robot to update a learned model by making use of corrective demonstrations from an end-user in its environment. We propose three different types of model updates that make structural changes to a finite state automaton (FSA) representation of the task by first converting the FSA into a state transition auto-regressive hidden Markov model (STARHMM). The STARHMM's probabilistic properties are then used to perform approximate Bayesian model selection to choose the best model update, if any. We evaluate ITMCD Model Selection in a simulated block sorting domain and the full algorithm on a real-world pouring task. The simulation results show our approach can choose new task models that sufficiently incorporate new demonstrations while remaining as simple as possible. The results from the pouring task show that ITMCD performs well when the modeled segments of the corrective demonstrations closely comply with the original task model.
keywords: {Hidden Markov models;Task analysis;Robots;Computational modeling;Adaptation models;Probabilistic logic;Bayes methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461215&isnumber=8460178

P. Sermanet et al., "Time-Contrastive Networks: Self-Supervised Learning from Video," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1134-1141.
doi: 10.1109/ICRA.2018.8462891
Abstract: We propose a self-supervised approach for learning representations and robotic behaviors entirely from unlabeled videos recorded from multiple viewpoints, and study how this representation can be used in two robotic imitation settings: imitating object interactions from videos of humans, and imitating human poses. Imitation of human behavior requires a viewpoint-invariant representation that captures the relationships between end-effectors (hands or robot grippers) and the environment, object attributes, and body pose. We train our representations using a triplet loss, where multiple simultaneous viewpoints of the same observation are attracted in the embedding space, while being repelled from temporal neighbors which are often visually similar but functionally different. This signal causes our model to discover attributes that do not change across viewpoint, but do change across time, while ignoring nuisance variables such as occlusions, motion blur, lighting and background. We demonstrate that this representation can be used by a robot to directly mimic human poses without an explicit correspondence, and that it can be used as a reward function within a reinforcement learning algorithm. While representations are learned from an unlabeled collection of task-related videos, robot behaviors such as pouring are learned by watching a single 3rd-person demonstration by a human. Reward functions obtained by following the human demonstrations under the learned representation enable efficient reinforcement learning that is practical for real-world robotic systems. Video results, open-source code and dataset are available at sermanet.github.io/imitate.
keywords: {Robots;Task analysis;Visualization;Learning (artificial intelligence);Training;Liquids;Lighting},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462891&isnumber=8460178

G. Sutanto, Z. Su, S. Schaal and F. Meier, "Learning Sensor Feedback Models from Demonstrations via Phase-Modulated Neural Networks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1142-1149.
doi: 10.1109/ICRA.2018.8460986
Abstract: In order to robustly execute a task under environmental uncertainty, a robot needs to be able to reactively adapt to changes arising in its environment. The environment changes are usually reflected in deviation from expected sensory traces. These deviations in sensory traces can be used to drive the motion adaptation, and for this purpose, a feedback model is required. The feedback model maps the deviations in sensory traces to the motion plan adaptation. In this paper, we develop a general data-driven framework for learning a feedback model from demonstrations. We utilize a variant of a radial basis function network structure -with movement phases as kernel centers- which can generally be applied to represent any feedback models for movement primitives. To demonstrate the effectiveness of our framework, we test it on the task of scraping on a tilt board. In this task, we are learning a reactive policy in the form of orientation adaptation, based on deviations of tactile sensor traces. As a proof of concept of our method, we provide evaluations on an anthropomorphic robot.
keywords: {Robot sensing systems;Adaptation models;Task analysis;Mathematical model;Neural networks;Quaternions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460986&isnumber=8460178

M. Wigness, J. G. Rogers and L. E. Navarro-Serment, "Robot Navigation from Human Demonstration: Learning Control Behaviors," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1150-1157.
doi: 10.1109/ICRA.2018.8462900
Abstract: When working alongside human collaborators in dynamic environments such as a disaster recovery, an unmanned ground vehicle (UGV) may require fast field adaptation to perform its duties or learn novel tasks. In disaster recovery situations, personnel and equipment are constrained, so training must be accomplished with minimal human supervision. In this paper, we introduce a novel framework which uses learned visual perception and inverse optimal control trained with minimal human supervisory examples. This approach is used to learn to mimic navigation behavior and is demonstrated through extensive evaluation in a real-world environment. Finally, we demonstrate the ability to learn an additional behavior with minimal human demonstration in the field.
keywords: {Navigation;Robots;Trajectory;Entropy;Training;Collision avoidance;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462900&isnumber=8460178

T. Qin, P. Li and S. Shen, "Relocalization, Global Optimization and Map Merging for Monocular Visual-Inertial SLAM," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1197-1204.
doi: 10.1109/ICRA.2018.8460780
Abstract: The monocular visual-inertial system (VINS), which consists one camera and one low-cost inertial measurement unit (IMU), is a popular approach to achieve accurate 6-DOF state estimation. However, such locally accurate visual-inertial odometry is prone to drift and cannot provide absolute pose estimation. Leveraging history information to relocalize and correct drift has become a hot topic. In this paper, we propose a monocular visual-inertial SLAM system, which can relocalize camera and get the absolute pose in a previous-built map. Then 4-DOF pose graph optimization is performed to correct drifts and achieve global consistent. The 4-DOF contains x, y, z, and yaw angle, which is the actual drifted direction in the visual-inertial system. Furthermore, the proposed system can reuse a map by saving and loading it in an efficient way. Current map and previous map can be merged together by the global pose graph optimization. We validate the accuracy of our system on public datasets and compare against other state-of-the-art algorithms. We also evaluate the map merging ability of our system in the large-scale outdoor environment. The source code of map reuse is integrated into our public code, VINS-Monol11https://github.com/HKUST-Aerial-Robotics/VINS-Mono.
keywords: {Cameras;Optimization;Visualization;Feature extraction;Microsoft Windows;Simultaneous localization and mapping;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460780&isnumber=8460178

C. Park, P. Moghadam, S. Kim, A. Elfes, C. Fookes and S. Sridharan, "Elastic LiDAR Fusion: Dense Map-Centric Continuous-Time SLAM," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1206-1213.
doi: 10.1109/ICRA.2018.8462915
Abstract: The concept of continuous-time trajectory representation has brought increased accuracy and efficiency to multi-modal sensor fusion in modern SLAM. However, regardless of these advantages, its offline property caused by the requirement of global batch optimization is critically hindering its relevance for real-time and life-long applications. In this paper, we present a dense map-centric SLAM method based on a continuous-time trajectory to cope with this problem. The proposed system locally functions in a similar fashion to conventional Continuous-Time SLAM (CT-SLAM). However, it removes the need for global trajectory optimization by introducing map deformation. The computational complexity of the proposed approach for loop closure does not depend on the operation time, but only on the size of the space it explored before the loop closure. It is therefore more suitable for long term operation compared to the conventional CT-SLAM. Furthermore, the proposed method reduces uncertainty in the reconstructed dense map by using probabilistic surface element (surfel) fusion. We demonstrate that the proposed method produces globally consistent maps without global batch trajectory optimization, and effectively reduces LiDAR noise by surfel fusion.
keywords: {Laser radar;Trajectory optimization;Simultaneous localization and mapping;Strain;Interpolation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462915&isnumber=8460178

S. J. Lee, J. Yoo and H. J. Kim, "Design, modeling and control of t3-multirotor: a tilting thruster type multirotor," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1214-1219.
doi: 10.1109/ICRA.2018.8462888
Abstract: This paper presents a new design of multirotor, named as `Tilting Thruster Type' (T3)-multirotor. The new platform is equipped with mechanically separated thrusters, which can take any fuselage posture within a specified range regardless of any direction of translational acceleration. A specially designed servo-linkage mechanism is employed for relative attitude control between the thruster and the fuselage. Mathematical modeling and analysis of the new platform are conducted to explore the control method of the dynamically complex system. For demonstrating the potential of the new T3-multirotor, an autonomous level flight is performed where the fuselage maintains zero roll and pitch angle during the entire flight. Both simulation and experimental results are provided with detailed analysis.
keywords: {Servomotors;Mathematical model;Force;Torque;Dynamics;Attitude control;Analytical models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462888&isnumber=8460178

J. Moore, A. Fein and W. Setzler, "Design and Analysis of a Fixed-Wing Unmanned Aerial-Aquatic Vehicle," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1236-1243.
doi: 10.1109/ICRA.2018.8461240
Abstract: In this paper, we describe the design and analysis of a fixed-wing unmanned aerial-aquatic vehicle. Inspired by prior work in aerobatic post-stall maneuvers for fixed-wing vehicles [1], we explore the feasibility of executing a water-to-air transition with a fixed-wing vehicle using almost entirely commercial off-the-shelf components (excluding the fuselage). To do this, we first propose a conceptual design based on observations about the dominant forces and dimensionless analysis. We then further refine this concept by building a design tool based on simplified models to explore the design space. To verify the results of the design tool, we use a higher fidelity model along with a direct hybrid trajectory optimization approach to show via numerical simulation that the water-to-air transition is feasible. Finally, we successfully test our design experimentally by hand-piloting a prototype vehicle through the water-to-air transition and discuss our approach for replacing the human-pilot with closed-loop control.
keywords: {Propellers;Vehicle dynamics;Prototypes;Unmanned aerial vehicles;Design tools},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461240&isnumber=8460178

S. A. Conyers, M. J. Rutherford and K. P. Valavanis, "An Empirical Evaluation of Ground Effect for Small-Scale Rotorcraft," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1244-1250.
doi: 10.1109/ICRA.2018.8461035
Abstract: Ground effect refers to the apparent increase in lift that an aircraft experiences when it flies close to the ground. For helicopters, this effect has been modeled since the 1950's based on the work of Cheeseman and Bennett, perhaps the most common method for predicting hover performance due to ground effect. This model, however, is based on assumptions that do not hold for small-scale rotorcraft because it was developed specifically for conventional helicopters. It is not clear if the Cheeseman-Bennett model can be applied to today's multirotor UAVs. In this paper, we compare the Cheeseman-Bennett model to experimental results for rotor performance due to ground effect in several small-scale multirotor and single-rotor configurations. Experimental findings suggest that some of the conventional thinking surrounding helicopter ground effect cannot be applied directly to rotorcraft using fixed propellers at variable speeds (e.g. multirotors), and that it is necessary to adjust the helicopter models to better reflect the differences in such aircraft. The experimental results for multirotors presented are for multiple propeller configurations, speeds and spacings. Ultimately, this work will facilitate the development of an improved UAV flight controller that can accurately account for ground effect to improve flight stability near surfaces and structures.
keywords: {Rotors;Propellers;Mathematical model;Atmospheric modeling;Blades;Helicopters},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461035&isnumber=8460178

N. Kingry et al., "Design, Modeling and Control of a Solar-Powered Quadcopter," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1251-1258.
doi: 10.1109/ICRA.2018.8462896
Abstract: This paper presents the design, modeling, control, and experimental test of a solar-powered quadcopter to allow for long-endurance missions. We first present the design of a large-scale quadcopter that incorporates solar energy harvesting capabilities. Based on the design results, we built the dynamical model of the customized quadcopter with analysis of the aerodynamic influence. A feedback control system is developed for the solar-powered quadcopter that takes into account the wind disturbance and is verified in virtual simulation examples. All parameters used in the modeling and simulations are based on a developed prototype of the solar-powered quadcopter. Flight tests with the prototype are presented to validate the feasibility and theoretical basis of the solar-powered quadcopter.
keywords: {Solar panels;Prototypes;Batteries;Photovoltaic cells;Payloads;Propellers;Aerodynamics;Solar Energy;Quadcopter;System Design;Vehicle Control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462896&isnumber=8460178

G. D. Bousquet, M. S. Triantafyllou and J. E. Slotine, "The UNAV, a Wind-Powered UAV for Ocean Monitoring: Performance, Control and Validation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1259-1266.
doi: 10.1109/ICRA.2018.8462893
Abstract: Wind power is the source of propulsive energy for sailboats and albatrosses. We present the UNAv, an Unmanned Nautical Air-water vehicle, that borrows features from both. It is composed of a glider-type airframe fitted with a vertical wing-sail extending above the center of mass of the system and a vertical surface-piercing hydrofoil keel extending below. The sail and keel are both actuated in pitch about their span-wise axes. Like an albatross, the UNAv is fully streamlined, high lift-to-drag ratio and generates the gravity-cancelling force by means of its airborne wings. Like a sailboat, the UNAv interacts with water and may access the full magnitude of the wind. A trim analysis predicts that a 3.4-meter span, 3 kg system could stay airborne in winds as low as 2.8 m/s (5.5 knots), and travel several times faster than the wind speed. Trim flight requires the ability to fly at extreme low height with the keel immersed in water. For that purpose, a multi-input longitudinal flight controller that leverages fast flap actuation is presented. The flight maneuver is demonstrated experimentally.
keywords: {Drag;Force;Sea surface;Aerodynamics;Wind;Atmospheric modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462893&isnumber=8460178

A. Viseras, Z. Xu and L. Merino, "Distributed Multi-Robot Cooperation for Information Gathering Under Communication Constraints," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1267-1272.
doi: 10.1109/ICRA.2018.8460846
Abstract: Many recent works have proposed algorithms for information gathering that benefit from multi-robot cooperation. However, most algorithms either employ discretization of the state and action spaces, which makes them computationally intractable for robotic systems with complex dynamics; or cannot deal with inter-robot restrictions like e.g. communication constraints. This paper presents an approach for multi-robot information gathering that tackles the two aforementioned issues. To this end we propose an algorithm that combines in an innovative manner Gaussian processes (GPs) to model the physical process of interest, RRT planners to plan paths in a continuous domain, and a distributed decision-making algorithm to achieve multi-robot cooperation. Specifically, we employ the Max-sum algorithm for distributed multi-robot cooperation by defining an information-theoretic utility function together with a path clustering approach. This function maximizes information gathering, subject to inter-robot communication constraints. We validate the proposed approach in simulations, and in a field experiment where three quadcopters explore a simulated wind field. Results demonstrate the effectiveness of the approach.
keywords: {Clustering algorithms;Robot kinematics;Robot sensing systems;Heuristic algorithms;Linear programming},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460846&isnumber=8460178

C. D'Ettorre et al., "Automated Pick-Up of Suturing Needles for Robotic Surgical Assistance," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1370-1377.
doi: 10.1109/ICRA.2018.8461200
Abstract: Robot-assisted laparoscopic prostatectomy (RALP) is a treatment for prostate cancer that involves complete or nerve sparing removal prostate tissue that contains cancer. After removal the bladder neck is successively sutured directly with the urethra. The procedure is called urethrovesical anastomosis and is one of the most dexterity demanding tasks during RALP. Two suturing instruments and a pair of needles are used in combination to perform a running stitch during urethrovesical anastomosis. While robotic instruments provide enhanced dexterity to perform the anastomosis, it is still highly challenging and difficult to learn. In this paper, we presents a vision-guided needle grasping method for automatically grasping the needle that has been inserted into the patient prior to anastomosis. We aim to automatically grasp the suturing needle in a position that avoids hand-offs and immediately enables the start of suturing. The full grasping process can be broken down into: a needle detection algorithm; an approach phase where the surgical tool moves closer to the needle based on visual feedback; and a grasping phase through path planning based on observed surgical practice. Our experimental results show examples of successful autonomous grasping that has the potential to simplify and decrease the operational time in RALP by assisting a small component of urethrovesical anastomosis.
keywords: {Needles;Grasping;Robots;Tools;Instruments;Surgery;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461200&isnumber=8460178

N. Evangeliou and A. Tzes, "A Hybrid Actuated Robotic Prototype for Minimally Invasive Surgery," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1386-1391.
doi: 10.1109/ICRA.2018.8460640
Abstract: This article presents the design and experimental evaluation of a prototype robotic platform for minimally invasive surgical procedures. The platform utilizes a hybrid actuation scheme, consisting of a 5 Degree-of-Freedom (DoF) servo-actuated manipulator for extra-operative and pivoting motion and a 4 DoF shape memory alloy actuated probe at the distal end, for intra-operative dexterity. The architecture targets thoracic and abdominal operations, with low interaction forces at the probe's end-effector. The system, runs under the Robot Operating System framework for easier deployment and development. Additional accompanying software is developed to aid the surgeon during deployment. Specifically, a Graphical User Interface employing modules controls for online parameter reconfiguration, operation mode switching while custom viewports for stereo imaging are implemented. Teleoperation is feasible with the integration of a haptic device. In-vitro evaluation of the robot is presented, to assess the maneuvering efficiency and further potential exploitation of the design.
keywords: {Probes;Manipulators;Actuators;Wires;Kinematics;Minimally Invasive Surgery;Robot Assisted Surgery;Shape Memory Alloy actuation;Visual Servoing;Medical Imaging},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460640&isnumber=8460178

X. Liu, R. A. Yazdanpanah, T. Zuo, Y. Guan, G. J. Mancini and J. Tan, "Design and Test of an In-Vivo Robotic Camera Integrated with Optimized Illumination System for Single-port Laparoscopic Surgery," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1392-1397.
doi: 10.1109/ICRA.2018.8460614
Abstract: This paper proposes a novel in-vivo robotic laparo-scopic camera design with an optimized illumination system, which is a crucial component for achieving high imaging quality. The robotic camera design with three extendable wings can reserve sufficient on-board space to harbor the optimized illumination system without affecting the compactness of the camera. We contribute a freeform optical lens design method and develop three miniature optical lenses for the LEDs to achieve greater than 95% illumination uniformity, greater than 14, 000 lx illuminance on a target plane with a distance of 100 mm, and greater than 89% optical efficiency. The prototype is implemented and experimentally tested, which demonstrates great performance of the in-vivo robotic laparoscopic camera and the significance of the optimized illumination system.
keywords: {Cameras;Robot vision systems;Lighting;Lenses;Laparoscopes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460614&isnumber=8460178

T. Cheng, X. Zhang, C. S. H. Ng, P. W. Y. Chiu and Z. Li, "A Novel Magnetic Anchored and Steered Camera Robot for Single Port Access Surgery," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1406-1412.
doi: 10.1109/ICRA.2018.8460677
Abstract: This paper presents a novel magnetic anchored and steered camera robot intended for minimally invasive surgery (MIS), particularly for single port access (SPA) surgery. The design aims to achieve both compactness and a planar pan/tilt workspace (instead of hemispheric) to lower robot footprint in vertical space. Robot comprises two 6mm×6mm diametrically magnetized internal permanent magnets (IPMs) fixed at either ends of a small cylindrical capsule, with camera module and a 45°mirror capped inside capsule. As such, camera view orientation can be steered in 2-DOF across range of 180° tilt and 360° panning, all within a planar workspace close to surface of anchor. Using only two small IPMs for all necessary functions (anchoring, translation along intra-abdominal surface, and steering) reduces bulk and length of robot. The robot is investigated first by finite element methods. Theoretical models for both tilting and panning were then built based on FEM results. The models are evaluated and verified by checking its predictions in benchtop experiments. Ex vivo evaluations was also utilized to prove feasibility of device in environment similar to human anatomy. Overall, the camera robot prototype is compact (4cm length; 7mm diameter), lightweight (3.6g), motor-free, and allow view orientation control (tilting and panning) in a planar workspace. Minimal footprint in vertical space is ideal for many MIS applications, where vertical space is extremely limited.
keywords: {Cameras;Robot vision systems;Magnetic separation;Soft magnetic materials;Surgery;Instruments},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460677&isnumber=8460178

S. Verma et al., "Vehicle Detection, Tracking and Behavior Analysis in Urban Driving Environments Using Road Context," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1413-1420.
doi: 10.1109/ICRA.2018.8460951
Abstract: We present a real-time vehicle detection and tracking system to accomplish the complex task of driving behavior analysis in urban environments. We propose a robust fusion system that combines a monocular camera and a 2D Lidar. This system takes advantage of three key components: robust vehicle detection using deep learning techniques, high precision range estimation from Lidar, and road context from the prior map knowledge. The camera and Lidar sensor fusion, data association and track management are all performed in the global map coordinate system by taking into account the sensors' characteristics. Lastly, behavior reasoning is performed by examining the tracked vehicle states in the lane coordinate system in which the road context is encoded. We validated our approach by tracking a leading vehicle while it performed usual urban driving behaviors such as lane keeping, stop-and-go at intersections, lane changing, overtaking and turning. The leading vehicle was tracked consistently throughout the 2.3 km route and its behavior was classified reliably.
keywords: {Roads;Laser radar;Sensor fusion;Robot sensing systems;Vehicle detection;Estimation;Autonomous vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460951&isnumber=8460178

R. Mascaro, L. Teixeira, T. Hinzmann, R. Siegwart and M. Chli, "GOMSF: Graph-Optimization Based Multi-Sensor Fusion for robust UAV Pose estimation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1421-1428.
doi: 10.1109/ICRA.2018.8460193
Abstract: Achieving accurate, high-rate pose estimates from proprioceptive and/or exteroceptive measurements is the first step in the development of navigation algorithms for agile mobile robots such as Unmanned Aerial Vehicles (UAVs). In this paper, we propose a decoupled Graph-Optimization based Multi-Sensor Fusion approach (GOMSF) that combines generic 6 Degree-of-Freedom (DoF) visual-inertial odometry poses and 3 DoF globally referenced positions to infer the global 6 DoF pose of the robot in real-time. Our approach casts the fusion as a real-time alignment problem between the local base frame of the visual-inertial odometry and the global base frame. The alignment transformation that relates these coordinate systems is continuously updated by optimizing a sliding window pose graph containing the most recent robot's states. We evaluate the presented pose estimation method on both simulated data and large outdoor experiments using a small UAV that is capable to run our system onboard. Results are compared against different state-of-the-art sensor fusion frameworks, revealing that the proposed approach is substantially more accurate than other decoupled fusion strategies. We also demonstrate comparable results in relation with a finely tuned Extended Kalman Filter that fuses visual, inertial and GPS measurements in a coupled way and show that our approach is generic enough to deal with different input sources in a straightforward manner. Video - https//youtu.be/GIZNSZ2soL8.
keywords: {Robot sensing systems;Robot kinematics;Optimization;Pose estimation;Global Positioning System;Time measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460193&isnumber=8460178

M. Hua, N. Manerikar, T. Hamel and C. Samson, "Attitude, Linear Velocity and Depth Estimation of a Camera Observing a Planar Target Using Continuous Homography and Inertial Data," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1429-1435.
doi: 10.1109/ICRA.2018.8460512
Abstract: This paper revisits the problem of estimating the attitude, linear velocity and depth of an IMU-Camera with respect to a planar target. The considered solution relies on the measurement of the optical flow (extracted from the continuous homography) complemented with gyrometer and accelerometer measurements. The proposed deterministic observer is accompanied with an observability analysis that points out camera's motion excitation conditions whose satisfaction grants stability of the observer and convergence of the estimation errors to zero. The performance of the observer is illustrated by performing experiments on a testbed IMU-Camera system.
keywords: {Observers;Observability;Robot sensing systems;Accelerometers;Magnetometers;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460512&isnumber=8460178

K. Liu, K. Ok, W. Vega-Brown and N. Roy, "Deep Inference for Covariance Estimation: Learning Gaussian Noise Models for State Estimation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1436-1443.
doi: 10.1109/ICRA.2018.8461047
Abstract: We present a novel method of measurement covariance estimation that models measurement uncertainty as a function of the measurement itself. Existing work in predictive sensor modeling outperforms conventional fixed models, but requires domain knowledge of the sensors that heavily influences the accuracy and the computational cost of the models. In this work, we introduce Deep Inference for Covariance Estimation (DICE), which utilizes a deep neural network to predict the covariance of a sensor measurement from raw sensor data. We show that given pairs of raw sensor measurement and ground-truth measurement error, we can learn a representation of the measurement model via supervised regression on the prediction performance of the model, eliminating the need for hand-coded features and parametric forms. Our approach is sensor-agnostic, and we demonstrate improved covariance prediction on both simulated and real data.
keywords: {Robot sensing systems;Measurement uncertainty;Measurement errors;Covariance matrices;Predictive models;Estimation;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461047&isnumber=8460178

I. B. Wijayasinghe, M. N. Saadatzi, S. Abubakar and D. O. Popa, "A Study on Optimal Placement of Accelerometers for Pose Estimation of a Robot Arm," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1444-1451.
doi: 10.1109/ICRA.2018.8460501
Abstract: This study investigates the effects of inertial sensor placement and noise characteristics on the accuracy of robot pose estimation. Of course, most robots are equipped with joint angle encoders for pose estimation and end-effector positioning. However, in some situations, it's not possible or not desirable to introduce encoders on all joints. Such common examples include legged locomotion, dual arm co-manipulation, and prosthetic limbs. To tackle such situations, one solution is to embed inertial measurement units (IMUs) into artificial skin patches placed on robots' limbs and body. This work analyzes the effects of design parameters such as the number of sensors, their placement on the robot, and noise properties on the quality of robot pose estimation and its signal-to-noise Ratio (SNR). We study the benefits of using a large number of IMUs, which is possible due to the proliferation of inexpensive micro-machined sensors. We use Monte-Carlo simulations and experiments with a two-link robot arm to obtain the distributions of expected estimation error metric values for several accelerometer configurations, which are then compared to determine the optimal number and placement for the IMUs. Results show that the placement of at least two accelerometers on each link has the most significant impact on the pose estimation error, while using a larger number of accelerometers plays a less significant role in reducing the arm pose estimation error and resultant SNR.
keywords: {Robot sensing systems;Accelerometers;Manipulators;Pose estimation;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460501&isnumber=8460178

C. Chou, A. Kingery, D. Wang, H. Li and D. Song, "Encoder-Camera-Ground Penetrating Radar Tri-Sensor Mapping for Surface and Subsurface Transportation Infrastructure Inspection," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1452-1457.
doi: 10.1109/ICRA.2018.8461080
Abstract: We report system and algorithmic development for a sensing suite comprising multiple sensors for both surface and subsurface transportation infrastructure inspection focusing on multi-modal mapping for inspection. The sensing suite contains a camera, a ground penetrating radar (GPR), and a wheel encoder. We design the sensing suite and propose a data collection scheme using customized artificial landmarks (ALs). We use ALs to synchronize two types data streams: camera images that are temporally evenly-spaced and GPR/encoder data that are spatially evenly-spaced. We also employ pose graph optimization with synchronization as penalty functions to further refine synchronization and perform data fusion for 3D reconstruction. We have implemented the system and tested it in physical experiments. The results show that our system successfully fuses three sensory data and product metric 3D reconstruction. The sensor fusion approach reduces the end-to-end distance error from 7.45cm to 3.10cm.
keywords: {Ground penetrating radar;Cameras;Inspection;Synchronization;Robot sensing systems;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461080&isnumber=8460178

X. Zhang, E. Peltola and J. Mattila, "Angle Estimation for Robotic Arms on Floating Base Using Low-Cost IMUS," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1458-1465.
doi: 10.1109/ICRA.2018.8462898
Abstract: An algorithm that uses low-cost inertial measurement units (IMUs) for estimating link angles for floating base robotic platforms is proposed. Each link has four IMUs attached on its surfaces, and an Extended Kalman Filter (EKF) and a Complementary Filter (CF) are used for fusing the sensors' data. The algorithm is validated with a commercial mobile working machine, which consist of six degrees-of-freedom (DOF) wheeled base platform, and a 3-DOF hydraulic anthropomorphic arm. Although there are vibrational disturbances from the machine's diesel engine and deformation of the links themselves, the measured results from the planar motion of a floating base hydraulic arm show that the accuracy of the angle estimation is impressively less than 1 degree in the root mean square (RMS) error.
keywords: {Accelerometers;Estimation;Force;Manipulators;Hydraulic systems;Gyroscopes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462898&isnumber=8460178

X. Cheng, G. Jiang, K. Lee and Y. N. Laker, "IntuBot: Design and Prototyping of a Robotic Intubation Device," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1482-1487.
doi: 10.1109/ICRA.2018.8460779
Abstract: Endotracheal intubation is one of the most common procedures performed worldwide in emergency departments and operating rooms. It is a highly complicated procedure susceptible to failure. This paper presents a robotic prototype, called IntuBot, designed to automate this procedure. The hardware system consists of a stepper motor to steer the stylet in forward and backward motions and two servo motors to generate bending at the stylet tip to navigate through a patient's airway. A real-time vision-based navigation algorithm is also presented to guide the stylet to localize the vocal cords, which is the tubes ultimate target. For pre-clinical testing, we 3D printed and then molded a silicone model of the airway from the mouth to the vocal cords based on a series of actual CT scan images. The prototype was tested for its steering capabilities.
keywords: {Gears;Prototypes;Servomotors;Electron tubes;Mouth;Training;Testing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460779&isnumber=8460178

N. Dhir, H. Dallali, E. M. Ficanha, G. A. Ribeiro and M. Rastgaar, "Locomotion Envelopes for Adaptive Control of Powered Ankle Prostheses," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1488-1495.
doi: 10.1109/ICRA.2018.8460929
Abstract: In this paper we combine Gaussian process regression and impedance control, to illicit robust, anthropomorphic, adaptive control of a powered ankle prosthesis. We learn the non-linear manifolds which guide how locomotion variables temporally evolve, and regress that surface over a velocity range to create a manifold. The joint set of manifolds, as well as the temporal evolution of the gait-cycle duration is what we term a locomotion envelope. Current powered prostheses have problems adapting across speeds. It is likely that humans rely upon a control strategy which is adaptable, can become more robust and accurate with more data and provides a nonparametric approach which allows the strategy to grow with the number of observations. We demonstrate such a strategy in this study and successfully simulate locomotion well beyond our training data. The method we propose is based on common physical features observed in numerous human subjects walking at different speeds. Based on the derived locomotion envelopes we show that ankle power increases monotonically with speed among all subjects. We demonstrate our methods in simulation and human experiments, on a powered ankle foot prosthesis to demonstrate the effectiveness of the method.
keywords: {Legged locomotion;Prosthetics;Impedance;Manifolds;Kernel;Gaussian processes;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460929&isnumber=8460178

K. B. Freckleton and M. A. Minor, "Modeling and Characterization of a Potential Bladder Based Orthotic Device to Mitigate Shoe Slip," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1496-1503.
doi: 10.1109/ICRA.2018.8460791
Abstract: The exploration of an “intelligent” orthotic shoe sole to negate, or minimize, longitudinal slip by momentarily increasing friction force is presented. The conceptual device takes the form of a rubberized shoe sole containing pockets of air that can be released via valves controlled by a microprocessor. During a slip event, the valves would be opened and the bladders would be collapsed by the weight of the user, which modulates contact and friction forces. The goal is to increase friction forces in this process, by creating an impact force between the user and ground surface, with the potential to increase friction and mitigate slip. Simulations of bladder walls, air flow through valves, contact forces, and friction forces are modeled and combined into a lumped parameter model to predict device behavior. Prototypes of the device are created and evaluated to validate models and slip-mitigating potential.
keywords: {Bladder;Atmospheric modeling;Conferences;Automation;Australia;Friction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460791&isnumber=8460178

S. Yim et al., "Preliminary Results of a Handheld Nerve Electrode Insertion Device," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1504-1510.
doi: 10.1109/ICRA.2018.8460882
Abstract: This paper presents preliminary results of a handheld device to assist the insertion of intra-fascicular planar electrodes into a peripheral nervous system. The developed device consists of two units, a nerve holder and an electrode inserter. We introduce design considerations, features, and underlying mechanisms of the device. User tests and animal experiments show that users can easily and accurately adjust the insertion position and direction of nerve electrodes while manipulating the device in 3D, and that planar electrodes are successfully inserted into sciatic nerves of rats. We hope that the proposed device will help neural engineering researchers and scientists to simplify the surgical process and produce consistent experimental results.
keywords: {Electrodes;Springs;Force;Thumb;Polyimides;Silicon},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460882&isnumber=8460178

A. du Plessis d'Argentré et al., "Programmable Medicine: Autonomous, Ingestible, Deployable Hydrogel Patch and Plug for Stomach Ulcer Therapy," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1511-1518.
doi: 10.1109/ICRA.2018.8460615
Abstract: Gastric ulcer is a chronic and complex (and often complete) erosion of the stomach wall that happens as a complication of a previous chronic, inflammatory process. It represents a catastrophic situation in which the patient is critical and its conditions need to be treated fast. This study presents a remotely navigatable and deployable ingestible patch and plug for gastric ulcer treatment. The patch/plug structure is made of agarose hydrogel that can change rigidity through hydration and dehydration. When dehydrated, it is rigid and can maintain a folded configuration so it can be ingested as a “pill”. This can be guided to the targeted location by a magnetic field, and be deployed instantly by hydration, namely by supplying water from the mouth. Due to the deployable origami design, it exhibits an expansion of 10 times its initial surface area, making the device suitable for the use of dressing a surface as a patch, and filling a hole as a plug.
keywords: {Plugs;Stomach;Navigation;Shape;Fabrication;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460615&isnumber=8460178

W. Amokrane, K. Belharet, M. Souissi, A. B. Grayeli and A. Ferreira, "Open-Loop Drug Delivery Strategy to the Cochlea Using a Permanent Magnetic Actuator," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1519-1524.
doi: 10.1109/ICRA.2018.8460216
Abstract: The use ofrobotic devices for drug delivery in sensitive area of the human body is an innovative and reliable solution. Most of them use magnetics fields, to steer micro-nano-robots into diseases locations. In this study, we use a magnetic actuator based on two permanent magnets as an end-effector of a robotic manipulator. The actuator offers the possibility to generate both pushing and pulling forces on the magnetic actuator axis in an open-loop control way. We describe in this paper the robotic drug delivery strategy that we implemented in a 6 degree of freedom robotic manipulator to push and to steer a magnetic microparticle from the round window to the apex of the human cochlea. Different experiments have been conducted in order to demonstrate the effectiveness and robustness of the navigation proposed strategy on a human phantom cochlea. The results demonstrate clearly that precise and reliable drug administration is rendered possible.
keywords: {Actuators;Robots;Ear;Magnetic separation;Drug delivery;Drugs;Permanent magnets},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460216&isnumber=8460178

N. Thompson, X. Zhang, F. Ayala, E. T. Hsiao-Wecksler and G. Krishnan, "Augmented Joint Stiffness and Actuation Using Architectures of Soft Pneumatic Actuators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1533-1538.
doi: 10.1109/ICRA.2018.8460746
Abstract: Soft robotic actuators are well suited for use in exoskeleton applications due to their innate compliance and low weight. We have developed a wearable soft robotic sleeve that uses fiber reinforced elastomeric enclosures (FREEs) to provide actuation and stiffness at the elbow for augmented lifting and carrying ability. The sleeve includes novel linear and helical actuator architectures to induce and resist joint movement respectively, and is intended to be comfortable, lightweight, and low profile. We developed test protocols to measure actuation and stiffness performance of different helical and linear architectures, and to compare helical and linear actuator groups when used individually and together. Our findings indicate that nested linear actuators have superior contraction ratios compared to parallel linear actuators, resulting in greater angular displacement. Stiffness from helical actuators increased with pressure and number of parallel actuators. A combined linear-helical actuator configuration considerably outperformed helical and linear actuator groups when used on their own.
keywords: {Conferences;Automation;Australia},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460746&isnumber=8460178

N. S. Usevitch, A. M. Okamura and E. W. Hawkes, "APAM: Antagonistic Pneumatic Artificial Muscle," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1539-1546.
doi: 10.1109/ICRA.2018.8460881
Abstract: We present a pneumatic actuator capable of changing length by 1000%, applying both pushing and pulling forces, and independently modulating its length and stiffness. These characteristics are enabled by individually addressable internal and external chambers that work antagonistically against one another. The high deformation with low hysteresis is achieved by wrinkling of thin materials that are assumed to be inextensible but flexible, as opposed to stretchable. A model for the actuator is presented and validated with experimental results, showing capabilities of high strain, pushing and pulling, and independent control of length and stiffness. These characteristics are motivated by the application of a compliant truss robot. Accordingly, we show a simple grounded tetrahedron with three actuator elements and three static elements. We demonstrate motion of the tetrahedron apex against external loads and the ability of the structure to vary its stiffness. The actuator offers a unique set of characteristics that could increase the capabilities of soft robotic devices.
keywords: {Actuators;Shape;Electron tubes;Force;Muscles;Robots;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460881&isnumber=8460178

Y. Li, Y. Chen, T. Ren and Y. Hu, "Passive and Active Particle Damping in Soft Robotic Actuators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1547-1552.
doi: 10.1109/ICRA.2018.8462895
Abstract: Soft robotic actuators are highly elastic bodies that oscillate drastically once excited. This oscillation is undesirable in many applications. So far, very little studies on soft actuator damping have been reported. In this paper, we report a simple and effective vibration damping method based on passive and active particle damping. Experimental studies on the effectiveness of particle damping have been conducted. It is found that active particle damping is more effective than passive damping, nevertheless, active particle damping demands a more complicated design with extra energy source and control. Since particles are discrete matters, they can be seamless integrated into soft actuator design with only minor influence of soft actuator's compliance and softness.
keywords: {Actuators;Damping;Vibrations;Robots;Friction;Shock absorbers;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462895&isnumber=8460178

T. Wang, Y. Li, Y. Li, J. Zhang, J. Hong and M. Y. Wang, "A Fluid-Filled Tubular Dielectric Elastomer Variable Stiffness Structure Inspired by the Hydrostatic Skeleton Principle," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1553-1558.
doi: 10.1109/ICRA.2018.8461245
Abstract: This work presents a novel variable stiffness structure consisting of a fiber-constrained dielectric elastomer tube filled with insulating oil. The tensile stiffness of the structure can be adjusted by voltages and its initial value can be customized according to the initial pre-stretch of the material. The structure has a dimension of ∼30 mm diameter × 50 mm length. A mathematical analysis is established to predict the initial tensile stiffness of the structure. The changes of the tensile stiffness of the structure under voltages are verified experimentally. The results show a decrease of the tensile stiffness of the device by 25% at 4 kV and the decrement is also related to the elongation of the structure. With different pre-stretches and dimensions of the dielectric elastomer, one can obtain devices with different variation ranges of tensile stiffness.
keywords: {Electron tubes;Strain;Oils;Muscles;Hydraulic systems;Force;Soft robotics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461245&isnumber=8460178

S. Hauser, M. Mutlu, F. Freundler and A. Ijspeert, "Stiffness Variability in Jamming of Compliant Granules and a Case Study Application in Climbing Vertical Shafts," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1559-1566.
doi: 10.1109/ICRA.2018.8462899
Abstract: Jamming of granular media has been shown to possess the property of stiffness variation, transitioning from a soft to a quasi-solid state depending on the packing density of the granules. Recently, a gradual stiffness change for bending has been reported by using compliant, cubic shaped granules. Here we demonstrate that the same method and material also exhibits a gradual stiffness change for compression. As a potential application of “compliant jamming”, a bio-inspired robotic platform with jamming membranes as end effectors is designed and tasked with climbing straight vertical shafts. First, the benefit of varying the bending stiffness is investigated in the climbing task by measuring the friction force that the end effectors are applying to the shaft walls, especially if the walls are irregularly shaped. Then the role of compressive stiffness variation is explored by analyzing the performance of the robot in the climbing task, showing multi-modal properties of jamming membranes: (i) enabling a pressure sensor to detect the shaft walls, acting (ii) as grippers that actively use the irregularities of the walls to climb up by state-switching the granular material and (iii) as force dissipators that can dissipate internal forces caused by closed kinematic chains.
keywords: {Jamming;Biomembranes;End effectors;Shape;Shafts;Legged locomotion;Soft robotics;variable stiffness joints;vacuum jamming;universal gripper;climbing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462899&isnumber=8460178

F. Renda and L. Seneviratne, "A Geometric and Unified Approach for Modeling Soft-Rigid Multi-Body Systems with Lumped and Distributed Degrees of Freedom," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1567-1574.
doi: 10.1109/ICRA.2018.8461186
Abstract: In this paper, a geometric and unified model of soft-rigid multi-body systems is presented, based on a discrete Cosserat approach of the soft-body dynamics. The model is in fact a generalization to soft and hybrid systems of the geometric theory of rigid robotics characterized by the exponential map. A generalization of the recursive Newton-Euler algorithm is also presented, able to solve inverse and forward dynamic problems with linear O(N) complexity. The proposed model provides several improvements with respect to the existing flexible multi-body models, which make it particularly suitable to study the dynamics of modern soft robots as shown for a multi-body system inspired by motile bacteria.
keywords: {Kinematics;Fasteners;Strain;Heuristic algorithms;Algebra;Soft robotics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461186&isnumber=8460178

S. Katiyar, G. Kandasamy, E. Kulatunga, M. Mustafizur, F. Iida and S. G. Nurzaman, "Morphological Adaptation in an Energy Efficient Vibration-Based Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1575-1582.
doi: 10.1109/ICRA.2018.8461107
Abstract: Morphological computation is a concept relevant to robots made of soft and elastic materials. It states that robot's rich dynamics can be exploited to generate desirable behaviors, which can be altered when their morphology is adapted accordingly. This paper presents a low-cost robot made of elastic curved beam driven by a motor, with morphological computation and adaptation ability. Simply by changing robot's shape and the rotating frequency of the motor that vibrates the robot's body, the robot is able to shift its behavior from showing a tendency to slide when it needs to perform tasks like going under confined space, to have more tendency to hop diagonally forward when the robot stands upright. It will also be shown that based on the proposed mechanism, the energy efficiency of the robot locomotion can be maximized.
keywords: {Legged locomotion;DC motors;Springs;Resonant frequency;Foot;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461107&isnumber=8460178

J. Fras, Y. Noh, M. Macias, H. Wurdemann and K. Althoefer, "Bio-Inspired Octopus Robot Based on Novel Soft Fluidic Actuator," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1583-1588.
doi: 10.1109/ICRA.2018.8460629
Abstract: Many modern roboticists take inspiration from biology to create novel robotic structures, including those that are modeled after the octopus. This paper advances this trend by creating soft robots modeling the complex motion patterns of octopus tentacles employing a bio-mimetic approach. The proposed octopus robot is entirely made from soft material and uses a novel fluidic actuation mechanism that allows the robot to advance forward, change directions and rotate around its primary axis. The paper presents the robot's design and fabrication process. An experimental study is conducted showing the feasibility of the proposed robot and actuation mechanism.
keywords: {Actuators;Manipulators;Force;Robot sensing systems;Soft robotics;Fabrication},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460629&isnumber=8460178

H. Kim and J. Lee, "Completion Time Analysis for Automated Manufacturing Systems with Parallel Processing Modules," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1589-1594.
doi: 10.1109/ICRA.2018.8460980
Abstract: This paper analyzes the completion time of automated manufacturing systems, especially a dual-armed cluster tool, equipped with parallel processing modules (PMs). Cluster tools, which consist of multiple PMs, a transport robot, and loadlocks where wafer lots are loaded and unloaded, perform semiconductor manufacturing processes, such as lithography, etching, deposition, and testing. Wafer lots are transported by overhead hoist transports (OHTs) between tools or stockers where wafer lots are stored. To reduce the idle time of OHTs or cluster tools, it is essential to estimate the time when all wafers of a lot finish processing in a tool. Hence, we derive closed-form expressions for the completion time of wafer lots, especially in dual-armed cluster tools with parallel PMs to reflect real circumstances of fabs. We finally show that the formulas derived can be used even when there are small processing time variations with numerical experiments.
keywords: {Tools;Robots;Task analysis;Switches;Optimal scheduling;Job shop scheduling;Time factors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460980&isnumber=8460178

A. S. Anders, L. P. Kaelbling and T. Lozano-Perez, "Reliably Arranging Objects in Uncertain Domains," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1603-1610.
doi: 10.1109/ICRA.2018.8462892
Abstract: A crucial challenge in robotics is achieving reliable results in spite of sensing and control uncertainty. In this work, we explore the conformant planning approach to robot manipulation. In particular, we tackle the problem of pushing multiple planar objects simultaneously to achieve a specified arrangement without external sensing. Conformant planning is a belief-state planning problem. A belief state is the set of all possible states of the world, and the goal is to find a sequence of actions that will bring an initial belief state to a goal belief state. To do forward belief-state planning, we created a deterministic belief-state transition model from supervised learning based on off-line physics simulations. We compare our method with an on-line physics-based manipulation approach and show significantly reduced planning times and increased robustness in simulated experiments. Finally, we demonstrate the success of this approach in simulations and physical robot experiments.
keywords: {Planning;Robot sensing systems;Task analysis;Reliability;Computational modeling;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462892&isnumber=8460178

F. Suárez-Ruiz, T. S. Lembono and Q. Pham, "RoboTSP – A Fast Solution to the Robotic Task Sequencing Problem," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1611-1616.
doi: 10.1109/ICRA.2018.8460581
Abstract: In many industrial robotics applications, such as spot-welding, spray-painting or drilling, the robot is required to visit successively multiple targets. The robot travel time among the targets is a significant component of the overall execution time. This travel time is in turn greatly affected by the order of visit of the targets, and by the robot configurations used to reach each target. Therefore, it is crucial to optimize these two elements, a problem known in the literature as the Robotic Task Sequencing Problem (RTSP). Our contribution in this paper is two-fold. First, we propose a fast, near-optimal, algorithm to solve RTSP. The key to our approach is to exploit the classical distinction between task space and configuration space, which, surprisingly, has been so far overlooked in the RTSP literature. Second, we provide an open-source implementation of the above algorithm, which has been carefully benchmarked to yield an efficient, ready-to-use, software solution. We discuss the relationship between RTSP and other Traveling Salesman Problem (TSP) variants, such as the Generalized Traveling Salesman Problem (GTSP), and show experimentally that our method finds motion sequences of the same quality but using several orders of magnitude less computation time than existing approaches.
keywords: {Task analysis;Measurement;Collision avoidance;Service robots;Planning;Space exploration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460581&isnumber=8460178

H. I. Bozma and F. Öztüirk, "An Automated Reactive Approach to Single Robot Exogeneous Planar Assembly," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1617-1622.
doi: 10.1109/ICRA.2018.8460665
Abstract: In this paper, we are concerned with the automation of single robot exogeneous assembly in simple planar settings. Here, a set of of unactuated disk-shaped parts needs to be serviced by a single robot that resides outside the workspace and is capable of moving the parts one at a time through sliding or lifting slightly. The task is to have the parts end up in their respective goal positions without any collisions whilst moving. We present an automated reactive approach through the composition of one-part movements. The movement of each part is achieved by a controller obtained through the projection of a carefully constructed vector field on the respective configuration subspace. Such a scheme is known to accommodate positional variations naturally. Once the movement terminates, the robot chooses the next part to move in a cyclic manner. The contribution of this paper is to show for the first time that with certain restrictions on the allowed goal configurations, the assembly task is either successfully completed or terminated (rather than useless cycling of a part or from part to part) while the generated sequence of motions never causes collisions among the parts.
keywords: {Conferences;Automation;Australia},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460665&isnumber=8460178

S. Elliott and M. Cakmak, "Robotic Cleaning Through Dirt Rearrangement Planning with Learned Transition Models," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1623-1630.
doi: 10.1109/ICRA.2018.8460915
Abstract: We address the problem of enabling a manipulator to move arbitrary amounts and configurations of dirt on a surface to a goal region using a cleaning tool. We represent this problem as heuristic search with a set of primitive dirt-oriented tool actions. We present dirt and action representations that allow efficient learning and prediction of future dirt states, given the current dirt state and applied action. We also present a method for sampling promising actions based on a clustering of dirt states and heuristics for planning. We demonstrate the effectiveness of our approach on challenging cleaning tasks through implementations on PR2 and Fetch robots.
keywords: {Tools;Planning;Surface cleaning;Manipulators;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460915&isnumber=8460178

Y. Hou, Z. Jia and M. T. Mason, "Fast Planning for 3D Any-Pose-Reorienting Using Pivoting," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1631-1638.
doi: 10.1109/ICRA.2018.8462834
Abstract: In this paper, we consider reorienting 3D objects on a table using a two-finger pinch gripper. Given the 3D mesh model of the object, our algorithm solves for the gripper motions that are required to transit between arbitrary object poses, grasping positions and gripper poses. The two motion primitives we used, pivoting and compliant rolling, enable us to decompose the planning problem and solve it more efficiently. Our algorithm can work with approximated (simplified) mesh models while being robust to approximation errors, thereby allowing us to efficiently handle object shapes with originally thousands of facets. We show the effectiveness of the proposed method by testing on objects with non-trivial geometry in both simulations and experiments. Results show that our algorithm can solve a larger range of reorienting problems with less number of making and breaking contacts when compared to traditional pick-and-place based methods, especially when the gripper workspace is highly constrained.
keywords: {Grippers;Planning;Gravity;Robots;Three-dimensional displays;Friction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462834&isnumber=8460178

H. J. Asl, S. Pyo and J. Yoon, "An Intelligent Control Scheme to Facilitate Abrupt Stopping on Self-Adjustable Treadmills," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1639-1644.
doi: 10.1109/ICRA.2018.8462897
Abstract: The control problem in self-adjustable treadmills is to keep the position of the user at a reference position. The position error is the key obstacle in facilitating the abrupt stopping on self-adjustable treadmills. Another difficulty in this application is the oscillatory response of the closed-loop system. The conventional control methods utilize a high-gain observer to estimate the user velocity and exploit this information beside feedback signals to decrease the position error. Utilizing the high-gain observer, however, applies anomalous force (AF) to the user, leading to an unnatural feeling, and does not guarantee an oscillation-free response for the output. This paper aims to alleviate these problems by proposing a supervisory control scheme. First, a RISE controller is utilized for walking/running stage to compensate for slowly varying uncertainties in the system model without applying a large AF. Then, a positive-output controller is exploited for the stopping stage to guarantee the convergence of the position error without oscillation. Using the estimated intentional velocity and acceleration, a supervisory system is designed to switch between the controllers. Experimental results show the superiority of the proposed approach over the existing methods.
keywords: {Observers;Acceleration;Force;Convergence;Feedforward systems;Closed loop systems;Self-adjustable treadmill;observer;RISE controller},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462897&isnumber=8460178

S. Farzan, A. Hu, E. Davies and J. Rogers, "Modeling and Control of Brachiating Robots Traversing Flexible Cables," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1645-1652.
doi: 10.1109/ICRA.2018.8461036
Abstract: This paper describes the dynamic modeling and locomotion control of a two-link underactuated brachiating robot traversing a flexible cable. A multi-body system comprised of a two-link robot, a flexible cable, and coupling soft junctions is modeled dynamically. This model is used to formulate an energy-minimizing optimal control strategy that includes the effects of cable vibration induced by robot locomotion. Optimized trajectories and control torque profiles are obtained via multiple-shooting and parametric trajectory approaches. Simulation results show that these optimal torque profiles result in energy-efficient continuous brachiation over a flexible cable. Additional studies examine how the optimal torque profiles change depending on the robot's initial position along a catenary cable.
keywords: {Junctions;Mathematical model;Grippers;Legged locomotion;Trajectory;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461036&isnumber=8460178

R. Behrens et al., "Performance Indicator for Benchmarking Force-Controlled Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1653-1660.
doi: 10.1109/ICRA.2018.8460858
Abstract: Robot-based sensitive assembly is a recent and growing trend in robotics. Force-controlled robots are expected to interact with an unknown environment using solely force feedback information. In general, the exact contact is difficult to predict due to various impact factors, such as the dynamics of the interaction, work-piece stiffness and geometry, the robot's configuration, and the efficiency of the control algorithm. Currently, there is no general indicator for evaluating the performance of a force-controlled robot. This work presents a concept of such a performance indicator. In order to test the proposed concept for comparison, an experimental setup is presented that simulates a contour-following task under force control. This setup is used to test two robots with different force-controllers and control principles, namely direct force and impedance control. The results indicate good applicability of the proposed performance indicator to benchmark force-controlled robots, and this is extensively discussed.
keywords: {Force;Robot sensing systems;Service robots;Task analysis;Tools;Benchmark testing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460858&isnumber=8460178

Z. Liu, H. Wang, L. Xu, Y. -H. Liu, J. Lu and W. Chen, "A Failure-Tolerant Approach to Synchronous Formation Control of Mobile Robots Under Communication Delays," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1661-1666.
doi: 10.1109/ICRA.2018.8460660
Abstract: Robot malfunction is inevitable in practical applications of the robot formation control due to uncontrolled crashing, system malfunction or communication loss. In this paper, we study the synchronous formation control problem in the presence of robot malfunctions. Our main idea is to improve the network connectivity and motion synchronism of the robot formation through a series of topology switchings and robot replacements. Firstly, the synchronous formation control method is introduced which enables the robots to tracking their desired trajectories while keeping predefined formation shapes. Secondly, a recursive switched topology control strategy is proposed to restore the formation shape as well as to improve the network connectivity and motion synchronism in the presence of robot malfunctions. Thirdly, the convergence analysis of the proposed control system is presented and a sufficient condition is obtained under an average dwell time scheme. What's more, the proposed approach is fully distributed and the communication delays between neighboring robots also have been taken into consideration. Simulation results demonstrate the effectiveness of the proposed approach.
keywords: {Topology;Switches;Robot kinematics;Network topology;Synchronization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460660&isnumber=8460178

L. Santos and R. Cortesão, "Perceived Stiffness Estimation for Robot Force Control," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1667-1672.
doi: 10.1109/ICRA.2018.8460925
Abstract: Typical robot force control architectures have a positive force feedback loop to decouple robot dynamics from contact dynamics. Due to the noisy profile of force measurements, it is common to filter force signals by low pass filters. This paper shows that, when force feedback is filtered, robot and environment dynamics are no longer decoupled, affecting force control performance. Additionally, the perceived stiffness from the force control perspective, is correlated with the robot effective mass. To cope with this issue, a force based stiffness estimation strategy that also includes the inertial properties (effective mass) in the estimation algorithm is proposed, allowing to adapt control gains based on the robot effective mass. In this way, the perceived stiffness can be seen as a control optimization parameter, rather than a well defined physical property. Simulation and experimental results with a 1-DoF robot and 7-DoF manipulator, respectively, validate the estimation strategy, showing better force control results with the perceived stiffness in the control loop, as compared to the real environment stiffness.
keywords: {Robots;Force;Estimation;Dynamics;Force control;Effective mass;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460925&isnumber=8460178

G. Zhang et al., "Grasp a Moving Target from the Air: System & Control of an Aerial Manipulator," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1681-1687.
doi: 10.1109/ICRA.2018.8461103
Abstract: Grasping a moving target has been investigated extensively for fixed-base manipulator. However, such a task becomes much more challenging when the manipulator is free flying in the air with an UAV. Towards moving target grasping, this paper presents an aerial manipulator system composed of a hex-rotor and a 7-DoF (Degree of Freedom) manipulator. An independent control structure is used in the aerial manipulator control system, i.e., the hex-rotor and the manipulator are controlled separately. In the hex-rotor's controller, the system CoM (Center of Mass) offset motion is used to compensate disturbance of the robotic arm. In the manipulator's controller, the relative kinematics between the target and the aerial vehicle is taken into consideration to grasp the target. At last aerial grasping experiments are conducted to validate the feasibility of the proposed control scheme and the reliability of our aerial manipulator system.
keywords: {Manipulator dynamics;Grasping;Control systems;Kinematics;Vehicle dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461103&isnumber=8460178

N. Larkin, A. Short, Z. Pan and S. Van Duin, "Task Space Motion Planning Decomposition," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1688-1694.
doi: 10.1109/ICRA.2018.8460903
Abstract: In autonomous robotics there are many situations that require solving a motion planning problem to complete a task. A Task Space (T-Space), composed of parameters that define the task being performed, can be a more effective planning space for these problems, however, planning within a T-Space is often computationally challenging. In this paper, we present a novel method to analyse the relationship between T-Space parameters and the pose of manipulator bodies to create a dependency matrix. We then use this information to decompose the motion planning problem into sequential lower complexity sub-problems. We call this approach Task Space Motion Planning Decomposition (TSMPD). This paper introduces TSMPD and quantifies the improvement to planning efficiency on a challenging maze navigation problem and weld path planning problem.
keywords: {Planning;Task analysis;Manipulators;Manifolds;Kinematics;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460903&isnumber=8460178

T. Klamt and S. Behnke, "Planning Hybrid Driving-Stepping Locomotion on Multiple Levels of Abstraction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1695-1702.
doi: 10.1109/ICRA.2018.8461054
Abstract: Navigating in search and rescue environments is challenging, since a variety of terrains has to be considered. Hybrid driving-stepping locomotion, as provided by our robot Momaro, is a promising approach. Similar to other locomotion methods, it incorporates many degrees of freedom - offering high flexibility but making planning computationally expensive for larger environments. We propose a navigation planning method, which unifies different levels of representation in a single planner. In the vicinity of the robot, it provides plans with a fine resolution and a high robot state dimensionality. With increasing distance from the robot, plans become coarser and the robot state dimensionality decreases. We compensate this loss of information by enriching coarser representations with additional semantics. Experiments show that the proposed planner provides plans for large, challenging scenarios in feasible time.
keywords: {Planning;Robot sensing systems;Legged locomotion;Semantics;Motion segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461054&isnumber=8460178

G. Bellegarda, K. van Teeffelen and K. Byl, "Design and Evaluation of Skating Motions for a Dexterous Quadruped," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1703-1709.
doi: 10.1109/ICRA.2018.8460600
Abstract: This paper describes skating locomotion for a quadruped robot with dexterous limbs. The emphasis is on design of omnidirectional motion primitives and quantification of resulting speed and accuracy when traversing different types of smooth but potentially non-flat terrain. In particular, we study trade-offs between using four-wheeled versus three-wheeled skating maneuvers. In four-wheeled skating, motions have the benefit of symmetry, so that errors due to wheel slip should theoretically cancel out on average. Three-wheeled skating, by contrast, introduces significantly more asymmetry in configuration and contact force distribution over time; however, it has the advantage of guaranteeing continuous ground contact for all skates when terrain has bumps or other curvature. We present simulation results quantifying errors for each approach, for various terrains. Our results allow us to tune motions to reduce biases and variability in motion, which are primarily due to accelerations as locomotion begins.
keywords: {Wheels;Mobile robots;Planning;Force;Trajectory;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460600&isnumber=8460178

E. Heiden, L. Palmieri, S. Koenig, K. O. Arras and G. S. Sukhatme, "Gradient-Informed Path Smoothing for Wheeled Mobile Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1710-1717.
doi: 10.1109/ICRA.2018.8460818
Abstract: Planning smooth trajectories is important for the safe, efficient and comfortable operation of mobile robots, such as wheeled robots moving in crowded environments or cars moving at high speed. Asymptotically optimal sampling-based motion planners can be used to generate such trajectories. However, to achieve the necessary efficiency for the realtime operation of robots, one often uses their initial feasible trajectories or the trajectories of non-optimal motion planners instead, typically after a post-smoothing step. We propose a gradient-informed post-smoothing algorithm, called GRIPS, that deforms given trajectories by locally optimizing the placement of vertices while satisfying the system's kinodynamic constraints. We show experimentally that GRIPS typically produces trajectories of significantly smaller length and higher smoothness than several existing post-smoothing algorithms.
keywords: {Trajectory;Smoothing methods;Shape;Mobile robots;Interpolation;Strain},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460818&isnumber=8460178

R. Bormann, F. Jordan, J. Hampp and M. Hägele, "Indoor Coverage Path Planning: Survey, Implementation, Analysis," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1718-1725.
doi: 10.1109/ICRA.2018.8460566
Abstract: Coverage Path Planning (CPP) describes the process of generating robot trajectories that fully cover an area or volume. Applications are, amongst many others, mobile cleaning robots, lawn mowing robots or harvesting machines in agriculture. Many approaches and facets of this problem have been discussed in literature but despite the availability of several surveys on the topic there is little work on quantitative assessment and comparison of different coverage path planning algorithms. This paper analyzes six popular off-line coverage path planning methods, applicable to previously recorded maps, in the setting of indoor coverage path planning on room-sized units. The implemented algorithms are thoroughly compared on a large dataset of over 550 rooms with and without furniture.
keywords: {Path planning;Cleaning;Robot sensing systems;Planning;Traveling salesman problems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460566&isnumber=8460178

P. Vlantis, C. Vrohidis, C. P. Bechlioulis and K. J. Kyriakopoulos, "Robot Navigation in Complex Workspaces Using Harmonic Maps," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1726-1731.
doi: 10.1109/ICRA.2018.8460695
Abstract: Artificial Potential Fields (APFs) constitute an intuitive tool for designing autonomous robot navigation control schemes, though they generally suffer from the existence of local minima which may trap the robot away from its desired configuration, an issue usually addressed by appropriate offline “tuning” of the potential field's parameters. On the other side, most APF based approaches rely on a diffeomorphism to sphere worlds to handle realistic scenarios, which may be either costly to compute (e.g., conformal mappings) or requires some sort of preconditioning of the workspace (e.g., decomposition of complex geometries to simple elementary components). In this work, we first propose a constructive procedure to map multiply connected compact 2D workspaces to one or more punctured disks based on harmonic maps. Subsequently, we design an APF based control scheme along with an adaptive law for its parameters that requires no offline tuning to guarantee safe convergence to its goal configuration. Finally, an extensive simulation study is conducted to demonstrate the efficacy of the proposed control scheme.
keywords: {Harmonic analysis;Navigation;Robot kinematics;Convergence;Tuning;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460695&isnumber=8460178

D. Mehta, G. Ferrer and E. Olson, "Backprop-MPDM: Faster Risk-Aware Policy Evaluation Through Efficient Gradient Optimization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1740-1746.
doi: 10.1109/ICRA.2018.8462903
Abstract: In Multi-Policy Decision-Making (MPDM), many computationally-expensive forward simulations are performed in order to predict the performance of a set of candidate policies. In risk-aware formulations of MPDM, only the worst outcomes affect the decision making process, and efficiently finding these influential outcomes becomes the core challenge. Recently, stochastic gradient optimization algorithms, using a heuristic function, were shown to be significantly superior to random sampling. In this paper, we show that accurate gradients can be computed - even through a complex forward simulation - using approaches similar to those in deep networks. We show that our proposed approach finds influential outcomes more reliably, and is faster than earlier methods, allowing us to evaluate more policies while simultaneously eliminating the need to design an easily-differentiable heuristic function. We demonstrate significant performance improvements in simulation as well as on a real robot platform navigating a highly dynamic environment.
keywords: {Robots;Computational modeling;Trajectory;Navigation;Decision making;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462903&isnumber=8460178

B. J. DeHart, R. Gorbet and D. Kulić, "Spherical Foot Placement Estimator for Humanoid Balance Control and Recovery," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1747-1754.
doi: 10.1109/ICRA.2018.8460718
Abstract: One of the main challenges of bipedal gait is to avoid falling due to unknown disturbances. Compensating for these disturbances in bipeds is often achieved by leaning or stepping. In this work, the Spherical Foot Placement Estimator (SFPE) is introduced, which uses the biped's current kinematics and dynamics to predict if a step is needed, and if so where to step, to restore balance in 3D. An example of a controller using the SFPE is shown, which augments an existing optimal controller with both leaning and stepping: SFPE-based feedback is used to generate a desired momentum for momentum-based leaning while the SFPE point is used as a control reference for stepping. The new estimator outperforms existing balance criteria by providing both recovery step location prediction and momentum objectives with smooth dynamics.
keywords: {Three-dimensional displays;Foot;Integrated circuit modeling;Mathematical model;Legged locomotion;Solid modeling;Iterative closest point algorithm},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460718&isnumber=8460178

T. Kamioka, H. Kaneko, T. Takenaka and T. Yoshiike, "Simultaneous Optimization of ZMP and Footsteps Based on the Analytical Solution of Divergent Component of Motion," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1763-1770.
doi: 10.1109/ICRA.2018.8460572
Abstract: Real-time planning of footsteps has been a big challenge for bipedal research. A large number of methods have been proposed over the last several years. In addition, divergent component of motion (DCM) of linear inverted pendulum (LIP) has been applied to solve this problem thus attracting a great deal of attention. In this paper, we derive an analytical solution of DCM for an arbitrary input function and propose a novel quadratic programming (QP) problem for the simultaneous optimization of zero moment point (ZMP) and foot placements based on the analytical solution. To validate the method, we conducted a push recovery experiment on real hardware. The result of the experiment shows that our new algorithm realizes a hierarchical strategy for disturbance compensation.
keywords: {Planning;Lips;Trajectory;Foot;Real-time systems;Optimization;Laplace equations},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460572&isnumber=8460178

A. Rai, R. Antonova, S. Song, W. Martin, H. Geyer and C. Atkeson, "Bayesian Optimization Using Domain Knowledge on the ATRIAS Biped," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1771-1778.
doi: 10.1109/ICRA.2018.8461237
Abstract: Robotics controllers often consist of expert-designed heuristics, which can be hard to tune in higher dimensions. Simulation can aid in optimizing these controllers if parameters learned in simulation transfer to hardware. Unfortunately, this is often not the case in legged locomotion, necessitating learning directly on hardware. This motivates using data-efficient learning techniques like Bayesian Optimization (BO) to minimize collecting expensive data samples. BO is a black-box data-efficient optimization scheme, though its performance typically degrades in higher dimensions. We aim to overcome this problem by incorporating domain knowledge, with a focus on bipedal locomotion. In our previous work, we proposed a feature transformation that projected a 16-dimensional locomotion controller to a 1-dimensional space using knowledge of human walking. When optimizing a human-inspired neuromuscular controller in simulation, this feature transformation enhanced sample efficiency of BO over traditional BO with a Squared Exponential kernel. In this paper, we present a generalized feature transform applicable to non-humanoid robot morphologies and evaluate it on the ATRIAS bipedal robot, in both simulation and hardware. We present three different walking controllers and two are evaluated on the real robot. Our results show that this feature transform captures important aspects of walking and accelerates learning on hardware and simulation, as compared to traditional BO.
keywords: {Hardware;Legged locomotion;Optimization;Kernel;Transforms;Measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461237&isnumber=8460178

S. Caron and B. Mallein, "Balance Control Using Both ZMP and COM Height Variations: A Convex Boundedness Approach," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1779-1784.
doi: 10.1109/ICRA.2018.8460942
Abstract: Developments for 3D control of the center of mass (CoM) of biped robots are currently located in two local minima: on the one hand, methods that allow CoM height variations but only work in the 2D sagittal plane; on the other hand, nonconvex direct transcriptions of centroidal dynamics that are delicate to handle. This paper presents an alternative that controls the CoM in 3D via an indirect transcription that is both low-dimensional and solvable fast enough for real-time control. The key to this development is the notion of boundedness condition, which quantifies the capturability of 3D CoM trajectories.
keywords: {Trajectory;Mathematical model;Three-dimensional displays;Two dimensional displays;Robots;Radio frequency;Differential equations},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460942&isnumber=8460178

S. Mason, N. Rotella, S. Schaal and L. Righetti, "An MPC Walking Framework with External Contact Forces," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1785-1790.
doi: 10.1109/ICRA.2018.8461236
Abstract: In this work, we present an extension to a linear Model Predictive Control (MPC) scheme that plans external contact forces for the robot when given multiple contact locations and their corresponding friction cone. To this end, we set up a two-step optimization problem. In the first optimization, we compute the Center of Mass (CoM) trajectory, foot step locations, and introduce slack variables to account for violating the imposed constraints on the Zero Moment Point (ZMP). We then use the slack variables to trigger the second optimization, in which we calculate the optimal external force that compensates for the ZMP tracking error. This optimization considers multiple contacts positions within the environment by formulating the problem as a Mixed Integer Quadratic Program (MIQP) that can be solved at a speed between 100-300 Hz. Once contact is created, the MIQP reduces to a single Quadratic Program (QP) that can be solved in real-time (<; 1kHz). Simulations show that the presented walking control scheme can withstand disturbances 2-3× larger with the additional force provided by a hand contact.
keywords: {Optimization;Force;Legged locomotion;Trajectory;Friction;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461236&isnumber=8460178

T. Seyde, A. Shrivastava, J. Englsberger, S. Bertrand, J. Pratt and R. J. Griffin, "Inclusion of Angular Momentum During Planning for Capture Point Based Walking," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1791-1798.
doi: 10.1109/ICRA.2018.8461140
Abstract: When walking at high speeds, the swing legs of robots produce a non-negligible angular momentum rate. To accommodate this, we provide a reference trajectory generator for bipedal walking that incorporates predicted centroidal angular momentum at the planning stage. This can be done efficiently as the Centroidal Moment Pivot (CMP), Instantaneous Capture Point (ICP) and the center of mass (CoM) all have closed-form trajectory solutions due to their linear dynamics. This is then used to produce smooth, continuous trajectories. We furthermore provide a lightweight model to estimate angular momentum as induced during leg swing of the gait cycle. Our proposed trajectory generator is tested thoroughly in simulation and has been shown to successfully operate on the real hardware.
keywords: {Legged locomotion;Trajectory;Iterative closest point algorithm;Planning;Dynamics;Lips},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461140&isnumber=8460178

A. P. H. Needham et al., "Subject-Independent Data Pooling in Classification of Gait Intent Using Mechanomyography on a Transtibial Amputee," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1806-1811.
doi: 10.1109/ICRA.2018.8461246
Abstract: Active lower limb prosthetics rely on the detection of gait mode to direct controller response. The majority of systems require feedback from the prosthetic and/or inertial measurement units (IMUs). Reliance on movement delays classification, reducing the range of patient activities and terrain traversed. Neuromuscular interfaces using electromyography (EMG) enable real-time monitoring by registering user intent, however EMG has known robustness issues out-of-clinic that have impeded its translation. Furthermore, supervised training of gait classifiers can require large subject-specific amputee data sets which are difficult to obtain. Mechanomyography (MMG) has shown less dependence on environmental conditions than EMG yet has seen limited use in this realm. In this investigation we introduce an MMG gait classifier targeting improved control of prosthetic (robotic) legs. We compare the accuracy of subject specific classifiers to those trained using subject-independent pooling. Additionally, we quantify the effect of introducing a small amount of data from individual test subjects to the training pool. Experiments were performed on 12 participants and 5 gait modes. A support vector machine (SVM) classifier achieved 65% accuracy with subject-specific data, 92% with pooled training data, and 94% with pooled plus limited user-specific data. The results show the promise of MMG gait classifiers with increased robustness and reduced subject-specific training in prosthetic control.
keywords: {Electromyography;Training;Legged locomotion;Muscles;Sensors;Prosthetics;Support vector machines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461246&isnumber=8460178

S. Pitou, F. Wu, A. Shafti, B. Michael, R. Stopforth and M. Howard, "Embroidered Electrodes for Control of Affordable Myoelectric Prostheses," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1812-1817.
doi: 10.1109/ICRA.2018.8461066
Abstract: The low-cost manufacturing and maintenance of prostheses is of vital importance to their successful deployment in developing countries. Low-cost prosthesis actuation is generally achieved by combining pre-programmed control strategies, with surface-electromyographic measurements taken from the residual limb. In a standard setting, these signals are measured with disposable gel electrodes. However, this limit on electrode reuse requires that prosthesis users have a stable supply of electrodes. Alternatively, the textile electrodes sewn from conductive thread are studied in the context of hand gesture recognition to consider their future use with low-cost prostheses. In this paper, it is demonstrated that textile electrodes can be applied for gesture recognition. To do so, surface electromyography (sEMG) experiments are run in South Africa on three amputees where they were asked to perform gestures with their phantom limb (i.e., the missing limb segment). A gesture recognition method is implemented, and the classification accuracy with data recorded from textile electrodes is compared to that from gel electrodes. Further analysis examining the relationship between classifier performance and physiological parameters are performed. Results show that textile electrodes can be used to perform accurate gesture recognition, and are comparable to disposable gel electrodes. This demonstrates that low-cost sensory systems are not barrier to myoelectric control in developing countries.
keywords: {Electrodes;Electromyography;Textiles;Prosthetics;Muscles;Gesture recognition;Wrist},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461066&isnumber=8460178

A. Kato et al., "Continuous Wrist Joint Control Using Muscle Deformation Measured on Forearm Skin," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1818-1824.
doi: 10.1109/ICRA.2018.8460491
Abstract: Continuous, easy-to-implement, accurate inference of intended joint angles is important for effectively controlling powered prosthetic devices that can improve the lives and capabilities of upper-limb amputees. Estimation of intended joint angles is difficult because conventional biosignals are not directly related to the intended angle motion. In previous work, we began to address this issue by confirming that both transra-dial amputees and intact subjects, the measured deformation of the muscle bulge on the skin surface change according to the intended wrist joint angle. This paper presents a continuous prosthesis wrist joint control method using this deformation signal. We here verify the effectiveness of the distribution of the muscle bulge for accurate and stable wrist joint angle control in real time. The wrist joint angles were calculated in real time from a muscle viscoelastic model using the previously determined algorithm. We compared the error between measured and estimated angles with a conventional method, the Voigt model, and the KelvinVoigt model. Experimental results obtained for three intact people over three trials of wrist movement tasks gave the accuracy and stability of 7.96±6.16° when using the Voigt model; this is a similar performance compared to related work using a surface electromyogram. A method for continuously controlling the wrist joint angle for a prosthesis using the distribution of the muscle bulge was thus successfully established.
keywords: {Wrist;Muscles;Strain;Skin;Prosthetic hand;Mathematical model;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460491&isnumber=8460178

L. A. Hallock, A. Kato and R. Bajcsy, "Empirical Quantification and Modeling of Muscle Deformation: Toward Ultrasound-Driven Assistive Device Control," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1825-1832.
doi: 10.1109/ICRA.2018.8462887
Abstract: Surface electromyography is currently the sensing modality of choice for control of biosignal-driven prostheses and exoskeletons; however, the sensor's noisy and aggregate nature inhibits collection of distinguishable signal streams to robustly manipulate multiple device degrees of freedom (DoF). We here explore 2D B-mode ultrasound as an alternative source of muscle activation data (namely, muscle deformation) that can be more precisely localized, allowing for the theoretical collection of multiple naturally-varying signals that could be used to control high-DoF assistive devices. We here present a proof-of-concept study showing a) the observability of muscle deformation via ultrasound, and b) novel descriptions of the spatially-varying nature of the signal. These analyses are accomplished through the study of nine volumetric scans of the biceps brachii under varied elbow angle and loading conditions, collected and spatially localized using an ultrasound scanner and motion capture. We here establish the feasibility of measuring several force-associated deformation signals (including muscle cross-sectional area and thickness) via real-time ultrasound scanning and quantify the spatial variation of these signals. Additionally, we propose future applications for both our signal characterizations and the generated muscle volume data set, including better design of assistive device sensor locations and validation of existing muscle deformation models.
keywords: {Muscles;Strain;Ultrasonic imaging;Elbow;Assistive devices;Deformable models;Ultrasonic variables measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462887&isnumber=8460178

S. Okajima et al., "Grasp-training Robot to Activate Neural Control Loop for Reflex and Experimental Verification," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1849-1854.
doi: 10.1109/ICRA.2018.8461114
Abstract: Using a rehabilitation robot to activate motion intention and reflex response simultaneously is an effective approach to aiding recovery from paralysis caused by neurological disorders. Mechanical motions supported by conventional robots are, however, not enough to activate reflex. In this paper, we propose a grasp-training robot that can stimulate the grasp reflex of a paralyzed hand by pushing the hand onto an elastic bar while supporting the grasping movements. In addition to this feature, we discuss the robot design in relation to its usability and wearability for ease of use in clinical practice. Experimental results obtained from healthy subjects show that the proposed robot can support grasping in a way similar to the traditional range-of-motion exercise used by therapists for grasp rehabilitation. Combining this appropriate grasping-motion support and the mechanism for pushing the hand onto an elastic bar succeeds in activating the grasp reflex of a completely paralyzed patient in a clinical test that involves monitoring electromyography signals from the paralyzed hand.
keywords: {Robots;Grasping;Shafts;Bars;Force;Electromyography;Rubber},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461114&isnumber=8460178

M. Antonello, D. Wolf, J. Prankl, S. Ghidoni, E. Menegatti and M. Vincze, "Multi-View 3D Entangled Forest for Semantic Segmentation and Mapping," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1855-1862.
doi: 10.1109/ICRA.2018.8460837
Abstract: Applications that provide location related services need to understand the environment in which humans live such that verbal references and human interaction are possible. We formulate this semantic labelling task as the problem of learning the semantic labels from the perceived 3D structure. In this contribution we propose a batch approach and a novel multi-view frame fusion technique to exploit multiple views for improving the semantic labelling results. The batch approach works offline and is the direct application of an existing single-view method to scene reconstructions with multiple views. The multi-view frame fusion works in an incremental fashion accumulating the single-view results, hence allowing the online multi-view semantic segmentation of single frames and the offline reconstruction of semantic maps. Our experiments show the superiority of the approaches based on our fusion scheme, which leads to a more accurate semantic labelling.
keywords: {Semantics;Three-dimensional displays;Simultaneous localization and mapping;Forestry;Labeling;Context modeling;Standards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460837&isnumber=8460178

T. Bruls, W. Maddern, A. A. Morye and P. Newman, "Mark Yourself: Road Marking Segmentation via Weakly-Supervised Annotations from Multimodal Data," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1863-1870.
doi: 10.1109/ICRA.2018.8460952
Abstract: This paper presents a weakly-supervised learning system for real-time road marking detection using images of complex urban environments obtained from a monocular camera. We avoid expensive manual labelling by exploiting additional sensor modalities to generate large quantities of annotated images in a weakly-supervised way, which are then used to train a deep semantic segmentation network. At run time, the road markings in the scene are detected in real time in a variety of traffic situations and under different lighting and weather conditions without relying on any preprocessing steps or predefined models. We achieve reliable qualitative performance on the Oxford RobotCar dataset, and demonstrate quantitatively on the CamVid dataset that exploiting these annotations significantly reduces the required labelling effort and improves performance.
keywords: {Roads;Laser radar;Cameras;Image segmentation;Real-time systems;Labeling;Semantics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460952&isnumber=8460178

M. Brucker et al., "Semantic Labeling of Indoor Environments from 3D RGB Maps," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1871-1878.
doi: 10.1109/ICRA.2018.8462922
Abstract: We present an approach to automatically assign semantic labels to rooms reconstructed from 3D RGB maps of apartments. Evidence for the room types is generated using state-of-the-art deep-learning techniques for scene classification and object detection based on automatically generated virtual RGB views, as well as from a geometric analysis of the map's 3D structure. The evidence is merged in a conditional random field, using statistics mined from different datasets of indoor environments. We evaluate our approach qualitatively and quantitatively and compare it to related methods.
keywords: {Semantics;Labeling;Three-dimensional displays;Robots;Training;Task analysis;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462922&isnumber=8460178

C. Rubino, A. Del Bue and T. Chin, "Practical Motion Segmentation for Urban Street View Scenes," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1879-1886.
doi: 10.1109/ICRA.2018.8460993
Abstract: Though a long-studied problem, motion segmentation has yet to migrate into practical applications. We argue that a vital step towards that goal lies in addressing motion segmentation for the specific setting of interest. To this end, this paper presents a new approach for image-based motion segmentation in the case of vehicles navigating inside an urban environment. We exploit two application-specific factors - the restricted camera movement and the known type of moving objects - to deal with the two major limiting factors - missing data and strong perspective effects - that affect most previous “generic” motion segmentation algorithms. By constraining the geometry and exploiting known semantic classes in the scene, we achieve much higher accuracy than previous approaches. In addition to the novel algorithm, we contribute a more realistic motion segmentation benchmark dataset for moving platforms by annotating real video sequences from the KITTI dataset. Experiments on this dataset and other synthetic data confirm the effectiveness of the proposed approach.
keywords: {Motion segmentation;Trajectory;Computer vision;Cameras;Transmission line matrix methods;Semantics;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460993&isnumber=8460178

B. Wu, A. Wan, X. Yue and K. Keutzer, "SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1887-1893.
doi: 10.1109/ICRA.2018.8462926
Abstract: We address semantic segmentation of road-objects from 3D LiDAR point clouds. In particular, we wish to detect and categorize instances of interest, such as cars, pedestrians and cyclists. We formulate this problem as a point-wise classification problem, and propose an end-to-end pipeline called SqueezeSeg based on convolutional neural networks (CNN): the CNN takes a transformed LiDAR point cloud as input and directly outputs a point-wise label map, which is then refined by a conditional random field (CRF) implemented as a recurrent layer. Instance-level labels are then obtained by conventional clustering algorithms. Our CNN model is trained on LiDAR point clouds from the KITTI [1] dataset, and our point-wise segmentation labels are derived from 3D bounding boxes from KITTI. To obtain extra training data, we built a LiDAR simulator into Grand Theft Auto V (GTA-V), a popular video game, to synthesize large amounts of realistic training data. Our experiments show that SqueezeSeg achieves high accuracy with astonishingly fast and stable runtime (8.7±0.5 ms per frame), highly desirable for autonomous driving. Furthermore, additionally training on synthesized data boosts validation accuracy on real-world data. Our source code is open-source released1. The paper is accompanied by a video2 containing a high level introduction and demonstrations of this work.
keywords: {Three-dimensional displays;Laser radar;Computational modeling;Pipelines;Autonomous vehicles;Semantics;Clustering algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462926&isnumber=8460178

D. Barnes, W. Maddern, G. Pascoe and I. Posner, "Driven to Distraction: Self-Supervised Distractor Learning for Robust Monocular Visual Odometry in Urban Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1894-1900.
doi: 10.1109/ICRA.2018.8460564
Abstract: We present a self-supervised approach to ignoring “distractors” in camera images for the purposes of robustly estimating vehicle motion in cluttered urban environments. We leverage offline multi-session mapping approaches to automatically generate a per-pixel ephemerality mask and depth map for each input image, which we use to train a deep convolutional network. At run-time we use the predicted ephemerality and depth as an input to a monocular visual odometry (VO) pipeline, using either sparse features or dense photometric matching. Our approach yields metric-scale VO using only a single camera and can recover the correct egomotion even when 90% of the image is obscured by dynamic, independently moving objects. We evaluate our robust VO methods on more than 400km of driving from the Oxford RobotCar Dataset and demonstrate reduced odometry drift and significantly improved egomotion estimation in the presence of large moving vehicles in urban traffic.
keywords: {Three-dimensional displays;Cameras;Robustness;Visual odometry;Motion estimation;Entropy;Training data},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460564&isnumber=8460178

L. F. Posada, A. Velasquez-Lopez, F. Hoffmann and T. Bertram, "Semantic Mapping with Omnidirectional Vision," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1901-1907.
doi: 10.1109/ICRA.2018.8461165
Abstract: This paper presents a purely visual semantic mapping framework using omnidirectional images. The approach rests upon the robust segmentation of the robot's local free space, replacing conventional range sensors for the generation of occupancy grid maps. The perceptions are mapped into a bird's eye view allowing an inverse sensor model directly by removing the non-linear distortions of the omnidirectional camera mirror. The system relies on a place category classifier to label the navigation relevant categories: room, corridor, doorway, and open room. Each place class maintains a separated grid map that are fused with the range-based occupancy grid for building a dense semantic map.
keywords: {Semantics;Sensors;Cameras;Robots;Buildings;Mirrors;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461165&isnumber=8460178

A. Milan et al., "Semantic Segmentation from Limited Training Data," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1908-1915.
doi: 10.1109/ICRA.2018.8461082
Abstract: We present our approach for robotic perception in cluttered scenes that led to winning the recent Amazon Robotics Challenge (ARC) 2017. Next to small objects with shiny and transparent surfaces, the biggest challenge of the 2017 competition was the introduction of unseen categories. In contrast to traditional approaches which require large collections of annotated data and many hours of training, the task here was to obtain a robust perception pipeline with only few minutes of data acquisition and training time. To that end, we present two strategies that we explored. One is a deep metric learning approach that works in three separate steps: semantic-agnostic boundary detection, patch classification and pixel-wise voting. The other is a fully-supervised semantic segmentation approach with efficient dataset collection. We conduct an extensive analysis of the two methods on our ARC 2017 dataset. Interestingly, only few examples of each class are sufficient to fine-tune even very deep convolutional neural networks for this specific task.
keywords: {Task analysis;Image segmentation;Training;Semantics;Robots;Measurement;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461082&isnumber=8460178

B. Busch, M. Toussaint and M. Lopes, "Planning Ergonomic Sequences of Actions in Human-Robot Interaction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1916-1923.
doi: 10.1109/ICRA.2018.8462927
Abstract: In this paper, we define the problem of human-robot collaboration as a combined task and motion planning problem which is extended to the multi-agent case (human and robot). Our proposed approach allows us to explicitly take into account ergonomic cost, synchrony and concurrency of behavior in an optimization formulation. We show simulated results as well as an experiment with a real robot combined with a user study. Results show that optimizing over a sequence of actions leads to more ergonomic situations.
keywords: {Ergonomics;Task analysis;Robot kinematics;Planning;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462927&isnumber=8460178

M. Dohi, K. Okada, I. Maeda, S. Fujitani and T. Fujita, "Proposal of Collaboration Safety in a Coexistence Environment of Human and Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1924-1930.
doi: 10.1109/ICRA.2018.8460869
Abstract: Whereas various things are connected via networks thanks to IoT technology, and the era of the 4th industrial revolution which realizes optimization and efficiency by utilizing AI and big data is emerging, manufacturing systems are also significantly transforming globally. In addition to the robot revolution, along with progressing digitalization, manufacturing sites in Japan are changing, aiming at establishment of “Connected Industries” that is a solution-oriented industrial society, based on the high technological capabilities. In order to respond timely to diversifying demands of customers, it is necessary to build a next-generation manufacturing systems that realizes flexible and high productivity, such as human-robot collaboration, and it is becoming difficult to respond to the necessity by conventional safety concept. Therefore, in order to realize the 4th industrial revolution, the robot revolution, and “Connected Industries,” it is essential to establish a new safety concept corresponding to the next-generation manufacturing systems to ensure safety. This paper introduces the safety concept to be changed along with the evolution of manufacturing sites, and proposes a new safety concept, which realizes collaboration safety of humans and robots, and an outline of its safety level, for the first time in the world.
keywords: {Collaboration;Service robots;Production;Hazards;Optimization;Robot Safety;Industrial Robots;Factory Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460869&isnumber=8460178

E. Hourdakis and P. Trahanias, "A Robust Method to Predict Temporal Aspects of Actions by Observation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1931-1938.
doi: 10.1109/ICRA.2018.8461067
Abstract: The ability to predict the duration of an activity can enable a robot to plan its behaviors ahead, interact seamlessly with other humans, by coordinating its actions, and allocate effort and resources to tasks that are time-constrained or critical. Despite its usefulness, models that examine the temporal properties of an activity remain relatively unexplored. In the current paper we present, to the best of our knowledge, the first method that can estimate temporal properties of an activity by observation. We evaluate it on three use-cases (i) wiping a table, (ii) chopping vegetables and (iii) cleaning the floor, using ground truth data from real demonstrations, and show that it can make predictions with high accuracy and little training. In addition, we investigate different methods to approximate the progress of each task, and demonstrate how a model can generalize, by reusing part of it in different activities.
keywords: {Task analysis;Frequency modulation;Motion segmentation;Predictive models;Process control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461067&isnumber=8460178

J. Elsdon and Y. Demiris, "Augmented Reality for Feedback in a Shared Control Spraying Task," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1939-1946.
doi: 10.1109/ICRA.2018.8461179
Abstract: Using industrial robots to spray structures has been investigated extensively, however interesting challenges emerge when using handheld spraying robots. In previous work we have demonstrated the use of shared control of a handheld spraying robot to assist a user in a 3D spraying task. In this paper we demonstrate the use of Augmented Reality Interfaces to increase the user's progress and task awareness. We describe our solutions to challenging calibration issues between the Microsoft Hololens system and a motion capture system without the need for well defined markers or careful alignment on the part of the user. Error relative to the motion capture system was shown to be 10mm after only a 4 second calibration routine. Secondly we outline a logical approach for visualising liquid density for an augmented reality spraying task, this system allows the user to see target regions to complete, areas that are complete and areas that have been overdosed clearly. Finally we produced a user study to investigate the level of assistance that a handheld robot utilising shared control methods should provide during a spraying task. Using a handheld spraying robot with a moving spray head did not aid the user much over simply actuating spray nozzle for them. Compared to manual control the automatic modes significantly reduced the task load experienced by the user and significantly increased the quality of the result of the spraying task, reducing the error by 33-45%.
keywords: {Task analysis;Robots;Spraying;Augmented reality;Calibration;Paints;Headphones},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461179&isnumber=8460178

H. Liu, Y. Zhang, W. Si, X. Xie, Y. Zhu and S. -C. Zhu, "Interactive Robot Knowledge Patching Using Augmented Reality," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1947-1954.
doi: 10.1109/ICRA.2018.8462837
Abstract: We present a novel Augmented Reality (AR) approach, through Microsoft HoloLens, to address the challenging problems of diagnosing, teaching, and patching interpretable knowledge of a robot. A Temporal And-Or graph (T-AOG) of opening bottles is learned from human demonstration and programmed to the robot. This representation yields a hierarchical structure that captures the compositional nature of the given task, which is highly interpretable for the users. By visualizing the knowledge structure represented by a T-AOG and the decision making process by parsing the T-AOG, the user can intuitively understand what the robot knows, supervise the robot's action planner, and monitor visually latent robot states (e.g., the force exerted during interactions). Given a new task, through such comprehensive visualizations of robot's inner functioning, users can quickly identify the reasons of failures, interactively teach the robot with a new action, and patch it to the current knowledge structure. In this way, the robot is capable of solving similar but new tasks only through minor modifications provided by the users interactively. This process demonstrates the interpretability of our knowledge representation and the effectiveness of the AR interface.
keywords: {Task analysis;Decision making;Knowledge representation;Visualization;Robot sensing systems;Grammar},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462837&isnumber=8460178

A. E. Vijayan, S. Alexanderson, J. Beskow and I. Leite, "Using Constrained Optimization for Real-Time Synchronization of Verbal and Nonverbal Robot Behavior," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1955-1961.
doi: 10.1109/ICRA.2018.8462828
Abstract: Most of the motion re-targeting techniques are grounded on virtual character animation research, which means that they typically assume that the target embodiment has unconstrained joint angular velocities. However, because robots often do have such constraints, traditional re-targeting approaches can originate irregular delays in the robot motion. With the goal of ensuring synchronization between verbal and nonverbal behavior, this paper proposes an optimization framework for processing re-targeted motion sequences that addresses constraints such as joint angle and angular velocities. The proposed framework was evaluated on a humanoid robot using both objective and subjective metrics. While the analysis of the joint motion trajectories provides evidence that our framework successfully performs the desired modifications to ensure verbal and nonverbal behavior synchronization, results from a perceptual study showed that participants found the robot motion generated by our method more natural, elegant and lifelike than a control condition.
keywords: {Optimization;Trajectory;Angular velocity;Synchronization;Dynamics;Robot motion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462828&isnumber=8460178

H. Maske, E. Kieson, G. Chowdhary and C. Abramson, "Learning Task-Based Instructional Policy for Excavator-Like Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1962-1969.
doi: 10.1109/ICRA.2018.8462923
Abstract: We explore beyond existing work in learning from demonstration by asking the question: “Can robots learn to guide?”, that is, can a robot autonomously learn an instructional policy from expert demonstration and use it to instruct humans in executing complex task? As a solution, we propose learning of instructional policy (πI) that maps the state to an instruction for a human. To learn πI, we define action primitives that addresses the challenge of mapping continuous state action trajectories to human parse-able instructions. Action primitives are demonstrated to be very effective in automatic segmentation of demonstration trajectories into fewer repetitive and reusable segments, and a highly scalable approach in comparison to the existing state-of-the art. Finally, we construct a non-generic policy model as a generative model for instructional policies to generate instruction for an entire task. With few modifications, the proposed model is demonstrated to perform autonomous execution of complex truck loading task on hydraulic actuated scaled excavator robot. Guidance approach is tested based on a controlled group study involving 75 participants, who learn to perform the same task.
keywords: {Task analysis;Robots;Trajectory;Hidden Markov models;Load modeling;Actuators;Loading},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462923&isnumber=8460178

M. Mutlu, S. Hauser, A. Bernardino and A. Ijspeert, "Playdough to Roombots: Towards a Novel Tangible User Interface for Self-reconfigurable Modular Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1970-1977.
doi: 10.1109/ICRA.2018.8461248
Abstract: One of the main strengths of self-reconfigurable modular robots (SRMR) is their ability to shape-shift and dynamically change their morphology. In the case of our SRMR system “Roombots”, these shapes can be quite arbitrary for a great variety of tasks while the major utility is envisioned to be self-reconfigurable furniture. As such, the ideas and inspirations from users quickly need to be translated into the final Roombots shape. This involves a multitude of separate processes and - most importantly - requires an intuitive user interface. Our current approach led to the development of a tangible user interface (TUI) which involves 3D-scanning of a shape formed by modeling clay and the necessary steps to prepare the digitized model to be formed by Roombots. The system is able to generate a solution in less than two minutes for our target use as demonstrated with various examples.
keywords: {Shape;Three-dimensional displays;User interfaces;Solid modeling;Robots;Planning;Buildings;tangible user interface;self-reconfigurable modular robots;deformable material;shape formation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461248&isnumber=8460178

Z. Shao, Y. Li, Y. Guo, J. Yang and Z. Wang, "A Hierarchical Model for Action Recognition Based on Body Parts," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1978-1985.
doi: 10.1109/ICRA.2018.8460516
Abstract: As increasing attention is paid on human action recognition from skeleton data, this paper focuses on such tasks by proposing a hierarchical model to discover the structure information of body-parts involved in human actions. Considering human actions as simultaneous motions of different body-parts of the human skeleton, we propose a hierarchical model to simultaneously apply discriminative body-parts selection at a same scale and group coupling of bundles of body-parts at different scales, while we decompose the human skeleton into a hierarchy of body-parts of varying scales. To represent such hierarchy of body-parts, we accordingly build a hierarchical RRV (Rotation and Relative Velocity) descriptors. The hierarchical representations encoded by Fisher vectors of the hierarchical RRV descriptors are properly formulated into the hierarchical model via the proposed hierarchical mixed norm, to apply sparse selection of body-parts and regularize the structure of such hierarchy of body-parts. The extensive evaluations on three challenging datasets demonstrate the effectiveness of our proposed approach, which achieves superior performance compared to state-of-the-art results on different sizes of datasets, showing it is more widely applicable than existing approaches.
keywords: {Skeleton;Feature extraction;Three-dimensional displays;Task analysis;Trajectory;Couplings;Biological system modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460516&isnumber=8460178

C. Zimmermann, T. Welschehold, C. Dornhege, W. Burgard and T. Brox, "3D Human Pose Estimation in RGBD Images for Robotic Task Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1986-1992.
doi: 10.1109/ICRA.2018.8462833
Abstract: We propose an approach to estimate 3D human pose in real world units from a single RGBD image and show that it exceeds performance of monocular 3D pose estimation approaches from color as well as pose estimation exclusively from depth. Our approach builds on robust human keypoint detectors for color images and incorporates depth for lifting into 3D. We combine the system with our learning from demonstration framework to instruct a service robot without the need of markers. Experiments in real world settings demonstrate that our approach enables a PR2 robot to imitate manipulation actions observed from a human teacher.
keywords: {Three-dimensional displays;Two dimensional displays;Color;Pose estimation;Robot sensing systems;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462833&isnumber=8460178

R. Weitschat, J. Ehrensperger, M. Maier and H. Aschemann, "Safe and Efficient Human-Robot Collaboration Part I: Estimation of Human Arm Motions," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 1993-1999.
doi: 10.1109/ICRA.2018.8461190
Abstract: A significant barrier regarding a successful implementation of fenceless robot cells into manufacturing areas with humans is given by the inefficiency due to safety requirements. Robot motions have to be slowed down so that an unexpected collision with a human does not result in human injuries. This velocity reduction leads to longer cycle times and, hence, fenceless robot cells turn out as uneconomic. In this paper, a new approach for human-robot collaboration in assembly tasks is presented. For a better performance of the robot, methods are investigated on how the robot can exploit a maximum performance while maintaining the safety of collaborating humans. For this purpose, the kinematics and dynamics of a human arm are described by a control-oriented dynamic model to determine its capability and reachability. Successful experiments validate the dynamic model as well as a corresponding projection approach for calculating possible movements of the human arm that may lead to a collision with the robot. Finally, this information is used to calculate an admissible path velocity that minimizes the danger of human injuries.
keywords: {Collision avoidance;Manipulators;Kinematics;Collaboration;Safety;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461190&isnumber=8460178

R. Hanten, P. Kuhlmann, S. Otte and A. Zell, "Robust Real-Time 3D Person Detection for Indoor and Outdoor Applications," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2000-2006.
doi: 10.1109/ICRA.2018.8461257
Abstract: Fast and robust person detection is one of the most important tasks for robotic applications involving human interaction. Particularly in mobile robotics this task is still challenging. Though there are already reliable and real-time capable approaches, they are usually computationally expensive. They either require GPUs or multiple CPU cores in order to work properly. Furthermore, some of the approaches are designed for special environments and sensor types, which reduces general applicability. In this work, we present a robust, generic and lightweight solution for real-time 3D person detection. Since our approach requires only a single CPU thread, it can be run as a background process and is suitable for smaller robotic systems. We demonstrate applicability to indoor and outdoor scenarios using different 3D sensor types separately. Moreover, we are able to show that the proposed method outperforms other state-of-the-art approaches, including a DCNN.
keywords: {Three-dimensional displays;Robot sensing systems;Feature extraction;Visualization;Pipelines;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461257&isnumber=8460178

Y. Qian, M. Yang, C. Wang and B. Wang, "Pedestrian Feature Generation in Fish-Eye Images via Adversary," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2007-2012.
doi: 10.1109/ICRA.2018.8460565
Abstract: Pedestrian detection in fish-eye images is always an important problem in advanced driver assistance systems (ADAS). In conventional methods, pedestrian detectors will be trained using fish-eye images. But it is hard to collect and label enough fish-eye images manually. Therefore, a new strategy for training fish-eye pedestrian detectors using images from normal pedestrian datasets is proposed in this work. Concretely, Fish-eye Spatial Transformer Network (FSTN) is designed to generate pedestrian features in fish-eye images. FSTN aims to simulate distorted pedestrian features on the feature maps. Then the entire network is trained via adversary. FSTN is trained to generate examples which are difficult for pedestrian detectors to classify. So that the detectors are more robust to the deformation. FSTN can be embedded into state-of-the-art detectors easily. And the entire pedestrian detector, where the FSTN embedded, can be trained end to end via adversary. Moreover, experiments on ETH and KITTI pedestrian datasets show the slight accuracy improvement of pedestrian detection in fish-eye images using adversarial network compared with conventional methods.
keywords: {Detectors;Training;Feature extraction;Mathematical model;Cameras;Proposals;Convolution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460565&isnumber=8460178

W. -C. Chang, C. -W. Wu, R. Y. -C. Tsai, K. C. -J. Lin and Y. -C. Tseng, "Eye on You: Fusing Gesture Data from Depth Camera and Inertial Sensors for Person Identification," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2021-2026.
doi: 10.1109/ICRA.2018.8462924
Abstract: Person identification (PID) is a key issue in many IoT applications. It has long been studied and achieved by technologies such as RFID and face/fingerprint/iris recognition. These approaches, however, have their limitations due to environmental constraints (such as lighting and obstacles) or require close contact to specific devices. Therefore, their recognition rates highly depend on use scenarios. To enable reliable and remote PID, in this work, we present EOY (Eye On You)1, a data fusion approach that combines two kinds of sensors, a 3D depth camera and wearable sensors embedded with inertial measurement unit (IMU). Since these two kinds of data share common features, we are able to fuse them to conduct PID. Further, the result can be transferred to a mobile platform (such as robot) since we have less constraints on devices. To realize EOY, we develop fusion algorithms to address practical challenges, such as asynchronous timing and coordinate calibration. The experimental evaluation shows that EOY can achieve the recognition rate of 95% and is very robust even in crowded areas.
keywords: {Skeleton;Cameras;Sensors;Correlation;Iris recognition;Feature extraction;Motion segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462924&isnumber=8460178

X. Zhou, S. Liu, G. Pavlakos, V. Kumar and K. Daniilidis, "Human Motion Capture Using a Drone," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2027-2033.
doi: 10.1109/ICRA.2018.8462830
Abstract: Current motion capture (MoCap) systems generally require markers and multiple calibrated cameras, which can be used only in constrained environments. In this work we introduce a drone-based system for 3D human MoCap. The system only needs an autonomously flying drone with an on-board RGB camera and is usable in various indoor and outdoor environments. A reconstruction algorithm is developed to recover full-body motion from the video recorded by the drone. We argue that, besides the capability of tracking a moving subject, a flying drone also provides fast varying viewpoints, which is beneficial for motion reconstruction. We evaluate the accuracy of the proposed system using our new DroCap dataset and also demonstrate its applicability for MoCap in the wild using a consumer drone.
keywords: {Cameras;Drones;Two dimensional displays;Three-dimensional displays;Image reconstruction;Tracking;Joints},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462830&isnumber=8460178

D. Isele, R. Rahimi, A. Cosgun, K. Subramanian and K. Fujimura, "Navigating Occluded Intersections with Autonomous Vehicles Using Deep Reinforcement Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2034-2039.
doi: 10.1109/ICRA.2018.8461233
Abstract: Providing an efficient strategy to navigate safely through unsignaled intersections is a difficult task that requires determining the intent of other drivers. We explore the effectiveness of Deep Reinforcement Learning to handle intersection problems. Using recent advances in Deep RL, we are able to learn policies that surpass the performance of a commonly-used heuristic approach in several metrics including task completion time and goal success rate and have limited ability to generalize. We then explore a system's ability to learn active sensing behaviors to enable navigating safely in the case of occlusions. Our analysis, provides insight into the intersection handling problem, the solutions learned by the network point out several shortcomings of current rule-based methods, and the failures of our current deep reinforcement learning system point to future research directions.
keywords: {Autonomous vehicles;Automobiles;Machine learning;Safety;Navigation;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461233&isnumber=8460178

T. Ort, L. Paull and D. Rus, "Autonomous Vehicle Navigation in Rural Environments Without Detailed Prior Maps," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2040-2047.
doi: 10.1109/ICRA.2018.8460519
Abstract: State-of-the-art autonomous driving systems rely heavily on detailed and highly accurate prior maps. However, outside of small urban areas, it is very challenging to build, store, and transmit detailed maps since the spatial scales are so large. Furthermore, maintaining detailed maps of large rural areas can be impracticable due to the rapid rate at which these environments can change. This is a significant limitation for the widespread applicability of autonomous driving technology, which has the potential for an incredibly positive societal impact. In this paper, we address the problem of autonomous navigation in rural environments through a novel mapless driving framework that combines sparse topological maps for global navigation with a sensor-based perception system for local navigation. First, a local navigation goal within the sensor view of the vehicle is chosen as a waypoint leading towards the global goal. Next, the local perception system generates a feasible trajectory in the vehicle frame to reach the waypoint while abiding by the rules of the road for the segment being traversed. These trajectories are updated to remain in the local frame using the vehicle's odometry and the associated uncertainty based on the least-squares residual and a recursive filtering approach, which allows the vehicle to navigate road networks reliably, and at high speed, without detailed prior maps. We demonstrate the performance of the system on a full-scale autonomous vehicle navigating in a challenging rural environment and benchmark the system on a large amount of collected data.
keywords: {Roads;Navigation;Autonomous vehicles;Trajectory;Robot sensing systems;Reliability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460519&isnumber=8460178

M. I. Valls et al., "Design of an Autonomous Racecar: Perception, State Estimation and System Integration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2048-2055.
doi: 10.1109/ICRA.2018.8462829
Abstract: This paper introduces jlüela driverless: the first autonomous racecar to win a Formula Student Driverless competition. In this competition, among other challenges, an autonomous racecar is tasked to complete 10 laps of a previously unknown racetrack as fast as possible and using only onboard sensing and computing. The key components of flüela's design are its modular redundant sub-systems that allow robust performance despite challenging perceptual conditions or partial system failures. The paper presents the integration of key components of our autonomous racecar, i.e., system design, EKF-based state estimation, LiDAR-based perception, and particle filter-based SLAM. We perform an extensive experimental evaluation on real-world data, demonstrating the system's effectiveness by outperforming the next-best ranking team by almost half the time required to finish a lap. The autonomous racecar reaches lateral and longitudinal accelerations comparable to those achieved by experienced human drivers.
keywords: {Automobiles;State estimation;Robot sensing systems;Current measurement;Laser radar;Wheels;Global Positioning System},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462829&isnumber=8460178

S. Hoermann, M. Bach and K. Dietmayer, "Dynamic Occupancy Grid Prediction for Urban Autonomous Driving: A Deep Learning Approach with Fully Automatic Labeling," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2056-2063.
doi: 10.1109/ICRA.2018.8460874
Abstract: Long-term situation prediction plays a crucial role for intelligent vehicles. A major challenge still to overcome is the prediction of complex downtown scenarios with multiple road users, e.g., pedestrians, bikes, and motor vehicles, interacting with each other. This contribution tackles this challenge by combining a Bayesian filtering technique for environment representation, and machine learning as long-term predictor. More specifically, a dynamic occupancy grid map is utilized as input to a deep convolutional neural network. This yields the advantage of using spatially distributed velocity estimates from a single time step for prediction, rather than a raw data sequence, alleviating common problems dealing with input time series of multiple sensors. Furthermore, convolutional neural networks have the inherent characteristic of using context information, enabling the implicit modeling of road user interaction. Pixel-wise balancing is applied in the loss function counteracting the extreme imbalance between static and dynamic cells. One of the major advantages is the unsupervised learning character due to fully automatic label generation. The presented algorithm is trained and evaluated on multiple hours of recorded sensor data and compared to Monte-Carlo simulation. Experiments show the ability to model complex interactions.
keywords: {Vehicle dynamics;Machine learning;Sensor fusion;Roads;Time series analysis;Laser radar},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460874&isnumber=8460178

A. Buyval, A. Gabdullin, R. Mustafin and I. Shimchik, "Realtime Vehicle and Pedestrian Tracking for Didi Udacity Self-Driving Car Challenge," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2064-2069.
doi: 10.1109/ICRA.2018.8460913
Abstract: The efficiency and execution time of a road scene evaluation subsystem directly influences a self-driving car's control effectiveness. This article presents a novel approach to fuse data from various sensors (camera, LIDAR, radar, IMU) for pedestrian and vehicle tracking. Our approach, thanks to modern methods of image processing and power of GPU for LIDAR processing, achieves 25Hz update frequency for tracking. The system has been tested on the DiDi-Udacity Self-Driving Challenge datasets.
keywords: {Radar tracking;Laser radar;Cameras;Three-dimensional displays;Sensor fusion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460913&isnumber=8460178

M. Jaritz, R. de Charette, M. Toromanoff, E. Perot and F. Nashashibi, "End-to-End Race Driving with Deep Reinforcement Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2070-2075.
doi: 10.1109/ICRA.2018.8460934
Abstract: We present research using the latest reinforcement learning algorithm for end-to-end driving without any mediated perception (object recognition, scene understanding). The newly proposed reward and learning strategies lead together to faster convergence and more robust driving using only RGB image from a forward facing camera. An Asynchronous Actor Critic (A3C) framework is used to learn the car control in a physically and graphically realistic rally game, with the agents evolving simultaneously on tracks with a variety of road structures (turns, hills), graphics (seasons, location) and physics (road adherence). A thorough evaluation is conducted and generalization is proven on unseen tracks and using legal speed limits. Open loop tests on real sequences of images show some domain adaption capability of our method.
keywords: {Automobiles;Training;Brakes;Games;Roads;Physics;Computer architecture},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460934&isnumber=8460178

M. Bouton, A. Nakhaei, K. Fujimura and M. J. Kochenderfer, "Scalable Decision Making with Sensor Occlusions for Autonomous Driving," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2076-2081.
doi: 10.1109/ICRA.2018.8460914
Abstract: Autonomous driving in urban areas requires avoiding other road users with only partial observability of the environment. Observations are only partial because obstacles can occlude the field of view of the sensors. The problem of robust and efficient navigation under uncertainty can be framed as a partially observable Markov decision process (POMDP). In order to bypass the computational cost of scaling the formulation to avoiding multiple road users, this paper demonstrates a decomposition method that leverages the optimal avoidance strategy for a single user. We evaluate the performance of two POMDP solution techniques augmented with the decomposition method for scenarios involving a pedestrian crosswalk and an intersection.
keywords: {Automobiles;Uncertainty;Roads;Acceleration;Autonomous vehicles;Approximation algorithms;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460914&isnumber=8460178

O. Scheel, L. Schwarz, N. Navab and F. Tombari, "Situation Assessment for Planning Lane Changes: Combining Recurrent Models and Prediction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2082-2088.
doi: 10.1109/ICRA.2018.8462838
Abstract: One of the greatest challenges towards fully autonomous cars is the understanding of complex and dynamic scenes. Such understanding is needed for planning of maneuvers, especially those that are particularly frequent such as lane changes. While in recent years advanced driver-assistance systems have made driving safer and more comfortable, these have mostly focused on car following scenarios, and less on maneuvers involving lane changes. In this work we propose a situation assessment algorithm for classifying driving situations with respect to their suitability for lane changing. For this, we propose a deep learning architecture based on a Bidirectional Recurrent Neural Network, which uses Long Short-Term Memory units, and integrates a prediction component in the form of the Intelligent Driver Model. We prove the feasibility of our algorithm on the publicly available NGSIM datasets, where we outperform existing methods.
keywords: {Automobiles;Planning;Machine learning;Predictive models;Prediction algorithms;Autonomous automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462838&isnumber=8460178

T. Ranganathan, S. Aravazhi, S. Mishra and A. Thondiyath, "Design and Analysis of a Novel Underwater Glider - RoBuoy," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2089-2094.
doi: 10.1109/ICRA.2018.8462921
Abstract: Underwater gliders are special class of autonomous underwater vehicles (AUVs) proven to be power efficient with better range and endurance compared to the conventional underwater robots. Most of the existing underwater gliders use `change of mass' based variable buoyancy (VB) method in which the overall system architecture and construction are complex. A novel underwater glider RoBuoy based on the `change of volume' concept of variable buoyancy method is presented here. RoBuoy uses actuated metallic bellows to change the volume which makes the system simple and modular in construction without any compromise in the performance. It uses minimal number of parts compared to the existing gliders which reduces the overall complexity of the system. Also, most of the conventional gliders use the external fluid for its working which may result in corrosion or fouling of parts and requires frequent maintenance. In the proposed glider, all the vital parts required for its working, apart from the sensing payloads are enclosed inside the hull, thereby increasing the durability. In this paper, a detailed design of RoBuoy is discussed with its possible modes of operation. An integrated mathematical model considering the individual dynamics of the actuator, hull/fuselage, and the wings has been developed and the open loop performance of the glider is studied at different input conditions. An experimental prototype has been designed and fabricated based on optimized dimensions, with the required mechatronic system. Experiments have been conducted and the results prove the feasibility of the concept.
keywords: {Actuators;Buoyancy;Bellows;Surges;Pistons;Unmanned underwater vehicles;Prototypes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462921&isnumber=8460178

A. Wahrburg et al., "Modeling Speed-, Load-, and Position-Dependent Friction Effects in Strain Wave Gears," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2095-2102.
doi: 10.1109/ICRA.2018.8461043
Abstract: Strain wave gears are frequently used in small and medium size industrial robots. In order to describe and quantify friction effects in gearboxes of such type, a structurally simple, yet powerful model is proposed taking into account both speed-and load-dependent friction effects. Moreover, position-dependent disturbances in a robotic joint are considered. An identification procedure is presented that allows to separate the individual components of the model and identify them subsequently. The effectiveness of the model and identification procedure is validated using experimental data gathered from four different robotic joints of varying size. Furthermore, the benefits of improved friction modeling are shown by means of different applications, including smooth lead-through programming and sensorless force control.
keywords: {Friction;Load modeling;Torque;Gravity;Strain;Gears;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461043&isnumber=8460178

S. Farsoni, C. T. Landi, F. Ferraguti, C. Secchi and M. Bonfè, "Real-Time Identification of Robot Payload Using a Multirate Quaternion-Based Kalman Filter and Recursive Total Least-Squares," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2103-2109.
doi: 10.1109/ICRA.2018.8461167
Abstract: The paper describes an estimation and identification procedure that allows to reconstruct the inertial parameters of a rigid load attached to the end-effector of an industrial manipulator. In particular, the proposed method adopts a multirate quaternion-based Kalman filter, fusing measurements obtained from robot kinematics and inertial sensors at possibly different sampling frequencies, to estimate linear accelerations and angular velocities/accelerations of the load. Then, a recursive total least-squares (RTLS) process is executed to identify the load parameters. Both steps of the estimation and identification procedure are performed in real-time, without the need for offline post-processing of measured data.
keywords: {Kalman filters;Quaternions;Robot kinematics;Service robots;Robot sensing systems;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461167&isnumber=8460178

M. Cognetti, P. Salaris and P. Robuffo Giordano, "Optimal Active Sensing with Process and Measurement Noise," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2118-2125.
doi: 10.1109/ICRA.2018.8460476
Abstract: The goal of this paper is to increase the estimation performance of an Extended Kalman Filter for a nonlinear differentially flat system by planning trajectories able to maximize the amount of information gathered by onboard sensors in presence of both process and measurement noises. In a previous work, we presented an online gradient descent method for planning optimal trajectories along which the smallest eigenvalue of the Observability Gramian (OG) is maximized. As the smallest eigenvalue of the OG is inversely proportional to the maximum estimation uncertainty, its maximization reduces the maximum estimation uncertainty of any estimation algorithm employed during motion. However, the OG does not consider the process noise that, instead, in several applications is far from being negligible. For this reason, this paper proposes a novel solution able to cope with non-negligible process noise: this is achieved by minimizing the largest eigenvalue of the a posteriori covariance matrix obtained by solving the Continuous Riccati Equation as a measure of the total available information. This minimization is expected to maximize the information gathered by the outputs while, at the same time, limiting as much as possible the negative effects of the process noise. We apply our method to a unicycle robot. The comparison between the novel method and the one of our previous work (which did not consider process noise) shows significant improvements in the obtained estimation accuracy.
keywords: {Robot sensing systems;Estimation;Trajectory;Eigenvalues and eigenfunctions;Observability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460476&isnumber=8460178

C. L. Choi, J. Rebello, L. Koppel, P. Ganti, A. Das and S. L. Waslander, "Encoderless Gimbal Calibration of Dynamic Multi-Camera Clusters," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2126-2133.
doi: 10.1109/ICRA.2018.8462920
Abstract: Dynamic Camera Clusters (DCCs) are multi-camera systems where one or more cameras are mounted on actuated mechanisms such as a gimbal. Existing methods for DCC calibration rely on joint angle measurements to resolve the time-varying transformation between the dynamic and static camera. This information is usually provided by motor encoders, however, joint angle measurements are not always readily available on off-the-shelf mechanisms. In this paper, we present an encoderless approach for DCC calibration which simultaneously estimates the kinematic parameters of the transformation chain as well as the unknown joint angles. We also demonstrate the integration of an encoderless gimbal mechanism with a state-of-the art VIO algorithm, and show the extensions required in order to perform simultaneous online estimation of the joint angles and vehicle localization state. The proposed calibration approach is validated both in simulation and on a physical DCC composed of a 2-DOF gimbal mounted on a UAV. Finally, we show the experimental results of the calibrated mechanism integrated into the OKVIS VIO package, and demonstrate successful online joint angle estimation while maintaining localization accuracy that is comparable to a standard static multi-camera configuration.
keywords: {Cameras;Calibration;Robot vision systems;Estimation;Reluctance motors;Kinematics;Vehicle dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462920&isnumber=8460178

M. T. Pope, S. Christensen, D. Christensen, A. Simeonov, G. Imahara and G. Niemeyer, "Stickman: Towards a Human Scale Acrobatic Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2134-2140.
doi: 10.1109/ICRA.2018.8462836
Abstract: Human performers have developed impressive acrobatic techniques over thousands of years of practicing the gymnastic arts. At the same time, robots have started to become more mobile and autonomous, and can begin to imitate these stunts in dramatic and informative ways. We present a simple two degree of freedom robot that uses a gravity-driven pendulum launch and produces a variety of somersaulting stunts. The robot uses an IMU and a laser range-finder to estimate its state mid-flight and actuates to change its motion both on and and off the pendulum. We discuss the dynamics of this behavior in a framework of acrobatic capability and present experimental results.
keywords: {Robot sensing systems;Angular velocity;Mathematical model;Aerodynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462836&isnumber=8460178

C. Le Gentil, T. Vidal-Calleja and S. Huang, "3D Lidar-IMU Calibration Based on Upsampled Preintegrated Measurements for Motion Distortion Correction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2149-2155.
doi: 10.1109/ICRA.2018.8460179
Abstract: In this paper, we present a probabilistic framework to recover the extrinsic calibration parameters of a lidar-IMU sensing system. Unlike global-shutter cameras, lidars do not take single snapshots of the environment. Instead, lidars collect a succession of 3D-points generally grouped in scans. If these points are assumed to be expressed in a common frame, this becomes an issue when the sensor moves rapidly in the environment causing motion distortion. The fundamental idea of our proposed framework is to use preintegration over interpolated inertial measurements to characterise the motion distortion in each lidar scan. Moreover, by using a set of planes as a calibration target, the proposed method makes use of lidar point-to-plane distances to jointly calibrate and localise the system using on-manifold optimisation. The calibration does not rely on a predefined target as arbitrary planes are detected and modelled in the first lidar scan. Simulated and real data are used to show the effectiveness of the proposed method.
keywords: {Laser radar;Calibration;Distortion;Robot sensing systems;Three-dimensional displays;Distortion measurement;Motion measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460179&isnumber=8460178

K. Park, S. Kim and K. Sohn, "High-Precision Depth Estimation with the 3D LiDAR and Stereo Fusion," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2156-2163.
doi: 10.1109/ICRA.2018.8461048
Abstract: We present a deep convolutional neural network (CNN) architecture for high-precision depth estimation by jointly utilizing sparse 3D LiDAR and dense stereo depth information. In this network, the complementary characteristics of sparse 3D LiDAR and dense stereo depth are simultaneously encoded in a boosting manner. Tailored to the LiDAR and stereo fusion problem, the proposed network differs from previous CNNs in the incorporation of a compact convolution module, which can be deployed with the constraints of mobile devices. As training data for the LiDAR and stereo fusion is rather limited, we introduce a simple yet effective approach for reproducing the raw KITTI dataset. The raw LiDAR scans are augmented by adapting an off-the-shelf stereo algorithm and a confidence measure. We evaluate the proposed network on the KITTI benchmark and data collected by our multi-sensor acquisition system. Experiments demonstrate that the proposed network generalizes across datasets and is significantly more accurate than various baseline approaches.
keywords: {Three-dimensional displays;Laser radar;Estimation;Computer architecture;Sensors;Reliability;Image color analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461048&isnumber=8460178

J. Chen, Y. K. Cho and J. Ueda, "Sampled-Point Network for Classification of Deformed Building Element Point Clouds," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2164-2169.
doi: 10.1109/ICRA.2018.8461095
Abstract: Search-and-rescue (SAR) robots operating in post-disaster urban areas need to accurately identify physical site information to perform navigation, mapping and manipulation tasks. This can be achieved by acquiring a 3D point cloud of the environment and performing object recognition from the point cloud data. However, this task is complicated by the unstructured environments and potentially-deformed objects encountered during disaster relief operations. Current 3D object recognition methods rely on point cloud input acquired under suitable conditions and do not consider deformations such as outlier noise, bending and truncation. This work introduces a deep learning architecture for 3D class recognition from point clouds of deformed building elements. The classification network, consisting of stacked convolution and average pooling layers applied directly to point coordinates, was trained using point clouds sampled from a database of mesh models. The proposed method achieves robustness to input variability using point sorting, resampling, and rotation normalization techniques. Experimental results on synthetically-deformed object datasets show that the proposed method outperforms the conventional deep learning methods in terms of classification accuracy and computational efficiency.
keywords: {Three-dimensional displays;Strain;Object recognition;Deformable models;Machine learning;Feature extraction;Buildings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461095&isnumber=8460178

M. Reza Loghmani, B. Caputo and M. Vincze, "Recognizing Objects in-the-Wild: Where do we Stand?," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2170-2177.
doi: 10.1109/ICRA.2018.8460985
Abstract: The ability to recognize objects is an essential skill for a robotic system acting in human-populated environments. Despite decades of effort from the robotic and vision research communities, robots are still missing good visual perceptual systems, preventing the use of autonomous agents for realworld applications. The progress is slowed down by the lack of a testbed able to accurately represent the world perceived by the robot in-the-wild. In order to fill this gap, we introduce a large-scale, multi-view object dataset collected with an RGB-D camera mounted on a mobile robot. The dataset embeds the challenges faced by a robot in a real-life application and provides a useful tool for validating object recognition algorithms. Besides describing the characteristics of the dataset, the paper evaluates the performance of a collection of well-established deep convolutional networks on the new dataset and analyzes the transferability of deep representations from Web images to robotic data. Despite the promising results obtained with such representations, the experiments demonstrate that object classification with real-life robotic data is far from being solved. Finally, we provide a comparative study to analyze and highlight the open challenges in robot vision, explaining the discrepancies in the performance.
keywords: {Task analysis;Clutter;Visualization;Mobile robots;Cameras;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460985&isnumber=8460178

A. Glover, V. Vasco and C. Bartolozzi, "A Controlled-Delay Event Camera Framework for On-Line Robotics," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2178-2183.
doi: 10.1109/ICRA.2018.8460541
Abstract: Event cameras offer many advantages for dynamic robotics due to their low latency response to motion, high dynamic range, and inherent compression of the visual signal. Many algorithms easily achieve real-time performance when testing on off-line datasets, however with an increase in camera resolution and applications on fast-moving robots, latency-free operation is not guaranteed. The event-rate is not constant, but is proportional to the amount of movement in the scene, or the velocity of the camera itself. Recently, algorithms have instead reported a maximum event-rate that can be achieved in real-time. In this paper we present the event-driven framework used on the iCub robot, which closes the loop between algorithm processing rate and the actual event-rate of the camera in order to smoothly control and limit the latency, while allowing the algorithm to degrade gracefully when large bursts of events occur. We show two algorithms that process events differently from each other and demonstrate the trade-off between latency and algorithm performance that the framework provides.
keywords: {Cameras;Robot vision systems;Delays;Corner detection;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460541&isnumber=8460178

M. Maghoumi, J. J. LaVioia, K. Desingh and O. Chadwicke Jenkins, "Gemsketch: Interactive Image-Guided Geometry Extraction from Point Clouds," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2184-2191.
doi: 10.1109/ICRA.2018.8460532
Abstract: We introduce an interactive system for extracting the geometries of generalized cylinders and cuboids from single-or multiple-view point clouds. Our proposed method is intuitive and only requires the object's silhouettes to be traced by the user. Leveraging the user's perceptual understanding of what an object looks like, our proposed method is capable of extracting accurate models, even in the presence of occlusion, clutter or incomplete point cloud data, while preserving the original object's details and scale. We demonstrate the merits of our proposed method through a set of experiments on a public RGB-D dataset. We extracted 16 objects from the dataset using at most two views of each object. Our extracted models represent a high degree of visual similarity to the original objects. Further, we achieved a mean normalized Hausdorff distance of 5.66% when comparing our extracted models with the dataset's ground truths.
keywords: {Three-dimensional displays;Shape;Geometry;Solid modeling;Tools;Cameras;Data mining},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460532&isnumber=8460178

E. Ruiz and W. Mayol-Cuevas, "Where can i do this? Geometric Affordances from a Single Example with the Interaction Tensor," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2192-2199.
doi: 10.1109/ICRA.2018.8462835
Abstract: This paper introduces and evaluates a new tensor field representation to express the geometric affordance of one object relative to another, a key competence for Cognitive and Autonomous robots. We expand the bisector surface representation to one that is weight-driven and that retains the provenance of surface points with directional vectors. We also incorporate the notion of affordance keypoints which allow for faster decisions at a point of query and with a compact and straightforward descriptor. Using a single interaction example, we are able to generalize to previously-unseen scenarios; both synthetic and also real scenes captured with RGB-D sensors. Evaluations also include crowdsourcing comparisons that confirm the validity of our affordance proposals, which agree on average 84 % of the time with human judgments, that is 20-40 % better than the baseline methods.
keywords: {Tensile stress;Robots;Three-dimensional displays;Solid modeling;Task analysis;Shape;Tools},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462835&isnumber=8460178

G. Riggio, C. Fantuzzi and C. Secchi, "A Low-Cost Navigation Strategy for Yield Estimation in Vineyards," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2200-2205.
doi: 10.1109/ICRA.2018.8462839
Abstract: Accurate yield estimation is very important for improving the vineyard management, the quality of the grapes and the health of the vines. The most common systems use RGB image processing for achieving a good estimation. In order to collect images, robots or farming vehicles can be equipped with a RGB camera. In this paper, we propose a low-cost autonomous system which can navigate through a vineyard while collecting grape pictures in order to provide a yield estimation. Our system uses only a laser scanner to detect the row and follows it until its end, then it navigates towards the next one, exploiting the knowledge of the vineyard. The navigation algorithm was tested both in simulation and in a real environment with good results. Furthermore, a yield estimation of two different grape varieties is presented.
keywords: {Navigation;Pipelines;Yield estimation;Cameras;Robot vision systems;Lasers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462839&isnumber=8460178

J. Gardenier, J. Underwood and C. Clark, "Object Detection for Cattle Gait Tracking," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2206-2213.
doi: 10.1109/ICRA.2018.8460523
Abstract: Lameness in cattle is a health issue where gait is modified to minimise pain. Cattle are currently visually assessed for locomotion score, which provides the degree of lameness for individual animals. This subjective method is costly in terms of labour, and its level of accuracy and ability to detect small changes in locomotion that is critical for early detection of lameness and associated intervention. Current automatic lameness detection systems found in literature have not yet met the ultimate goal of widespread commercial adoption. We present a sensor configuration to record cattle kinematics towards automatic lameness detection. This configuration features four Time of Flight sensors to view cattle from above and from one side as they exit an automatic rotary milking dairy. Two dimensional near infrared images sampled from 223 cows passing through the system were used to train a Faster R-CNN to detect hooves (F1-score = 0.90) and carpal/tarsal joints (Fl-score = 0.85). The depth images were used to project these detected key points into Cartesian space where they were tracked to obtain individual trajectories per limb. The results show that kinematic gait features can be successfully obtained as a first and important step towards objective, accurate, automatic lameness detection.
keywords: {Cows;Feature extraction;Kinematics;Laser radar;Robot sensing systems;Three-dimensional displays;Australia},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460523&isnumber=8460178

T. C. Thayer, S. Vougioukas, K. Goldberg and S. Carpin, "Routing Algorithms for Robot Assisted Precision Irrigation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2221-2228.
doi: 10.1109/ICRA.2018.8461242
Abstract: When robots navigate through vineyards to perform irrigation adjustments, an optimization problem emerges whereby robots are tasked with performing adjustments having the highest cumulative outcome within a given temporal budget due to limited battery charge. To this end, the robot needs to reach a set of spatially distributed sites, and the specific structure of the vineyard imposes various constraints on possible motions. In this paper we first demonstrate that this type of orienteering problem remains NP-hard even for the restricted class of graphs associated with precision irrigation. Then, we devise and analyze two greedy heuristics informed by the problem we consider. Finally, these algorithms are evaluated on settings associated with a commercial vineyard and we show that our methods favorably compare to solutions proposed in the past.
keywords: {Irrigation;Routing;Approximation algorithms;Robot sensing systems;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461242&isnumber=8460178

A. Milioto, P. Lottes and C. Stachniss, "Real-Time Semantic Segmentation of Crop and Weed for Precision Agriculture Robots Leveraging Background Knowledge in CNNs," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2229-2235.
doi: 10.1109/ICRA.2018.8460962
Abstract: Precision farming robots, which target to reduce the amount of herbicides that need to be brought out in the fields, must have the ability to identify crops and weeds in real time to trigger weeding actions. In this paper, we address the problem of CNN-based semantic segmentation of crop fields separating sugar beet plants, weeds, and background solely based on RGB data. We propose a CNN that exploits existing vegetation indexes and provides a classification in real time. Furthermore, it can be effectively re-trained to so far unseen fields with a comparably small amount of training data. We implemented and thoroughly evaluated our system on a real agricultural robot operating in different fields in Germany and Switzerland. The results show that our system generalizes well, can operate at around 20 Hz, and is suitable for online operation in the fields.
keywords: {Agriculture;Vegetation mapping;Semantics;Real-time systems;Soil;Indexes;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460962&isnumber=8460178

R. Berenstein, R. Fox, S. McKinley, S. Carpin and K. Goldberg, "Robustly Adjusting Indoor Drip Irrigation Emitters with the Toyota HSR Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2236-2243.
doi: 10.1109/ICRA.2018.8460969
Abstract: Indoor plants in homes and commercial buildings such as malls, offices, airports, and hotels, can benefit from precision irrigation to maintain healthy growth and reduce water consumption. As active valves are too costly, and ongoing precise manual adjustment of drip emitters is impractical, we explore how the Toyota HSR mobile manipulator robot can autonomously adjust low-cost passive emitters. To provide sufficient accuracy for gripper alignment, we designed a lightweight, modular Emitter Localization Device (ELD) with cameras and LEDs that can be non-invasively mounted on the arm. This paper presents details of the design, algorithms, and experiments with adjusting emitters using a two-phase procedure: (1) aligning the robot base using the build-in hand camera, and (2) aligning the gripper axis with the emitter axis using the ELD. We report success rates and sensitivity analysis to tune computer vision parameters and joint motor gains. Experiments suggest that emitters can be adjusted with 95 % success rate in approximately 20 seconds.
keywords: {Cameras;Irrigation;Robot vision systems;Manipulators;Grippers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460969&isnumber=8460178

B. Suthar, M. Usman, H. Seong, I. Gaponov and J. -H. Ryu, "Preliminary Study of Twisted String Actuation Through a Conduit Toward Soft and Wearable Actuation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2260-2265.
doi: 10.1109/ICRA.2018.8460589
Abstract: Twisted string actuators (TSAs) are gaining popularity in modern engineering and robotic applications. However, in conventional actuators of this type, the twisted part of the string should not be in contact with any surfaces or objects because this may interfere with the propagation of twisting. This imposes significant constraint on potential applications of TSAs. In this paper, we investigated the feasibility of using TSAs inside conduit and demonstrated that the twists of the string can be fully propagated through the sheath and that consistent periodic behavior of the twisted string can be achieved. In addition, we investigated input-output position and force characteristics of TSAs for various deflection angles of the conduit, effect of lubrication on transmission efficiency, and compared it with conventional cable sliding transmission. We found that TSA has higher transmission efficiency than sliding due to decreased friction between the string and conduit, which is further improved by lubrication. We have managed to achieve 85 % of force transmission efficiency for the case of lubricated twisting, as opposed to the 71.74% for lubricated sliding.
keywords: {Friction;Force;Mathematical model;Cable shielding;DC motors;Power cables;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460589&isnumber=8460178

M. Kim, J. Park, J. Kim and M. Kim, "Stiffness Decomposition and Design Optimization of Under-Actuated Tendon-Driven Robotic Systems," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2266-2272.
doi: 10.1109/ICRA.2018.8462906
Abstract: We present a novel systematic design framework for general under-actuated tendon-driven (UATD) robotic systems to exhibit desired behaviors both during the free motion and the contact task. For this, we propose stiffness decomposition, which enables us to completely decompose the configuration space of the UATD robotic systems into the actuated space (with full actuation via active tendons) and the un-actuated space (with no actuation, only with passive compliance and contact wrench). The behavior in the actuated space is then fully-controllable, thus, the attainment of the desired behaviors, particularly those during the contact task, hinges upon that in the un-actuated space. For this, relying on the stiffness decomposition, we optimize the design parameters (e.g., tendon routing, pulley radius, passive compliance, etc.) to ensure the deformation in the un-actuated space as directional (e.g., for adaptive grasping) and minimized (e.g., pushing with posture maintained) for different contact wrench sets as possible, while also rendering the free motion to be as compliant and backdrivable as possible. The presented framework is then applied to design a UATD robotic finger and experimentally verified with the robot able to mimic the behavior of human index finger both during the free motion and pinch-pushing.
keywords: {Robots;Tendons;Pulleys;Routing;Springs;Grasping;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462906&isnumber=8460178

S. Park, L. Weber, L. Bishop, J. Stein and M. Ciocarlie, "Design and Development of Effective Transmission Mechanisms on a Tendon Driven Hand Orthosis for Stroke Patients," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2281-2287.
doi: 10.1109/ICRA.2018.8461069
Abstract: Tendon-driven hand orthoses have advantages over exoskeletons with respect to wearability and safety because of their low-profile design and ability to fit a range of patients without requiring custom joint alignment. However, no existing study on a wearable tendon-driven hand orthosis for stroke patients presents evidence that such devices can overcome spasticity given repeated use and fatigue, or discusses transmission efficiency. In this study, we propose two designs that provide effective force transmission by increasing moment arms around finger joints. We evaluate the designs with geometric models and experiment using a 3D-printed artificial finger to find force and joint angle characteristics of the suggested structures. We also perform clinical tests with stroke patients to demonstrate the feasibility of the designs. The testing supports the hypothesis that the proposed designs efficiently elicit extension of the digits in patients with spasticity as compared to existing baselines.
keywords: {Tendons;Force;Exoskeletons;Robots;Electron tubes;Task analysis;Thumb},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461069&isnumber=8460178

C. Rennie and K. E. Bekris, "Discovering a Library of Rhythmic Gaits for Spherical Tensegrity Locomotion," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2290-2295.
doi: 10.1109/ICRA.2018.8460873
Abstract: Tensegrity robots, which combine both rigid and soft elements, provide exciting new locomotion capabilities but introduce significant control challenges given their high-dimensionality and non-linear nature. This work first defines an effective parameterization of a spherical tensegrity for generating rhythmic gaits based on Central Pattern Generators (cp G). This allows the definition of periodic and rhythmic control signals, while exposing only five gait parameters. Then, this work proposes a framework for optimizing such gaits by exploring the parameter space through Bayesian Optimization on an underlying Gaussian Process regression model. The objective is to provide gaits that allow the platform to move along different directions with high velocity. Additionally, kNN binary classifiers are trained to estimate whether a parameter sample will result in an effective gait. The classification biases the sampling toward subspaces likely to yield effective gaits. An asynchronous communication layer is defined between the optimization and classification processes. The proposed gait discovery process is shown to efficiently optimize the parameters of gaits defined given the novel CPG architecture and outperforms less holistic approaches and Monte Carlo sampling.
keywords: {Robots;Optimization;Aerospace electronics;Bayes methods;Shape;Angular velocity;Libraries},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460873&isnumber=8460178

T. Goto, S. Pathak, Y. Ji, H. Fujii, A. Yamashita and H. Asama, "Line-Based Global Localization of a Spherical Camera in Manhattan Worlds," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2296-2303.
doi: 10.1109/ICRA.2018.8460920
Abstract: Localization is an important task for mobile service robots in indoor spaces. In this research, we propose a novel technique for indoor localization using a spherical camera. Spherical cameras can obtain a complete view of the surroundings allowing the use of global environmental information. We take advantage of this in order to estimate camera position and the orientation with respect to a known 3D line map of an indoor environment, using a single image. We robustly extract 2D line information from the spherical image via spherical-gradient filtering and match it to 3D line information in the line map. Our method requires no information about the 3D-2D line correspondences. In order to avoid a complicated six degrees of freedom (6 DoF) search for position and orientation, we use a Manhattan world assumption to decompose the line information in the image. The 6 DoF localization process is divided into two phases. First, we estimate the orientation by extracting the three principle directions from the image. Then, the position is estimated by robustly matching the distribution of lines between the image and the 3D model via a spherical Hough representation. This decoupled search can robustly localize a spherical camera using a single image, as we demonstrate experimentally.
keywords: {Cameras;Three-dimensional displays;Image edge detection;Robustness;Robot vision systems;Solid modeling;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460920&isnumber=8460178

R. Falque, M. Patel and J. Biehl, "Optimizing Placement and Number of RF Beacons to Achieve Better Indoor Localization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2304-2311.
doi: 10.1109/ICRA.2018.8460202
Abstract: In this paper, we propose a novel solution to optimize the deployment of Radio Frequency (RF) beacons for the purpose of indoor localization. We propose a system that optimizes both the number of beacons and their placement in a given environment. We propose a novel cost-function, called CovBsm, that allows to simultaneously optimize the 3-coverage while maximizing the beacon spreading. Using this cost function, we propose a framework that maximize both the number of beacons and their placement in a given environment. The proposed solution accounts for the indoor infrastructure and its influence on the RF signal propagation by embedding a realistic simulator into the optimization process.
keywords: {Sensors;Optimization;Wireless sensor networks;Lattices;Genetic algorithms;Radio frequency;RF signals;Indoor localization;Beacon deployment;Bluetooth Low Energy (BLE);k-Coverage;Wireless sensor networks (WSN)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460202&isnumber=8460178

T. -M. Nguyen, A. Hanif Zaini, C. Wang, K. Guo and L. Xie, "Robust Target-Relative Localization with Ultra-Wideband Ranging and Communication," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2312-2319.
doi: 10.1109/ICRA.2018.8460844
Abstract: In this paper we propose a method to achieve relative positioning and tracking of a target by a quadcopter using Ultra-wideband (UWB) ranging sensors, which are strategically installed to help retrieve both relative position and bearing between the quadcopter and target. To achieve robust localization for autonomous flight even with uncertainty in the speed of the target, two main features are developed. First, an estimator based on Extended Kalman Filter (EKF) is developed to fuse UWB ranging measurements with data from onboard sensors including inertial measurement unit (IMU), altimeters and optical flow. Second, to properly handle the coupling of the target&#x0027;s orientation with the range measurements, UWB based communication capability is utilized to transfer the target&#x0027;s orientation to the quadcopter. Experiments results demonstrate the ability of the quadcopter to control its position relative to the target autonomously in both cases when the target is static and moving.
keywords: {Distance measurement;Sensors;Antenna measurements;Robustness;Iron;Robots;Kalman filters},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460844&isnumber=8460178

B. Guan, P. Vasseur, C. Demonceaux and F. Fraundorfer, "Visual Odometry Using a Homography Formulation with Decoupled Rotation and Translation Estimation Using Minimal Solutions," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2320-2327.
doi: 10.1109/ICRA.2018.8460747
Abstract: In this paper we present minimal solutions for two-view relative motion estimation based on a homography formulation. By assuming a known vertical direction (e.g. from an IMU) and assuming a dominant ground plane we demonstrate that rotation and translation estimation can be decoupled. This result allows us to reduce the number of point matches needed to compute a motion hypothesis. We then derive different algorithms based on this decoupling that allow an efficient estimation. We also demonstrate how these algorithms can be used efficiently to compute an optimal inlier set using exhaustive search or histogram voting instead of a traditional RANSAC step. Our methods are evaluated on synthetic data and on the KITTI data set, demonstrating that our methods are well suited for visual odometry in road driving scenarios.
keywords: {Estimation;Visual odometry;Mathematical model;Cameras;Histograms;Gravity;Motion estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460747&isnumber=8460178

G. Duenas Arana, M. Joerger and M. Spenko, "Local Nearest Neighbor Integrity Risk Evaluation for Robot Navigation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2328-2333.
doi: 10.1109/ICRA.2018.8460762
Abstract: This paper describes the design of a new integrity risk prediction/monitoring methodology for robot localization that uses feature extraction and data association algorithms. The work specifically addresses incorrect association faults when employing a local nearest neighbor data association algorithm. This approach is more efficient and easier to implement than previous work. The methodology is tested in simulation, showing that the computed upper bound on integrity risk is a performance metric capable of providing warnings when the safety of the system cannot be guaranteed.
keywords: {Feature extraction;Technological innovation;Covariance matrices;Robots;Upper bound;Safety;Noise measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460762&isnumber=8460178

Y. Yang and G. Huang, "Aided Inertial Navigation with Geometric Features: Observability Analysis," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2334-2340.
doi: 10.1109/ICRA.2018.8460670
Abstract: In this paper, we perform observability analysis for inertial navigation systems (INS) aided by generic exteroceptive range and/or bearing sensors with different geometric features including points, lines and planes. While the observability of vision-aided INS (VINS, which uses camera as a bearing sensor) with point features has been extensively studied in the literature, we analytically show that the same observability property remains if using generic range and/or bearing measurements, and if global measurements are also available, as expected, some unobservable directions dismiss. We study in-depth the effects of four degenerate motions on the system observability. In particular, building upon the observability analysis of the aided INS with point features, we perform observability analysis for the same system but with line and plane features, respectively, and show that there exist 5 (and 6) unobservable directions for a single line (and plane) feature. Moreover, we, for the first time, analytically derive the unobservable directions for the cases of multiple lines/planes. We validate our analysis through Monte Carlo simulations.
keywords: {Observability;Jacobian matrices;Sensors;Position measurement;Gravity;Rotation measurement;Current measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460670&isnumber=8460178

T. -H. Wang, H. -J. Huang, J. -T. Lin, C. -W. Hu, K. -H. Zeng and M. Sun, "Omnidirectional CNN for Visual Place Recognition and Navigation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2341-2348.
doi: 10.1109/ICRA.2018.8463173
Abstract: Visual place recognition is challenging, especially when only a few place exemplars are given. To mitigate the challenge, we consider place recognition method using omnidirectional cameras and propose a novel Omnidirectional Convolutional Neural Network (O-CNN) to handle severe camera pose variation. Given a visual input, the task of the O-CNN is not to retrieve the matched place exemplar, but to retrieve the closest place exemplar and estimate the relative distance between the input and the closest place. With the ability to estimate relative distance, a heuristic policy is proposed to navigate a robot to the retrieved closest place. Note that the network is designed to take advantage of the omnidirectional view by incorporating circular padding and rotation invariance. To train a powerful O-CNN, we build a virtual world for training on a large scale. We also propose a continuous lifted structured feature embedding loss to learn the concept of distance efficiently. Finally, our experimental results confirm that our method achieves state-of-the-art accuracy and speed with both the virtual world and real-world datasets.
keywords: {Visualization;Navigation;Robots;Measurement;Cameras;Feature extraction;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463173&isnumber=8460178

Y. Latif, R. Garg, M. Milford and I. Reid, "Addressing Challenging Place Recognition Tasks Using Generative Adversarial Networks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2349-2355.
doi: 10.1109/ICRA.2018.8461081
Abstract: Place recognition is an essential component of Simultaneous Localization And Mapping (SLAM). Under severe appearance change, reliable place recognition is a difficult perception task since the same place is perceptually very different in the morning, at night, or over different seasons. This work addresses place recognition as a domain translation task. Using a pair of coupled Generative Adversarial Networks (GANs), we show that it is possible to generate the appearance of one domain (such as summer) from another (such as winter) without requiring image-to-image correspondences across the domains. Mapping between domains is learned from sets of images in each domain without knowing the instance-to-instance correspondence by enforcing a cyclic consistency constraint. In the process, meaningful feature spaces are learned for each domain, the distances in which can be used for the task of place recognition. Experiments show that learned features correspond to visual similarity and can be effectively used for place recognition across seasons.
keywords: {Task analysis;Gallium nitride;Lighting;Generators;Image recognition;Feature extraction;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461081&isnumber=8460178

A. Sadeghi and S. L. Smith, "Re-Deployment Algorithms for Multiple Service Robots to Optimize Task Response," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2356-2363.
doi: 10.1109/ICRA.2018.8460726
Abstract: This paper focuses on the problem of deploying a set of autonomous robots to efficiently service tasks that arrive sequentially in an environment over time. Each task is serviced when the robot visits the corresponding task location. Robots can then redeploy while waiting for the next task to arrive. The objective is to redeploy the robots taking into account the next N task arrivals. We seek to minimize a linear combination of the expected cost to service tasks and the redeployment cost between task arrivals. In the single robot case, we propose a one-stage greedy algorithm and prove its optimality. For multiple robots, the problem is NP-hard, and we propose two constant-factor approximation algorithm, one for the problem with a horizon of two task arrivals and the other for the infinite horizon when redeployment cost is weighted more heavily than service cost. Finally, we present extensive benchmarking results to characterize both solution quality and runtime.
keywords: {Robots;Task analysis;Time factors;Approximation algorithms;Probability distribution;Measurement;Vehicle dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460726&isnumber=8460178

T. Miki, M. Popović, A. Gawel, G. Hitz and R. Siegwart, "Multi-Agent Time-Based Decision-Making for the Search and Action Problem," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2365-2372.
doi: 10.1109/ICRA.2018.8460996
Abstract: Many robotic applications, such as search-and-rescue, require multiple agents to search for and perform actions on targets. However, such missions present several challenges, including cooperative exploration, task selection and allocation, time limitations, and computational complexity. To address this, we propose a decentralized multi-agent decision-making framework for the search and action problem with time constraints. The main idea is to treat time as an allocated budget in a setting where each agent action incurs a time cost and yields a certain reward. Our approach leverages probabilistic reasoning to make near-optimal decisions leading to maximized reward. We evaluate our method in the search, pick, and place scenario of the Mohamed Bin Zayed International Robotics Challenge (MBZIRC), by using a probability density map and reward prediction function to assess actions. Extensive simulations show that our algorithm outperforms benchmark strategies, and we demonstrate system integration in a Gazebo-based environment, validating the framework's readiness for field application.
keywords: {Task analysis;Search problems;Decision making;Planning;Time factors;Robots;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460996&isnumber=8460178

N. Karapetyan, J. Moulton, J. S. Lewis, A. Quattrini Li, J. M. O'Kane and I. Rekleitis, "Multi-robot Dubins Coverage with Autonomous Surface Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2373-2379.
doi: 10.1109/ICRA.2018.8460661
Abstract: In large scale coverage operations, such as marine exploration or aerial monitoring, single robot approaches are not ideal, as they may take too long to cover a large area. In such scenarios, multi-robot approaches are preferable. Furthermore, several real world vehicles are non-holonomic, but can be modeled using Dubins vehicle kinematics. This paper focuses on environmental monitoring of aquatic environments using Autonomous Surface Vehicles (ASVs). In particular, we propose a novel approach for solving the problem of complete coverage of a known environment by a multi-robot team consisting of Dubins vehicles. It is worth noting that both multi-robot coverage and Dubins vehicle coverage are NP-complete problems. As such, we present two heuristics methods based on a variant of the traveling salesman problem-k-TSP-formulation and clustering algorithms that efficiently solve the problem. The proposed methods are tested both in simulations to assess their scalability and with a team of ASVs operating on a 200 km2 lake to ensure their applicability in real world.
keywords: {Robot sensing systems;Clustering algorithms;Task analysis;Lakes;Multi-robot systems;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460661&isnumber=8460178

X. Zhou, H. Wang and B. Ding, "How Many Robots are Enough: A Multi-Objective Genetic Algorithm for the Single-Objective Time-Limited Complete Coverage Problem," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2380-2387.
doi: 10.1109/ICRA.2018.8461028
Abstract: Complete coverage, which is the foundation of many robotic applications, aims to cover an area as quickly as possible. This study investigates the time-limited version of multi-robot complete coverage problem, that is, to find the least number of robots and allocate tasks properly to them such that they can finish a known mission within the time limit. This version of problem can be tackled straightforwardly based on optimizing the task-allocation to a fixed number of robots and enumerating the number. However, the number-fixed problem is NP-hard and the existing algorithm for the number-fixed problem allows intersecting tasks (possibly causing robots' interference) and endures high approximation factor. In this study, the time-limited complete coverage problem is tackled with a multi-objective approach, instead of enumerating robots' number and optimizing each number-fixed problem one by one. The multi-objective GA, Mofint, at first estimates the lower and upper bounds of the number of robots. It abstracts each task as a weighted node of a graph. Then, Mofint evolves individuals, each individual being a forest containing a certain number (within the bounds) of non-intersecting trees. Mofint can finally obtain higher precision than existing work with less time: the approximation factor for Mofint is 1.1 to 1.5 times the ideal allocation when robots' number is fixed, while for existing work is 1.5 to 2. Due to its higher precision, the least number of robots obtained in the experiments by Mofint is 0.6 times of existing work.
keywords: {Robots;Vegetation;Task analysis;Genetic algorithms;Resource management;Optimization;Approximation algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461028&isnumber=8460178

B. Zhou, W. Schwarting, D. Rus and J. Alonso-Mora, "Joint Multi-Policy Behavior Estimation and Receding-Horizon Trajectory Planning for Automated Urban Driving," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2388-2394.
doi: 10.1109/ICRA.2018.8461138
Abstract: When driving in urban environments, an autonomous vehicle must account for the interaction with other traffic participants. It must reason about their future behavior, how its actions affect their future behavior, and potentially consider multiple motion hypothesis. In this paper we introduce a method for joint behavior estimation and trajectory planning that models interaction and multi-policy decision-making. The method leverages Partially Observable Markov Decision Processes to estimate the behavior of other traffic participants given the planned trajectory for the ego-vehicle, and Receding-Horizon Control for generating safe trajectories for the ego-vehicle. To achieve safe navigation we introduce chance constraints over multiple motion policies in the receding-horizon planner. These constraints account for uncertainty over the behavior of other traffic participants. The method is capable of running in real-time and we show its performance and good scalability in simulated multi-vehicle intersection scenarios.
keywords: {Trajectory;Planning;Estimation;Space vehicles;Uncertainty;Roads;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461138&isnumber=8460178

H. Park, J. Liu, M. Johnson-Roberson and R. Vasudevan, "Robust Environmental Mapping by Mobile Sensor Networks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2395-2402.
doi: 10.1109/ICRA.2018.8461034
Abstract: Constructing a spatial map of environmental parameters is a crucial step to preventing hazardous chemical leakages, forest fires, or while estimating a spatially distributed physical quantities such as terrain elevation. Although prior methods can do such mapping tasks efficiently via dispatching a group of autonomous agents, they are unable to ensure satisfactory convergence to the underlying ground truth distribution in a decentralized manner when any of the agents fail. Since the types of agents utilized to perform such mapping are typically inexpensive and prone to failure, this results in poor overall mapping performance in real-world applications, which can in certain cases endanger human safety. This paper presents a Bayesian approach for robust spatial mapping of environmental parameters by deploying a group of mobile robots capable of ad-hoc communication equipped with short-range sensors in the presence of hardware failures. Our approach first utilizes a variant of the Voronoi diagram to partition the region to be mapped into disjoint regions that are each associated with at least one robot. These robots are then deployed in a decentralized manner to maximize the likelihood that at least one robot detects every target in their associated region despite a non-zero probability of failure. A suite of simulation results is presented to demonstrate the effectiveness and robustness of the proposed method when compared to existing techniques.
keywords: {Robot sensing systems;Robustness;Mutual information;Computational modeling;Mobile robots;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461034&isnumber=8460178

G. Williams, B. Goldfain, P. Drews, J. M. Rehg and E. A. Theodorou, "Best Response Model Predictive Control for Agile Interactions Between Autonomous Ground Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2403-2410.
doi: 10.1109/ICRA.2018.8462831
Abstract: We introduce an algorithm for autonomous control of multiple fast ground vehicles operating in close proximity to each other. The algorithm is based on a combination of the game theoretic notion of iterated best response, and an information theoretic model predictive control algorithm designed for non-linear stochastic systems. We test the algorithm on two one-fifth scale AutoRally platforms traveling at speeds upwards of 8 meters per second, while maintaining a following distance of under two meters from bumper-to-bumper.
keywords: {Games;Stochastic processes;Predictive control;Nash equilibrium;Optimization;Vehicle dynamics;Prediction algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462831&isnumber=8460178

F. I. Doğan, H. Çelikkanat and S. Kalkan, "A Deep Incremental Boltzmann Machine for Modeling Context in Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2411-2416.
doi: 10.1109/ICRA.2018.8462925
Abstract: Context is an essential capability for robots that are to be as adaptive as possible in challenging environments. Although there are many context modeling efforts, they assume a fixed structure and number of contexts. In this paper, we propose an incremental deep model that extends Restricted Boltzmann Machines. Our model gets one scene at a time, and gradually extends the contextual model when necessary, either by adding a new context or a new context layer to form a hierarchy. We show on a scene classification benchmark that our method converges to a good estimate of the contexts of the scenes, and performs better or on-par on several tasks compared to other incremental models or non-incremental models.
keywords: {Neurons;Context modeling;Hidden Markov models;Robots;Computational modeling;Adaptation models;Data models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462925&isnumber=8460178

N. Makondo, B. Rosman and O. Hasegawa, "Accelerating Model Learning with Inter-Robot Knowledge Transfer," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2417-2424.
doi: 10.1109/ICRA.2018.8461218
Abstract: Online learning of a robot's inverse dynamics model for trajectory tracking necessitates an interaction between the robot and its environment to collect training data. This is challenging for physical robots in the real world, especially for humanoids and manipulators due to their large and high dimensional state and action spaces, as a large amount of data must be collected over time. This can put the robot in danger when learning tabula rasa and can also be a time-intensive process especially in a multi-robot setting, where each robot is learning its model from scratch. We propose accelerating learning of the inverse dynamics model for trajectory tracking tasks in this multi-robot setting using knowledge transfer, where robots share and re-use data collected by preexisting robots, in order to speed up learning for new robots. We propose a scheme for collecting a sample of correspondences from the robots for training transfer models, and demonstrate, in simulations, the benefit of knowledge transfer in accelerating online learning of the inverse dynamics model between several robots, including between a low-cost Interbotix PhantomX Pincher arm, and a more expensive and relatively heavier Kuka youBot arm. We show that knowledge transfer can save up to 63% of training time of the youBot arm compared to learning from scratch, and about 58% for the lighter Pincher arm.
keywords: {Adaptation models;Manipulator dynamics;Data models;Acceleration;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461218&isnumber=8460178

F. Meier, D. Kappler and S. Schaal, "Online Learning of a Memory for Learning Rates," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2425-2432.
doi: 10.1109/ICRA.2018.8460625
Abstract: The promise of learning to learn for robotics rests on the hope that by extracting some information about the learning process itself we can speed up subsequent similar learning tasks. Here, we introduce a computationally efficient online meta-learning algorithm that builds and optimizes a memory model of the optimal learning rate landscape from previously observed gradient behaviors. While performing task specific optimization, this memory of learning rates predicts how to scale currently observed gradients. After applying the gradient scaling our meta-learner updates its internal memory based on the observed effect its prediction had. Our meta-learner can be combined with any gradient-based optimizer, learns on the fly and can be transferred to new optimization tasks. In our evaluations we show that our meta-learning algorithm speeds up learning of MNIST classification and a variety of learning control tasks, either in batch or online learning settings.
keywords: {Task analysis;Optimization;Prediction algorithms;Robots;Transforms;Computational modeling;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460625&isnumber=8460178

D. Koert, G. Maeda, G. Neumann and J. Pcters, "Learning Coupled Forward-Inverse Models with Combined Prediction Errors," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2433-2439.
doi: 10.1109/ICRA.2018.8460675
Abstract: Challenging tasks in unstructured environments require robots to learn complex models. Given a large amount of information, learning multiple simple models can offer an efficient alternative to a monolithic complex network. Training multiple models-that is, learning their parameters and their responsibilities-has been shown to be prohibitively hard as optimization is prone to local minima. To efficiently learn multiple models for different contexts, we thus develop a new algorithm based on expectation maximization (EM). In contrast to comparable concepts, this algorithm trains multiple modules of paired forward-inverse models by using the prediction errors of both forward and inverse models simultaneously. In particular, we show that our method yields a substantial improvement over only considering the errors of the forward models on tasks where the inverse space contains multiple solutions.
keywords: {Inverse problems;Computational modeling;Data models;Predictive models;Adaptation models;Robots;Context modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460675&isnumber=8460178

Z. Wang et al., "DEFO-NET: Learning Body Deformation Using Generative Adversarial Networks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2440-2447.
doi: 10.1109/ICRA.2018.8462832
Abstract: Modelling the physical properties of everyday objects is a fundamental prerequisite for autonomous robots. We present a novel generative adversarial network (DEFO-NET), able to predict body deformations under external forces from a single RGB-D image. The network is based on an invertible conditional Generative Adversarial Network (IcGAN) and is trained on a collection of different objects of interest generated by a physical finite element model simulator. Defo-netinherits the generalisation properties of GANs. This means that the network is able to reconstruct the whole 3-D appearance of the object given a single depth view of the object and to generalise to unseen object configurations. Contrary to traditional finite element methods, our approach is fast enough to be used in real-time applications. We apply the network to the problem of safe and fast navigation of mobile robots carrying payloads over different obstacles and floor materials. Experimental results in real scenarios show how a robot equipped with an RGB-D camera can use the network to predict terrain deformations under different payload configurations and use this to avoid unsafe areas.
keywords: {Strain;Gallium nitride;Force;Deformable models;Robots;Training;Generators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462832&isnumber=8460178

G. Soter, A. Conn, H. Hauser and J. Rossiter, "Bodily Aware Soft Robots: Integration of Proprioceptive and Exteroceptive Sensors," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2448-2453.
doi: 10.1109/ICRA.2018.8463169
Abstract: Being aware of our body has great importance in our everyday life. It helps us to complete difficult tasks, such as movement in a dark room or grasping a complex object. These skills are important for robots as well, however, robotic bodily awareness is still an open question, and the nonlinearity of soft robots adds even more complexity. In this paper, we address this problem and present a novel method to implement bodily awareness into a real soft robot by the integration of its exteroceptive and proprioceptive sensors. We use an octopus-inspired arm as an example where the proprioceptive representation is approximated by four bend sensors integrated into the soft body, while a camera records the movement of the arm capturing its exteroceptive representation. The internal sensory signals are mapped to the visual information using a combination of a stacked convolutional autoencoder (CAE) and a recurrent neural network (RNN). As a result, the soft robot can learn to estimate and, therefore, to imagine its motion even when its visual sensor is not available.
keywords: {Convolution;Soft robotics;Robot sensing systems;Visualization;Recurrent neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463169&isnumber=8460178

N. Mohajerin, M. Mozifian and S. Waslander, "Deep Learning a Quadrotor Dynamic Model for Multi-Step Prediction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2454-2459.
doi: 10.1109/ICRA.2018.8460840
Abstract: We develop a multi-step motion prediction modeling method for dynamic systems over long horizons using deep learning. Building on previous work, we propose a novel hybrid network architecture, by combining deep recurrent neural networks with a quadrotor motion model created using classic system identification methods. The proposed model takes only the initial system state and motor speeds over the prediction horizon as inputs and returns robust state predictions for up to two seconds of motion at 100 Hz. We employ recurrent neural network state initialization during training, to exploit real-world dataset collected from quadrotor vehicle flights in an indoor flight arena. Our experiments demonstrate that the proposed hybrid network model consistently outperforms both black box and rigid body dynamics predictions over single and multi-step prediction scenarios, with an order of magnitude improvements in velocity estimates in particular.
keywords: {Mathematical model;Predictive models;Vehicle dynamics;Aerodynamics;Recurrent neural networks;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460840&isnumber=8460178

L. Wang, E. A. Theodorou and M. Egerstedt, "Safe Learning of Quadrotor Dynamics Using Barrier Certificates," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2460-2465.
doi: 10.1109/ICRA.2018.8460471
Abstract: To effectively control complex dynamical systems, accurate nonlinear models are typically needed. However, these models are not always known. In this paper, we present a data-driven approach based on Gaussian processes that learns models of quadrotors operating in partially unknown environments. What makes this challenging is that if the learning process is not carefully controlled, the system will go unstable, i.e., the quadcopter will crash. To this end, barrier certificates are employed for safe learning. The barrier certificates establish a non-conservative forward invariant safe region, in which high probability safety guarantees are provided based on the statistics of the Gaussian Process. A learning controller is designed to efficiently explore those uncertain states and expand the barrier certified safe region based on an adaptive sampling scheme. Simulation results are provided to demonstrate the effectiveness of the proposed approach.
keywords: {Safety;Control systems;Computational modeling;Gaussian processes;Adaptation models;Lyapunov methods;System dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460471&isnumber=8460178

T. Cieslewski, S. Choudhary and D. Scaramuzza, "Data-Efficient Decentralized Visual SLAM," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2466-2473.
doi: 10.1109/ICRA.2018.8461155
Abstract: Decentralized visual simultaneous localization and mapping (SLAM) is a powerful tool for multi-robot applications in environments where absolute positioning is not available. Being visual, it relies on cheap, lightweight and versatile cameras, and, being decentralized, it does not rely on communication to a central entity. In this work, we integrate state-of-the-art decentralized SLAM components into a new, complete decentralized visual SLAM system. To allow for data association and optimization, existing decentralized visual SLAM systems exchange the full map data among all robots, incurring large data transfers at a complexity that scales quadratically with the robot count. In contrast, our method performs efficient data association in two stages: first, a compact full-image descriptor is deterministically sent to only one robot. Then, only if the first stage succeeded, the data required for relative pose estimation is sent, again to only one robot. Thus, data association scales linearly with the robot count and uses highly compact place representations. For optimization, a state-of-the-art decentralized pose-graph optimization method is used. It exchanges a minimum amount of data which is linear with trajectory overlap. We characterize the resulting system and identify bottlenecks in its components. The system is evaluated on publicly available datasets and we provide open access to the code. Supplementary Material Data and code are at: https://github.com/uzh-rpg/dslam_open.
keywords: {Simultaneous localization and mapping;Visualization;Optimization;Pose estimation;Trajectory;Bandwidth},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461155&isnumber=8460178

S. M. Nasiri, H. Moradi and R. Hosseini, "A Linear Least Square Initialization Method for 3D Pose Graph Optimization Problem," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2474-2479.
doi: 10.1109/ICRA.2018.8460741
Abstract: Pose Graph Optimization (PGO) is an important optimization problem arising in robotics and machine vision applications like 3D reconstruction and 3D SLAM. Each node of pose graph corresponds to an orientation and a location. The PGO problem finds orientations and locations of the nodes from relative noisy observation between nodes. Recent investigations show that well-known iterative PGO solvers need good initialization to converge to good solutions. However, we observed that state-of-the-art initialization methods obtain good initialization only in low noise problems, and they fail in challenging problems having more measurement noise. Consequently, iterative methods may converge to bad solutions in high noise problems. In this paper, a new method for obtaining orientations in the PGO optimization problem is presented. Like other well-known methods the initial locations are obtained from the result of a least-squares problem. The proposed method iteratively approximates the problem around current estimation and converts it to a least-squares problem. Therefore, the method can be seen as an iterative least-squares method which is computationally efficient. Simulation results show that the proposed initialization method helps the most well-known iterative solver to obtain better optima and significantly outperform other solvers in some cases.
keywords: {Robots;Integrated circuits;Cost function;Iterative methods;Three-dimensional displays;Estimation;Pose Graph Optimization;Least square;3D SLAM;Initialization method},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460741&isnumber=8460178

J. Deschaud, "IMLS-SLAM: Scan-to-Model Matching Based on 3D Data," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2480-2485.
doi: 10.1109/ICRA.2018.8460653
Abstract: The Simultaneous Localization And Mapping (SLAM) problem has been well studied in the robotics community, especially using mono, stereo cameras or depth sensors. 3D depth sensors, such as Velodyne LiDAR, have proved in the last 10 years to be very useful to perceive the environment in autonomous driving, but few methods exist that directly use these 3D data for odometry. We present a new low-drift SLAM algorithm based only on 3D LiDAR data. Our method relies on a scan-to-model matching framework. We first have a specific sampling strategy based on the LiDAR scans. We then define our model as the previous localized LiDAR sweeps and use the Implicit Moving Least Squares (IMLS) surface representation. We show experiments with the Velodyne HDL32 with only 0.40% drift over a 4 km acquisition without any loop closure (i.e., 16 m drift after 4 km). We tested our solution on the KITTI benchmark with a Velodyne HDL64 and ranked among the best methods (against mono, stereo and LiDAR methods) with a global drift of only 0.69%.
keywords: {Three-dimensional displays;Laser radar;Simultaneous localization and mapping;Two dimensional displays;Iterative closest point algorithm;Observability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460653&isnumber=8460178

X. Wang, R. Marcotte, G. Ferrer and E. Olson, "ApriISAM: Real-Time Smoothing and Mapping," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2486-2493.
doi: 10.1109/ICRA.2018.8461072
Abstract: For online robots, incremental SLAM algorithms offer huge potential computational savings over batch algorithms. The dominant incremental algorithms are iSAM and iSAM2 which offer radically different approaches to computing incremental updates, balancing issues like 1) the need to re-linearize, 2) changes in the desirable variable marginalization order, and 3) the underlying conceptual approach (i.e. the “matrix” story versus the “factor graph” story). In this paper, we propose a new incremental algorithm that computes solutions with lower absolute error and generally provides lower error solutions for a fixed computational budget than either iSAM or iSAM2. Key to AprilSAM's performance are a new dynamic variable reordering algorithm for fast incremental Cholesky factorizations, a method for reducing the work involved in backsubstitutions, and a new algorithm for deciding between incremental and batch updates.
keywords: {Simultaneous localization and mapping;Heuristic algorithms;Smoothing methods;Sparse matrices;Clustering algorithms;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461072&isnumber=8460178

D. -N. Ta, N. Banerjee, S. Eick, S. Lenser and M. E. Munich, "Fast Nonlinear Approximation of Pose Graph Node Marginalization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2494-2501.
doi: 10.1109/ICRA.2018.8460979
Abstract: We present a fast nonlinear approximation method for marginalizing out nodes on pose graphs for longterm simultaneous localization, mapping, and navigation. Our approximation preserves the pose graph structure to leverage the rich literature of pose graphs and optimization schemes. By re-parameterizing from absolute-to relative-pose spaces, our method does not suffer from the choice of linearization points as in previous works. We then join our approximation process with a scaled version of the recently-demoted pose-composition approach. Our approach eschews the expenses of many state-of-the-art convex optimization schemes through our efficient and simple O(N2) implementation for a given known topology of the approximate subgraph. We demonstrate its speed and near optimality in practice by comparing against state-of-the-art techniques on popular datasets.
keywords: {Topology;Jacobian matrices;Covariance matrices;Gaussian distribution;Simultaneous localization and mapping;Approximation methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460979&isnumber=8460178

J. Delmerico and D. Scaramuzza, "A Benchmark Comparison of Monocular Visual-Inertial Odometry Algorithms for Flying Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2502-2509.
doi: 10.1109/ICRA.2018.8460664
Abstract: Flying robots require a combination of accuracy and low latency in their state estimation in order to achieve stable and robust flight. However, due to the power and payload constraints of aerial platforms, state estimation algorithms must provide these qualities under the computational constraints of embedded hardware. Cameras and inertial measurement units (IMUs) satisfy these power and payload constraints, so visual-inertial odometry (VIO) algorithms are popular choices for state estimation in these scenarios, in addition to their ability to operate without external localization from motion capture or global positioning systems. It is not clear from existing results in the literature, however, which VIO algorithms perform well under the accuracy, latency, and computational constraints of a flying robot with onboard state estimation. This paper evaluates an array of publicly-available VIO pipelines (MSCKF, OKVIS, ROVIO, VINS-Mono, SVO+MSF, and SVO+GTSAM) on different hardware configurations, including several single-board computer systems that are typically found on flying robots. The evaluation considers the pose estimation accuracy, per-frame processing time, and CPU and memory load while processing the EuRoC datasets, which contain six degree of freedom (6DoF) trajectories typical of flying robots. We present our complete results as a benchmark for the research community.
keywords: {State estimation;Visualization;Optimization;Pipelines;Hardware;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460664&isnumber=8460178

L. Von Stumberg, V. Usenko and D. Cremers, "Direct Sparse Visual-Inertial Odometry Using Dynamic Marginalization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2510-2517.
doi: 10.1109/ICRA.2018.8462905
Abstract: We present VI-DSO, a novel approach for visual-inertial odometry, which jointly estimates camera poses and sparse scene geometry by minimizing photometric and IMU measurement errors in a combined energy functional. The visual part of the system performs a bundle-adjustment like optimization on a sparse set of points, but unlike key-point based systems it directly minimizes a photometric error. This makes it possible for the system to track not only corners, but any pixels with large enough intensity gradients. IMU information is accumulated between several frames using measurement preintegration and is inserted into the optimization as an additional constraint between keyframes. We explicitly include scale and gravity direction into our model and jointly optimize them together with other variables such as poses. As the scale is often not immediately observable using IMU data this allows us to initialize our visual-inertial system with an arbitrary scale instead of having to delay the initialization until everything is observable. We perform partial marginalization of old variables so that updates can be computed in a reasonable time. In order to keep the system consistent we propose a novel strategy which we call “dynamic marginalization”. This technique allows us to use partial marginalization even in cases where the initial scale estimate is far from the optimum. We evaluate our method on the challenging EuRoC dataset, showing that VI-DSO outperforms the state of the art.
keywords: {Cameras;Optimization;Visualization;Gravity;Measurement;Geometry;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462905&isnumber=8460178

H. Li, J. Yao, J. -C. Bazin, X. Lu, Y. Xing and K. Liu, "A Monocular SLAM System Leveraging Structural Regularity in Manhattan World," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2518-2525.
doi: 10.1109/ICRA.2018.8463165
Abstract: The structural features in Manhattan world encode useful geometric information of parallelism, orthogonality and/or coplanarity in the scene. By fully exploiting these structural features, we propose a novel monocular SLAM system which provides accurate estimation of camera poses and 3D map. The foremost contribution of the proposed system is a structural feature-based optimization module which contains three novel optimization strategies. First, a rotation optimization strategy using the parallelism and orthogonality of 3D lines is presented. We propose a global binding method to compute an accurate estimation of the absolute rotation of the camera. Then we propose an approach for calculating the relative rotation to further refine the absolute rotation. Second, a translation optimization strategy leveraging coplanarity is proposed. Coplanar features are effectively identified, and we leverage them by a unified model handling both points and lines to calculate the relative translation, and then the optimal absolute translation. Third, a 3D line optimization strategy utilizing parallelism, orthogonality and coplanarity simultaneously is proposed to obtain an accurate 3D map consisting of structural line segments with low computational complexity. Experiments in man-made environments have demonstrated that the proposed system outperforms existing state-of-the-art monocular SLAM systems in terms of accuracy and robustness.
keywords: {Three-dimensional displays;Cameras;Optimization;Parallel processing;Simultaneous localization and mapping;Robustness;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463165&isnumber=8460178

T. Dang, C. Papachristos and K. Alexis, "Visual Saliency-Aware Receding Horizon Autonomous Exploration with Application to Aerial Robotics," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2526-2533.
doi: 10.1109/ICRA.2018.8460992
Abstract: This paper presents a novel strategy for autonomous visual saliency-aware receding horizon exploration of unknown environments using aerial robots. Through a model of visual attention, incrementally built maps are annotated regarding the visual importance and saliency of different objects and entities in the environment. Provided this information, a path planner that simultaneously optimizes for exploration of unknown space, and also directs the robot's attention to focus on the most salient objects, is developed. Following a two-step optimization paradigm, the algorithm first samples a random tree and identifies the branch maximizing for new volume to be explored. The first viewpoint of this path is then provided as a reference to the second planning step. Within that, a new tree is spanned, admissible branches arriving at the reference viewpoint while respecting a time budget dependent on the robot endurance and its environment exploration rate are found and evaluated in terms of reobserving salient regions at sufficient resolution. The best branch is then selected and executed by the robot, and the whole process is iteratively repeated. The proposed method is evaluated regarding its ability to provide increased attention toward salient objects, is verified to run onboard a small aerial robot, and is demonstrated in a set of challenging experimental studies.
keywords: {Visualization;Robot sensing systems;Planning;Computational modeling;Path planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460992&isnumber=8460178

Z. Zhang and D. Scaramuzza, "Perception-aware Receding Horizon Navigation for MAVs," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2534-2541.
doi: 10.1109/ICRA.2018.8461133
Abstract: To reach a given destination safely and accurately, a micro aerial vehicle needs to be able to avoid obstacles and minimize its state estimation uncertainty at the same time. To achieve this goal, we propose a perception-aware receding horizon approach. In our method, a single forward-looking camera is used for state estimation and mapping. Using the information from the monocular state estimation and mapping system, we generate a library of candidate trajectories and evaluate them in terms of perception quality, collision probability, and distance to the goal. The best trajectory to execute is then selected as the one that maximizes a reward function based on these three metrics. To the best of our knowledge, this is the first work that integrates active vision within a receding horizon navigation framework for a goal reaching task. We demonstrate by simulation and real-world experiments on an actual quadrotor that our active approach leads to improved state estimation accuracy in a goal-reaching task when compared to a purely-reactive navigation system, especially in difficult scenes (e.g., weak texture).
keywords: {Trajectory;State estimation;Planning;Navigation;Cameras;Measurement;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461133&isnumber=8460178

F. Maffra, Z. Chen and M. Chli, "Viewpoint-Tolerant Place Recognition Combining 2D and 3D Information for UAV Navigation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2542-2549.
doi: 10.1109/ICRA.2018.8460786
Abstract: The booming interest in Unmanned Aerial Vehicles (UAV s) is fed by their potentially great impact, however progress is hindered by their limited perception capabilities. While vision-based odometry was shown to run successfully onboard UAV s, loop-closure detection to correct for drift or to recover from tracking failures, has so far, proven particularly challenging for UAVs. At the heart of this is the problem of viewpoint-tolerant place recognition; in stark difference to ground robots, UAVs can revisit a scene from very different viewpoints. As a result, existing approaches struggle greatly as the task at hand violates underlying assumptions in assessing scene similarity. In this paper, we propose a place recognition framework, which exploits both efficient binary features and noisy estimates of the local 3D geometry, which are anyway computed for visual-inertial odometry onboard the UAV. Attaching both an appearance and a geometry signature to each `location', the proposed approach demonstrates unprecedented recall for perfect precision as well as high quality loop-closing transformations on both flying and hand-held datasets exhibiting large viewpoint and appearance changes as well as perceptual aliasing.
keywords: {Simultaneous localization and mapping;Three-dimensional displays;Visualization;Vocabulary;Image recognition;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460786&isnumber=8460178

T. Hinzmann, T. Taubner and R. Siegwart, "Flexible Stereo: Constrained, Non-Rigid, Wide-Baseline Stereo Vision for Fixed-Wing Aerial Platforms," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2550-2557.
doi: 10.1109/ICRA.2018.8461085
Abstract: This paper proposes a computationally efficient method to estimate the time-varying relative pose between two visual-inertial sensor rigs mounted on the flexible wings of a fixed-wing unmanned aerial vehicle (UAV). The estimated relative poses are used to generate highly accurate depth maps in real-time and can be employed for obstacle avoidance in low-altitude flights or landing maneuvers. The approach is structured as follows: Initially, a wing model is identified by fitting a probability density function to measured deviations from the nominal relative baseline transformation. At runtime, the prior knowledge about the wing model is fused in an Extended Kalman filter (EKF) together with relative pose measurements obtained from solving a relative perspective N-point problem (PNP), and the linear accelerations and angular velocities measured by the two inertial measurement units (IMU) which are rigidly attached to the cameras. Results obtained from extensive synthetic experiments demonstrate that our proposed framework is able to estimate highly accurate baseline transformations and depth maps.
keywords: {Cameras;Visualization;Mathematical model;Quaternions;Unmanned aerial vehicles;Real-time systems;Accelerometers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461085&isnumber=8460178

T. Sayre-McCord et al., "Visual-Inertial Navigation Algorithm Development Using Photorealistic Camera Simulation in the Loop," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2566-2573.
doi: 10.1109/ICRA.2018.8460692
Abstract: The development of fast, agile micro Unmanned Aerial Vehicles (UAVs) has been limited by (i) on-board computing hardware restrictions, (ii) the lack of sophisticated vision-based perception and vision-in-the-loop control algorithms, and (iii) the absence of development environments where such systems and algorithms can be rapidly and easily designed, implemented, and validated. Here, we first present a new micro UAV platform that integrates high-rate cameras, inertial sensors, and an NVIDIA Jetson Tegra X1 system-on-chip compute module that boasts 256 GPU cores. The UAV mechanics and electronics were designed and built in house, and are described in detail. Second, we present a novel “virtual reality” development environment, in which photorealistically-rendered synthetic on-board camera images are generated in real time while the UAV is in flight. This development environment allows us to rapidly prototype computing and sensing hardware as well as perception and control algorithms, using real physics, real interoceptive sensor data (e.g., from the on-board inertial measurement unit), and synthetic exteroceptive sensor data (e.g., from synthetic cameras). Third, we demonstrate repeated agile maneuvering with closed-loop vision-based perception and control algorithms, which we have developed using this environment.
keywords: {Cameras;Sensors;Visualization;Real-time systems;Unmanned aerial vehicles;Navigation;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460692&isnumber=8460178

X. Zhang, H. Kim, L. W. Rogowski, S. Sheckman and M. JunKim, "Development and Implementation of High Power Hexapole Magnetic Tweezer System for Micromanipulations," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2670-2675.
doi: 10.1109/ICRA.2018.8463175
Abstract: This paper presents the design, development and implementation of a novel, high power hexapole magnetic tweezer system for 3D micromanipulations. Six tapering-tipped magnetic poles are deployed in a tilted Cartesian coordinate system, with an electromagnetic coil on each for actuation, connected by two 3D printed magnetic yokes to form a double layer structure. The power source is integrated to the magnetic tweezer system through a control algorithm on the software level; image processing was used for experiment analysis. Because of the high magnetic field that the magnetic coils can generate, the working space in the system is relatively larger than other similar designs, which provides better performance on microscale robotic swimmer manipulations. Simulations and experiments performed in this paper demonstrate the agile and powerful manipulation of microswimmers with desired control input to follow complex trajectories, avoid obstacles and move against micro-flow in the samples. We prove that the developed hexapole magnetic tweezer has enough power and controllability to guide microswimmers in Newtonian and Non-Newtonian fluid environments. The system will be optimized continuously and implemented into cell penetration experiments. Finally, the application will be deployed into in vivo based environments.
keywords: {Magnetic flux;Magnetic resonance imaging;Magnetic fields;Saturation magnetization;Magnetic hysteresis;Force;Power supplies},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463175&isnumber=8460178

Z. Zhang et al., "Robotic Immobilization of Motile Sperm," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2676-2681.
doi: 10.1109/ICRA.2018.8462912
Abstract: Manipulation of motile cells such as bacteria and sperm is required in both cell biology and clinical applications. For immobilizing a motile sperm, the sperm head and tail positions must be accurately tracked, interference of proximal sperms on the target sperm must be tackled, and the orientation of the sperm must be properly aligned with the manipulation tool in order not to damage the sperm head where DNA is contained. Manual operation of sperm immobilization has stringent skill requirements, and both manual operation and existing robotic sperm immobilization suffer from inconsistent success rates and incapability of manipulating sperms swimming in all directions. This paper presents a robotic system for fully automated tracking, orientation control, and immobilization of motile sperms. Algorithms were developed for robustly tracking the sperm head and estimating the sperm tail positions under interfering conditions. A new visual servo control strategy was developed to enable the robotic system to actively adjust sperm orientation for immobilizing a sperm swimming in any direction. Experimental results from robotic immobilization of 400 sperms confirmed that the robotic system achieved a consistent success rate of 94.5 %, independent of sperm velocity or swimming direction.
keywords: {Robots;Head;Visualization;Target tracking;Servosystems;Glass},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462912&isnumber=8460178

C. Sheng Dai et al., "Automated Non-Invasive Measurement of Sperm Motility and Morphology Parameters," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2682-2687.
doi: 10.1109/ICRA.2018.8461252
Abstract: Measuring the motility and morphology parameters of motile cells is important for revealing their functional characteristics. This paper presents automation techniques that, for the first time, enable automated, non-invasive measurement of motility and morphology parameters of individual sperms. Compared to the status quo of qualitative estimation of single sperm's motility and morphology based on embryologists' empirical experience, the automation techniques provide quantitative data in nearly real time. An adapted joint probabilistic data association filter (JPDAF) was used for multi-sperm tracking and tackled challenges of identifying sperms that intersect or have small spatial distances. Since the standard differential interference contrast (DIC) imaging method has side illumination effect which causes inherent inhomogeneous image intensity and poses difficulties for accurate sperm morphology measurement, we integrated total variation norm into the quadratic cost function method, which together effectively removed inhomogeneous image intensity and retained sperm's subcellular structures after DIC image reconstruction. In order to relocate the same sperm of interest identified under low magnification after switching to high magnification, coordinate transformation was conducted to handle the changes in the field of view caused by magnification switch. Experimental results demonstrated an accuracy of 95.6% in sperm motility measurement and errors <;10% in morphology measurement.
keywords: {Morphology;Switches;Head;Target tracking;Microscopy;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461252&isnumber=8460178

E. Kim et al., "Construction of Hepatic Lobule-Like Vascular Network by Using Magnetic Fields," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2688-2693.
doi: 10.1109/ICRA.2018.8460628
Abstract: Fabrication of vascular network is an important research for transporting required nutrients and oxygen to the artificial tissues. In this paper, we propose a novel method to construct a hepatic lobule-like vascular network in a 3D cellular structure. The network is simply constructed by three types of veins, central vein, portal vein, and sinusoids. To realize these kinds veins, we utilize two different sizes of steel rods and magnetic fibers for delivering nutrients in 3D cellular structure. Alginate gel fibers embedding ferrite particles are prepared as the same length and are magnetized by magnetizer at 3T. A magnetic tweezer with seven poles is proposed to generate sufficient forces that can manipulate magnetized fibers. Here, two types of rods are magnetized to different magnetic poles in order to attract opposite the end of fibers. This manipulation process is performed in fibrinogen and thrombin solution with liver cells (RLC-18). After solidification of the solution, we deposit solutions with cells and fibers repeatedly, and therefore, a multi-layered structure can be constructed. In addition, we investigate cell a viability in fibrin gel according to the depth of the gel. The result is that the deeper the depth of the gel is, the lower the cell viability is. The cell viability is conducted in several condition. As a result, at the low temperature (here at 22 °C), the viability of cell is increased.
keywords: {Steel;Optical fiber networks;Veins;Magnetic flux;Three-dimensional displays;Electromagnetics;Toroidal magnetic fields},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460628&isnumber=8460178

P. Triantafyllou, P. Wisanuvej, S. Giannarou, J. Liu and G. -Z. Yang, "A Framework for Sensorless Tissue Motion Tracking in Robotic Endomicroscopy Scanning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2694-2699.
doi: 10.1109/ICRA.2018.8462907
Abstract: Recent advances in probe-based Confocal Laser Endomicroscopy (pCLE) enable real-time, in situ and in vivo tissue assessment at the micro scale. The limited field-of-view offered by pCLE necessitates the use of mosaicking to allow for accurate tissue characterization from the incoming image stream. However, mosaicking requires a series of contiguous good-quality images, which is particularly challenging because probe-tissue distance must be maintained within a very narrow working range at all times and probe-tissue contact force must be kept to a minimum so that tissue deformation is avoided. Robotic manipulation of the endomicroscopy probe has provided partial solution to these challenges, but sensorless approaches have not been thoroughly investigated up to date. This paper proposes a novel sensorless framework that uses a single non-reference image-quality metric to learn an approximation of tissue motion and subsequently track it. Moreover, a pCLE robotic tool for autonomous endomicroscopy scanning is designed and used for testing and validation purposes. Experiments on lens paper and ex vivo porcine tissue validate the philosophy of the framework.
keywords: {Probes;Tools;Force;Robot sensing systems;Strain},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462907&isnumber=8460178

V. Foroutan, F. Farzami, D. Erricolo, R. Majumdar and I. Paprotny, "SAT-C: An Efficient Control Strategy for Assembly of Heterogeneous Stress-Engineered MEMS Microrobots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2700-2707.
doi: 10.1109/ICRA.2018.8460481
Abstract: We present a new efficient control framework for controlling groups of heterogeneous stress-engineered MEMS microrobots for accomplishing micro-assembly. The objective is to maximize the number of controllable microrobots in the system while keeping the number of external global signals as low as possible. This work proposes a theoretical control strategy that could complete multiple-shapes microassembly from arbitrary initial configuration where all the control primitives can be accompanied with a constant number (O(1)) of control pulses of the power delivery waveform. We focus on microrobotic systems that can be modeled as nonholonomic unicycles. We validate the control policy with hardware experiments for implementing planar assembly using multiple macroscale robots with direct drive wheels. These results lay the foundation for developing new methods to control of a large number of MEMS microrobots.
keywords: {Robots;Hysteresis;Microassembly;Micromechanical devices;Voltage control;Bandwidth;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460481&isnumber=8460178

X. Wang et al., "Robotic Intracellular Manipulation: 3D Navigation and Measurement Inside a Single Cell," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2716-2721.
doi: 10.1109/ICRA.2018.8463170
Abstract: Magnetic micromanipulation is an untethered technique and has enabled numerous applications in the scale of millimeters to micrometers from the tissue level to cell level. However, existing systems are not capable of maneuvering a sub-micrometer object for precise force control, preventing the realization of intracellular manipulation or `fantastic voyage' inside a single cell. The magnetic micromanipulation task achieved in this work is sub-micrometer position control and piconewton force control of a sub-micron (0.7 μm) magnetic bead inside a single human bladder cancer cell (RT4). The magnetic bead was 3D positioned in the cell using a generalized predictive controller that effectively tackled the control challenge caused by the slow visual feedback (1 Hz) from high-resolution confocal microscopy. The average positioning error was quantified to be 0.43 μm, which is slightly larger than Brownian motion-imposed constraint (0.31 μm). The system is capable of three-dimensionally applying a maximum force of 60 pN with a resolution of 4 pN. In experiments, a 0.7 μm magnetic bead was controlled to move from an initial position in a cell to target positions on the cell nucleus. Force-displacement data were obtained from multiple locations along the cell nucleus' major and minor axes. The results revealed, for the first time, significantly higher stiffness exists in the cell nucleus' major axis than the minor axis. This stiffness polarity was likely attributed to the aligned stress fibers of actin filament inside the cells.
keywords: {Magnetic resonance imaging;Magnetic levitation;Force;Magnetic noise;Magnetic shielding;Magnetic devices;Magnetic separation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463170&isnumber=8460178

S. Luo, W. Yuan, E. Adelson, A. G. Cohn and R. Fuentes, "ViTac: Feature Sharing Between Vision and Tactile Sensing for Cloth Texture Recognition," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2722-2727.
doi: 10.1109/ICRA.2018.8460494
Abstract: Vision and touch are two of the important sensing modalities for humans and they offer complementary information for sensing the environment. Robots could also benefit from such multi-modal sensing ability. In this paper, addressing for the first time (to the best of our knowledge) texture recognition from tactile images and vision, we propose a new fusion method named Deep Maximum Covariance Analysis (DMCA) to learn a joint latent space for sharing features through vision and tactile sensing. The features of camera images and tactile data acquired from a GelSight sensor are learned by deep neural networks. But the learned features are of a high dimensionality and are redundant due to the differences between the two sensing modalities, which deteriorates the perception performance. To address this, the learned features are paired using maximum covariance analysis. Results of the algorithm on a newly collected dataset of paired visual and tactile data relating to cloth textures show that a good recognition performance of greater than 90% can be achieved by using the proposed DMCA framework. In addition, we find that the perception performance of either vision or tactile sensing can be improved by employing the shared representation space, compared to learning from unimodal data.
keywords: {Visualization;Tactile sensors;Cameras;Task analysis;Surface topography},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460494&isnumber=8460178

K. Van Wyk and J. Falco, "Calibration and Analysis of Tactile Sensors as Slip Detectors," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2744-2751.
doi: 10.1109/ICRA.2018.8461117
Abstract: The existence of tactile afferents sensitive to slip-related mechanical transients in the human hand augments the robustness of grasping through secondary force modulation protocols. Despite this knowledge and the fact that tactile-based slip detection has been researched for decades, robust slip detection is still not an out-of-the-box capability for any commercially available tactile sensor. This research seeks to bridge this gap with a comprehensive study addressing several aspects of slip detection. In particular, key developments include a systematic data collection process yielding millions of sensory data points, a spectral analysis of sensory responses providing insight into sensor behavior, and the application of Long Short-Term Memory (LSTM) neural networks to produce robust slip detectors from three commercially available sensors capable of tactile sensing. The sensing mechanics behind these sensors are all fundamentally different and leverage principles in electro-mechanical resistance, optics, and hydro-acoustics. Critically, slip detection performance of the tactile technologies is quantified through a measurement methodology that unveils the effects of data window size, sampling rate, material type, slip speed, and sensor manufacturing variability. Results indicate that the investigated commercial tactile sensors are inherently capable of high-quality slip detection.
keywords: {Force;Tactile sensors;Detectors;Robustness;Spectral analysis;tactile sensors;slip detection;neural networks;deep learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461117&isnumber=8460178

L. Cramphorn, J. Lloyd and N. F. Lepora, "Voronoi Features for Tactile Sensing: Direct Inference of Pressure, Shear, and Contact Locations," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2752-2757.
doi: 10.1109/ICRA.2018.8460644
Abstract: There are a wide range of features that tactile contact provides, each with different aspects of information that can be used for object grasping, manipulation, and perception. In this paper inference of some key tactile features, tip displacement, contact location, shear direction and magnitude, is demonstrated by introducing a novel method of transducing a third dimension to the sensor data via Voronoi tessellation. The inferred features are displayed throughout the work in a new visualisation mode derived from the Voronoi tessellation; these visualisations create easier interpretation of data from an optical tactile sensor that measures local shear from displacement of internal pins (the TacTip). The output values of tip displacement and shear magnitude are calibrated to appropriate mechanical units and validate the direction of shear inferred from the sensor. We show that these methods can infer the direction of shear to ~2.3° without the need for training a classifier or regressor. The approach demonstrated here will increase the versatility and generality of the sensors and thus allow sensor to be used in more unstructured and unknown environments, as well as improve the use of these tactile sensors in more complex systems such as robot hands.
keywords: {Pins;Tactile sensors;Optical sensors;Data visualization;Biomedical optical imaging;Strain},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460644&isnumber=8460178

Z. Su, O. Kroemer, G. E. Loeb, G. S. Sukhatme and S. Schaal, "Learning Manipulation Graphs from Demonstrations Using Multimodal Sensory Signals," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2758-2765.
doi: 10.1109/ICRA.2018.8461121
Abstract: Complex contact manipulation tasks can be decomposed into sequences of motor primitives. Individual primitives often end with a distinct contact state, such as inserting a screwdriver tip into a screw head or loosening it through twisting. To achieve robust execution, the robot should be able to verify that the primitive's goal has been reached as well as disambiguate it from erroneous contact states. In this paper, we introduce and evaluate a framework to autonomously construct manipulation graphs from manipulation demonstrations. Our manipulation graphs include sequences of motor primitives for performing a manipulation task as well as corresponding contact state information. The sensory models for the contact states allow the robot to verify the goal of each motor primitive as well as detect erroneous contact changes. The proposed framework was experimentally evaluated on grasping, unscrewing, and insertion tasks on a Barrett arm and hand equipped with two BioTacs. The results of our experiments indicate that the learned manipulation graphs achieve more robust manipulation executions by confirming sensory goals as well as discovering and detecting novel failure modes.
keywords: {Robot sensing systems;Task analysis;Fasteners;Trajectory;Motion segmentation;Vibrations},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461121&isnumber=8460178

E. Battaglia, M. G. Catalano, G. Grioli, M. Bianchi and A. Bicchi, "ExoSense: Measuring Manipulation in a Wearable Manner," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2774-2781.
doi: 10.1109/ICRA.2018.8460498
Abstract: Grasp and manipulation is a complex task, deceivingly simple to accomplish for humans in everyday life, yet challenging to implement in a robotic hand. There is a trend in literature to use information obtained from studies on human grasp for the design and control of robotic manipulators. However, the effectiveness of such approach is dependent on the measurement tools that are available for use with human hands. While there are many sensing solutions that are designed for this purpose, obtaining a complete set of measurements of forces during grasp interaction is still challenging. In this work we aim to bridge this gap by introducing ExoSense, a passive hand exoskeleton. This device can provide position and orientation of the fingertips and, when integrated with the fingertip wearable force/torque sensing system ThimbleSense, a complete characterization of manipulation in terms of generalized forces and position of contacts on each fingertip in a completely wearable and unconstrained manner. After validating the device in terms of end-effector posture measurements and overall accuracy of grasp measurements, we report on a preliminary experiment aiming to show the potentialities of the system to study human internal grasp force variations and for neuroscientific investigation in general.
keywords: {Kinematics;Exoskeletons;Robot sensing systems;Force;Calibration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460498&isnumber=8460178

T. Noda, A. Takai, T. Teramae, E. Hirookai, K. Hase and J. Morimoto, "Robotizing Double-Bar Ankle-Foot Orthosis," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2782-2787.
doi: 10.1109/ICRA.2018.8462911
Abstract: This paper introduces an approach that robotizes an ankle-foot orthosis (AFO). In particular, toward post-stroke gait rehabilitation, we robotize a double-bar AFO, which is widely used in rehabilitation facilities, by newly designing a modular joint, a pneumatic actuator, and a Bowden cable force-transmission system. Our modular joint system, called the Modular Exoskeletal Joint (MEJ), has a hollow shaft for simple attachment to an AFO's pivot. We designed MEJ to compactly house an encoder that is built in a bearing in a pulley. We adopted Bowden cables to transmit contraction forces from an actuator to the MEJ. As an actuation scheme, we developed the Nested-cylinder Pneumatic Artificial Muscle (NcPAM) system. Even though PAMs are mechanically compliant and lightweight, they can still generate a large force. Therefore, they can provide an ideal actuation system for exoskeletal robots. The nested-cylinder in NcPAM houses a cable-tensioning spring to properly maintain small cable tension for passive movements and a cable stopper to connect the PAM and the cable for properly transmitting the large force generated by PAM. We show the ankle-joint trajectory tracking performances of this integrated system using iterative learning control.
keywords: {Robots;Force;Actuators;Mechanical cables;Exoskeletons;Torque;Springs},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462911&isnumber=8460178

T. Elery, S. Rezazadeh, C. Nesler, J. Doan, H. Zhu and R. D. Gregg, "Design and Benchtop Validation of a Powered Knee-Ankle Prosthesis with High-Torque, Low-Impedance Actuators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2788-2795.
doi: 10.1109/ICRA.2018.8461259
Abstract: This paper describes the design of a powered knee-and-ankle transfemoral prosthetic leg, which implements high torque density actuators with low-reduction transmissions. The low reduction of the transmission coupled with a high-torque and low-speed motor creates an actuator with low mechanical impedance and high backdrivability. This style of actuation presents several possible benefits over modern actuation styles implemented in emerging robotic prosthetic legs. Such benefits include free-swinging knee motion, compliance with the ground, negligible unmodeled actuator dynamics, and greater potential for power regeneration. Benchtop validation experiments were conducted to verify some of these benefits. Backdrive and free-swinging knee tests confirm that both joints can be backdriven by small torques (~3 Nm). Bandwidth tests reveal that the actuator is capable of achieving frequencies required for walking and running. Lastly, open-loop impedance control tests prove that the intrinsic impedance and unmodeled dynamics of the actuator are sufficiently small to control joint impedance without torque feedback.
keywords: {Actuators;Gears;Legged locomotion;Knee;Torque;Brushless DC motors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461259&isnumber=8460178

X. Sun, F. Sugai, K. Okada and M. Inaba, "Variable Transmission Series Elastic Actuator for Robotic Prosthesis," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2796-2803.
doi: 10.1109/ICRA.2018.8460796
Abstract: In this paper, we introduce a novel robotic prosthetic knee as shown in Fig. 1 (named as SuKnee) with variable transmission mechanism that could vary transmission ratio while knee angle varies during ambulation activities. A slider crank mechanism is utilized to transform linear motion of series elastic actuator to rotary motion of knee joint. And it contributes to variable transmission ratio with knee angle, which help obtain desired speed variation and torque output in different activities in one mechanism. This feature could uniquely give the SuKnee both: the torque necessary to assist with standing up from a chair and the speed necessary to swing the leg forward during walking. The knee has an active mode, where it operates with batteries and is capable of providing external power, and a passive mode, behaving like a passive prosthesis. Preliminary tests have been performed by a transfemoral amputee and SuKnee could provide user with power to assist walking on level ground and standing up from a chair. And a passive mode test shows it could work like passive prosthesis after battery exhaustion.
keywords: {Knee;Prosthetics;Legged locomotion;Springs;Batteries;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460796&isnumber=8460178

T. Gurriet et al., "Towards Restoring Locomotion for Paraplegics: Realizing Dynamically Stable Walking on Exoskeletons," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2804-2811.
doi: 10.1109/ICRA.2018.8460647
Abstract: This paper presents the first experimental results of crutch-less dynamic walking with paraplegics on a lower-body exoskeleton: ATALANTE, designed by the French start-up company Wandercraft. The methodology used to achieve these results is based on the partial hybrid zero dynamics (PHZD) framework for formally generating stable walking gaits. A direct collocation optimization formulation is used to provide fast and efficient generation of gaits tailored to each patient. These gaits are then implemented on the exoskeleton for three paraplegics. The end result is dynamically stable walking in an exoskeleton without the need for crutches. After a short period of tuning by the engineers and practice by the subjects, each subject was able to dynamically walk across a room of about 10 m up to a speed of 0.15 m/s (0.5 km/h) without the need for crutches or any other kind of assistance.
keywords: {Exoskeletons;Legged locomotion;Foot;Companies;Optimization;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460647&isnumber=8460178

S. Lee et al., "Autonomous Multi-Joint Soft Exosuit for Assistance with Walking Overground," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2812-2819.
doi: 10.1109/ICRA.2018.8460972
Abstract: Soft exosuits are a new approach for assisting with human locomotion, which applies assistive torques to the wearer through functional apparel. In this paper, we present a new version of autonomous multi-joint soft exosuit for gait assistance, particularly designed for overground walking. The soft exosuit assists with ankle plantarflexion, hip flexion, and hip extension, equally distributing the forces between ankle plantarflexion and hip flexion. A mobile actuation system was developed to generate high assistive forces, and Bowden cables are used to transmit the forces to the exosuit. A sensor harness connects two load cells and three IMU s per leg that are used to measure real-time data for a controller that commands desired force profiles as a function of the walking cycle. In addition, a control adaptation method was developed which adjusts control parameters while walking on irregular surfaces. In preliminary studies, the proposed method substantially improved the force consistency while walking over uneven terrain. Specifically, the number of steps where the peak force deviated from the target force decreased from 100 to 57 out of 250 steps, and RMS error on the peak force decreased from 90.0 N to 76.6 N with respect to 300 N target force. Also, a two-subject case study on country-course walking demonstrated the potential of this soft exosuit to improve human energy economy while walking overground.
keywords: {Legged locomotion;Hip;Belts;Force;Actuators;Thigh},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460972&isnumber=8460178

J. Bae et al., "A Lightweight and Efficient Portable Soft Exosuit for Paretic Ankle Assistance in Walking After Stroke," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2820-2827.
doi: 10.1109/ICRA.2018.8461046
Abstract: Hemiparetic gait after stroke is typically asymmetric and energetically inefficient. A major contributor to walking deficits is impaired paretic ankle function. Impaired paretic ankle plantarflexion (PF) reduces forward propulsion symmetry and impaired paretic ankle dorsiflexion (DF) diminishes ground clearance during swing. We have developed soft wearable robots (soft exosuits) to assist paretic PF and DF during walking after stroke. Through experimental studies with poststroke patients, we have demonstrated that exosuits can improve forward propulsion symmetry and ground clearance in walking, ultimately reducing the metabolic cost of walking. This paper presents an optimized soft exosuit aimed at use in clinical gait training for patients poststroke. The optimized exosuit is lightweight, easy to don and doff, and capable of efficiently delivering mechanical assistance to the paretic ankle. This paper focuses on the optimized controller that can deliver well-timed consistent ankle assistance to patients. A preliminary study was performed using this exosuit with three poststroke patients with heterogeneous gait patterns. Results showed that compared to a previously published controller, more consistent assistive force profiles could be delivered to individuals poststroke while consuming 50% less electrical power. Additionally, a preliminary biomechanical assessment was performed during overground walking.
keywords: {Legged locomotion;Prototypes;Foot;Actuators;Force;Mechanical cables},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461046&isnumber=8460178

P. G. Van Lenthe, S. Verros, E. E. G. Hekman, R. Carloni and H. F. J. M. Koopman, "Comparing Assistive Admittance Control Algorithms for a Trunk Supporting Exoskeleton," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2828-2834.
doi: 10.1109/ICRA.2018.8461062
Abstract: Duchenne muscular dystrophy leaves patients with severe dependency on health care. In an effort to increase independence and quality of life, active exoskeletons are developed to support activities of daily living. This study is dedicated to the development and assessment of three different admittance control algorithms for a trunk supporting robot; a law with constant parameters, a law with added feed-forward force, and a law with variable parameters. A Fitts'-like experiment with 12 healthy subjects was performed to compare the control laws. The results show decreased movement times for the feedforward and variable admittance controllers with respect to the standard admittance.
keywords: {Force;Admittance;Robots;Trajectory;Force measurement;Exoskeletons;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461062&isnumber=8460178

N. Ebrahimi, S. Nugroho, A. F. Taha, N. Gatsis, W. Gao and A. Jafari, "Dynamic Actuator Selection and Robust State-Feedback Control of Networked Soft Actuators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2857-2864.
doi: 10.1109/ICRA.2018.8460679
Abstract: The design of robots that are light, soft, powerful is a grand challenge. Since they can easily adapt to dynamic environments, soft robotic systems have the potential of changing the status-quo of bulky robotics. A crucial component of soft robotics is a soft actuator that is activated by external stimuli to generate desired motions. Unfortunately, there is a lack of powerful soft actuators that operate through lightweight power sources. To that end, we recently designed a highly scalable, flexible, biocompatible Electromagnetic Soft Actuator (ESA). With ESAs, artificial muscles can be designed by integrating a network of ESAs. The main research gap addressed in this work is in the absence of system-theoretic understanding of the impact of the realtime control and actuator selection algorithms on the performance of networked soft-body actuators and ESAs. The objective of this paper is to establish a framework that guides the analysis and robust control of networked ESAs. A novel ESA is described, and a configuration of soft actuator matrix to resemble artificial muscle fiber is presented. A mathematical model which depicts the physical network is derived, considering the disturbances due to external forces and linearization errors as an integral part of this model. Then, a robust control and minimal actuator selection problem with logistic constraints and control input bounds is formulated, and tractable computational routines are proposed with numerical case studies.
keywords: {Actuators;Muscles;Force;Coils;Robust control;Magnetic cores;Springs},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460679&isnumber=8460178

G. A. Folkertsma, S. S. Groothuis and S. Stramigioli, "Safety and Guaranteed Stability Through Embedded Energy-Aware Actuators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2902-2908.
doi: 10.1109/ICRA.2018.8463174
Abstract: Safety is essential for robots in unknown environments, especially when there is physical Human-Robot Interaction (pHRI). Control over energy, or passivity, is an effective safety mechanism. However, when the control algorithm is implemented in a discrete-time computer, computation and communication delays readily lead to loss of passivity and to instability. In this paper, a way to make the actuators aware of the energy that they inject into the system is presented. Passivity and stability are then always guaranteed, even in situations of total communication loss. These Embedded Energy-Aware Actuators are a model-free passivity and safety layer that make complex robotic systems dependable, well-behaved and safe. The proposed method is validated in simulation and experiments.
keywords: {Actuators;Robots;Safety;Force;Springs;Shock absorbers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463174&isnumber=8460178

O. Adjali and A. Ramdane-Cherif, "High-Level MLN-Based Approach for Spatial Context Disambiguation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2909-2915.
doi: 10.1109/ICRA.2018.8460923
Abstract: In this paper, we propose a probabilistic MLN-based model for spatial context disambiguation. This model serves as a solution for the problem of incomplete knowledge in High-level task planning. By applying the state of the art MLN probabilistic reasoning such as MCSAT, we determine the concept class of the current spatial context of the robot and contribute by combining semantic spatial relations with observed data at different timesteps. The inherent uncertainty of robot dynamic environments makes the proposed approach suitable to deal with partial observability and sensing limitations of robots. Simulation experiments and evaluation results are presented to validate our model.
keywords: {Robot sensing systems;Context modeling;Semantics;Probabilistic logic;Object recognition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460923&isnumber=8460178

J. G. Mangelson, D. Dominic, R. M. Eustice and R. Vasudevan, "Pairwise Consistent Measurement Set Maximization for Robust Multi-Robot Map Merging," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2916-2923.
doi: 10.1109/ICRA.2018.8460217
Abstract: This paper reports on a method for robust selection of inter-map loop closures in multi-robot simultaneous localization and mapping (SLAM). Existing robust SLAM methods assume a good initialization or an “odometry backbone” to classify inlier and outlier loop closures. In the multi-robot case, these assumptions do not always hold. This paper presents an algorithm called Pairwise Consistency Maximization (PCM) that estimates the largest pairwise internally consistent set of measurements. Finding the largest pairwise internally consistent set can be transformed into an instance of the maximum clique problem from graph theory, and by leveraging the associated literature it can be solved in realtime. This paper evaluates how well PCM approximates the combinatorial gold standard using simulated data. It also evaluates the performance of PCM on synthetic and real-world data sets in comparison with DCS, SCGP, and RANSAC, and shows that PCM significantly outperforms these methods.
keywords: {Simultaneous localization and mapping;Robot kinematics;Phase change materials;Trajectory;Robustness;Merging},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460217&isnumber=8460178

G. Rosman, C. Choi, M. Dogar, J. W. Fisher and D. Rus, "Task-Specific Sensor Planning for Robotic Assembly Tasks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2932-2939.
doi: 10.1109/ICRA.2018.8460194
Abstract: When performing multi-robot tasks, sensory feedback is crucial in reducing uncertainty for correct execution. Yet the utilization of sensors should be planned as an integral part of the task planning, taken into account several factors such as the tolerance of different inferred properties of the scene and interaction with different agents. In this paper we handle this complex problem in a principled, yet efficient way. We use surrogate predictors based on open-loop simulation to estimate and bound the probability of success for specific tasks. We reason about such task-specific uncertainty approximants and their effectiveness. We show how they can be incorporated into a multi-robot planner, and demonstrate results with a team of robots performing assembly tasks.
keywords: {Robot sensing systems;Task analysis;Uncertainty;Planning;Robotic assembly;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460194&isnumber=8460178

A. Rechy Rormero, P. V. K. Borges, A. Pfrunder and A. Elfes, "Map-Aware Particle Filter for Localization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2940-2947.
doi: 10.1109/ICRA.2018.8460707
Abstract: This work presents a method to improve vehicle localization by using the information from a prior occupancy grid to bound the possible poses. The method, named Map-Aware Particle Filter, uses a nonlinear approach to map-matching that can be integrated into a particle filter framework for localization. Each particle is re-weighted based on the validity of its current position in the map. In addition, we buffer the trajectory followed by the vehicle and then append it to each particle's pose. We then quantify the overlap between the trajectory and the map's free space. This serves as a measure of each particle's validity given the trajectory and the shape of the map. We evaluated the method by performing experiments with different types of localization sensors: First, (i) we significantly reduced the drift inherent to dead reckoning. By only using wheel odometry and map information we achieved loop closure over a distance of approximately 3 km. We also (ii) increased the accuracy of GPS localization. Finally, (iii) we fused a fragile 2D LiDAR localization with the map information. The resulting system had a higher robustness and managed to close the loop in an outdated map where it had failed before.
keywords: {Trajectory;Roads;Atmospheric measurements;Particle measurements;Sensors;Particle filters;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460707&isnumber=8460178

H. Nishimura and M. Schwager, "Active Motion-Based Communication for Robots with Monocular Vision," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2948-2955.
doi: 10.1109/ICRA.2018.8463152
Abstract: In this paper, we consider motion as a means of sending messages between robots. We focus on a scenario in which a message is encoded in a sending robot's trajectory, and decoded by a receiver robot equipped with a monocular camera. The relative pose between the robots is unknown. We introduce an online Bayesian estimation algorithm based on the Multi-hypothesis Extended Kalman Filter for the receiving robot to simultaneously estimate its relative pose to the sender, and the trajectory class of the sender. The difficulty in this problem arises from the monocular vision model of the receiver and the unknown relative pose between robots, which brings inherent ambiguity into the trajectory identification, and hence the message decoding. An active vision-based control policy is derived and combined with the Bayesian estimation in order to deal with this difficulty. The policy is constructed online based on Monte Carlo Tree Search and aims at reducing the entropy over the trajectory class distribution. The algorithm has broad applications, e.g., to intent modeling and motion prediction for autonomous driving and autonomous drone operations. Simulation results demonstrate that the proposed estimation algorithm and the control policy result in an accurate trajectory classification.
keywords: {Trajectory;Receivers;Cameras;Robot vision systems;Bayes methods;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463152&isnumber=8460178

Y. Li, S. Li and B. Hannaford, "A Novel Recurrent Neural Network for Improving Redundant Manipulator Motion Planning Completeness," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2956-2961.
doi: 10.1109/ICRA.2018.8461204
Abstract: Recurrent Neural Networks (RNNs) demonstrated advantages on control precision, system robustness and computational efficiency, and have been widely applied to redundant manipulator control optimization. Existing RNN control schemes locally optimize trajectories and are efficient and reliable on obstacle avoidance. However, for motion planning, they suffer from local minimum and do not have planning completeness. This work explained the cause of the planning incompleteness and addressed the problem with a novel RNN control scheme. The paper presented the proposed method in detail and analyzed the global stability and the planning completeness in theory. The proposed method was compared with other three control schemes on the precision, the robustness and the planning completeness in software simulation and the results shows the proposed method has improved precision and robustness, and planning completeness.
keywords: {Planning;Manipulators;Task analysis;Recurrent neural networks;Collision avoidance;Robustness;Aerospace electronics;Motion Planning;Kinematic Control;Recurrent Neural Networks;Redundant Manipulator;Robot},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461204&isnumber=8460178

B. T. Lopez, J. Slotine and J. P. How, "Robust Collision Avoidance via Sliding Control," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2962-2969.
doi: 10.1109/ICRA.2018.8460817
Abstract: Recent advances in perception and planning algorithms have enabled robots to navigate autonomously through unknown, cluttered environments at high-speeds. A key component of these systems is the ability to identify, select, and execute a safe trajectory around obstacles. Many of these systems, however, lack performance guarantees because model uncertainty and external disturbances are ignored when a trajectory is selected for execution. This work leverages results from nonlinear control theory to establish a bound on tracking performance that can be used to select a provably safe trajectory. The Composite Adaptive Sliding Controller (CASC) provides robustness to disturbances and reduces model uncertainty through high-rate parameter estimation. CASC is demonstrated in simulation and hardware to significantly improve the performance of a quadrotor navigating through unknown environments with external disturbances and unknown model parameters.
keywords: {Trajectory;Electron tubes;Uncertainty;Robustness;Optimization;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460817&isnumber=8460178

K. Choromanski, A. Iscen, V. Sindhwani, J. Tan and E. Coumans, "Optimizing Simulations with Noise-Tolerant Structured Exploration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2970-2977.
doi: 10.1109/ICRA.2018.8460492
Abstract: We propose a simple drop-in noise-tolerant replacement for the standard finite difference procedure used ubiquitously in blackbox optimization. In our approach, parameter perturbation directions are defined by a family of structured orthogonal matrices. We show that at the small cost of computing a Fast Walsh-Hadamard/Fourier Transform (FWHT/FFT), such structured finite differences consistently give higher quality approximation of gradients and Jacobians in comparison to vanilla approaches that use coordinate directions or random Gaussian perturbations. We find that trajectory optimizers like Iterative LQR and Differential Dynamic Programming require fewer iterations to solve several classic continuous control tasks when our methods are used to linearize noisy, blackbox dynamics instead of standard finite differences. By embedding structured exploration in a quasi-Newton optimizer (LBFGS), we are able to learn agile walking and turning policies for quadruped locomotion, that successfully transfer from simulation to actual hardware. We theoretically justify our methods via bounds on the quality of gradient reconstruction and provide a basis for applying them also to nonsmooth problems.
keywords: {Perturbation methods;Optimization;Standards;Smoothing methods;Robots;Jacobian matrices;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460492&isnumber=8460178

N. Mansard, A. DelPrete, M. Geisert, S. Tonneau and O. Stasse, "Using a Memory of Motion to Efficiently Warm-Start a Nonlinear Predictive Controller," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2986-2993.
doi: 10.1109/ICRA.2018.8463154
Abstract: Predictive control is an efficient model-based methodology to control complex dynamical systems. In general, it boils down to the resolution at each control cycle of a large nonlinear optimization problem. A critical issue is then to provide a good guess to initialize the nonlinear solver so as to speed up convergence. This is particularly important when disturbances or changes in the environment prevent the use of the trajectory computed at the previous control cycle as initial guess. In this paper, we introduce an original and very efficient solution to automatically build this initial guess. We propose to rely on off-line computation to build an approximation of the optimal trajectories, that can be used on-line to initialize the predictive controller. To that end, we combined the use of sampling-based planning, policy learning with generic representations (such as neural networks), and direct optimal control. We first propose an algorithm to simultaneously build a kinodynamic probabilistic roadmap (PRM) and approximate value function and control policy. This algorithm quickly converges toward an approximation of the optimal state-control trajectories (along with an optimal PRM). Then, we propose two methods to store the optimal trajectories and use them to initialize the predictive controller. We experimentally show that directly storing the state-control trajectories leads the predictive controller to quickly converges (2 to 5 iterations) toward the (global) optimal solution. The results are validated in simulation with an unmanned aerial vehicle (UAV) and other dynamical systems.
keywords: {Computational modeling;Approximation algorithms;Optimal control;Planning;Robots;Trajectory optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463154&isnumber=8460178

E. Todorov, "Goal Directed Dynamics," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 2994-3000.
doi: 10.1109/ICRA.2018.8462904
Abstract: We develop a general control framework where a low-level optimizer is built into the robot dynamics. This optimizer together with the robot constitute a goal directed dynamical system, controlled on a higher level. The high level command is a cost function. It can encode desired accelerations, end-effector poses, center of pressure, and other intuitive features that have been studied before. Unlike the currently popular quadratic programming framework, which comes with performance guarantees at the expense of modeling flexibility, the optimization problem we solve at each time step is non-convex and non-smooth. Nevertheless, by exploiting the unique properties of the soft-constraint physics model we have recently developed, we are able to design an efficient solver for goal directed dynamics. It is only two times slower than the forward dynamics solver, and is much faster than real time. The simulation results reveal that complex movements can be generated via greedy optimization of simple costs. This new computational infrastructure can facilitate teleoperation, feature-based control, deep learning of control policies, and trajectory optimization. It will become a standard feature in future releases of the MuJoCo simulator.
keywords: {Acceleration;Robots;Force;Cost function;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462904&isnumber=8460178

H. Carlos, J. Hayer and R. Murrieta-Cid, "Regression-Based Linear Quadratic Regulator," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3001-3006.
doi: 10.1109/ICRA.2018.8460479
Abstract: We present the Regression-based Linear Quadratic Regulator (R-LQR), a new approach for determining locally-optimal control feedback policies for robots with non-linear dynamics and non-quadratic cost functions. Our proposal uses a free-derivative algorithm based on local quadratic regressions to obtain the robot motion policy. In addition, our methodology allows to define a notion of scale that translates into the definition of neighborhoods of valid policy and into the exploration of larger areas of the search space to find the optimal policies. The results show that our formulation allows to reach policies with lower costs than existing algorithms and to avoid problems when the behavior of the cost function makes the optimization difficult.
keywords: {Cost function;Approximation algorithms;Heuristic algorithms;Regulators;Optimal control;Robots;Aerospace electronics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460479&isnumber=8460178

H. Pham and Q. Pham, "Time-Optimal Path Tracking via Reachability Analysis," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3007-3012.
doi: 10.1109/ICRA.2018.8460576
Abstract: Given a geometric path, the Time-Optimal Path Tracking problem consists in finding the control strategy to traverse the path time-optimally while regulating tracking errors. A simple yet effective approach to this problem is to decompose the controller into two components: (i) a path controller, which modulates the parameterization of the desired path in an online manner, yielding a reference trajectory; and (ii) a tracking controller, which takes the reference trajectory and outputs joint torques for tracking. However, there is one major difficulty: the path controller might not find any feasible reference trajectory that can be tracked by the tracking controller because of torque bounds. In turn, this results in degraded tracking performances. Here, we propose a new path controller that is guaranteed to find feasible reference trajectories by accounting for possible future perturbations. The main technical tool underlying the proposed controller is Reachability Analysis, a new method for analyzing path parameterization problems. Simulations show that the proposed controller outperforms existing methods.
keywords: {Trajectory;Torque;Robustness;Perturbation methods;Acceleration;Manipulator dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460576&isnumber=8460178

M. Okada and T. Taniguchi, "Acceleration of Gradient-Based Path Integral Method for Efficient Optimal and Inverse Optimal Control," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3013-3020.
doi: 10.1109/ICRA.2018.8463164
Abstract: This paper deals with a new accelerated path integral method, which iteratively searches optimal controls with a small number of iterations. This study is based on the recent observations that a path integral method for reinforcement learning can be interpreted as gradient descent. This observation also applies to an iterative path integral method for optimal control, which sets a convincing argument for utilizing various optimization methods for gradient descent, such as momentum-based acceleration, step-size adaptation and their combination. We introduce these types of methods to the path integral and demonstrate that momentum-based methods, like Nesterov Accelerated Gradient and Adam, can significantly improve the convergence rate to search for optimal controls in simulated control systems. We also demonstrate that the accelerated path integral could improve the performance on model predictive control for various vehicle navigation tasks. Finally, we represent this accelerated path integral method as a recurrent network, which is the accelerated version of the previously proposed path integral networks (PI-Net). We can train the accelerated PI-Net more efficiently for inverse optimal control with less RAM than the original PI-Net.
keywords: {Iterative methods;Acceleration;Optimal control;Convergence;Mirrors;Trajectory;Vehicle dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463164&isnumber=8460178

T. Kundu and I. Saha, "Charging Station Placement for Indoor Robotic Applications," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3029-3036.
doi: 10.1109/ICRA.2018.8461006
Abstract: For an autonomous mobile robot, when the available power goes below a certain threshold, the robot needs to abort its current task and move towards a charging station to recharge its battery. The efficiency of an autonomous mobile robot depends significantly on the location of the charging stations. In this paper, we address the charging station placement problem for mobile robots in a controlled workspace. We propose two algorithms to place a number of charging stations so that a robot is always capable of reaching one of the charging stations from any obstacle-free location in the workspace without aborting its task too early. We reduce the charging-station placement problem to a series of Satisfiability Modulo Theory (SMT) problems and use the off-the-shelf SMT solver Z3 to implement our algorithm. The algorithm produces as output the locations of the charging stations in the workspace and the trajectories from any obstacle-free locations to one of the charging stations. Our experimental results show how our algorithm can efficiently find the locations of the charging stations and robot trajectories to reach the charging stations. We demonstrate through simulation how the generated trajectories can be effectively used by a robot to reach a charging stations autonomously without getting depleted with power.
keywords: {Charging stations;Trajectory;Batteries;Planning;Mobile robots;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461006&isnumber=8460178

M. Deremetz, R. Lenain and B. Thuilot, "Path Tracking of a Two-Wheel Steering Mobile Robot: An Accurate and Robust Multi-Model Off-Road Steering Strategy," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3037-3044.
doi: 10.1109/ICRA.2018.8460598
Abstract: In this paper, the problem associated with accurate control of a two-wheel steering mobile robot following a path is addressed thanks to a backstepping control strategy. This approach involves an observer to estimate the grip conditions, based on previous work, and the proposed control algorithm for the front axle. Since the significant parameters of the grip conditions are available from the observer, namely the sideslip angles and the cornering stiffnesses, it is then suitable to include them into an algorithm to control mobile robots and obtain a more accurate path tracking. This is made possible by gathering into a single backstepping approach both kinematic and dynamic models. This new point of view permits to take account of both kinematic and dynamic behaviors and grip parameters in the control law. The proposed approach is experimentally evaluated at different speeds and compared with two other state-of-the-art path tracking algorithms and evaluated for several values of lateral deviations.
keywords: {Mobile robots;Kinematics;Mathematical model;Trajectory;Observers;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460598&isnumber=8460178

J. L. Vermeulen, A. Hillebrand and R. Geraerts, "Annotating Traversable Gaps in Walkable Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3045-3052.
doi: 10.1109/ICRA.2018.8461152
Abstract: Autonomous agents typically need a navigation mesh of a 3D virtual environment to allow efficient path planning. This mesh needs as input a continuous representation of the walkable areas. However, the walkable environment (WE), i.e. the parts of the 3D environment that an agent can walk on, may contain gaps. These may be due to the filtering steps performed to compute the WE, because of modelling errors in the 3D model, or simply be part of the geometry of the environment. We provide an algorithm that identifies and fills these gaps. We detect gaps, up to a given distance, between pairs of boundary edges of the walkable environment, and fill them with polygons. We employ a heuristic for choosing which pairs of edges should be connected. We compare our algorithm to Recast [10], a voxel-based method for navigation mesh generation. We find that our method gives more accurate results in many environments: it retains the exact representation of the walkable environment, semantically separates the gaps from the walkable areas, and requires no tweaking of parameters to obtain good results. However, our method is currently slower than Recast, and requires more memory.
keywords: {Navigation;Three-dimensional displays;Maintenance engineering;Image edge detection;Geometry;Surface morphology;Path planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461152&isnumber=8460178

R. Sandström, A. Bregger, B. Smith, S. Thomas and N. M. Amato, "Topological Nearest-Neighbor Filtering for Sampling-Based Planners," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3053-3060.
doi: 10.1109/ICRA.2018.8460896
Abstract: Nearest-neighbor finding is a major bottleneck for sampling-based motion planning algorithms. The cost of finding nearest neighbors grows with the size of the roadmap, leading to significant slowdowns for problems which require many configurations to find a solution. Prior work has investigated relieving this pressure with quicker computational techniques, such as kd-trees or locality-sensitive hashing. In this work, we investigate an alternative direction for expediting this process based on workspace connectivity. We present an algorithm called Topological Nearest-Neighbor Filtering, which employs a workspace decomposition to select a topologically relevant set of candidate neighbor configurations as a pre-processing step for a nearest-neighbor algorithm. We investigate the application of this filter to several varieties of RRT and demonstrate that the filter improves both nearest-neighbor time and overall planning performance.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460896&isnumber=8460178

V. Pacelli, O. Arslan and D. E. Koditschek, "Integration of Local Geometry and Metric Information in Sampling-Based Motion Planning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3061-3068.
doi: 10.1109/ICRA.2018.8460739
Abstract: The efficiency of sampling-based motion planning algorithms is dependent on how well a steering procedure is capable of capturing both system dynamics and configuration space geometry to connect sample configurations. This paper considers how metrics describing local system dynamics may be combined with convex subsets of the free space to describe the local behavior of a steering function for sampling-based planners. Subsequently, a framework for using these subsets to extend the steering procedure to incorporate this information is introduced. To demonstrate our framework, three specific metrics are considered: the LQR cost-to-go function, a Gram matrix derived from system linearization, and the Mahalanobis distance of a linear-Gaussian system. Finally, numerical tests are conducted for a second-order linear system, a kinematic unicycle, and a linear-Gaussian system to demonstrate that our framework increases the connectivity of sampling-based planners and allows them to better explore the free space.
keywords: {Measurement;Heuristic algorithms;Trajectory;Geometry;Robots;System dynamics;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460739&isnumber=8460178

S. Wang and K. Hauser, "Realization of a Real-Time Optimal Control Strategy to Stabilize a Falling Humanoid Robot with Hand Contact," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3092-3098.
doi: 10.1109/ICRA.2018.8460500
Abstract: In this paper, we present a real-time falling robot stabilization system for a humanoid robot in which the robot can prevent falling using hand contact with walls and other surfaces in the environment. Instead of ignoring or avoiding interaction with environmental obstacles, our system uses obstacle geometry to determine a contact point that reduces impact and necessary friction. It uses a planar dynamic model that is appropriate for falling stabilization in the robot's sagittal plane and frontal plane. The hand contact is determined with an optimal control approach, and to make the algorithm run in realtime, a simplified three-link robot model and a pre-computed database of subproblems for the hand contact optimization are adopted. Moreover, if the robot is not leaning too far after stabilization, we employ a heuristic push-up strategy to recover the robot to a standing posture. System integration is performed on the Darwin-Mini robot and validation is conducted in several environments and falling scenarios.
keywords: {Real-time systems;Legged locomotion;Computational modeling;Humanoid robots;Robot sensing systems;Kinetic energy},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460500&isnumber=8460178

C. Fantacci, G. Vezzani, U. Pattacini, V. Tikhanoff and L. Natale, "Markerless Visual Servoing on Unknown Objects for Humanoid Robot Platforms," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3099-3106.
doi: 10.1109/ICRA.2018.8462914
Abstract: To precisely reach for an object with a humanoid robot, it is of central importance to have good knowledge of both end-effector, object pose and shape. In this work we propose a framework for markerless visual servoing on unknown objects, which is divided in four main parts: I) a leastsquares minimization problem is formulated to find the volume of the object graspable by the robot's hand using its stereo vision; II) a recursive Bayesian filtering technique, based on Sequential Monte Carlo (SMC) filtering, estimates the 6D pose (position and orientation) of the robot's end-effector without the use of markers; III) a nonlinear constrained optimization problem is formulated to compute the desired graspable pose about the object; IV) an image-based visual servo control commands the robot's end-effector toward the desired pose. We demonstrate effectiveness and robustness of our approach with extensive experiments on the iCub humanoid robot platform, achieving real-time computation, smooth trajectories and subpixel precisions.
keywords: {Visual servoing;Grasping;Solid modeling;Three-dimensional displays;Mathematical model;Humanoid robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462914&isnumber=8460178

K. Otani, K. Bouyarmane and S. Ivaldi, "Generating Assistive Humanoid Motions for Co-Manipulation Tasks with a Multi-Robot Quadratic Program Controller," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3107-3113.
doi: 10.1109/ICRA.2018.8463167
Abstract: Human-humanoid collaborative tasks require that the robot take into account the goals of the task, interaction forces with the human, and its own balance. We present a formulation for a real-time humanoid controller which allows the robot to keep itself balanced, while also assisting the human in achieving their shared objectives. We achieve this with a multi-robot quadratic program controller, which solves for human dynamics reconstruction and optimal robot controls in a single optimization problem. Our experiments on a simulated robot platform demonstrate the ability to generate interaction motions and forces that are similar to what a human collaborator would produce.
keywords: {Task analysis;Dynamics;Robot sensing systems;Mathematical model;Optimization;Humanoid robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463167&isnumber=8460178

P. Kaiser, C. Mandery, A. Boltres and T. Asfour, "Affordance-Based Multi-Contact Whole-Body Pose Sequence Planning for Humanoid Robots in Unknown Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3114-3121.
doi: 10.1109/ICRA.2018.8461087
Abstract: Despite impressive advances of humanoid robotics, the autonomous planning of whole-body loco-manipulation actions in unknown environments is still an open problem. In our previous work, we addressed two fundamental aspects related to this problem: 1) the autonomous detection of end-effector contact opportunities in unknown environments and 2) the goal-directed planning of multi-contact pose sequences, which can serve as the starting point for motion planning and control approaches of reduced complexity. Both problems suffer from the extensive amounts of possible solutions, particularly due to the complexity of humanoid robots and the multitude of available contact opportunities. In this paper, we propose a method for the planning of whole-body multi-contact tasks based on our previous work on vision-based detection of loco-manipulation affordances and whole-body multi-contact pose sequence planning. We demonstrate a combined approach for planning multi-contact pose sequences with a focus on the utilization of available end-effectors for stabilizing contacts with the environment during loco-manipulation tasks. The method is evaluated in simulation in multiple exemplary scenarios based on actual sensor data and the humanoid robot ARMAR-4.
keywords: {Planning;Humanoid robots;Task analysis;Motion segmentation;Robot sensing systems;Complexity theory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461087&isnumber=8460178

M. Benallegue et al., "Model-Based External Force/Moment Estimation for Humanoid Robots with no Torque Measurement," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3122-3129.
doi: 10.1109/ICRA.2018.8460809
Abstract: The dynamics of a humanoid robot cannot be correctly described independently from the external forces acting on it. These forces have to be reconstructed to enable the robot to control them or to compensate for them. Force sensors are usually used to measure these forces, but because of their cost, they are often put only on the ankle/feet and possibly the wrists. This paper addresses the issue of the estimation of external forces and moments that apply at any part of a robot without direct force measurements and without torque measurements. The sensors used are the regular force sensors and the IMUs of the robot. The method relies on a model-based estimator able to make the fusion between these sensors and the whole body dynamics. The estimator reconstructs a single state vector containing the floating-base kinematics, a filtered measurement of contact force and an additional estimation external force that we evaluate in this paper. Validation is performed on HRP-2 in a multi-contact motion.
keywords: {Dynamics;Robot sensing systems;Kinematics;Force;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460809&isnumber=8460178

G. Bellegarda, N. Talele and K. By, "Nonintuitive Optima for Dynamic Locomotion: The Acrollbot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3130-3136.
doi: 10.1109/ICRA.2018.8461221
Abstract: This paper explores locally-optimal, efficient locomotion of a two-link planar robot balancing on a single, unactuated wheel. Because this model is essentially an acrobot mounted on a passive wheel, we name this model the acrollbot. By actuating an internal degree of freedom, the model can indirectly produce ground reaction forces yielding net accelerations and decelerations, to achieve locomotion. As with bipedal robot locomotion, this toy system is particularly challenging to control due to the need to balance continuously while controlling forward locomotion speed. However, unlike typical legged or rolling locomotion solutions, it is not immediately obvious how best to exploit actuation, internal reconfigurations, and motions to produce and control forward velocity along the ground, providing a useful benchmarking system for exploring optimization techniques. We use a direct collocation optimization framework to study this toy system, both to achieve a range of feasible locomotion solutions for nonintuitive dynamic robot models, and to investigate optimization of physical robot parameterizations, in the sense of improving locomotion efficiency. The framework and example presented throughout are designed with an aim toward bridging the gap between non-intuitive, data-driven optimization and model-based methods for design and control of underactuated and dynamically-stable locomotion.
keywords: {Wheels;Optimization;Damping;Trajectory;Controllability;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461221&isnumber=8460178

M. Murooka, S. Nozawa, M. Bando, I. Yanokura, K. Okada and M. Inaba, "Simultaneous Planning and Estimation Based on Physics Reasoning in Robot Manipulation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3137-3144.
doi: 10.1109/ICRA.2018.8463156
Abstract: For robots to autonomously achieve manipulation tasks in various scenes, advanced operational skills such as tool use, learning from demonstration, and multi-robot/human-robot cooperation are necessary. In this research, we devise a method for robots to realize such operational skills in a unified manner by evaluating physical consistency (referred to as “physics reasoning”) based on the formulation of the manipulation statics constraints. First, we propose manipulation planning and estimation methods in which the operational feasibility and properties' likelihood are derived by physics reasoning. In addition, we propose a framework to manipulate an object with unknown physical properties by executing planning and estimation both sequentially and in parallel. We demonstrate the effectiveness of the proposed methods by performing experiments in which real humanoid robots achieve various manipulation tasks with advanced operational skills.
keywords: {Planning;Cognition;Estimation;Force;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463156&isnumber=8460178

B. Calli, K. Srinivasan, A. Morgan and A. M. Dollar, "Learning Modes of Within-Hand Manipulation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3145-3151.
doi: 10.1109/ICRA.2018.8461187
Abstract: In this work, we investigate methods to detect four phenomena (modes) that occur during prehensile fingertip-based within-hand manipulation without the use of tactile sensors. By using actuator states and visual data, we aim to recognize different modes of operation such as interpreting if the hand is about to drop the object, if the object will begin to slide on the fingers, or if the system is at or near a singularity. For this purpose, we utilize supervised learning techniques, which allow us to detect the modes without the use of a mechanical model of the system. We analyze the individual roles of specific features available through both the actuator and visual data, and identify the ones that have the most significance for detecting the operation modes. Our results show classification performance of 96% (using either Extra Trees, Gradient Boosting, or SVM) when using combined actuator and visual features. Interestingly, we were able to achieve a 94% classification rate using only actuator information, and 93 % using only visual information. Overall, the classifiers identified actuator positions, actuator loads, and commanded velocities as the most important features for detecting a mode. These results have implications for enabling the control of within-hand manipulation movements utilizing a minimal amount of sensory information without a model of the hand/object system.
keywords: {Actuators;Visualization;Task analysis;Robot sensing systems;Grippers;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461187&isnumber=8460178

P. Ruppel, N. Hendrich, S. Starke and J. Zhang, "Cost Functions to Specify Full-Body Motion and Multi-Goal Manipulation Tasks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3152-3159.
doi: 10.1109/ICRA.2018.8460799
Abstract: While the problem of inverse kinematics on serial kinematic chains is well researched, solving motion tasks quickly on more complex robots remains an open problem. Examples include dual-arm manipulation, grasping with multi-finger hands, and full-body motion generation for humanoids. In this paper, we introduce an open-source software package for ROS and MoveIt! that solves inverse kinematics and motion tasks on robots with arbitrary kinematic trees. The underlying memetic algorithm integrates evolutionary optimization, particle swarm optimization, and gradient methods. The optimization respects joint limits, effectively avoids local minima, and achieves fast convergence to accurate solutions. More importantly, the overall motion goal is specified using a set of weighted sub-goals, providing great flexibility and control of secondary objectives. Several application examples demonstrate how to combine the predefined sub-goals to achieve complex motion tasks.
keywords: {Kinematics;Task analysis;Cost function;Robot kinematics;End effectors;Quaternions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460799&isnumber=8460178

L. Zhao et al., "Robot Composite Learning and the Nunchaku Flipping Challenge," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3160-3165.
doi: 10.1109/ICRA.2018.8461141
Abstract: Advanced motor skills are essential for robots to physically coexist with humans. Much research on robot dynamics and control has achieved success on hyper robot motor capabilities, but mostly through heavily case-specific engineering. Meanwhile, in terms of robot acquiring skills in a ubiquitous manner, robot learning from human demonstration (LfD) has achieved great progress, but still has limitations handling dynamic skills and compound actions. We present a composite learning scheme which goes beyond LfD and integrates robot learning from human definition, demonstration, and evaluation. The method tackles advanced motor skills that require dynamic time-critical maneuver, complex contact control, and handling partly soft partly rigid objects. We also introduce the “nunchaku flipping challenge”, an extreme test that puts hard requirements to all these three aspects. Continued from our previous presentations, this paper introduces the latest update of the composite learning scheme and the physical success of the nunchaku flipping challenge.
keywords: {Petri nets;Robot learning;Mobile robots;Compounds;Dynamics;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461141&isnumber=8460178

M. Yashima and T. Yamawaki, "Iterative Learning Scheme for Dexterous In-Hand Manipulation with Stochastic Uncertainty," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3166-3171.
doi: 10.1109/ICRA.2018.8462913
Abstract: In-hand manipulation has attracted attention because of its potential for performing dexterous manipulation tasks. Few successful examples using real robotic fingers have been reported because model-based approaches have been assumed. A gradient descent-based iterative learning control is one of the typical methods for improving the control performance without the need for a precise model. However, the learning performances deteriorate greatly owing to the stochastic uncertainties, and the learning rates have to be determined manually. We propose a novel iterative learning scheme with adaptive learning rate methods for dexterous in-hand manipulation. The proposed scheme not only eliminates the need for a precise model and manual tuning of a learning rate but also is robust to stochastic uncertainties and insensitive to hyperparameters. The validity of the proposed iterative learning scheme is demonstrated through several experiments.
keywords: {Uncertainty;Stochastic processes;Robots;Torque;Cost function;Noise measurement;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462913&isnumber=8460178

Y. Jia and Y. Xue, "Dexterous Manipulation by Two Fingers with Coupled Joints," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3172-3179.
doi: 10.1109/ICRA.2018.8460531
Abstract: This paper studies dexterous manipulation in the plane by a two-fingered hand in the plane. The dynamics of each finger, which consists of two links with coupled joints, are derived based on Lagrangian mechanics. As an object is being manipulated, its orientation and the two independent joint angles of the hand constitute the state of the entire system. Contact kinematics, accounting for both stick and slip modes, are combined with dynamics to establish a dependence of the object's linear and angular accelerations on joint accelerations. This allows control of joint torques, under a proportional-derivative (PD) law, to move the object to a target position in a desired orientation.
keywords: {Acceleration;Kinematics;Task analysis;Thumb;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460531&isnumber=8460178

S. Stepputtis, Y. Yang and H. Ben Amor, "Extrinsic Dexterity Through Active Slip Control Using Deep Predictive Models," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3180-3185.
doi: 10.1109/ICRA.2018.8461055
Abstract: We present a machine learning methodology for actively controlling slip, in order to increase robot dexterity. Leveraging recent insights in deep learning, we propose a Deep Predictive Model that uses tactile sensor information to reason about slip and its future influence on the manipulated object. The obtained information is then used to precisely manipulate objects within a robot end-effector using external perturbations imposed by gravity or acceleration. We show in a set of experiments that this approach can be used to increase a robot's repertoire of motor skills.
keywords: {Grippers;Training;Robot sensing systems;Predictive models;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461055&isnumber=8460178

X. Du, M. H. Ang, S. Karaman and D. Rus, "A General Pipeline for 3D Detection of Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3194-3200.
doi: 10.1109/ICRA.2018.8461232
Abstract: Autonomous driving requires 3D perception of vehicles and other objects in the in environment. Much of the current methods support 2D vehicle detection. This paper proposes a flexible pipeline to adopt any 2D detection network and fuse it with a 3D point cloud to generate 3D information with minimum changes of the 2D detection networks. To identify the 3D box, an effective model fitting algorithm is developed based on generalised car models and score maps. A two-stage convolutional neural network (CNN) is proposed to refine the detected 3D box. This pipeline is tested on the KITTI dataset using two different 2D detection networks. The 3D detection results based on these two networks are similar, demonstrating the flexibility of the proposed pipeline. The results rank second among the 3D detection algorithms, indicating its competencies in 3D detection.
keywords: {Three-dimensional displays;Two dimensional displays;Automobiles;Pipelines;Solid modeling;Proposals;Laser radar},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461232&isnumber=8460178

M. Tanner, S. Săftescu, A. Bewley and P. Newman, "Meshed Up: Learnt Error Correction in 3D Reconstructions," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3201-3206.
doi: 10.1109/ICRA.2018.8460977
Abstract: Dense reconstructions often contain errors that prior work has so far minimised using high quality sensors and regularising the output. Nevertheless, errors still persist. This paper proposes a machine learning technique to identify errors in three dimensional (3D) meshes. Beyond simply identifying errors, our method quantifies both the magnitude and the direction of depth estimate errors when viewing the scene. This enables us to Improve the reconstruction accuracy. We train a suitably deep network architecture with two 3D meshes: a high-quality laser reconstruction, and a lower quality stereo image reconstruction. The network predicts the amount of error in the lower quality reconstruction with respect to the high-quality one, having only view the former through its input. We evaluate our approach by correcting two dimensional (2D) inverse-depth images extracted from the 3D model, and show that our method improves the quality of these depth reconstructions by up to a relative 10% RMSE.
keywords: {Image reconstruction;Feature extraction;Cameras;Three-dimensional displays;Lasers;Image color analysis;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460977&isnumber=8460178

R. Atienza, "Fast Disparity Estimation Using Dense Networks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3207-3212.
doi: 10.1109/ICRA.2018.8463172
Abstract: Disparity estimation is a difficult problem in stereo vision because the correspondence technique fails in images with textureless and repetitive regions. Recent body of work using deep convolutional neural networks (CNN) overcomes this problem with semantics. Most CNN implementations use an autoencoder method; stereo images are encoded, merged and finally decoded to predict the disparity map. In this paper, we present a CNN implementation inspired by dense networks to reduce the number of parameters. Furthermore, our approach takes into account semantic reasoning in disparity estimation. Our proposed network, called DenseMapNet, is compact, fast and can be trained end-to-end. DenseMapNet requires 290k parameters only and runs at 30Hz or faster on color stereo images in full resolution. Experimental results show that DenseMapNet accuracy is comparable with other significantly bigger CNN-based methods.
keywords: {Estimation;Two dimensional displays;Semantics;Image resolution;Three-dimensional displays;Cameras;Computer vision},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463172&isnumber=8460178

T. T. Pham, T. -T. Do, N. Sünderhauf and I. Reid, "SceneCut: Joint Geometric and Object Segmentation for Indoor Scenes," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3213-3220.
doi: 10.1109/ICRA.2018.8461108
Abstract: This paper presents SceneCut, a novel approach to jointly discover previously unseen objects and non-object surfaces using a single RGB-D image. SceneCut's joint reasoning over scene semantics and geometry allows a robot to detect and segment object instances in complex scenes where modern deep learning-based methods either fail to separate object instances, or fail to detect objects that were not seen during training. SceneCut automatically decomposes a scene into meaningful regions which either represent objects or scene surfaces. The decomposition is qualified by an unified energy function over objectness and geometric fitting. We show how this energy function can be optimized efficiently by utilizing hierarchical segmentation trees. Moreover, we leverage a pre-trained convolutional oriented boundary network to predict accurate boundaries from images, which are used to construct high-quality region hierarchies. We evaluate SceneCut on several different indoor environments, and the results show that SceneCut significantly outperforms all the existing methods.
keywords: {Image segmentation;Semantics;Silicon;Object segmentation;Robots;Training;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461108&isnumber=8460178

Y. Feldman and V. Indelman, "Bayesian Viewpoint-Dependent Robust Classification Under Model and Localization Uncertainty," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3221-3228.
doi: 10.1109/ICRA.2018.8461127
Abstract: We propose an algorithm for robust visual classification of an object of interest observed from multiple views using a black-box Bayesian classifier which provides a measure of uncertainty, in the presence of significant ambiguity and classifier noise, and of localization error. The fusion of classifier outputs takes into account viewpoint dependency and spatial correlation among observations, as well as pose uncertainty when these observations are taken and a measure of confidence provided by the classifier itself. Our experiments confirm an improvement in robustness over state-of-the-art.
keywords: {Uncertainty;Measurement uncertainty;Robots;Correlation;Bayes methods;Robustness;Training data},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461127&isnumber=8460178

W. J. Beksi and N. Papanikolopoulos, "Signature of Topologically Persistent Points for 3D Point Cloud Description," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3229-3234.
doi: 10.1109/ICRA.2018.8460605
Abstract: We present the Signature of Topologically Persistent Points (STPP), a global descriptor that encodes topological invariants of 3D point cloud data. These topological invariants include the zeroth and first homology groups and are computed using persistent homology, a method for finding the features of a topological space at different spatial resolutions. STPP is a competitive 3D point cloud descriptor when compared to the state of art and is resilient to noisy sensor data. We demonstrate experimentally on a publicly available RGB-D dataset that STPP can be used as a distinctive signature, thus allowing for 3D point cloud processing tasks such as object detection and classification.
keywords: {Three-dimensional displays;Shape;Robot sensing systems;Generators;Histograms;Topology;Face},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460605&isnumber=8460178

P. Marion, P. R. Florence, L. Manuelli and R. Tedrake, "Label Fusion: A Pipeline for Generating Ground Truth Labels for Real RGBD Data of Cluttered Scenes," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3235-3242.
doi: 10.1109/ICRA.2018.8460950
Abstract: Deep neural network (DNN) architectures have been shown to outperform traditional pipelines for object segmentation and pose estimation using RGBD data, but the performance of these DNN pipelines is directly tied to how representative the training data is of the true data. Hence a key requirement for employing these methods in practice is to have a large set of labeled data for your specific robotic manipulation task, a requirement that is not generally satisfied by existing datasets. In this paper we develop a pipeline to rapidly generate high quality RGBD data with pixelwise labels and object poses. We use an RGBD camera to collect video of a scene from multiple viewpoints and leverage existing reconstruction techniques to produce a 3D dense reconstruction. We label the 3D reconstruction using a human assisted ICP-fitting of object meshes. By reprojecting the results of labeling the 3D scene we can produce labels for each RGBD image of the scene. This pipeline enabled us to collect over 1,000,000 labeled object instances in just a few days. We use this dataset to answer questions related to how much training data is required, and of what quality the data must be, to achieve high performance from a DNN architecture. Our dataset and annotation pipeline are available at labelfusion.csail.mit.edu.
keywords: {Pipelines;Three-dimensional displays;Robot sensing systems;Image segmentation;Cameras;Image reconstruction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460950&isnumber=8460178

D. Miller, L. Nicholson, F. Dayoub and N. Sünderhauf, "Dropout Sampling for Robust Object Detection in Open-Set Conditions," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3243-3249.
doi: 10.1109/ICRA.2018.8460700
Abstract: Dropout Variational Inference, or Dropout Sampling, has been recently proposed as an approximation technique for Bayesian Deep Learning and evaluated for image classification and regression tasks. This paper investigates the utility of Dropout Sampling for object detection for the first time. We demonstrate how label uncertainty can be extracted from a state-of-the-art object detection system via Dropout Sampling. We evaluate this approach on a large synthetic dataset of 30,000 images, and a real-world dataset captured by a mobile robot in a versatile campus environment. We show that this uncertainty can be utilized to increase object detection performance under the open-set conditions that are typically encountered in robotic vision. A Dropout Sampling network is shown to achieve a 12.3 % increase in recall (for the same precision score as a standard network) and a 15.1 % increase in precision (for the same recall score as the standard network).
keywords: {Object detection;Uncertainty;Training;Bayes methods;Entropy;Task analysis;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460700&isnumber=8460178

T. Zhou and J. P. Wachs, "Early Turn-Taking Prediction with Spiking Neural Networks for Human Robot Collaboration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3250-3256.
doi: 10.1109/ICRA.2018.8461208
Abstract: Turn-taking is essential to the structure of human teamwork. Humans are typically aware of team members' intention to keep or relinquish their turn before a turn switch, where the responsibility of working on a shared task is shifted. Future co-robots are also expected to provide such competence. To that end, this paper proposes the Cognitive Turn-taking Model (CTTM), which leverages cognitive models (i.e., Spiking Neural Network) to achieve early turn-taking prediction. The CTTM framework can process multimodal human communication cues (both implicit and explicit) and predict human turn-taking intentions in an early stage. The proposed framework is tested on a simulated surgical procedure, where a robotic scrub nurse predicts the surgeon's turn-taking intention. It was found that the proposed CTTM framework outperforms the state-of-the-art turn-taking prediction algorithms by a large margin. It also outperforms humans when presented with partial observations of communication cues (i.e., less than 40 % of full actions). This early prediction capability enables robots to initiate turn-taking actions at an early stage, which facilitates collaboration and increases overall efficiency.
keywords: {Neurons;Robot kinematics;Task analysis;Training;Teamwork},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461208&isnumber=8460178

A. Bestick, R. Pandya, R. Bajcsy and A. D. Dragan, "Learning Human Ergonomic Preferences for Handovers," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3257-3264.
doi: 10.1109/ICRA.2018.8461216
Abstract: Our goal is for people to be physically comfortable when taking objects from robots. This puts a burden on the robot to hand over the object in such a way that a person can easily reach it, without needing to strain or twist their arm - a way that is conducive to ergonomic human grasping configurations. To achieve this, the robot needs to understand what makes a configuration more or less ergonomic to the person, i.e. their ergonomic cost function. In this work, we formulate learning a person's ergonomic cost as an online estimation problem. The robot can implicitly make queries to the person by handing them objects in different configurations, and gets observations in response about the way they choose to take the object. We compare the performance of both passive and active approaches for solving this problem in simulation, as well as in an in-person user study.
keywords: {Ergonomics;Handover;Cost function;Training;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461216&isnumber=8460178

G. Canal, E. Pignat, G. Alenyà, S. Calinon and C. Torras, "Joining High-Level Symbolic Planning with Low-Level Motion Primitives in Adaptive HRI: Application to Dressing Assistance," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3273-3278.
doi: 10.1109/ICRA.2018.8460606
Abstract: For a safe and successful daily living assistance, far from the highly controlled environment of a factory, robots should be able to adapt to ever-changing situations. Programming such a robot is a tedious process that requires expert knowledge. An alternative is to rely on a high-level planner, but the generic symbolic representations used are not well suited to particular robot executions. Contrarily, motion primitives encode robot motions in a way that can be easily adapted to different situations. This paper presents a combined framework that exploits the advantages of both approaches. The number of required symbolic states is reduced, as motion primitives provide “smart actions” that take the current state and cope online with variations. Symbolic actions can include interactions (e.g., ask and inform) that are difficult to demonstrate. We show that the proposed framework can adapt to the user preferences (in terms of robot speed and robot verbosity), can readjust the trajectories based on the user movements, and can handle unforeseen situations. Experiments are performed in a shoe-dressing scenario. This scenario is particularly interesting because it involves a sufficient number of actions, and the human-robot interaction requires the handling of user preferences and unexpected reactions.
keywords: {Task analysis;Planning;Robot sensing systems;Footwear;Foot;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460606&isnumber=8460178

C. Talignani Landi, F. Ferraguti, C. Fantuzzi and C. Secchi, "A Passivity-Based Strategy for Coaching in Human-Robot Interaction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3279-3284.
doi: 10.1109/ICRA.2018.8460836
Abstract: In order to make robot programming more easy and immediate, walk-through programming techniques can be exploited. However, a modification of a portion of the trajectory usually means to execute the path from the beginning. In this paper we propose a passivity-based framework to modify the trajectory online, manually driving the robot throughout the desired correction. The system follows the initial trajectory, encoded with Dynamical Movement Primitives, by setting high gains in the admittance control. When the human operator grabs the end-effector, the robot becomes compliant and the user can easily teach the desired correction, until he/she releases it at the end of the modification. Finally, the correction is optimally joined to the initial trajectory, restarting the path tracking. To avoid unsafe behaviors, the variation of the admittance parameters is performed exploiting energy tanks, in order to preserve the passivity of the interaction.
keywords: {Trajectory;Admittance;Service robots;Robot sensing systems;Hidden Markov models;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460836&isnumber=8460178

J. M. Friesen, J. L. Dean, T. Bewley and V. Sunspiral, "A Tensegrity-Inspired Compliant 3-DOF Compliant Joint," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3301-3306.
doi: 10.1109/ICRA.2018.8460593
Abstract: Our Tensegrity-Inspired Compliant Three degree-of-freedom (DOF) robotic joint adds omnidirectional compliance to robotic limbs while reducing sprung mass through base mounted actuation. This enables a robotic limb which is safer to operate alongside humans and fragile equipment while still capable of generating quick movements and large forces if required. Unlike many other soft robotic systems which leverage continuously soft materials, our joint is simpler to model with low order dynamic systems and has a host of embedded sensing which provide ample information of its position and velocity. We first discuss geometry selection and optimization to maximize the theoretical configuration space of the joint. We then show several of our mechatronic design solutions, which are easily generalized to a multitude of cable-driven mechanisms, and demonstrate the performance of these mechanisms within the context of our hardware prototype. We then present results on the controllable stiffness of our physical prototype. Finally, we demonstrate the strength of our prototype which is capable of lifting a 7 kg mass at a distance of 0.95 meters from the joint.
keywords: {Robot kinematics;Robot sensing systems;Geometry;Force;Topology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460593&isnumber=8460178

Q. Bateux, E. Marchand, J. Leitner, F. Chaumette and P. Corke, "Training Deep Neural Networks for Visual Servoing," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3307-3314.
doi: 10.1109/ICRA.2018.8461068
Abstract: We present a deep neural network-based method to perform high-precision, robust and real-time 6 DOF positioning tasks by visual servoing. A convolutional neural network is fine-tuned to estimate the relative pose between the current and desired images and a pose-based visual servoing control law is considered to reach the desired pose. The paper describes how to efficiently and automatically create a dataset used to train the network. We show that this enables the robust handling of various perturbations (occlusions and lighting variations). We then propose the training of a scene-agnostic network by feeding in both the desired and current images into a deep network. The method is validated on a 6 DOF robot.
keywords: {Training;Robots;Feature extraction;Task analysis;Cameras;Voltage control;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461068&isnumber=8460178

T. Aykut, C. Zou, J. Xu, D. Van Opdenbosch and E. Steinbach, "A Delay Compensation Approach for Pan-Tilt-Unit-based Stereoscopic 360 Degree Telepresence Systems Using Head Motion Prediction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3323-3330.
doi: 10.1109/ICRA.2018.8460750
Abstract: The acceptance of teleoperation applications like tele-driving, tele-surgery, tele-maintenance, etc., is challenged by the quality-reducing effect of end-to-end latency. Particularly, when users wear Head-Mounted Displays to enhance the immersive experience, the lag between head motion and display response leads to unbearable motion sickness, indisposition, and, in the worst case, abortion of the teleoperation session. In this paper, we propose a delay compensation approach with head motion prediction that can be applied to pan-tilt-unit-based stereoscopic telepresence systems. We provide the user with the impression of a 3D 360° video that represents the remote scene without noticing the present delay, even when rotating the head. To this end, we propose a novel prediction paradigm for head motion estimation to substantially mitigate the negative impact of the latency on the quality of experience. We re-implemented state-of-the-art head movement predictors and compare them to our proposed approach by means of qualitative measures. In our experiments, we used two real and independent head motion datasets for validation and tested communication delays between 100-1000ms. Our results show that mean compensation rates of more than 99% are able with our approach.
keywords: {Delays;Head;Cameras;Stereo image processing;Three-dimensional displays;Visualization;Resists},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460750&isnumber=8460178

C. Mitash, A. Boularias and K. E. Bekris, "Improving 6D Pose Estimation of Objects in Clutter Via Physics-Aware Monte Carlo Tree Search," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3331-3338.
doi: 10.1109/ICRA.2018.8461163
Abstract: This work proposes a process for efficiently searching over combinations of individual object 6D pose hypotheses in cluttered scenes, especially in cases involving occlusions and objects resting on each other. The initial set of candidate object poses is generated from state-of-the-art object detection and global point cloud registration techniques. The best scored pose per object by using these techniques may not be accurate due to overlaps and occlusions. Nevertheless, experimental indications provided in this work show that object poses with lower ranks may be closer to the real poses than ones with high ranks according to registration techniques. This motivates a global optimization process for improving these poses by taking into account scene-level physical interactions between objects. It also implies that the Cartesian product of candidate poses for interacting objects must be searched so as to identify the best scene-level hypothesis. To perform the search efficiently, the candidate poses for each object are clustered so as to reduce their number but still keep a sufficient diversity. Then, searching over the combinations of candidate object poses is performed through a Monte Carlo Tree Search (MCTS) process that uses the similarity between the observed depth image of the scene and a rendering of the scene given the hypothesized pose as a score that guides the search procedure. MCTS handles in a principled way the tradeoff between fine-tuning the most promising poses and exploring new ones, by using the Upper Confidence Bound (UCB) technique. Experimental results indicate that this process is able to quickly identify in cluttered scenes physically-consistent object poses that are significantly closer to ground truth compared to poses found by point cloud registration methods.
keywords: {Search problems;Three-dimensional displays;Solid modeling;Pose estimation;Computational modeling;Training;Image segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461163&isnumber=8460178

A. Byravan, F. Leeb, F. Meier and D. Fox, "SE3-Pose-Nets: Structured Deep Dynamics Models for Visuomotor Control," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3339-3346.
doi: 10.1109/ICRA.2018.8461184
Abstract: In this work, we present an approach to deep visuomotor control using structured deep dynamics models. Our model, a variant of SE3-Nets, learns a low-dimensional pose embedding for visuomotor control via an encoder-decoder structure. Unlike prior work, our model is structured: given an input scene, our network explicitly learns to segment salient parts and predict their pose embedding and motion, modeled as a change in the pose due to the applied actions. We train our model using a pair of point clouds separated by an action and show that given supervision only through point-wise data associations between the frames our network is able to learn a meaningful segmentation of the scene along with consistent poses. We further show that our model can be used for closed-loop control directly in the learned low-dimensional pose space, where the actions are computed by minimizing pose error using gradient-based methods, similar to traditional model-based control. We present results on controlling a Baxter robot from raw depth data in simulation and RGBD data in the real world and compare against two baseline deep networks. We also test the robustness and generalization performance of our controller under changes in camera pose, lighting, occlusion, and motion. Our method is robust, runs in real-time, achieves good prediction of scene dynamics, and outperforms baselines on multiple control runs. Video results can be found at: https://rse-lab.cs.washington.edu/se3-structured-deep-ctrl/.
keywords: {Three-dimensional displays;Predictive models;Transforms;Computational modeling;Data models;Aerospace electronics;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461184&isnumber=8460178

M. Schwarz et al., "Fast Object Learning and Dual-arm Coordination for Cluttered Stowing, Picking, and Packing," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3347-3354.
doi: 10.1109/ICRA.2018.8461195
Abstract: Robotic picking from cluttered bins is a demanding task, for which Amazon Robotics holds challenges. The 2017 Amazon Robotics Challenge (ARC) required stowing items into a storage system, picking specific items, and packing them into boxes. In this paper, we describe the entry of team NimbRo Picking. Our deep object perception pipeline can be quickly and efficiently adapted to new items using a custom turntable capture system and transfer learning. It produces high-quality item segments, on which grasp poses are found. A planning component coordinates manipulation actions between two robot arms, minimizing execution time. The system has been demonstrated successfully at ARC, where our team reached second places in both the picking task and the final stow-and-pick task. We also evaluate individual components.
keywords: {Task analysis;Training;Robot kinematics;Pipelines;Robot sensing systems;Semantics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461195&isnumber=8460178

J. L. Molnar, C. Cheng, L. O. Tiziani, B. Boots and F. L. Hammond, "Optical Sensing and Control Methods for Soft Pneumatically Actuated Robotic Manipulators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3355-3362.
doi: 10.1109/ICRA.2018.8461110
Abstract: A low-cost optical sensing method for improved measurement and control of soft pneumatic manipulator motion is presented. The core of a soft continuum robot is embedded with several optically-diffuse elastomer sensors which attenuate light depending on their strain mode and degree. The optical sensors measure local strains at the robot's axial center, and these strain data are combined with measured actuator chamber pressures to determine the pose of the robot under various gravitational and tip loading conditions. Regression analyses using neural networks (NNs) demonstrate that when the soft continuum robot's base orientation is fixed, the position of its end-effector can be estimated with 3.42 times more accuracy (71 % smaller root mean squared error) when using both optical sensor and pressure data (~2.44mm) than when using only pressure data (~8.3mm). When the robot's base orientation was varied, the combined optical sensor and pressure data provide position estimates which are as much as 37.8 times more accurate (~2.76mm) than pressure data alone (~104mm).
keywords: {Robot sensing systems;Optical fiber sensors;Optical fibers;Pneumatic systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461110&isnumber=8460178

F. Brickwedde, S. Abraham and R. Mester, "Mono-Stixels: Monocular Depth Reconstruction of Dynamic Street Scenes," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3369-3375.
doi: 10.1109/ICRA.2018.8460490
Abstract: In this paper we present mono-stixels, a compact environment representation specially designed for dynamic street scenes. Mono-stixels are a novel approach to estimate stixels from a monocular camera sequence instead of the traditionally used stereo depth measurements. Our approach jointly infers the depth, motion and semantic information of the dynamic scene as a 1D energy minimization problem based on optical flow estimates, pixel-wise semantic segmentation and camera motion. The optical flow of a stixel is described by a homography. By applying the mono-stixel model the degrees of freedom of a stixel-homography are reduced to only up to two degrees of freedom. Furthermore, we exploit a scene model and semantic information to handle moving objects. In our experiments we use the public available DeepFlow for optical flow estimation and FCN8s for the semantic information as inputs and show on the KITTI 2015 dataset that mono-stixels provide a compact and reliable depth reconstruction of both the static and moving parts of the scene. Thereby, mono-stixels overcome the limitation to static scenes of previous structure-from-motion approaches.
keywords: {Semantics;Cameras;Optical imaging;Vehicle dynamics;Estimation;Dynamics;Motion segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460490&isnumber=8460178

A. Fregin, J. Muller, U. Krebel and K. Dietmayer, "The DriveU Traffic Light Dataset: Introduction and Comparison with Existing Datasets," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3376-3383.
doi: 10.1109/ICRA.2018.8460737
Abstract: Autonomous driving is a topic in computer vision which has captured a great deal of attention in recent years. One key problem is the detection and state analysis of traffic lights. Even over time, very few datasets for research in this topic have been published and they vary widely in quantity and in quality. To address the complexity of traffic light recognition, we introduce the DriveU**driveU is a joint innovation center of the Daimler AG and the University of Ulm Traffic Light Dataset (DTLD), a large-scale dataset consisting of more than 230,000 annotations. All annotations are hand-labeled according to strict rules and show a high quality. Recordings were made in eleven different cities during different weather conditions. Our dataset exceeds previous traffic light datasets in size, variance, annotation quality and amount of additional sensor data. We prove the extent of our dataset by an extensive comparison with existing traffic light datasets. Miscellaneous dataset criteria are compared, illustrated and statistically analyzed. In the process, metrics to express the quality and variance of datasets are developed and verified. The dataset can be downloaded from http://traffic-light-data.de.
keywords: {Cameras;Urban areas;Benchmark testing;Lenses;Training;Visualization;Detectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460737&isnumber=8460178

D. S. González, O. Erkent, V. Romero-Cano, J. Dibangoye and C. Laugier, "Modeling Driver Behavior from Demonstrations in Dynamic Environments Using Spatiotemporal Lattices," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3384-3390.
doi: 10.1109/ICRA.2018.8460208
Abstract: One of the most challenging tasks in the development of path planners for intelligent vehicles is the design of the cost function that models the desired behavior of the vehicle. While this task has been traditionally accomplished by hand-tuning the model parameters, recent approaches propose to learn the model automatically from demonstrated driving data using Inverse Reinforcement Learning (IRL). To determine if the model has correctly captured the demonstrated behavior, most IRL methods require obtaining a policy by solving the forward control problem repetitively. Calculating the full policy is a costly task in continuous or large domains and thus often approximated by finding a single trajectory using traditional path-planning techniques. In this work, we propose to find such a trajectory using a conformal spatiotemporal state lattice, which offers two main advantages. First, by conforming the lattice to the environment, the search is focused only on feasible motions for the robot, saving computational power. And second, by considering time as part of the state, the trajectory is optimized with respect to the motion of the dynamic obstacles in the scene. As a consequence, the resulting trajectory can be used for the model assessment. We show how the proposed IRL framework can successfully handle highly dynamic environments by modeling the highway tactical driving task from demonstrated driving data gathered with an instrumented vehicle.
keywords: {Trajectory;Lattices;Task analysis;Spatiotemporal phenomena;Vehicle dynamics;Learning (artificial intelligence);Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460208&isnumber=8460178

E. Schmerling, K. Leung, W. Vollprecht and M. Pavone, "Multimodal Probabilistic Model-Based Planning for Human-Robot Interaction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3399-3406.
doi: 10.1109/ICRA.2018.8460766
Abstract: This paper presents a method for constructing human-robot interaction policies in settings where multimodality, i.e., the possibility of multiple highly distinct futures, plays a critical role in decision making. We are motivated in this work by the example of traffic weaving, e.g., at highway on-ramps/off-ramps, where entering and exiting cars must swap lanes in a short distance-a challenging negotiation even for experienced drivers due to the inherent multimodal uncertainty of who will pass whom. Our approach is to learn multimodal probability distributions over future human actions from a dataset of human-human exemplars and perform real-time robot policy construction in the resulting environment model through massively parallel sampling of human responses to candidate robot action sequences. Direct learning of these distributions is made possible by recent advances in the theory of conditional variational autoencoders (CVAEs), whereby we learn action distributions simultaneously conditioned on the present interaction history, as well as candidate future robot actions in order to take into account response dynamics. We demonstrate the efficacy of this approach with a human-in-the-loop simulation of a traffic weaving scenario.
keywords: {Robots;Vehicles;Predictive models;History;Cognition;Probabilistic logic;Weaving},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460766&isnumber=8460178

A. L. Pavlov, G. W. Ovchinnikov, D. Y. Derbyshev, D. Tsetserukou and I. V. Oseledets, "AA-ICP: Iterative Closest Point with Anderson Acceleration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3407-3412.
doi: 10.1109/ICRA.2018.8461063
Abstract: Iterative Closest Point (ICP) is a widely used method for performing scan-matching and registration. Being simple and robust, this method is still computationally expensive and may be challenging to use in real-time applications with limited resources on mobile platforms. In this paper we propose a novel effective method for acceleration of ICP which does not require substantial modifications to the existing code. This method is based on an idea of Anderson acceleration which is an iterative procedure for finding a fixed point of contractive mapping. The latter is often faster than a standard Picard iteration, usually used in ICP implementations. We show that ICP, being a fixed point problem, can be significantly accelerated by this method enhanced by heuristics to improve overall robustness. We implement proposed approach into Point Cloud Library (PCL) and make it available online. Benchmarking on the real-world data fully supports our claims.
keywords: {Iterative closest point algorithm;Acceleration;History;Convergence;Three-dimensional displays;Robots;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461063&isnumber=8460178

N. Mehta, J. R. McBride and G. Pandey, "Robust and Fast 3D Scan Alignment Using Mutual Information," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3413-3420.
doi: 10.1109/ICRA.2018.8460716
Abstract: This paper presents a mutual information (MI) based algorithm for the estimation of full 6-degree-of-freedom (DOF) rigid body transformation between two overlapping point clouds. We first divide the scene into a 3D voxel grid and define simple to compute features for each voxel in the scan. The two scans that need to be aligned are considered as a collection of these features and the MI between these voxelized features is maximized to obtain the correct alignment of scans. We have implemented our method with various simple point cloud features (such as number of points in voxel, variance of z-height in voxel) and compared the performance of the proposed method with existing point-to-point and point-to-distribution registration methods. We show that our approach has an efficient and fast parallel implementation on GPU, and evaluate the robustness and speed of the proposed algorithm on two real-world datasets which have variety of dynamic scenes from different environments.
keywords: {Three-dimensional displays;Mutual information;Robustness;Histograms;Iterative closest point algorithm;Optimization;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460716&isnumber=8460178

H. Kataoka, T. Suzuki, S. Oikawa, Y. Matsui and Y. Satoh, "Drive Video Analysis for the Detection of Traffic Near-Miss Incidents," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3421-3428.
doi: 10.1109/ICRA.2018.8460812
Abstract: Because of their recent introduction, self-driving cars and advanced driver assistance system (ADAS) equipped vehicles have had little opportunity to learn, the dangerous traffic (including near-miss incident) scenarios that provide normal drivers with strong motivation to drive safely. Accordingly, as a means of providing learning depth, this paper presents a novel traffic database that contains information on a large number of traffic near-miss incidents that were obtained by mounting driving recorders in more than 100 taxis over the course of a decade. The study makes the following two main contributions: (i) In order to assist automated systems in detecting near-miss incidents based on database instances, we created a large-scale traffic near-miss incident database (NIDB) that consists of video clip of dangerous events captured by monocular driving recorders. (ii) To illustrate the applicability of NIDB traffic near-miss incidents, we provide two primary database-related improvements: parameter fine-tuning using various near-miss scenes from NIDB, and foreground/background separation into motion representation. Then, using our new database in conjunction with a monocular driving recorder, we developed a near-miss recognition method that provides automated systems with a performance level that is comparable to a human-level understanding of near-miss incidents (64.5% vs. 68.4% at near-miss recognition, 61.3% vs. 78.7% at near-miss detection).
keywords: {Databases;Vehicles;Autonomous automobiles;Semantics;Advanced driver assistance systems;Public transportation;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460812&isnumber=8460178

F. Berlinger, M. Duduta, H. Gloria, D. Clarke, R. Nagpal and R. Wood, "A Modular Dielectric Elastomer Actuator to Drive Miniature Autonomous Underwater Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3429-3435.
doi: 10.1109/ICRA.2018.8461217
Abstract: In this paper we present the design of a fin-like dielectric elastomer actuator (DEA) that drives a miniature autonomous underwater vehicle (AUV). The fin-like actuator is modular and independent of the body of the AUV. All electronics required to run the actuator are inside the 100 mm long 3D-printed body, allowing for autonomous mobility of the AUV. The DEA is easy to manufacture, requires no pre-stretch of the elastomers, and is completely sealed for underwater operation. The output thrust force can be tuned by stacking multiple actuation layers and modifying the Young's modulus of the elastomers. The AUV is reconfigurable by a shift of its center of mass, such that both planar and vertical swimming can be demonstrated on a single vehicle. For the DEA we measured thrust force and swimming speed for various actuator designs ran at frequencies from 1 Hz to 5 Hz. For the AUV we demonstrated autonomous planar swimming and closed-loop vertical diving. The actuators capable of outputting the highest thrust forces can power the AUV to swim at speeds of up to 0.55 body lengths per second. The speed falls in the upper range of untethered swimming robots powered by soft actuators. Our tunable DEAs also demonstrate the potential to mimic the undulatory motions of fish fins.
keywords: {Aquatic robots;Power supplies;Propulsion;Dielectric elastomer actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461217&isnumber=8460178

F. Ruscelli, G. Sartoretti, J. Nan, Z. Feng, M. Travers and H. Choset, "Proprioceptive-Inertial Autonomous Locomotion for Articulated Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3436-3441.
doi: 10.1109/ICRA.2018.8460584
Abstract: Inspired by the ability of animals to rely on proprioception and vestibular feedback to adapt their gait, we propose a modular framework for autonomous locomotion that relies on force sensing and inertial information. A first controller exploits anti-compliance, a new application of positive force feedback, to quickly react against obstacles upon impact. We hypothesize that, in situations where a robot experiences occasional impacts with the environment, anti-compliance can help negotiate unknown obstacles, similar to biological systems where positive feedback enables fast responses to external stimuli. A novel parallel controller, based on a bi-stable dynamical system, continuously adjusts the robot's direction of locomotion, and reverts it in reaction to major swerves. We present experimental results, demonstrating how our framework allows a snake robot to autonomously locomote through a row of unevenly-spaced obstacles. Finally, we extend our proprioceptive controller to legged locomotion, showing how a hexaprint robot can adapt its motion to climb over obstacles.
keywords: {Shape;Robot sensing systems;Snake robots;Legged locomotion;Force feedback;Robot motion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460584&isnumber=8460178

M. Ohradzansky, H. E. Alvarez, J. Keshavan, B. N. Ranganathan and J. S. Humbert, "Autonomous Bio-Inspired Small-Object Detection and Avoidance," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3442-3447.
doi: 10.1109/ICRA.2018.8461156
Abstract: Small-object detection and avoidance in unknown environments is a significant challenge to overcome for small autonomous vehicles that are generally highly agile and restricted in payload and computational processing power. Typical machine-vision and range measurement based solutions suffer either from restricted fields-of-view or significant computational complexity and are not easily portable to small platforms. In this paper, a novel bio-inspired navigation technique is introduced that is modeled using analogues of the small-field motion-sensitive interneurons of the insect visuomotor system. The proposed technique achieves small-field object detection based on Fourier residual analysis of instantaneous optic flow. The small field signal is used to extract relative range and bearing of the nearest obstacle, which is then combined with an artificial potential function-based low-order steering control law. The proposed sensing and control scheme is experimentally validated with a quadrotor vehicle that is able to effectively navigate an unknown environment laden with small-field clutter. This bio-inspired approach is computationally efficient and serves as a robust, reflexive solution to the problem of small-object detection and avoidance for autonomous robots.
keywords: {Optical sensors;Optical imaging;Navigation;Biomedical optical imaging;Insects;Neurons},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461156&isnumber=8460178

R. Xie, M. Su, Y. Zhang, M. Li, H. Zhu and Y. Guan, "PISRob: A Pneumatic Soft Robot for Locomoting Like an Inchworm," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3448-3453.
doi: 10.1109/ICRA.2018.8461189
Abstract: Climbing or crawling robots may be widely applied in agriculture, forestry, military, construction industry, disaster searching and rescuing, and so on. Soft robots possess better safety, flexibility, dexterity, portability, and adaption to complex environments than traditional robots. However, there are big challenges in system development, modeling and control of soft climbing robots. To address system development of a soft robot as a new type climbing robot, we present a pneumatic soft robot capable of inchworm-like locomotion, PISRob. The presented robot is composed of three soft parts in H-shaped configuration. Each part is able to perform 2D bending. While the middle part, as the main body, can bend in Ω -shape for actuation, the two end parts as legs can conduct simple bending motion for grasping or anchoring during locomotion. The system design and fabrication process of the soft robot is presented in details in this paper. A control system is developed for pneumatic actuation of the robot. Tests are carried out to get the relationship between the actuating air pressure and the step length in locomotion. Experiments of crawling on a floor and climbing on a pole are performed to verify the feasibility of development of the new soft robot and the effectiveness of the control method for the pneumatic system.
keywords: {Legged locomotion;Soft robotics;Pneumatic systems;Strain;Fabrication;Glass},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461189&isnumber=8460178

E. Del Dottore, A. Sadeghi, A. Mondini and B. Mazzolai, "Continuous Growth in Plant-Inspired Robots Through 3D Additive Manufacturing," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3454-3460.
doi: 10.1109/ICRA.2018.8460616
Abstract: This paper presents a new material deposition strategy for developing a growing robot capable of building its own body. The growing robot is inspired by plant growth and is based on a 3D printer-like mechanism. The plotting of a filament near the tip allows the forward movement of the robot and results in building a tubular body. A material deposition process is introduced to perform a straight continuous growth as well as a turning behavior in order to permit the navigation of the robot in the environment. Bending is achieved by controlling the filament height in each position of the plotting, lowering or increasing plotting velocity with a position PID control algorithm. We demonstrate that the continuous deposition of the filament allows to obtain homogeneous and robust structures, with a significant improvement of the robot's performance compared to our previous version of the system (i.e., more than 100 N pulling force and 200 N shear force). The current version of the robot can sustain its weight, move efficiently by growing in the environment - both air and soil - and penetrate hard medium (up to 60kPa).
keywords: {Magnetic heads;Force;Robot sensing systems;Soil;Wires;Fingers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460616&isnumber=8460178

H. Lu, F. Xue, W. Wan and Y. Shen, "Investigation of Scaling Effect of Copper Microwire Based on in-Situ Nanorobotic Twisting Inside SEM," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3461-3466.
doi: 10.1109/ICRA.2018.8460573
Abstract: Copper microwire is an essential metal widely used in micro-electron mechanical systems. Since micro/nano material usually demonstrates unique mechanical properties due to scaling effect, copper microwire mechanical properties need to be investigated for better adhibition. Herein, we propose a nanorobotics manipulation system for copper microwire insitu twisting test. Firstly, a system with six degree-of-freedoms (DOFs) nanorobotic manipulator integrated inside scanning electron microscope (SEM) is introduced. Secondly, a positioning and assembly method for copper microwire specimen are proposed to solve the mismatching problem. Finally, the copper microwire is twisted in-situ and its properties are investigated and analyzed. The copper microwire sample fracture morphology shows a severe plastic deformation and being along with the emergence of deformation twin and intertwine, which exhibit strong scaling effects. This system provides a new method for in-situ twisting test, which paves the way for mechanical characterization inside SEM and benefits the fundamental nanomaterial research immensely.
keywords: {Copper;Scanning electron microscopy;Manipulators;Mechanical factors;Calibration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460573&isnumber=8460178

S. Mathiesen, L. CarØe SØrensen, D. Kraft and L. Ellekilde, "Optimisation of Trap Design for Vibratory Bowl Feeders," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3467-3474.
doi: 10.1109/ICRA.2018.8460767
Abstract: Vibratory bowl feeders (VBFs) are a widely used option for industrial part feeding, but their design is still largely manual. A subtask of VBF design is determining an optimal parameter set for the passive devices, called traps, which the VBF uses to ensure correct part orientation. This paper proposes a fast and robust strategy for optimising traps, which makes use of dynamic simulation to efficiently evaluate the performance of parameter sets. The optimisation strategy is based on Bayesian Optimisation and selects new parameter sets to evaluate, using a modified Upper Confidence Bound with regression by Kernel Density Estimation as function estimator. The optimisation is run for four different traps with an industrial part and the best parameter sets are tested for robustness in simulation. The traps are then combined to create two sequences performing orientation of the parts and the designs are prototyped and tested on a real VBF.
keywords: {Optimization;Bayes methods;Task analysis;Vibrations;Shape;Manuals;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460767&isnumber=8460178

R. Ueda, M. Kato, A. Saito and R. Okazaki, "Teach-and-Replay of Mobile Robot with Particle Filter on Episode," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3475-3481.
doi: 10.1109/ICRA.2018.8461235
Abstract: A novel method for replaying behavior of a mobile robot from its memory of past experiences is presented in this paper. The method is a version of a particle filter on episode (PFoE), which applies a particle filter on the memory so as to efficiently find some similar situations with the current one. Though the original PFoE was proposed as a reinforcement learning method, we once removed the reward system from the original one so as to apply it to task teaching. In the experiment, we gave several kinds of motion to a micromouse type robot with the proposed method through a gamepad. The robot replayed the behaviors robustly with sensor feedback after several number of repetitive teaching.
keywords: {Robot sensing systems;Robot kinematics;Education;Hidden Markov models;Mobile robots;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461235&isnumber=8460178

X. Li, X. Su, Y. Gao and Y. -H. Liu, "Vision-Based Robotic Grasping and Manipulation of USB Wires," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3482-3487.
doi: 10.1109/ICRA.2018.8460694
Abstract: The fast expanding 3C (Computer, Communication, and Consumer electronics) manufacturing leads to a high demand on the fabrication of USB cables. While several commercial machines have been developed to automate the process of stripping and soldering of USB cables, the operation of manipulating USB wires according to the color code is heavily dependent on manual works because of the deformation property of wires, probably resulting in the falling-off or the escape of wires during manipulation. In this paper, a new vision-based controller is proposed for robotic grasping and manipulation of USB wires. A novel two-level structure is developed and embedded into the controller, where Level-I is referred to as the grasping and manipulation of wires, and Level-II is referred to as the wire alignment by following the USB color code. The proposed formulation allows the robot to automatically grasp, manipulate, and align the wires in a sequential, simultaneous, and smooth manner, and hence to deal with the deformation of wires. The dynamic stability of the closed-loop system is rigorously proved with Lyapunov methods, and experiments are performed to validate the proposed controller.
keywords: {Wires;Universal Serial Bus;Robots;Grasping;Grippers;Strain;Image color analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460694&isnumber=8460178

L. Fang, H. Chen, Y. Lou, Y. Li and Y. Liu, "Visual Grasping for a Lightweight Aerial Manipulator Based on NSGA-II and Kinematic Compensation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3488-3493.
doi: 10.1109/ICRA.2018.8460520
Abstract: The grasping control of an aerial manipulator in practical environments is challenging due to its complex kinematics/dynamics and motion constraints. This paper introduces a lightweight aerial manipulator, which is combined with an X8 coaxial octocopter and a 4-DoF manipulator. To address the grasping control problem, we develop an efficient scheme containing trajectory generation, visual trajectory tracking, and kinematic compensation. The NSGA-II method is utilized to implement the multiobjective optimization for trajectory planning. Motion constraints and collision avoidance are also considered in the optimization. A kinematic compensation-based visual trajectory tracking is introduced to address the coupled nature between manipulator and VAV body. No dynamic parameter calibration is needed. Finally, several experiments are performed to verify the stability and feasibility of the proposed approach.
keywords: {Manipulator dynamics;Trajectory;Grasping;Kinematics;Acceleration;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460520&isnumber=8460178

A. Ošep, W. Mehner, P. Voigtlaender and B. Leibe, "Track, Then Decide: Category-Agnostic Vision-Based Multi-Object Tracking," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3494-3501.
doi: 10.1109/ICRA.2018.8460975
Abstract: The most common paradigm for vision-based multi-object tracking is tracking-by-detection, due to the availability of reliable detectors for several important object categories such as cars and pedestrians. However, future mobile systems will need a capability to cope with rich human-made environments, in which obtaining detectors for every possible object category would be infeasible. In this paper, we address the problem of class-agnostic multi-object tracking using generic object proposals. We present an efficient segmentation mask-based tracker which associates pixel-precise masks reported by the segmentation. Our approach can utilize semantic information whenever it is available for classifying objects at the track level, while retaining the capability to track generic unknown objects in the absence of such information. We demonstrate experimentally that our approach achieves performance comparable to state-of-the-art tracking-by-detection methods for popular object categories such as cars and pedestrians. Additionally, we show that the proposed method can discover and robustly track a large variety of other objects.
keywords: {Proposals;Three-dimensional displays;Tracking;Laser radar;Semantics;Detectors;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460975&isnumber=8460178

A. Ribacki, V. A. M. Jorge, M. Mantelli, R. Maffei and E. Prestes, "Vision-Based Global Localization Using Ceiling Space Density," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3502-3507.
doi: 10.1109/ICRA.2018.8460515
Abstract: Service robots are becoming a reality across homes. Still, the range of applications supported by such robots remains tied to their ability to self-localize in the environment. Man-made constructions often have a documented blueprint which can be used as input information for robot localization and smart home applications. However, home environments commonly include movable objects and furniture, which can make localization a complicated task, especially for forward-facing horizontal range-finders. In this paper, we present a new and effective global localization approach for home environments which adapts the notion of free space density to a camera pointing to the ceiling. We exploit the available blueprint information, as well as evidence that ceiling vision can provide robust localization information, even in the presence of occlusions. We perform real-world experiments using a robotic vacuum cleaner equipped with an upward-facing camera in two different apartments across multiple trajectories and compare the proposed method with competing approaches. Our solution shows superior localization results using maps where neither furniture or movable objects are not modeled.
keywords: {Cameras;Kernel;Three-dimensional displays;Robot vision systems;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460515&isnumber=8460178

S. Sharma, J. A. Ansari, J. Krishna Murthy and K. Madhava Krishna, "Beyond Pixels: Leveraging Geometry and Shape Cues for Online Multi-Object Tracking," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3508-3515.
doi: 10.1109/ICRA.2018.8461018
Abstract: This paper introduces geometry and object shape and pose costs for multi-object tracking in urban driving scenarios. Using images from a monocular camera alone, we devise pairwise costs for object tracks, based on several 3D cues such as object pose, shape, and motion. The proposed costs are agnostic to the data association method and can be incorporated into any optimization framework to output the pairwise data associations. These costs are easy to implement, can be computed in real-time, and complement each other to account for possible errors in a tracking-by-detection framework. We perform an extensive analysis of the designed costs and empirically demonstrate consistent improvement over the state-of-the-art under varying conditions that employ a range of object detectors, exhibit a variety in camera and object motions, and, more importantly, are not reliant on the choice of the association framework. We also show that, by using the simplest of associations frameworks (two-frame Hungarian assignment), we surpass the state-of-the-art in multi-object-tracking on road scenes. More qualitative and quantitative results can be found at https://junaidcs032.github.io/Geometry_ObjectShape_MOT/.
keywords: {Three-dimensional displays;Shape;Target tracking;Roads;Trajectory;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461018&isnumber=8460178

K. Fang, Y. Bai, S. Hinterstoisser, S. Savarese and M. Kalakrishnan, "Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from Simulation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3516-3523.
doi: 10.1109/ICRA.2018.8461041
Abstract: Learning-based approaches to robotic manipulation are limited by the scalability of data collection and accessibility of labels. In this paper, we present a multi-task domain adaptation framework for instance grasping in cluttered scenes by utilizing simulated robot experiments. Our neural network takes monocular RGB images and the instance segmentation mask of a specified target object as inputs, and predicts the probability of successfully grasping the specified object for each candidate motor command. The proposed transfer learning framework trains a model for instance grasping in simulation and uses a domain-adversarial loss to transfer the trained model to real robots using indiscriminate grasping data, which is available both in simulation and the real world. We evaluate our model in real-world robot experiments, comparing it with alternative model architectures as well as an indiscriminate grasping baseline.
keywords: {Grasping;Robots;Adaptation models;Data models;Feature extraction;Image segmentation;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461041&isnumber=8460178

G. Thomas, M. Chien, A. Tamar, J. A. Ojea and P. Abbeel, "Learning Robotic Assembly from CAD," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3524-3531.
doi: 10.1109/ICRA.2018.8460696
Abstract: In this work, motivated by recent manufacturing trends, we investigate autonomous robotic assembly. Industrial assembly tasks require contact-rich manipulation skills, which are challenging to acquire using classical control and motion planning approaches. Consequently, robot controllers for assembly domains are presently engineered to solve a particular task, and cannot easily handle variations in the product or environment. Reinforcement learning (RL) is a promising approach for autonomously acquiring robot skills that involve contact-rich dynamics. However, RL relies on random exploration for learning a control policy, which requires many robot executions, and often gets trapped in locally suboptimal solutions. Instead, we posit that prior knowledge, when available, can improve RL performance. We exploit the fact that in modern assembly domains, geometric information about the task is readily available via the CAD design files. We propose to leverage this prior knowledge by guiding RL along a geometric motion plan, calculated using the CAD data. We show that our approach effectively improves over traditional control approaches for tracking the motion plan, and can solve assembly tasks that require high precision, even without accurate state estimation. In addition, we propose a neural network architecture that can learn to track the motion plan, thereby generalizing the assembly controller to changes in the object positions.
keywords: {Task analysis;Planning;Robots;Trajectory;Tracking;Robotic assembly;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460696&isnumber=8460178

M. Lussi et al., "Accurate and Adaptive in Situ Fabrication of an Undulated Wall Using an on-Board Visual Sensing System," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3532-3539.
doi: 10.1109/ICRA.2018.8460480
Abstract: In this paper we present a system for the in situ33In the context of building construction, “in situ” means that fabrication takes place at the structure's final location directly on the building site. fabrication of a full-scale, load-bearing, and doubly-curved steel reinforced concrete wall. Two complementary vision-based sensing systems provide the feedback necessary to build a 12 meter long steel wire mesh as part of a novel digital building process. The sensing systems provide estimates of the robot pose, referenced to the CAD model of the building site, as well as feedback on the accuracy of the built structure over the course of construction. This second piece of information is used to adapt the building plan to compensate for system inaccuracies and material deformations which occur during buildup. In this way, the structure was successfully built with 98% of the total geometry within 2 centimeters of the designed position. To the best of our knowledge, this is the largest structure which has been built by a mobile robot using solely vision-based sensing.
keywords: {Buildings;Robot sensing systems;Wires;Fabrication;Steel},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460480&isnumber=8460178

J. I. Lipton, A. Schulz, A. Spielberg, L. Trueba, W. Matusik and D. Rus, "Robot Assisted Carpentry for Mass Customization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3540-3547.
doi: 10.1109/ICRA.2018.8460736
Abstract: Despite the ubiquity of carpentered items, the customization of carpentered items remains labor intensive. The generation of laymen editable templates for carpentry is difficult. Current design tools rely heavily on CNC fabrication, limiting applicability. We develop a template based system for carpentry and a robotic fabrication system using mobile robots and standard carpentry tools. Our end-to-end design and fabrication tool democratizes design and fabrication of carpentered items. Our method combines expert knowledge for template design, allows laymen users to customize and verify specific designs, and uses robotics system to fabricate parts. We validate our system using multiple designs to make customizable, verifiable templates and fabrication plans and show an end-to-end example that was designed, manufactured, and assembled using our tools.
keywords: {Fabrication;Robots;Solid modeling;Tools;Standards;Face;Connectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460736&isnumber=8460178

T. Ebinger, S. Kaden, S. Thomas, R. Andre, N. M. Amato and U. Thomas, "A General and Flexible Search Framework for Disassembly Planning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3548-3555.
doi: 10.1109/ICRA.2018.8460483
Abstract: We present a new general framework for disassembly sequence planning. This framework is versatile allowing different types of search schemes (exhaustive vs. preemptive), various part separation techniques, and the ability to group parts, or not, into subassemblies to improve the solution efficiency and parallelism. This enables a truly hierarchical approach to disassembly sequence planning. We demonstrate two different search strategies using this framework that can either yield a single solution quickly or provide a spectrum of solutions from which an optimal may be selected. We also develop a method for subassembly identification based on collision information. Our results show improved performance over an iterative motion planning based method for finding a single solution and greater functionality through hierarchical planning and optimal solution search.
keywords: {Planning;Trajectory;Measurement;Data structures;Search problems;Learning systems;Containers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460483&isnumber=8460178

K. Yamaguchi and M. Higashimori, "1-Actuator 3-DoF Manipulation Using a Virtual Turntable Based on Differential Friction Surface," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3573-3580.
doi: 10.1109/ICRA.2018.8460634
Abstract: This paper describes nonprehensile manipulation realized using the vibration of a plate. A novel manipulation strategy is proposed wherein the three degrees-of-freedom (DoF) of a part are controlled by only one actuator. First, a manipulator driven by a single actuator is introduced. The end effector of this manipulator is a flat plate. The manipulator employs an active-passive hybrid joint mechanism with nonparallel axes. Based on the sinusoidal displacement input to the actuator, the manipulator can generate the velocity of a part omnidirectionally on the plate. Next, simulation results are presented to show that the velocity map of the part varies depending upon the surface friction property of the plate. Further, the control of the rotational behavior of the part on the boundary of two areas with different friction properties by means of the input frequency is shown. Based on this control, a 3- DoF manipulation strategy using a virtual turntable is developed to realize the desired position and orientation of the part. Finally, the proposed method is demonstrated via experiments.
keywords: {Friction;Actuators;Orbits;Vibrations;End effectors;Frequency control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460634&isnumber=8460178

P. Liao, J. Li, S. Zhang and D. Sun, "A Fish-Like Magnetically Propelled Microswimmer Fabricated by 3D Laser Lithography," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3581-3586.
doi: 10.1109/ICRA.2018.8460522
Abstract: This paper presents the development of a fish-like magnetically propelled microswimmer fabricated by 3D laser lithography. The microswimmer consists of a head and a caudal fin, just like a natural fish. There is a joint between the head and the fin so that the caudal fin can oscillate around the head to generate thrust, and the oscillation of the fin hardly transfers to the head, which benefits the stable motion of the microswimmer. The caudal fin of the microswimmer is deposited with a layer of 50 nm nickel (Ni) for magnetic actuation. Through applying an oscillating uniform magnetic field, the microswimmer can move along with the direction guided by the external magnetic field. A magnetic control system with permanent magnets is designed to provide such an oscillating uniform magnetic field, where the oscillating frequency and amplitude are controllable. A micro probe operation platform is used to detach the fabricated microswimmers from glass substrate in manufacturing. The proposed magnetically propelled microswimmer can be potentially used as powerful detoxification and biosensing tools for medical diagnosis and treatment in precision medicine.
keywords: {Magnetic fields;Magnetic domains;Magnetic heads;Magnetic flux;Magnetic resonance imaging;Propulsion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460522&isnumber=8460178

J. James, V. Iyer, Y. Chukewad, S. Gollakota and S. B. Fuller, "Liftoff of a 190 mg Laser-Powered Aerial Vehicle: The Lightest Wireless Robot to Fly," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3587-3594.
doi: 10.1109/ICRA.2018.8460582
Abstract: To date, insect scale aerial robots have required wire tethers for providing power due to the challenges of integrating the required high-voltage power electronics within their severely constrained weight budgets. In this paper we present a significant milestone in the achievement of flight autonomy: the first wireless liftoff of a 190 mg aerial vehicle. Our robot is remotely powered using a 976 nm laser and integrates a complete power electronics package weighing a total of 104 mg, using commercially available components and fabricated using a fast-turnaround laser based circuit fabrication technique. The onboard electronics include a lightweight boost converter capable of producing high voltage bias and drive signals of over 200 V at up to 170 Hz and regulated by a microcontroller performing feedback control. We present our system design and analysis, detailed description of our fabrication method, and results from flight experiments.
keywords: {Actuators;Insects;Microcontrollers;High-voltage techniques;Capacitors;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460582&isnumber=8460178

T. Qiu, S. Palagi, J. Sachs and P. Fischer, "Soft Miniaturized Linear Actuators Wirelessly Powered by Rotating Permanent Magnets," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3595-3600.
doi: 10.1109/ICRA.2018.8461145
Abstract: Wireless actuation by magnetic fields allows for the operation of untethered miniaturized devices, e.g. in biomedical applications. Nevertheless, generating large controlled forces over relatively large distances is challenging. Magnetic torques are easier to generate and control, but they are not always suitable for the tasks at hand. Moreover, strong magnetic fields are required to generate a sufficient torque, which are difficult to achieve with electromagnets. Here, we demonstrate a soft miniaturized actuator that transforms an externally applied magnetic torque into a controlled linear force. We report the design, fabrication and characterization of both the actuator and the magnetic field generator. We show that the magnet assembly, which is based on a set of rotating permanent magnets, can generate strong controlled oscillating fields over a relatively large workspace. The actuator, which is 3D-printed, can lift a load of more than 40 times its weight. Finally, we show that the actuator can be further miniaturized, paving the way towards strong, wirelessly powered microactuators.
keywords: {Actuators;Magnetic fields;Magnetic resonance imaging;Permanent magnets;Magnetic moments;Torque;Magnetic flux},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461145&isnumber=8460178

S. Salmanipour and E. Diller, "Eight-Degrees-of-Freedom Remote Actuation of Small Magnetic Mechanisms," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3608-3613.
doi: 10.1109/ICRA.2018.8461026
Abstract: Magnetically-driven micrometer to millimeter-scale robotic devices have recently shown great capabilities for remote applications in medical procedures, in microfluidic tools and in microfactories. Significant effort recently has been on the creation of mobile or stationary devices with multiple independently-controllable degrees of freedom (DOF) for multiagent or complex mechanism motions. In most applications of magnetic microrobots, however, the relatively large distance from the field generation source and the microscale devices results in controlling magnetic field signals which are applied homogeneously over all agents. While some progress has been made in this area allowing up to six independent DOF to be individually commanded, there has been no rigorous effort in determining the maximum achievable number of DOF for systems with homogeneous magnetic field input. In this work, we show that this maximum is eight and we introduce the theoretical basis for this conclusion, relying on the number of independent usable components in a magnetic field at a point. In order to verify the claim experimentally, we develop a simple demonstration mechanism with 8 DOF designed specifically to show independent actuation. Using this mechanism with 500 μm magnetic elements, we demonstrate eight independent motions of 0.6 mm with 8.6 % coupling using an eight coil system. These results will enable the creation of richer outputs in future microrobotic devices.
keywords: {Magnetic resonance imaging;Magnetic devices;Magnetic moments;Torque;Mathematical model;Force;Wireless communication},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461026&isnumber=8460178

E. Westman, A. Hinduja and M. Kaess, "Feature-Based SLAM for Imaging Sonar with Under-Constrained Landmarks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3629-3636.
doi: 10.1109/ICRA.2018.8461004
Abstract: Recent algorithms have demonstrated the feasibility of underwater feature-based SLAM using imaging sonar. But previous methods have either relied on manual feature extraction and correspondence or used prior knowledge of the scene, such as the planar scene assumption. Our proposed system provides a general-purpose method for feature-point extraction and correspondence in arbitrary scenes. Additionally, we develop a method of identifying point landmarks that are likely to be well-constrained and reliably reconstructed. Finally, we demonstrate that while under-constrained landmarks cannot be accurately reconstructed themselves, they can still be used to constrain and correct the sensor motion. These advances represent a large step towards general-purpose, feature-based SLAM with imaging sonar.
keywords: {Feature extraction;Imaging;Sonar measurements;Simultaneous localization and mapping;Three-dimensional displays;Image reconstruction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461004&isnumber=8460178

B. Bodin et al., "SLAMBench2: Multi-Objective Head-to-Head Benchmarking for Visual SLAM," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3637-3644.
doi: 10.1109/ICRA.2018.8460558
Abstract: SLAM is becoming a key component of robotics and augmented reality (AR) systems. While a large number of SLAM algorithms have been presented, there has been little effort to unify the interface of such algorithms, or to perform a holistic comparison of their capabilities. This is a problem since different SLAM applications can have different functional and non-functional requirements. For example, a mobile phone-based AR application has a tight energy budget, while a UAV navigation system usually requires high accuracy. SLAMBench2 is a benchmarking framework to evaluate existing and future SLAM systems, both open and close source, over an extensible list of datasets, while using a comparable and clearly specified list of performance metrics. A wide variety of existing SLAM algorithms and datasets is supported, e.g. ElasticFusion, InfiniTAM, ORB-SLAM2, OKVIS, and integrating new ones is straightforward and clearly specified by the framework. SLAMBench2 is a publicly-available software framework which represents a starting point for quantitative, comparable and val-idatable experimental research to investigate trade-offs across SLAM systems.
keywords: {Simultaneous localization and mapping;Measurement;Trajectory;Benchmark testing;User interfaces;C++ languages},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460558&isnumber=8460178

S. Garg, N. Suenderhauf and M. Milford, "Don't Look Back: Robustifying Place Categorization for Viewpoint- and Condition-Invariant Place Recognition," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3645-3652.
doi: 10.1109/ICRA.2018.8461051
Abstract: When a human drives a car along a road for the first time, they later recognize where they are on the return journey typically without needing to look in their rear view mirror or turn around to look back, despite significant viewpoint and appearance change. Such navigation capabilities are typically attributed to our semantic visual understanding of the environment [1] beyond geometry to recognizing the types of places we are passing through such as “passing a shop on the left” or “moving through a forested area”. Humans are in effect using place categorization [2] to perform specific place recognition even when the viewpoint is 180 degrees reversed. Recent advances in deep neural networks have enabled high performance semantic understanding of visual places and scenes, opening up the possibility of emulating what humans do. In this work, we develop a novel methodology for using the semantics-aware higher-order layers of deep neural networks for recognizing specific places from within a reference database. To further improve the robustness to appearance change, we develop a descriptor normalization scheme that builds on the success of normalization schemes for pure appearance-based techniques such as SeqSLAM [3]. Using two different datasets - one road-based, one pedestrian-based, we evaluate the performance of the system in performing place recognition on reverse traversals of a route with a limited field of view camera and no turn-back-and-Iook behaviours, and compare to existing state-of-the-art techniques and vanilla off-the-shelf features. The results demonstrate significant improvements over the existing state of the art, especially for extreme perceptual challenges that involve both great viewpoint change and environmental appearance change. We also provide experimental analyses of the contributions of the various system components: the use of spatio-temporal sequences, place categorization and place-centric characteristics as opposed to object-centric semantics.
keywords: {Semantics;Visualization;Robustness;Databases;Image recognition;Cameras;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461051&isnumber=8460178

K. P. Cop, P. V. K. Borges and R. Dubé, "Delight: An Efficient Descriptor for Global Localisation Using LiDAR Intensities," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3653-3660.
doi: 10.1109/ICRA.2018.8460940
Abstract: Place recognition is a key element of mobile robotics. It can assist with the “wake-up” and “kidnapped robot” problems, where the robot position needs to be estimated without prior information. Among the different sensors that can be used for the task (e.g., camera, GPS, LiDAR), LiDAR has the advantage of operating in the dark and in GPS-denied areas. We propose a new method that uses solely the LiDAR data and that can be performed without robot motion. In contrast to other methods, our system leverages intensity information (as opposed to only range information) which is encoded into a novel descriptor of LiDAR intensities as a group of histograms, named DELIGHT. The descriptor encodes the distributed histograms of intensity of the surroundings which are compared using chi-squared tests. Our pipeline is a two-stage solution consisting of an intensity-based prior estimation and a geometry-based verification. For a map of 220k square meters, the method achieves localisation in around 3s with a success rate of 97%, illustrating the applicability of the method in real environments.
keywords: {Laser radar;Histograms;Three-dimensional displays;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460940&isnumber=8460178

F. Nobre, C. Heckman, P. Ozog, R. W. Wolcott and J. M. Walls, "Online Probabilistic Change Detection in Feature-Based Maps," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3661-3668.
doi: 10.1109/ICRA.2018.8461111
Abstract: Sparse feature-based maps provide a compact representation of the environment that admit efficient algorithms, for example simultaneous localization and mapping. These representations typically assume a static world and therefore contain static map features. However, since the world contains dynamic elements, determining when map features no longer correspond to the environment is essential for long-term utility. This work develops a feature-based model of the environment which evolves over time through feature persistence. Moreover, we augment the state-of-the-art sparse mapping model with a correlative structure that captures spatio-temporal properties, e.g. that nearby features frequently have similar persistence. We show that such relationships, typically addressed through an ad hoc formalism focusing only on feature repeatability, are crucial to evaluate through a probabilistically principled approach. The joint posterior over feature persistence can be computed efficiently and used to improve online data association decisions for localization. The proposed algorithms are validated in numerical simulation and using publicly available data sets.
keywords: {Feature extraction;Simultaneous localization and mapping;Robustness;Heuristic algorithms;Probabilistic logic;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461111&isnumber=8460178

F. Schiano and R. Tron, "The Dynamic Bearing Observability Matrix Nonlinear Observability and Estimation for Multi-Agent Systems," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3669-3676.
doi: 10.1109/ICRA.2018.8460792
Abstract: We consider the problem of localization in multiagent formations with bearing only measurements, and analyze the fundamental observability properties for dynamic agents. The current well-established approach is based on the socalled rigidity matrix, and its algebraic properties (e.g., its rank and nullspace). This method is typically motivated using first-order derivatives, and shows, among other facts, that the global scale of the formation is not observable. This work shows that current results represent an incomplete view of the problem. In particular, we show that 1) current methods are a particular instantiation of nonlinear observability theory, 2) we can introduce the concept of the dynamic bearing observability matrix from higher order derivatives to study the observability of dynamic formations, and 3) the global scale is, in fact, generally observable when the agents move according to known inputs. We use tools from Riemannian geometry and Lie group theory to tackle, in a general and principled way, the general formulation of the localization problem with states that include both rotations and translations. Finally, we verify our theoretical results by deriving and applying, in both simulations and real experiments on UAVs, a centralized Extended Kalman Filter on Lie groups that is able to estimate the global scale of a moving formation.
keywords: {Observability;Robot sensing systems;Geometry;Manifolds;Cameras;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460792&isnumber=8460178

C. H. Walsh and S. Karaman, "CDDT: Fast Approximate 2D Ray Casting for Accelerated Localization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3677-3684.
doi: 10.1109/ICRA.2018.8460743
Abstract: Localization is an essential component for autonomous robots. A well-established localization approach combines ray casting with a particle filter, leading to a computationally expensive algorithm that is difficult to run on resource-constrained mobile robots. We present a novel data structure called the Compressed Directional Distance Transform for accelerating ray casting in two dimensional occupancy grid maps. Our approach allows online map updates, and near constant time ray casting performance for a fixed size map, in contrast with other methods exhibit poor worst case performance. Our experimental results show that the proposed algorithm approximates the performance characteristics of reading from a three dimensional lookup table of ray cast solutions while requiring two orders of magnitude less memory and precomputation. This results in a particle filter algorithm which can maintain 2500 particles with 61 ray casts per particle at 40Hz, using a single CPU thread onboard a mobile robot.
keywords: {Casting;Table lookup;Robot sensing systems;Transforms;Approximation algorithms;Memory management;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460743&isnumber=8460178

M. Karrer and M. Chli, "Towards Globally Consistent Visual-Inertial Collaborative SLAM," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3685-3692.
doi: 10.1109/ICRA.2018.8461213
Abstract: Motivated by the need for globally consistent tracking and mapping before autonomous robot navigation becomes realistically feasible, this paper presents a novel backend to monocular-inertial odometry. As some of the most challenging platforms for vision-based perception, we evaluate the performance of our system using Unmanned Aerial Vehicles (UAV s). Our experimental validation demonstrates that the proposed approach achieves drift correction and metric scale estimation from a single UAV on benchmarking datasets. Furthermore, the generality of our approach is demonstrated to achieve globally consistent maps built in a collaborative manner from two UAVs, each equipped with a monocular-inertial sensor suite, showing the possible gains opened by collaboration amongst robots to perform SLAM. Video - https://youtu.be/wbX36HBu2Eg.
keywords: {Simultaneous localization and mapping;Collaboration;Unmanned aerial vehicles;Optimization;Measurement;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461213&isnumber=8460178

A. W. Palmer, A. J. Hill and S. J. Scheding, "Modelling Resource Contention in Multi-Robot Task Allocation Problems with Uncertain Timing," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3693-3700.
doi: 10.1109/ICRA.2018.8460981
Abstract: This paper proposes an analytical framework for modelling resource contention in multi-robot systems, where the travel times and task durations are uncertain. It uses several approximation methods to quickly and accurately calculate the probability distributions describing the times at which the tasks start and finish. Specific contributions include exact and fast approximation methods for calculating the probability of a set of independent normally distributed random events occurring in a given order, a method for calculating the most likely and n-th most likely orders of occurrence for a set of independent normally distributed random events that have equal standard deviations, and a method for approximating the conditional probability distributions of the events given a specific order of the events. The complete framework is shown to be faster than a Monte Carlo approach for the same accuracy in two multi-robot task allocation problems. In addition, the importance of incorporating uncertainty is demonstrated through a comparison with a deterministic method. This is a general framework that is agnostic to the optimisation method and objective function used, and is applicable to a wide range of problems.
keywords: {Robots;Task analysis;Uncertainty;Probability distribution;Random variables;Resource management},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460981&isnumber=8460178

M. Fowler, P. Tokekar, T. Charles Clancy and R. K. Williams, "Constrained-Action POMDPs for Multi-Agent Intelligent Knowledge Distribution," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3701-3708.
doi: 10.1109/ICRA.2018.8461118
Abstract: This paper addresses a fundamental question of multi-agent knowledge distribution: what information should be sent to whom and when, with the limited resources available to each agent? Intelligent Knowledge Distribution is a framework that answers these questions. Communication requirements for multi-agent systems can be rather high when an accurate picture of the environment and the state of other agents must be maintained. To reduce the impact of multi-agent coordination on systems, including communications, this paper introduces the concept of action-based constraints on partially observable Markov decision processes, rewards based upon the value of information driven by Kullback-Leibler Divergence, and probabilistic constraint satisfaction through discrete optimization and Markov chain Monte Carlo analysis. Intelligent Knowledge Distribution is driven by determining the information content an agent believes another agent will obtain by receiving certain information, along with the importance or relevance of that information to the system objective. To perform constraint analysis on an infinite-horizon policy, policies are represented as a Finite State Controller allowing Markov chain Monte Carlo analysis to determine a probabilistic level of guarantee that the constraints will be satisfied. The analysis of performance for an example mission presented in this paper shows the constrained controllers, during the highest constraint seen in simulations, can be constructed to meet minimal constraint guarantees (80%) while impacting the optimal value less than 50%, where the unconstrained optimal controller only satisfied the constraint 10% of the time.
keywords: {Markov processes;Collaboration;Monte Carlo methods;Bandwidth;Proposals;Entropy;Power capacitors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461118&isnumber=8460178

S. Shriyam and S. K. Gupta, "Incorporating Potential Contingency Tasks in Multi-Robot Mission Planning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3709-3715.
doi: 10.1109/ICRA.2018.8460659
Abstract: In most complex missions, unexpected situations arise that may interfere with the planned execution of mission tasks. These situations result in the generation of contingency tasks that need to be executed before the originally planned tasks are completed. Potential contingency tasks may not always affect mission tasks due to the inherent uncertainty in the environment. Deferring action on a potential contingency task may incur a penalty in terms of wasted time due to idle robots if the contingency task becomes a bottleneck in the future. On the other hand, immediate action on a potential contingency task may incur a penalty in terms of wasted time if the contingency task did not actually impact the mission. When a contingency task is reported, the planner generates an updated plan that minimizes expected mission completion time by taking into account the probability of the contingency task impacting mission tasks, its effect on the mission, and its spatial location. We have characterized the performance of the algorithm through simulation experiments. We show that the proactive approach to contingency task management outperforms a conservative approach.
keywords: {Task analysis;Robot kinematics;Uncertainty;Schedules;Marine vehicles;Resource management},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460659&isnumber=8460178

Y. Sung, A. K. Budhiraja, R. K. Williams and P. Tokekar, "Distributed Simultaneous Action and Target Assignment for Multi-Robot Multi-Target Tracking," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3724-3729.
doi: 10.1109/ICRA.2018.8460974
Abstract: We study two multi-robot assignment problems for multi-target tracking. We consider distributed approaches in order to deal with limited sensing and communication ranges. We seek to simultaneously assign trajectories and targets to the robots. Our focus is on local algorithms that achieve performance close to the optimal algorithms with limited communication. We show how to use a local algorithm that guarantees a bounded approximate solution within O(hlog1/ε) communication rounds. We compare with a greedy approach that achieves a 2-approximation in as many rounds as the number of robots. Simulation results show that the local algorithm is an effective solution to the assignment problem.
keywords: {Robot sensing systems;Target tracking;Approximation algorithms;Partitioning algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460974&isnumber=8460178

G. Sharma, C. Busch and S. Mukhopadhyay, "How to Make Fat Autonomous Robots See all Others Fast?," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3730-3735.
doi: 10.1109/ICRA.2018.8460899
Abstract: The coordination problems arising in a team of autonomous mobile robots have received a lot of attention in the distributed robotics community. Along those lines, we study in this paper the problem of coordinating autonomous mobile robots to reposition on a convex hull so that each robot sees all others. In particular, we consider non-transparent fat robots operating in the 2-dimensional plane. They are abstracted as unit discs and they make local decisions with vision being the only mean of coordination among them. We develop a (deterministic) distributed algorithm that solves the problem for a team of N ≥ 3 fat robots in O(N) time avoiding collisions under the semi-synchronous scheduler. The main idea is to enforce the robots to reach a configuration in which (i) the robots' centers form a convex hull; (ii) all robots are on the convex hull's boundary; and (iii) each robot can see all other robots. The result is achieved assuming some reasonable conditions on the input configuration and showing that starting from any input configuration that satisfies our conditions, robots reach such a configuration in linear time and terminate.
keywords: {Robot kinematics;Fats;Cogeneration;Collision avoidance;Runtime;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460899&isnumber=8460178

G. Sun et al., "A Synchronization Scheme for Position Control of Multiple Rope-Climbing Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3736-3741.
doi: 10.1109/ICRA.2018.8460484
Abstract: The ability of rope-climbing robots in aloft operation is limited by its self-supporting and locomotion ability. In many applications, a given task is also too complex to be achieved by a single rope-climbing robot acting alone. The solution of multiple rope-climbing robots can overcome the limitations. However, existing control methods for rope-climbing robots are limited to single robot, and the open issue of coordination between multiple rope-climbing robots has not been systematically addressed. This paper presents a new synchronization scheme for position control of multiple rope-climbing robots, such that each robot moves to the corresponding desired position while synchronizing the heights between each other. Maintaining the same height is very important to guarantee the stability of the task-oriented manipulator installed among multiple robots, when it is performing the manipulation task. The development of the proposed controller is based on the singular perturbation approach, by treating the fast actuator dynamics as a perturbation of the slow robot dynamics, such that the lowest control complexity is achieved. The exponential stability of the overall system that consists of the fast and slow subsystems is proved by using Tikhonov’ s theorem. Experimental results are presented to illustrate the performance of the proposed controller.
keywords: {Robot kinematics;Synchronization;Task analysis;Actuators;Mathematical model;Position control;multiple Rope-Climbing Robots;climbing robots;motion control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460484&isnumber=8460178

A. Zeng et al., "Robotic Pick-and-Place of Novel Objects in Clutter with Multi-Affordance Grasping and Cross-Domain Image Matching," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3750-3757.
doi: 10.1109/ICRA.2018.8461044
Abstract: This paper presents a robotic pick-and-place system that is capable of grasping and recognizing both known and novel objects in cluttered environments. The key new feature of the system is that it handles a wide range of object categories without needing any task-specific training data for novel objects. To achieve this, it first uses a category-agnostic affordance prediction algorithm to select and execute among four different grasping primitive behaviors. It then recognizes picked objects with a cross-domain image classification framework that matches observed images to product images. Since product images are readily available for a wide range of objects (e.g., from the web), the system works out-of-the-box for novel objects without requiring any additional training data. Exhaustive experimental results demonstrate that our multi-affordance grasping achieves high success rates for a wide variety of objects in clutter, and our recognition algorithm achieves high accuracy for both known and novel grasped objects. The approach was part of the MIT-Princeton Team system that took 1st place in the stowing task at the 2017 Amazon Robotics Challenge. All code, datasets, and pre-trained models are available online at http://arc.cs.princeton.edu.
keywords: {Grasping;Robots;Clutter;Grippers;Robustness;Proposals;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461044&isnumber=8460178

R. Rahmatizadeh, P. Abolghasemi, L. Bölöni and S. Levine, "Vision-Based Multi-Task Manipulation for Inexpensive Robots Using End-to-End Learning from Demonstration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3758-3765.
doi: 10.1109/ICRA.2018.8461076
Abstract: We propose a technique for multi-task learning from demonstration that trains the controller of a low-cost robotic arm to accomplish several complex picking and placing tasks, as well as non-prehensile manipulation. The controller is a recurrent neural network using raw images as input and generating robot arm trajectories, with the parameters shared across the tasks. The controller also combines VAE-GAN-based reconstruction with autoregressive multimodal action prediction. Our results demonstrate that it is possible to learn complex manipulation tasks, such as picking up a towel, wiping an object, and depositing the towel to its previous position, entirely from raw images with direct behavior cloning. We show that weight sharing and reconstruction-based regularization substantially improve generalization and robustness, and training on multiple tasks simultaneously increases the success rate on all tasks.
keywords: {Task analysis;Robots;Feature extraction;Neural networks;Image reconstruction;Training;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461076&isnumber=8460178

X. Yan et al., "Learning 6-DOF Grasping Interaction via Deep Geometry-Aware 3D Representations," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3766-3773.
doi: 10.1109/ICRA.2018.8460609
Abstract: This paper focuses on the problem of learning 6- DOF grasping with a parallel jaw gripper in simulation. Our key idea is constraining and regularizing grasping interaction learning through 3D geometry prediction. We introduce a deep geometry-aware grasping network (DGGN) that decomposes the learning into two steps. First, we learn to build mental geometry-aware representation by reconstructing the scene (i.e., 3D occupancy grid) from RGBD input via generative 3D shape modeling. Second, we learn to predict grasping outcome with its internal geometry-aware representation. The learned outcome prediction model is used to sequentially propose grasping solutions via analysis-by-synthesis optimization. Our contributions are fourfold: (1) To best of our knowledge, we are presenting for the first time a method to learn a 6-DOF grasping net from RGBD input; (2) We build a grasping dataset from demonstrations in virtual reality with rich sensory and interaction annotations. This dataset includes 101 everyday objects spread across 7 categories, additionally, we propose a data augmentation strategy for effective learning; (3) We demonstrate that the learned geometry-aware representation leads to about 10% relative performance improvement over the baseline CNN on grasping objects from our dataset. (4) We further demonstrate that the model generalizes to novel viewpoints and object instances.
keywords: {Grasping;Three-dimensional displays;Shape;Geometry;Solid modeling;Two dimensional displays;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460609&isnumber=8460178

J. Hatori et al., "Interactively Picking Real-World Objects with Unconstrained Spoken Language Instructions," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3774-3781.
doi: 10.1109/ICRA.2018.8460699
Abstract: Comprehension of spoken natural language is an essential skill for robots to communicate with humans effectively. However, handling unconstrained spoken instructions is challenging due to (1) complex structures and the wide variety of expressions used in spoken language, and (2) inherent ambiguity of human instructions. In this paper, we propose the first comprehensive system for controlling robots with unconstrained spoken language, which is able to effectively resolve ambiguity in spoken instructions. Specifically, we integrate deep learning-based object detection together with natural language processing technologies to handle unconstrained spoken instructions, and propose a method for robots to resolve instruction ambiguity through dialogue. Through our experiments on both a simulated environment as well as a physical industrial robot arm, we demonstrate the ability of our system to understand natural instructions from human operators effectively, and show how higher success rates of the object picking task can be achieved through an interactive clarification process.
keywords: {Task analysis;Object recognition;Natural languages;Object detection;Feature extraction;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460699&isnumber=8460178

A. Nguyen, D. Kanoulas, L. Muratore, D. G. Caldwell and N. G. Tsagarakis, "Translating Videos to Commands for Robotic Manipulation with Deep Recurrent Neural Networks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3782-3788.
doi: 10.1109/ICRA.2018.8460857
Abstract: We present a new method to translate videos to commands for robotic manipulation using Deep Recurrent Neural Networks (RNN). Our framework first extracts deep features from the input video frames with a deep Convolutional Neural Networks (CNN). Two RNN layers with an encoder-decoder architecture are then used to encode the visual features and sequentially generate the output words as the command. We demonstrate that the translation accuracy can be improved by allowing a smooth transaction between two RNN layers and using the state-of-the-art feature extractor. The experimental results on our new challenging dataset show that our approach outperforms recent methods by a fair margin. Furthermore, we combine the proposed translation module with the vision and planning system to let a robot perform various manipulation tasks. Finally, we demonstrate the effectiveness of our framework on a full-size humanoid robot WALK-MAN.
keywords: {Videos;Robots;Feature extraction;Task analysis;Visualization;Recurrent neural networks;Logic gates},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460857&isnumber=8460178

G. Sartoretti, Y. Shi, W. Paivine, M. Travers and H. Choset, "Distributed Learning for the Decentralized Control of Articulated Mobile Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3789-3794.
doi: 10.1109/ICRA.2018.8460802
Abstract: Decentralized control architectures, such as those conventionally defined by central pattern generators, independently coordinate spatially distributed portions of articulated bodies to achieve system-level objectives. State of the art distributed algorithms for reinforcement learning employ a different but conceptually related idea; independent agents simultaneously coordinating their own behaviors in parallel environments while asynchronously updating the policy of a system-or, rather, meta-level agent. This work, to the best of the authors' knowledge, is the first to explicitly explore the potential relationship between the underlying concepts in homogeneous decentralized control for articulated locomotion and distributed learning. We present an approach that leverages the structure of the asynchronous advantage actor-critic (A3C) algorithm to provide a natural framework for learning decentralized control policies on a single platform. Our primary contribution shows an individual agent in the A3C algorithm can be defined by an independently controlled portion of the robot's body, thus enabling distributed learning on a single platform for efficient hardware implementation. To this end, we show how the system is trained offline using hardware experiments implementing an autonomous decentralized compliant control framework. Our experimental results show that the trained agent outperforms the compliant control baseline by more than 40% in terms of steady progression through a series of randomized, highly cluttered evaluation environments.
keywords: {Shape;Decentralized control;Aerospace electronics;Robot kinematics;Admittance;Hardware},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460802&isnumber=8460178

D. Xu et al., "Neural Task Programming: Learning to Generalize Across Hierarchical Tasks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3795-3802.
doi: 10.1109/ICRA.2018.8460689
Abstract: In this work, we propose a novel robot learning framework called Neural Task Programming (NTP), which bridges the idea of few-shot learning from demonstration and neural program induction. NTP takes as input a task specification (e.g., video demonstration of a task) and recursively decomposes it into finer sub-task specifications. These specifications are fed to a hierarchical neural program, where bottom-level programs are callable subroutines that interact with the environment. We validate our method in three robot manipulation tasks. NTP achieves strong generalization across sequential tasks that exhibit hierarchal and compositional structures. The experimental results show that NTP learns to generalize well towards unseen tasks with increasing lengths, variable topologies, and changing objectives.stanfordvl.github.io/ntp/.
keywords: {Task analysis;Programming;Robots;Sorting;Semantics;Topology;Data models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460689&isnumber=8460178

X. B. Peng, M. Andrychowicz, W. Zaremba and P. Abbeel, "Sim-to-Real Transfer of Robotic Control with Dynamics Randomization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3803-3810.
doi: 10.1109/ICRA.2018.8460528
Abstract: Simulations are attractive environments for training agents as they provide an abundant source of data and alleviate certain safety concerns during the training process. But the behaviours developed by agents in simulation are often specific to the characteristics of the simulator. Due to modeling error, strategies that are successful in simulation may not transfer to their real world counterparts. In this paper, we demonstrate a simple method to bridge this “reality gap”. By randomizing the dynamics of the simulator during training, we are able to develop policies that are capable of adapting to very different dynamics, including ones that differ significantly from the dynamics on which the policies were trained. This adaptivity enables the policies to generalize to the dynamics of the real world without any training on the physical system. Our approach is demonstrated on an object pushing task using a robotic arm. Despite being trained exclusively in simulation, our policies are able to maintain a similar level of performance when deployed on a real robot, reliably moving an object to a desired location from random initial configurations. We explore the impact of various design decisions and show that the resulting policies are robust to significant calibration error.
keywords: {Robots;Training;Adaptation models;Task analysis;Trajectory;Data models;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460528&isnumber=8460178

F. Blochliger, M. Fehr, M. Dymczyk, T. Schneider and R. Siegwart, "Topomap: Topological Mapping and Navigation Based on Visual SLAM Maps," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3818-3825.
doi: 10.1109/ICRA.2018.8460641
Abstract: Visual robot navigation within large-scale, semistructured environments deals with various challenges such as computation intensive path planning algorithms or insufficient knowledge about traversable spaces. Moreover, many state-of-the-art navigation approaches only operate locally instead of gaining a more conceptual understanding of the planning objective. This limits the complexity of tasks a robot can accomplish and makes it harder to deal with uncertainties that are present in the context of real-time robotics applications. In this work, we present Topomap, a framework which simplifies the navigation task by providing a map to the robot which is tailored for path planning use. This novel approach transforms a sparse feature-based map from a visual Simultaneous Localization And Mapping (SLAM) system into a three-dimensional topological map. This is done in two steps. First, we extract occupancy information directly from the noisy sparse point cloud. Then, we create a set of convex free-space clusters, which are the vertices of the topological map. We show that this representation improves the efficiency of global planning, and we provide a complete derivation of our algorithm. Planning experiments on real world datasets demonstrate that we achieve similar performance as RRT* with significantly lower computation times and storage requirements. Finally, we test our algorithm on a mobile robotic platform to prove its advantages.
keywords: {Navigation;Visualization;Simultaneous localization and mapping;Path planning;Three-dimensional displays;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460641&isnumber=8460178

Z. Zhang, S. Liu, G. Tsai, H. Hu, C. -C. Chu and F. Zheng, "PIRVS: An Advanced Visual-Inertial SLAM System with Flexible Sensor Fusion and Hardware Co-Design," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3826-3832.
doi: 10.1109/ICRA.2018.8460672
Abstract: In this paper, we present the PerceptIn Robotics Vision System (PIRVS), a visual-inertial computing hardware with embedded simultaneous localization and mapping (SLAM) algorithm. The PIRVS hardware is equipped with a multi-core processor, a global-shutter stereo camera, and an IMU with precise hardware synchronization. The PIRVS software features a flexible sensor fusion approach to not only tightly integrate visual measurements with inertial measurements and also to loosely couple with additional sensor modalities. It runs in real-time on both PC and the PIRVS hardware. We perform a thorough evaluation of the proposed system using multiple public visual-inertial datasets. Experimental results demonstrate that our system reaches comparable accuracy of state-of-the-art visual-inertial algorithms on PC, while being more efficient on the PIRVS hardware.
keywords: {Simultaneous localization and mapping;Hardware;Cameras;Feature extraction;Synchronization;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460672&isnumber=8460178

D. Schlegel, M. Colosi and G. Grisetti, "ProSLAM: Graph SLAM from a Programmer's Perspective," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3833-3840.
doi: 10.1109/ICRA.2018.8461180
Abstract: In this paper we present ProSLAM, a lightweight open-source stereo visual SLAM system designed with simplicity in mind. This work stems from the experience gathered by the authors while teaching SLAM and aims at providing a highly modular system that can be easily implemented and understood. Rather than focusing on the well known mathematical aspects of stereo visual SLAM, we highlight the data structures and the algorithmic aspects required to realize such a system. We implemented ProSLAM using the C++ programming language in combination with a minimal set of standard libraries. The results of a thorough validation performed on several standard benchmark datasets show that ProSLAM achieves precision comparable to state-of-the-art approaches, while requiring substantially less computation.
keywords: {Simultaneous localization and mapping;Visualization;Three-dimensional displays;Cameras;Data structures;Benchmark testing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461180&isnumber=8460178

M. Giamou, K. Khosoussi and J. P. How, "Talk Resource-Efficiently to Me: Optimal Communication Planning for Distributed Loop Closure Detection," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3841-3848.
doi: 10.1109/ICRA.2018.8460783
Abstract: Due to the distributed nature of cooperative simultaneous localization and mapping (CSLAM), detecting inter-robot loop closures necessitates sharing sensory data with other robots. A naïve approach to data sharing can easily lead to a waste of mission-critical resources. This paper investigates the logistical aspects of CSLAM. Particularly, we present a general resource-efficient communication planning framework that takes into account both the total amount of exchanged data and the induced division of labor between the participating robots. Compared to other state-of-the-art approaches, our framework is able to verify the same set of potential inter-robot loop closures while exchanging considerably less data and influencing the induced workloads. We develop a fast algorithm for finding globally optimal communication policies, and present theoretical analysis to characterize the necessary and sufficient conditions under which simpler strategies are optimal. The proposed framework is extensively evaluated with data from the KITTI odometry benchmark datasets.
keywords: {Robot sensing systems;Distributed databases;Planning;Trajectory;Visualization;Metadata},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460783&isnumber=8460178

R. Scona, M. Jaimez, Y. R. Petillot, M. Fallon and D. Cremers, "StaticFusion: Background Reconstruction for Dense RGB-D SLAM in Dynamic Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3849-3856.
doi: 10.1109/ICRA.2018.8460681
Abstract: Dynamic environments are challenging for visual SLAM as moving objects can impair camera pose tracking and cause corruptions to be integrated into the map. In this paper, we propose a method for robust dense RGB-D SLAM in dynamic environments which detects moving objects and simultaneously reconstructs the background structure. While most methods employ implicit robust penalisers or outlier filtering techniques in order to handle moving objects, our approach is to simultaneously estimate the camera motion as well as a probabilistic static/dynamic segmentation of the current RGB-D image pair. This segmentation is then used for weighted dense RGB-D fusion to estimate a 3D model of only the static parts of the environment. By leveraging the 3D model for frame-to-model alignment, as well as static/dynamic segmentation, camera motion estimation has reduced overall drift - as well as being more robust to the presence of dynamics in the scene. Demonstrations are presented which compare the proposed method to related state-of-the-art approaches using both static and dynamic sequences. The proposed method achieves similar performance in static environments and improved accuracy and robustness in dynamic scenes.
keywords: {Cameras;Robustness;Image segmentation;Motion segmentation;Dynamics;Three-dimensional displays;Image reconstruction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460681&isnumber=8460178

S. Vemprala and S. Saripalli, "Vision Based Collaborative Path Planning for Micro Aerial Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3889-3895.
doi: 10.1109/ICRA.2018.8462910
Abstract: In this paper, we present a collaborative path-planning framework for a group of micro aerial vehicles that are capable of localizing through vision. Each of the micro aerial vehicles is assumed to be equipped with a forward facing monocular camera. The vehicles initially use their captured images to build 3D maps through common features; and subsequently track these features to localize through 3D-2D correspondences. The planning algorithm, while connecting start locations to provided goal locations, also aims to reduce the localization uncertainty of the vehicles in the group. To achieve this, we develop a two-step planning framework: the first step attempts to build an improved map of the environment by solving the next-best-view problem for multiple cameras. We express this as a black-box optimization problem and solve it using the Covariance Matrix Adaption evolution strategy (CMA-ES). Once an improved map is available, the second stage of the planning framework performs belief space planning for the vehicles individually using the rapidly exploring random belief tree (RRBT) algorithm. Through the RRBT approach, the planner generates paths that ensure feature visibility while attempting to optimize path cost and reduce localization uncertainty. We validate our approach using experiments conducted in a high visual-fidelity aerial vehicle simulator, Microsoft AirSim.
keywords: {Planning;Uncertainty;Cameras;Three-dimensional displays;Collaboration;Optimization;Path planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462910&isnumber=8460178

W. Liu, G. Loianno, K. Mohta, K. Daniilidis and V. Kumar, "Semi-Dense Visual-Inertial Odometry and Mapping for Quadrotors with SWAP Constraints," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3904-3909.
doi: 10.1109/ICRA.2018.8463163
Abstract: Micro Aerial Vehicles have the potential to assist humans in real life tasks involving applications such as smart homes, search and rescue, and architecture construction. To enhance autonomous navigation capabilities these vehicles need to be able to create dense 3D maps of the environment, while concurrently estimating their own motion. In this paper, we are particularly interested in small vehicles that can navigate cluttered indoor environments. We address the problem of visual inertial state estimation, control and 3D mapping on platforms with Size, Weight, And Power (SWAP) constraints. The proposed approach is validated through experimental results on a 250 g, 22 cm diameter quadrotor equipped only with a stereo camera and an IMU with a computationally-limited CPU showing the ability to autonomously navigate, while concurrently creating a 3D map of the environment.
keywords: {Cameras;Three-dimensional displays;Visual odometry;Optimization;Navigation;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463163&isnumber=8460178

N. Stefas, P. A. Plonski and V. Isler, "Approximation Algorithms for Tours of Orientation-Varying View Cones," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3910-3915.
doi: 10.1109/ICRA.2018.8462908
Abstract: This paper considers the problem of finding the shortest tour to cover a given set of inverted cone views with apex angle α and height H when their apex points lie on a planar surface. This is a novel variant of the 3D Traveling Salesman Problem with intersecting Neighborhoods (TSPN) called Cone-TSPN. When the cones are allowed to tilt by an angle c we have the tilted Cone-TSPN problem, to which we present an algorithm that returns a solution with an approximation ratio of O (1+tan α/1-tan ϵ tan α (1 + log max(H)/min(H)). We demonstrate through simulations that our algorithm can be implemented in a practical way and by exploiting the structure of the cones we can achieve shorter tours. Finally, we present results from covering a reflective surface (lake area) that shows the importance of selecting different view angles under strong sunlight specularities.
keywords: {Approximation algorithms;Three-dimensional displays;Task analysis;Traveling salesman problems;Lakes;Animals;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462908&isnumber=8460178

M. Ourak, B. Tamadazte, G. J. Laurent and N. Andreff, "Geometric Calibration of an OCT Imaging System," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3993-3999.
doi: 10.1109/ICRA.2018.8463171
Abstract: This paper deals with an OCT (optical coherence tomography) geometric calibration method. OCT medical imaging system has received a growing interest during the last two decades. In medical purposes, OCT images are generally called optical biopsies which allows in-vivo investigation almost similar to a histopathological study. The physician can rely on the OCT images to establish a rapid and direct diagnosis. But the OCT images formation suffered numerous distortions due in particular to the optical path, from the source to the viewed sample passing through the two reflecting mirrors and a scan objective. The obtained optical biopsies include several spectral and geometric distortions. The proposed calibration model aims to compensate the geometrical ones. More precisely, two models were developed allowing the correction of both 2D images (B-Scan slices) and 3D images (volume). These models were experimentally validated (in both artificial and biological samples) using a spectral domain OCT system. It has demonstrated a significant enhancement of the OCT images accuracy.
keywords: {Optical distortion;Distortion;Optical imaging;Mirrors;Adaptive optics;Two dimensional displays;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463171&isnumber=8460178

Y. Adagolodjo, N. Golse, E. Vibert, M. De Mathelin, S. Cotin and H. Courtecuisse, "Marker-Based Registration for Large Deformations - Application to Open Liver Surgery," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4007-4012.
doi: 10.1109/ICRA.2018.8462909
Abstract: This paper introduces an Augmented Reality (AR) system for open liver surgery. Although open surgery remains the gold-standard for the treatment of complex tumors and central lesions, technological issues actually prevent using AR with sufficient accuracy for clinical use. We propose a markers-based method allowing for the tracking and the deformation of a preoperative model in real-time during the surgery. Markers are manually placed on the surface of the organ after opening the abdominal cavity, and tracked in real-time by a set of infrared cameras. Our framework is composed of both a nonrigid initial registration method, providing an estimation of the location of the markers in the preoperative model, and a realtime tracking algorithm to deform the model during the surgery (even for large deformation or partial occlusion of the organ). The method is validated on both synthetic and ex-vivo samples; in addition, we demonstrate its applicability in the operating room during a liver resection surgery on a human patient. Preliminary studies provided promising results to improve the location of tumors, and to help surgeons into planning the ideal resection intraoperatively.
keywords: {Surgery;Strain;Liver;Cameras;Deformable models;Biological system modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462909&isnumber=8460178

M. Draelos, B. Keller, G. Tang, A. Kuo, K. Hauser and J. Izatt, "Real-Time Image-Guided Cooperative Robotic Assist Device for Deep Anterior Lamellar Keratoplasty," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4013-4018.
doi: 10.1109/ICRA.2018.8463153
Abstract: Deep anterior lamellar keratoplasty (DALK) is a promising technique for corneal transplantation that avoids the chronic immunosuppression comorbidities and graft rejection risk associated with penetrating keratoplasty (PKP), the standard procedure. In DALK, surgeons must insert a needle 90% through the 500 μm cornea without penetrating its underlying membrane. This pushes surgeons to their manipulation and visualization limits such that 59% of DALK attempts fail due to corneal perforation or inadequate needle depth. We propose a robot-assisted solution to jointly solve the manipulation and visualization challenges using a cooperatively-controlled, precise robot arm and live optical coherence tomography (OCT) imaging, respectively. Our system features an interface handle, with which the surgeon and robot cooperatively hold the tool, and a posterior corneal boundary virtual fixture driven by real-time OCT segmentation. A study in which three operators performed DALK needle insertions manually and cooperatively in ex vivo human corneas demonstrated an 84% improvement in perforation-free needle depth without an increased perforation rate.
keywords: {Needles;Surgery;Robot sensing systems;Visualization;Tools;Cornea;Cooperative control;medical robotics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463153&isnumber=8460178

K. Borvorntanajanya and J. Suthakorn, "Hall Effect Sensing Workspace Estimation with Non-Permanent Magnetic Needle for Eye Anesthesia Training System via Robotic Experiments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4019-4024.
doi: 10.1109/ICRA.2018.8461015
Abstract: Ophthalmic anesthesia is an important preparation for eye surgery. The conventional practice is performed blind in a cadaver under the supervision of an experienced surgeon. This paper introduces a needle tip tracking system for ophthalmic anesthesia training without major modification of an anesthesia needle. The study presents a prototyped system to track a magnetized needle tip using Hall-effect sensor array. The orbital structure model was embedded with Hall-effect sensors after considering the sensing workspace and ophthalmic anesthesia pathway. The extended Kalman filter was used to calculate needle tip position. A commercial robotic manipulator was used to model the characteristics of sensor and accuracy of the developed system. A prototype can detect needle tip position with a root-mean-square deviation around 1.80 mm. As a result, the system is capable of providing needle tip positions for training purposes.
keywords: {Needles;Robot sensing systems;Magnetic flux;Anesthesia;Orbits},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461015&isnumber=8460178

M. Zhou et al., "Precision Needle Tip Localization Using Optical Coherence Tomography Images for Subretinal Injection," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4033-4040.
doi: 10.1109/ICRA.2018.8460745
Abstract: Subretinal injection is a delicate and complex microsurgery, which requires surgeons to inject the therapeutic substance in a pre-operatively defined and intra-operatively updated subretinal target area. Due to the lack of subretinal visual feedback, it is hard to sense the insertion depth during the procedure, thus affecting the results of surgical outcome and hindering the widespread use of this treatment. This paper presents a novel approach to estimate the 3D position of the needle under the retina using the information from microscope-integrated Intraoperative Optical Coherence Tomography (iOCT). We evaluated our approach on both tissue phantom and ex-vivo porcine eyes. Evaluation results show that the average error in distance measurement is 4.7 μm (maximum of 16.5 μm). We furthermore, verified the feasibility of the proposed method to track the insertion depth of needle in robot-assisted subretinal injection.
keywords: {Needles;Retina;Surgery;Microscopy;Robots;Probes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460745&isnumber=8460178

M. Burkhardt, S. Karumanchi, K. Edelberg, J. W. Burdick and P. Backes, "Proprioceptive Inference for Dual-Arm Grasping of Bulky Objects Using RoboSimian," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4049-4056.
doi: 10.1109/ICRA.2018.8460776
Abstract: This work demonstrates dual-arm lifting of bulky objects based on inferred object properties (center of mass (COM) location, weight, and shape) using proprioception (i.e. force torque measurements). Data-driven Bayesian models describe these quantities, which enables subsequent behaviors to depend on confidence of the learned models. Experiments were conducted using the NASA Jet Propulsion Laboratory's (JPL) RoboSimian to lift a variety of cumbersome objects ranging in mass from 7kg to 25kg. The position of a supporting second manipulator was determined using a particle set and heuristics that were derived from inferred object properties. The supporting manipulator decreased the initial manipulator's load and distributed the wrench load more equitably across each manipulator, for each bulky object. Knowledge of the objects came from pure proprioception (i.e. without reliance on vision or other exteroceptive sensors) throughout the experiments.
keywords: {Manipulators;Probabilistic logic;Rotation measurement;Grasping;Shape;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460776&isnumber=8460178

Y. Kanemoto, T. Yoshiike, M. Muromachi and M. Osada, "Compact and High Performance Torque-Controlled Actuators and its Implementation to Disaster Response Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4057-4063.
doi: 10.1109/ICRA.2018.8460789
Abstract: Applying robots in narrow and cluttered disaster environments such as oil refineries requires a slim body and a wide range of motion. It is also necessary to have abilities to absorb unexpected contact with the environment and to walk on scattered debris. In this paper we propose new compact and high performance torque-controlled actuators for legged robots to satisfy the above mentioned requirements. For axial compactness, torque sensors are designed as ring-shaped thin cylinders surrounding motors or gears with strain gauges for sensing. To achieve broad bandwidth of torque control, we introduced an analog differentiator circuit into an analog digital converter (ADC) board in order to suppress noise in the differential control of joint torque. We also propose methods to reduce torque ripple caused by the deformation of the harmonic drive gear and electromagnetic interference (EMI) from a motor and a motor driver. Finally, experiments of a collision with objects and movement on scattered debris were executed with a fully torque-controlled legged robot built with the proposed actuators.
keywords: {Torque;Actuators;Robot sensing systems;Torque measurement;Strain measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460789&isnumber=8460178

D. Okumura, S. Sakaino and T. Tsuji, "High Dynamic Range Sensing by a Multistage Six-Axis Force Sensor with Stopper Mechanism," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4065-4070.
doi: 10.1109/ICRA.2018.8460571
Abstract: This paper describes the design of a high dynamic range (HDR) six-axis force/torque sensor. The sensor is composed of a high-rigidity flexure element detecting large force and a low-rigidity flexure element detecting small force. The overload on the low-rigidity flexure element is prevented by an overload protection mechanism. An HDR measurement is achieved by combining the outputs of the two flexure elements. A loading test for the designed sensor is performed, and the results indicate that the six-axis sensor measures force with a dynamic range from 0.01N to 1000 N.
keywords: {Robot sensing systems;Force sensors;Force;Strain;Force measurement;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460571&isnumber=8460178

K. Aquilina, D. A. W. Barton and N. F. Lepora, "Principal Components of Touch," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4071-4078.
doi: 10.1109/ICRA.2018.8461045
Abstract: Our human sense of touch enables us to manipulate our surroundings; therefore, complex robotic manipulation will require artificial tactile sensing. Typically tactile sensor arrays are used in robotics, implying that a straightforward way of interpreting multidimensional data is required. In this paper we present a simple visualisation approach based on applying principal component analysis (PCA) to systematically collected sets of tactile data. We apply the visualisation approach to 4 different types of tactile sensor, encompassing fingertips and vibrissal arrays. The results show that PCA can reveal structure and regularities in the tactile data, which also permits the use of simple classifiers such as k-NN to achieve good inference. Additionally, the Euclidean distance in principal component space gives a measure of sensitivity, which can aid visualisation and also be used to find regions in the tactile input space where the sensor is able to perceive with higher accuracy. We expect that these observations will generalise, and thus offer the potential for novel control methods based on touch.
keywords: {Principal component analysis;Tactile sensors;Data visualization;Sensor arrays;Pins},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461045&isnumber=8460178

T. Kim, S. Yoo, H. S. Kim and J. Kim, "Design and Force-Tracking Impedance Control of a 2-DOF Wall-Cleaning Manipulator Using Disturbance Observer and Sliding Mode Control," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4079-4084.
doi: 10.1109/ICRA.2018.8460897
Abstract: This paper presents design and force-tracking impedance control of 2-degree-of-freedom (DOF) wall-cleaning manipulator equipped with disturbance observer (DOB) and sliding mode control (SMC). In order to keep in contact with various shapes of walls, the proposed manipulator is designed to ensure 2-DOF motions of translation and tilting by using ball screws. The position-based force tracking impedance control (FTIC) is first adopted for the proposed manipulator not only to interact with walls in a desired dynamic behavior but also to maintain a constant contact force. Also, to improve the force tracking capability of proposed manipulator against different walls and brushes for manipulator, the FTIC is combined with the disturbance observer (DOB) and the sliding mode control (SMC). Extensive experiments prove that although different brushes used for manipulator rotate against varying shapes of walls, the proposed manipulator can keep a constant contact force within a bound of ± 4.5 N by virtue of the proposed FTIC equipped with the DOB and the SMC.
keywords: {Force;Manipulator dynamics;Brushes;Impedance;Dynamics;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460897&isnumber=8460178

D. Song, T. Lee and Y. J. Kim, "Artistic Pen Drawing on an Arbitrary Surface Using an Impedance-Controlled Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4085-4090.
doi: 10.1109/ICRA.2018.8461084
Abstract: We present a semi-autonomous robotic pen-drawing system that is capable of creating pen art on an arbitrary surface with varying thickness of pen strokes but without reconstructing the surface explicitly. Our robotic system relies on an industrial, seven-degree-of-freedom (7DoF) manipulator that can be both position- and impedance-controlled. We use a vector-graphics engine to take an artist's pen drawing as input and generate Bézier spline curves with varying offsets. In order to estimate geometric details of the target, unknown surface, during drawing, we rely on incremental and adaptive sampling on the surface using a combination of position and impedance control. Then, our control algorithm physically replicates this drawing on any arbitrary, continuous surface by impedance-controlling the manipulator. We demonstrate that our system can create visually-pleasing and complicated artistic pen drawings on general surfaces without explicit surface-reconstruction nor visual feedback.
keywords: {Surface impedance;Robot sensing systems;Service robots;Surface reconstruction;Rendering (computer graphics);Art},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461084&isnumber=8460178

M. Karlsson, A. Robertsson and R. Johansson, "Detection and Control of Contact Force Transients in Robotic Manipulation Without a Force Sensor," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4091-4096.
doi: 10.1109/ICRA.2018.8461104
Abstract: In this research, it is shown that robot joint torques can be used to recognize contact force transients induced during robotic manipulation, thus detecting when a task is completed. The approach does not assume any external sensor, which is a benefit compared to the state of the art. The joint torque data are used as input to a recurrent neural network (RNN), and the output of the RNN indicates whether the task is completed. A real-time application for force transient detection is developed, and verified experimentally on an industrial robot.
keywords: {Robot sensing systems;Transient analysis;Training;Switches;Task analysis;Data models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461104&isnumber=8460178

X. Xie et al., "Unsupervised Learning of Hierarchical Models for Hand-Object Interactions," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4097-4102.
doi: 10.1109/ICRA.2018.8461214
Abstract: Contact forces of the hand are visually unobservable, but play a crucial role in understanding hand-object interactions. In this paper, we propose an unsupervised learning approach for manipulation event segmentation and manipulation event parsing. The proposed framework incorporates hand pose kinematics and contact forces using a low-cost easy-to-replicate tactile glove. We use a temporal grammar model to capture the hierarchical structure of events, integrating extracted force vectors from the raw sensory input of poses and forces. The temporal grammar is represented as a temporal And-Or graph (T-AOG), which can be induced in an unsupervised manner. We obtain the event labeling sequences by measuring the similarity between segments using the Dynamic Time Alignment Kernel (DTAK). Experimental results show that our method achieves high accuracy in manipulation event segmentation, recognition and parsing by utilizing both pose and force data.
keywords: {Force;Grammar;Robot sensing systems;Task analysis;Motion segmentation;Unsupervised learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461214&isnumber=8460178

F. Y. Wu and H. H. Asada, "Decoupled Motion Control of Wearable Robot for Rejecting Human Induced Disturbances," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4103-4110.
doi: 10.1109/ICRA.2018.8461109
Abstract: When a human performs a task with the assistance of wearable extra limbs, the human movement for performing the task may inadvertently disturb the position and orientation of the robot base, making it difficult for the robot to properly carry out its objective. Therefore, unlike self-standing robots, a wearable robot must not only assist the user without interfering or prohibiting the natural human movement, but also have the capability to detect and reject disturbances caused by the wearer's motion. This paper examines such a situation, where the human attempts to twist open a bottle while a pair of robotic fingers mounted on the same arm holds the bottle in place. As the human arm rotates to twist the cap, the robot and consequently the bottle would rotate in that same direction, which makes separation of the cap from the bottle almost impossible. To compensate for the human induced disturbances, a data-driven latent space impedance control method is developed such that the robot can secure the bottle and at the same time allow natural human movement to be carried out during manipulation. Simulation and experiments have demonstrated the efficacy of the latent space impedance controller to enable single-handed object manipulation with the assistance of wearable robotic fingers.
keywords: {5G mobile communication;Conferences;Automation;Australia},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461109&isnumber=8460178

G. Ponraj and H. Ren, "Estimation of Object Orientation Using Conductive Ink and Fabric Based Multilayered Tactile Sensor," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4135-4141.
doi: 10.1109/ICRA.2018.8461031
Abstract: Robots, either made from hard or soft materials, are being used increasingly for unknown object manipulation tasks in unstructured environments. To hold an object firmly and do the required task, the orientation of the object with respect to the robotic hand gripper is one of the necessary key information. Humans can sense the orientation of an object based on vision, kinesthetic sensation, or touch sensation. Similarly, robots shall also be able to estimate grasped object orientation just based on tactile sensing without knowing manipulator kinesthetic or kinematics. Existing sensors are mostly based on vision or rigid inertial measurement units (such as accelerometers, gyroscopes, magnetometers), which require additional setup and are typically not compliant with the arbitrary surfaces of the unknown obj ects. This paper discusses a new approach for object orientation estimation from a multilayered tactile sensor based on conductive silver ink and conductive fabric. Fabric based sensors are flexible and can confer to both hard and soft surfaces. Experimental results show that the tactile sensor developed is able to estimate the tilt angle without any information about manipulator kinematics.
keywords: {Ink;Fabrics;Tactile sensors;Piezoresistance;Silver;Fabric Tactile sensor;Multilayered sensor;Tilt sensing;Conductive silver ink},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461031&isnumber=8460178

Y. Kamikawa, N. Enayati and A. M. Okamura, "Magnified Force Sensory Substitution for Telemanipulation via Force-Controlled Skin Deformation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4142-4148.
doi: 10.1109/ICRA.2018.8460810
Abstract: Teleoperation systems could benefit from force sensory substitution when kinesthetic force feedback systems are too bulky or expensive, and when they cause instability by magnifying force feedback. We aim to magnify force feedback using sensory substitution via force-controlled tactile skin deformation, using a device with the ability to provide tangential and normal force directly to the fingerpads. The sensory substitution device is able to provide skin deformation force feedback over ten times the maximum stable kinesthetic force feedback on a da Vinci Research Kit teleoperation system. We evaluated the effect of this force magnification in two experimental tasks where the goal was to minimize interaction force with the environment. In a peg transfer task, magnified force feedback using sensory substitution improved participants' performance for force magnifications up to ten times, but decreased performance for higher force magnifications. In a tube connection task, sensory substitution that doubled the force feedback maximized performance; there was no improvement at the larger magnifications. These experiments demonstrate that magnified force feedback using sensory substitution via force-controlled skin deformation feedback can decrease applied forces similarly to magnified kinesthetic force feedback during teleoperation.
keywords: {Force;Force feedback;Manipulators;Robot sensing systems;Skin;Strain;Force sensors;Haptics and Haptic Interfaces;Surgical Robotics;Laparoscopy;Force Control;Telerobotics and Teleoperation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460810&isnumber=8460178

J. D. Greer, L. H. Blumenschein, A. M. Okamura and E. W. Hawkes, "Obstacle-Aided Navigation of a Soft Growing Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4165-4172.
doi: 10.1109/ICRA.2018.8460777
Abstract: For many types of robots, avoiding obstacles is necessary to prevent damage to the robot and environment. As a result, obstacle avoidance has historically been an important problem in robot path planning and control. Soft robots represent a paradigm shift with respect to obstacle avoidance because their low mass and compliant bodies can make collisions with obstacles inherently safe. Here we consider the benefits of intentional obstacle collisions for soft robot navigation. We develop and experimentally verify a model of robot-obstacle interaction for a tip-extending soft robot. Building on the obstacle interaction model, we develop an algorithm to determine the path of a growing robot that takes into account obstacle collisions. We find that obstacle collisions can be beneficial for open-loop navigation of growing robots because the obstacles passively steer the robot, both reducing the uncertainty of the location of the robot and directing the robot to targets that do not lie on a straight path from the starting point. Our work shows that for a robot with predictable and safe interactions with obstacles, target locations in a cluttered, mapped environment can be reached reliably by simply setting the initial trajectory. This has implications for the control and design of robots with minimal active steering.
keywords: {Collision avoidance;Computational modeling;Kinematics;Pneumatic systems;Soft robotics;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460777&isnumber=8460178

R. B. N. Scharff et al., "Color-Based Sensing of Bending Deformation on Soft Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4181-4187.
doi: 10.1109/ICRA.2018.8460521
Abstract: This paper introduces a novel approach for sensing the bending deformation on soft robots by leveraging multicolor 3D printing. The measurement of deformation enables to complete the feedback loop of deformation control on soft actuators. The working principle of our approach is based on using compact color sensors to detect deformation that is visualized by the change of color ratios. Two novel designs are presented to generate color signals on 3D printed objects, which we call an external signal generator and an internal signal generator. Signal processing and calibration methods are developed to transform the raw RGB-data into a meaningful deformation metric. Our experimental tests taken on soft pneumatic actuators verify that color signals can be stably generated and captured to indicate the bending deformation. The results also demonstrate the usability of this sensing approach in deformation control.
keywords: {Color;Strain;Actuators;Robot sensing systems;Signal generators;Soft robotics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460521&isnumber=8460178

J. Cao, W. Liang, Q. Ren, U. Gupta, F. Chen and J. Zhu, "Modelling and Control of a Novel Soft Crawling Robot Based on a Dielectric Elastomer Actuator," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4188-4193.
doi: 10.1109/ICRA.2018.8460784
Abstract: Soft robots have recently evoked extensive attention due to their abilities to work effectively in unstructured environments. As an actuation technology of soft robots, dielectric elastomers exhibit many intriguing attributes such as large strain and high energy density. This work presents a novel dielectric elastomer based soft crawling robot inspired by inchworms. To fill the need of control of the soft robot, a model describing the interaction between the dielectric elastomer actuator and the environment is proposed, which takes inertia, viscoelasticity and friction into consideration. The model can well describe the robot's dynamic performances and the modelling approach used here can be extended to other dielectric elastomer actuators with complicated geometries for control purposes. The obtained model allows us to design a feedforward plus feedback control scheme for the robot to achieve desired motion. Simulation shows fast response and good tracking performances which are further confirmed by the experiments.
keywords: {Force;Actuators;Soft robotics;Friction;Steady-state;Electrodes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460784&isnumber=8460178

G. Fang, C. -D. Matte, T. -H. Kwok and C. C. L. Wang, "Geometry-based Direct Simulation for Multi-Material Soft Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4194-4199.
doi: 10.1109/ICRA.2018.8461088
Abstract: Robots fabricated by soft materials can provide higher flexibility and thus better safety while interacting with natural objects with low stiffness such as food and human beings. However, as many more degrees of freedom are introduced, the motion simulation of a soft robot becomes cumbersome, especially when large deformations are presented. Moreover, when the actuation is defined by geometry variation, it is not easy to obtain the exact loads and material properties to be used in the conventional methods of deformation simulation. In this paper, we present a direct approach to take the geometric actuation as input and compute the deformed shape of soft robots by numerical optimization using a geometry-based algorithm. By a simple calibration, the properties of multiple materials can be modeled geometrically in the framework. Numerical and experimental tests have been conducted to demonstrate the performance of our approach on both cable-driven and pneumatic actuators in soft robotics.
keywords: {Shape;Soft robotics;Strain;Computational modeling;Optimization;Numerical models;Deformable models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461088&isnumber=8460178

X. Wang, H. Faraji and Y. Mengüç, "Incorporate Oblique Muscle Contractions to Strengthen Soft Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4200-4205.
doi: 10.1109/ICRA.2018.8461139
Abstract: For the state-of-the-art of soft robotics, the current actuation mechanisms cannot produce shear forces, neither are the current stiffening mechanisms adaptive to various deformations. Consequently, the soft robots gain strength at the price of losing flexibility. To fill this gap, we proposed a new mechanism based on the muscle arrangements and incompressible property identified in biological hydrostatic skeletons. Beside longitudinal and transverse muscles, the proposed mechanism includes the oblique arrangement which is proved to play an indispensable role of producing shear forces. The effectiveness of the new mechanism is demonstrated through a benchmark problem - carrying a distributed load at the initial horizontal configuration, thus indicating an improved direction to realise shape-independent load-carrying capability of soft robotics. Furthermore, the proposed mechanism may explain how elephants coordinate the two contradicting properties, strength and flexibility, during their trunk manipulations.
keywords: {Muscles;Skeleton;Strain;Shape;Soft robotics;Force;Frequency modulation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461139&isnumber=8460178

M. Pozzi et al., "Efficient FEM-Based Simulation of Soft Robots Modeled as Kinematic Chains," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4206-4213.
doi: 10.1109/ICRA.2018.8461106
Abstract: In the context of robotic manipulation and grasping, the shift from a view that is static (force closure of a single posture) and contact-deprived (only contact for force closure is allowed, everything else is obstacle) towards a view that is dynamic and contact-rich (soft manipulation) has led to an increased interest in soft hands. These hands can easily exploit environmental constraints and object surfaces without risk, and safely interact with humans, but present also some challenges. Designing them is difficult, as well as predicting, modelling, and “programming” their interactions with the objects and the environment. This paper tackles the problem of simulating them in a fast and effective way, leveraging on novel and existing simulation technologies. We present a triple-layered simulation framework where dynamic properties such as stiffness are determined from slow but accurate FEM simulation data once, and then condensed into a lumped parameter model that can be used to fast simulate soft fingers and soft hands. We apply our approach to the simulation of soft pneumatic fingers.
keywords: {Computational modeling;Actuators;Deformable models;Finite element analysis;Data models;Object oriented modeling;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461106&isnumber=8460178

R. Krug, Y. Bekiroglu, D. Kragic and M. A. Roa, "Evaluating the Quality of Non-Prehensile Balancing Grasps," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4215-4220.
doi: 10.1109/ICRA.2018.8461078
Abstract: Assessing grasp quality and, subsequently, predicting grasp success is useful for avoiding failures in many autonomous robotic applications. In addition, interest in nonprehensile grasping and manipulation has been growing as it offers the potential for a large increase in dexterity. However, while force-closure grasping has been the subject of intense study for many years, few existing works have considered quality metrics for non-prehensile grasps. Furthermore, no studies exist to validate them in practice. In this work we use a real-world data set of non-prehensile balancing grasps and use it to experimentally validate a wrench-based quality metric by means of its grasp success prediction capability. The overall accuracy of up to 84 % is encouraging and in line with existing results for force-closure grasps.
keywords: {Task analysis;Measurement;Force;Robots;Grasping;Friction;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461078&isnumber=8460178

D. Rodriguez, C. Cogswell, S. Koo and S. Behnke, "Transferring Grasping Skills to Novel Instances by Latent Space Non-Rigid Registration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4229-4236.
doi: 10.1109/ICRA.2018.8461169
Abstract: Robots acting in open environments need to be able to handle novel objects. Based on the observation that objects within a category are often similar in their shapes and usage, we propose an approach for transferring grasping skills from known instances to novel instances of an object category. Correspondences between the instances are established by means of a non-rigid registration method that combines the Coherent Point Drift approach with subspace methods. The known object instances are modeled using a canonical shape and a transformation which deforms it to match the instance shape. The principle axes of variation of these deformations define a low-dimensional latent space. New instances can be generated through interpolation and extrapolation in this shape space. For inferring the shape parameters of an unknown instance, an energy function expressed in terms of the latent variables is minimized. Due to the class-level knowledge of the object, our method is able to complete novel shapes from partial views. Control poses for generating grasping motions are transferred efficiently to novel instances by the estimated non-rigid transformation.
keywords: {Shape;Grasping;Strain;Aerospace electronics;Three-dimensional displays;Robots;Coherence},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461169&isnumber=8460178

A. Kothari, J. Morrow, V. Thrasher, K. Engle, R. Balasubramanian and C. Grimm, "Grasping Objects Big and Small: Human Heuristics Relating Grasp-Type and Object Size," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4237-4242.
doi: 10.1109/ICRA.2018.8460860
Abstract: This paper presents an online data collection method that captures human intuition about what grasp types are preferred for different fundamental object shapes and sizes. Survey questions are based on an adopted taxonomy that combines grasp pre-shape, approach, wrist orientation, object shape, orientation and size which covers a large swathe of common grasps. For example, the survey identifies at what object height or width dimension (normalized by robot hand size) the human prefers to use a two finger precision grasp versus a three-finger power grasp. This information is represented as a confidence-interval based polytope in the object shape space. The result is a database that can be used to quickly find potential pre-grasps that are likely to work, given an estimate of the object shape and size.
keywords: {Shape;Taxonomy;Robots;Grasping;Planning;Videos;Data collection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460860&isnumber=8460178

K. Bousmalis et al., "Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4243-4250.
doi: 10.1109/ICRA.2018.8460875
Abstract: Instrumenting and collecting annotated visual grasping datasets to train modern machine learning algorithms can be extremely time-consuming and expensive. An appealing alternative is to use off-the-shelf simulators to render synthetic data for which ground-truth annotations are generated automatically. Unfortunately, models trained purely on simulated data often fail to generalize to the real world. We study how randomized simulated environments and domain adaptation methods can be extended to train a grasping system to grasp novel objects from raw monocular RGB images. We extensively evaluate our approaches with a total of more than 25,000 physical test grasps, studying a range of simulation conditions and domain adaptation methods, including a novel extension of pixel-level domain adaptation that we term the GraspGAN. We show that, by using synthetic data and domain adaptation, we are able to reduce the number of real-world samples needed to achieve a given level of performance by up to 50 times, using only randomly generated simulated objects. We also show that by using only unlabeled real-world data and our GraspGAN methodology, we obtain real-world grasping performance without any real-world labels that is similar to that achieved with 939,777 labeled real-world samples.
keywords: {Grasping;Robots;Training;Feature extraction;Adaptation models;Cameras;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460875&isnumber=8460178

C. Erdogan, A. Schröder and O. Brock, "Coordination of Intrinsic and Extrinsic Degrees of Freedom in Soft Robotic Grasping," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4251-4256.
doi: 10.1109/ICRA.2018.8461075
Abstract: We demonstrate that moving the wrist while the fingers perform a grasp increases performance. The coordination shapes the interactions between the fingers, the object and its environment to extend the hand capabilities (e.g. higher payload and precision). We evaluated our hypothesis with a human grasping study where the volunteers grasped objects by moving the soft RBO Hand 2 while its fingers closed in a predefined motion. We limited their ability to coordinate their motion with the finger movements using a compliant robot attached to the hand, and observed that their grasp success decreases with increased constraints. We also successfully transferred one of the observed movement patterns to the robot, indicating that adaptive intrinsic/extrinsic motion increases robotic grasp performance as well.
keywords: {Robot kinematics;Grasping;Wrist;Manipulators;Protocols;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461075&isnumber=8460178

M. Ojer De Andres, M. Mahdi Ghazaei Ardakani and A. Robertsson, "Reinforcement Learning for 4-Finger-Gripper Manipulation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4257-4262.
doi: 10.1109/ICRA.2018.8461153
Abstract: In the framework of robotics, Reinforcement Learning (RL) deals with the learning of a task by the robot itself. This paper presents a hierarchical-planning approach in which the robot learns the optimal behavior for different levels in a decoupled way. For high-level discrete actions, Q-learning was chosen, whereas for the low level we utilize Policy Improvement with Path Integrals (PI2) algorithm to learn the parameters of policies, represented by rhythmic Dynamic Movement Primitives (DMPs). The paper studies the case of a 4-finger-gripper manipulator, which performs the task of continuously spinning a ball around a desired axis. The results demonstrate the efficacy of the hierarchical planning and the increased performance of the task when PI2 is used in conjunction with rhythmic DMPs in a real environment.
keywords: {Robots;Trajectory;Task analysis;Planning;Heuristic algorithms;Learning (artificial intelligence);Approximation algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461153&isnumber=8460178

S. Ceron, A. Kurumunda, E. Garg, M. Kim, T. Yeku and K. Pctersen, "Popcorn-Driven Robotic Actuators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4271-4276.
doi: 10.1109/ICRA.2018.8461147
Abstract: Popcorn kernels are a natural, edible, and inexpensive material that has the potential to rapidly expand with high force upon application of heat. Although this transition is irreversible, it carries potential for several robotic applications. Here, we examine relevant characteristics of three types of kernels including expansion ratio, transition temperature, popping force, compression strength, and biodegradability. We test the viability of popping by hot oil, hot air, microwaves, and direct contact with heated Nichrome wire. As kernels can change from regular to (larger) irregular shapes, we examine the change in inter-granular friction and propose their use as granular fluids in jamming actuators, without the need for a vacuum pump. Furthermore, as a proof-of-concept, we also demonstrate the use of popcorn-driven actuation in soft, compliant, and rigid-link grippers. Serving as a first introduction of popcorn into robotics, we hope this paper will inspire novel mechanisms for multi-functional designs.
keywords: {Kernel;Heating systems;Robots;Jamming;Actuators;Force;Wires},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461147&isnumber=8460178

F. wu and M. Howard, "A Hybrid Dynamic-Regenerative Damping Scheme for Energy Regeneration in Variable Impedance Actuators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4277-4282.
doi: 10.1109/ICRA.2018.8460207
Abstract: Increasing research efforts have been made to improve the energy efficiency of variable impedance actuators (VIAs) through reduction of energy consumption. However, the harvesting of dissipated energy in such systems remains under-explored. This study proposes a novel variable damping module design enabling energy regeneration in VIAs by exploiting the regenerative braking effect of DC motors. The proposed damping module uses four switches to combine regenerative and dynamic braking, in a hybrid approach that enables energy regeneration without reduction in the range of damping achievable. Numerical simulations and a physical experiment are presented in which the proposed module shows an optimal trade-off between task-performance and energy efficiency.
keywords: {Damping;Resistance;Actuators;DC motors;Task analysis;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460207&isnumber=8460178

A. Thoesen, S. Ramirez and H. Marvi, "Screw-Powered Propulsion in Granular Media: An Experimental and Computational Study," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4283-4288.
doi: 10.1109/ICRA.2018.8460916
Abstract: Screw-Propelled Vehicles (SPV's) have been widely used for terrestrial applications such as transportation over mud, snow, and amphibious environments. Similar vehicles have also been applied to industrial processes such as dewatering. Typical designs rely on a large pontoon shaft and relatively small blades to prevent unwanted sinkage or blade damage. These types of vehicles were considered during the design of the first lunar rover, given their success in aqueous and arctic media and simplicity compared to tracked vehicles. Studies have looked at the mobility of SPV's on the surface of granular media but there are not any computational and experimental studies on propulsive buried screws. Understanding the role of screw design and its angular velocity on thrust force is key to the advancement and control of SPV's. This study presents experimental and computational results of a submerged, double-helix Archimedes screw generating propulsive force against a bed of soda-lime glass beads. Thus, this research forms the basis for design of a future miniaturized exploration vehicle for space applications. In our study, we used two different screw designs (5 cm radius, 10 cm length, 63 and 44 degrees helix angle corresponding to 4 cm and 8 cm pitch, respectively) submerged in 2mm glass beads (90% roundness with sizes 1.8 mm to 2.2 mm), For both screws, a similar trend is observed between rotational speed and thrust force. We used EDEM, a Discrete Element Modeling (DEM) software for computational studies of the screw interactions with granular media. There is 5-20% discrepancy between our computational and experimental results. We will discuss possible sources of error and the potential for using DEM as a design tool for SPV's.
keywords: {Fasteners;Friction;Force;Glass;Media;Young's modulus;Propulsion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460916&isnumber=8460178

E. R. Perez-Guagnelli, S. Nejus, J. Yu, S. Miyashita, Y. Liu and D. D. Damian, "Axially and Radially Expandable Modular Helical Soft Actuator for Robotic Implantables," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4297-4304.
doi: 10.1109/ICRA.2018.8461239
Abstract: Soft robotics has advanced the field of biomedical engineering by creating safer technologies for interfacing with the human body. One of the challenges in this field is the realization of modular soft basic constituents and accessible assembly methods to increase the versatility of soft robots. We present a soft pneumatic actuator composed of two elastomeric strands that provide interdependent axial and radial expansion due to the modularity of the components and their helical arrangement. The actuator reaches 35% of elongation with respect to its initial height and both chambers achieve forces of 1N at about 19kPa. We describe the design, fabrication, modeling and benchtop testing of the soft actuator towards realizing 3D functional structures with potential medical applications. An example of application for soft medical robots is tissue regenerative for the long-gap esophageal atresia condition.
keywords: {Actuators;Implants;Soft robotics;Esophagus;Surgery;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461239&isnumber=8460178

T. Schlinquer, A. Mohand-Ousaid and M. Rakotondrabe, "Displacement Amplifier Mechanism for Piezoelectric Actuators Design Using SIMP Topology Optimization Approach," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4305-4311.
doi: 10.1109/ICRA.2018.8460183
Abstract: Due to their inherent crystalline properties piezoelectric actuators have a limited deformation. This intrinsic drawback deprives to exploit the potential of these actuators such as, high bandwidth and high resolution in applications that require large displacement range. To overcome this limitation, classical as well as systematic approaches were proposed to design amplification mechanisms. The classical approach leads to empirical mechanisms which are not trivial and needs much experience and intuition. In contrast, systematic approach uses topology optimization method which permits to automatically derive optimal designs that can satisfy specified performances and imposed constraints simultaneously, this with a reasonable time and cost. This paper proposes the design of a mechanism devoted to amplify the displacement of a piezoelectric actuators (PEA). Based on the SIMP topology optimization method, the approach permits to derive a design with a displacement amplification ratio of 4.5, which is higher than with the existing method of Rhombus mechanism. Both finite element (FE) simulation and experimental results confirm and demonstrate the efficiency of the approach.
keywords: {Optimization;Topology;Force;Piezoelectric actuators;Sensitivity;Mathematical model;piezoelectric actuators;optimal design;compliant structure;SIMP topology optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460183&isnumber=8460178

J. A. R. Silva and V. Grassi, "Clothoid-Based Global Path Planning for Autonomous Vehicles in Urban Scenarios," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4312-4318.
doi: 10.1109/ICRA.2018.8461201
Abstract: Intelligent vehicles require an efficient way to compute a feasible path that connects its current localization to a destination point. To achieve that, the knowledge about the road network, including its geometry, is important since connections between roads can be used in the path planning. This work consists on computing a feasible global path for autonomous vehicles with kinematic constraints. Piecewise linear continuous-curvature paths composed of clothoids, circular arcs, and straight lines are used for this purpose. Low curvature derivatives provide comfort to passengers. This approach provides a compact road network representation as only the parameters of the curves are stored. A real urban scenario with straight and curved roads, multiple lanes, intersections, and roundabouts is modeled and the proposed approach is validated. As a result of the proposed approaches, door-to-door global continuous-curvature paths are generated considering the shortest traveled distance.
keywords: {Roads;Path planning;Geometry;Autonomous vehicles;Wheels;Kinematics;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461201&isnumber=8460178

S. Song and S. Jo, "Surface-Based Exploration for Autonomous 3D Modeling," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4319-4326.
doi: 10.1109/ICRA.2018.8460862
Abstract: In this study, we addressed a path planning problem of a mobile robot to construct highly accurate 3D models of an unknown environment. Most studies have focused on exploration approaches, which find the most informative viewpoint or trajectories by analyzing a volumetric map. However, the completion of a volumetric map does not necessarily describe the completion of a 3D model. A highly complicated structure sometimes cannot be represented as a volumetric model. We propose a novel exploration algorithm that considers not only a volumetric map but also reconstructed surfaces. Unlike previous approaches, we evaluate the model completeness according to the quality of the reconstructed surfaces and extract low-confidence surfaces. The surface information is used to guide the computation of the exploration path. Experimental results showed that the proposed algorithm performed better than other state-of-the-art exploration methods and especially improved the completeness and confidence of the 3D models.
keywords: {Surface reconstruction;Computational modeling;Three-dimensional displays;Robot sensing systems;Inspection;Mobile robots;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460862&isnumber=8460178

P. Lertkultanon, J. Yang, H. Pham and Q. Pham, "Departure and Conflict Management in Multi-Robot Path Coordination," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4327-4333.
doi: 10.1109/ICRA.2018.8460587
Abstract: This paper addresses the problem of multi-robot path coordination, considering specific features that arise in applications such as automatic aircraft taxiing or driver-less cars coordination. The first feature is departure events: when robots arrive at their destinations (e.g. the runway for takeoff), they can be removed from the coordination diagram. The second feature is the “no-backward-movement” constraint: the robots can only move forward on their assigned paths. These features can interact to give rise to complex conflict situations, which existing planners are unable to solve in practical time. We propose a set of algorithms to efficiently account for these features and validate these algorithms on a realistic model of Charles de Gaulle airport.
keywords: {Robot kinematics;Planning;Aircraft;Collision avoidance;Airports;Automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460587&isnumber=8460178

A. Dornbush, K. Vijayakumar, S. Bardapurkar, F. Islam, M. Ito and M. Likhachev, "A Single-Planner Approach to Multi-Modal Humanoid Mobility," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4334-4341.
doi: 10.1109/ICRA.2018.8461134
Abstract: In this work, we present an approach to planning for humanoid mobility. Humanoid mobility is a challenging problem, as the configuration space for a humanoid robot is intractably large, especially if the robot is capable of performing many types of locomotion. For example, a humanoid robot may be able to perform such tasks as bipedal walking, crawling, and climbing. Our approach is to plan for all these tasks within a single search process. This allows the search to reason about all the capabilities of the robot at any point, and to derive the complete solution such that the plan is guaranteed to be feasible. A key observation is that we often can roughly decompose a mobility task into a sequence of smaller tasks, and focus planning efforts to reason over much smaller search spaces. To this end, we leverage the results of a recently developed framework for planning with adaptive dimensionality, and incorporate the capabilities of available controllers directly into the planning process. The resulting planner can also be run in an interleaved fashion alongside execution so that time spent idle is much reduced.
keywords: {Planning;Task analysis;Aerospace electronics;Legged locomotion;Superluminescent diodes;Humanoid robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461134&isnumber=8460178

M. Hutchinson, C. Liu and W. -H. Chen, "Information Based Mobile Sensor Planning for Source Term Estimation of a Non-Continuous Atmospheric Release," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4342-4347.
doi: 10.1109/ICRA.2018.8460686
Abstract: Ahstract- This paper presents a method to estimate the original location and the mass of an instantaneous release of hazardous material into the atmosphere. It is formulated as an inverse problem, where concentration observations from a mobile sensor are fused with meteorological information and a Gaussian puff dispersion model to characterise the source. Bayes' theorem is used to estimate the parameters of the release taking into account the uncertainty that exists in the dispersion parameters and meteorological variables. An information based reward is used to guide an unmanned aerial vehicle equipped with a chemical sensor to the expected most informative measurement locations. Simulation results compare the performance between a single mobile sensor with various amounts of static sensors.
keywords: {Robot sensing systems;Dispersion;Atmospheric modeling;Unmanned aerial vehicles;Position measurement;Wind speed;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460686&isnumber=8460178

J. -H. Chen and K. -T. Song, "Collision-Free Motion Planning for Human-Robot Collaborative Safety Under Cartesian Constraint," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4348-4354.
doi: 10.1109/ICRA.2018.8460185
Abstract: This paper presents a real-time motion planning and control design of a robotic arm for human-robot collaborative safety. A novel collision-free motion planning method is proposed not only to keep robot body from colliding with objects but also preserve the execution of robot's original task under the Cartesian constraint of the environment. Multiple KinectV2 depth cameras are utilized to model and track dynamic obstacles (e.g. Humans and objects) inside the robot workspace. Depth images are applied to generate point cloud of segmented objects in the environment. A K-nearest neighbor (KNN) searching algorithm is used to cluster and find the closest point from the obstacle to the robot. Then a Kalman filter is applied to estimate the obstacle position and velocity. For the collision avoidance in collaborative operation, attractive and repulsive potential is generated for robot end effector based on the task specification and obstacle observation. Practical experiments show that the 6-DOF robot arm can effectively avoid an obstacle in a constrained environment and complete the original task.
keywords: {Robots;Collision avoidance;Force;Planning;Three-dimensional displays;Collaboration;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460185&isnumber=8460178

L. Larocque and J. Liu, "Sampling-Based Motion Planning with μ-Calculus Specifications Without Steering," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4355-4360.
doi: 10.1109/ICRA.2018.8460769
Abstract: While using temporal logic specifications with motion planning has been heavily researched, the reliance on having an available steering function is impractical and often suited only to basic problems with linear dynamics. This is because a steering function is a solution to an optimal two-point boundary value problem (OBVP); to our knowledge, it is nearly impossible to find an analytic solution to such problems in many cases. Addressing this issue, we have developed a means of combining the asymptotically optimal and probabilistically complete kinodynamic planning algorithm SST* with a local deterministic μ-calculus model checking procedure to create a motion planning algorithm with deterministic μ-calculus specifications that does not rely on a steering function. The procedure involves combining only the most pertinent information from multiple Kripke structures in order to create one abstracted Kripke structure storing the best paths to all possible proposition regions of the state-space. A linear-quadratic regulator (LQR) feedback control policy is then used to track these best paths, effectively connecting the trajectories found from multiple Kripke structures. Simulations demonstrate that it is possible to satisfy a complex liveness specification for infinitely often reaching specified regions of state-space using only forward propagation.
keywords: {Calculus;Planning;Model checking;Trajectory;Reactive power;Lattices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460769&isnumber=8460178

D. K. Thomsen, R. S. Knudsen, D. Brandt, O. Balling and X. Zhang, "Generating Vibration Free Rest-to-Rest Trajectories for Configuration Dependent Dynamic Systems via 3-Segmented Input Shaping," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4361-4366.
doi: 10.1109/ICRA.2018.8460865
Abstract: This paper presents a new method to generate vibration free rest-to-rest (RTR) trajectories for configuration dependent dynamic systems, such as robots, cranes or machine tools. The new method named 3-Segmented Input Shaping is based on a combination of the widely known Input Shaping method and a new trajectory segmentation strategy for piece wise shaping of the trajectory. The new segmentation strategy facilitates the capability of accounting for variations in system dynamics during motion by shaping acceleration and deceleration profiles with individual frequencies. In this paper the new segmentation strategy is used in combination with the bang-coast-bang (BCB) trajectory. The generated trajectories are described in closed form, hence requires no optimization and thereby provides strong computational performance. The new method is verified by numerical simulations and detailed analysis and shows great potential in vibration-free RTR trajectory generation for systems with configuration dependent dynamics.
keywords: {Trajectory;Vibrations;Acceleration;Motion segmentation;System dynamics;Numerical simulation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460865&isnumber=8460178

G. Xin, H. Lin, J. Smith, O. Cebe and M. Mistry, "A Model-Based Hierarchical Controller for Legged Systems Subject to External Disturbances," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4375-4382.
doi: 10.1109/ICRA.2018.8461172
Abstract: Legged robots have many potential applications in real-world scenarios where the tasks are too dangerous for humans, and compliance is needed to protect the system against external disturbances and impacts. In this paper, we propose a model-based controller for hierarchical tasks of legged systems subject to external disturbance. The control framework is based on projected inverse dynamics controller, such that the control law is decomposed into two orthogonal subspaces, i.e., the constrained and the unconstrained subspaces. The unconstrained component controls multiple desired tasks with impedance responses. The constrained space controller maintains the contact subject to unknown external disturbances, without the use of any force/torque sensing at the contact points. By explicitly modelling the external force, our controller is robust to external disturbances and errors arising from incorrect dynamic model information. The main contributions of this paper include (1) incorporating an impedance controller to control external disturbances and allow impedance shaping to adjust the behaviour of the motion under external disturbances, (2) optimising contact forces within the constrained subspace that also takes into account the external disturbances without using force/torque sensors at the contact locations. The techniques are evaluated on the ANYmal quadruped platform under a variety of scenarios.
keywords: {Task analysis;Force;Legged locomotion;Aerospace electronics;Dynamics;Jacobian matrices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461172&isnumber=8460178

J. M. Brown, C. P. Carbiener, J. Nicholson, N. Hemenway, J. L. Pusey and J. E. Clark, "Fore-Aft Leg Specialization Controller for a Dynamic Quadruped," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4383-4390.
doi: 10.1109/ICRA.2018.8460763
Abstract: Many running animals, unlike their robotic counterparts, have distinct morphologies and functional roles for their front and rear legs. In this paper we present a new control approach for a 5kg autonomous dynamic quadruped that explicitly encodes separate roles for each contralateral pair of legs. This controller utilizes a functional dynamic decomposition similar to Raibert's three part control law, but focuses on fore-aft leg specialization to regulate the robot's performance. The velocity of this controller, which exceeds 5 body lengths per sec, is compared with an improved trajectory-based controller and shown to be significantly more robust to changes in environment.
keywords: {Legged locomotion;Trajectory;Force;Springs;Vehicle dynamics;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460763&isnumber=8460178

G. Bledt, P. M. Wensing, S. Ingersoll and S. Kim, "Contact Model Fusion for Event-Based Locomotion in Unstructured Terrains," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4399-4406.
doi: 10.1109/ICRA.2018.8460904
Abstract: As legged robots are sent into unstructured environments, the ability to robustly manage contact transitions will be a critical skill. This paper introduces an approach to probabilistically fuse contact models, managing uncertainty in terrain geometry, dynamic modeling, and kinematics to improve the robustness of contact initiation at touchdown. A discrete-time extension of the generalized-momentum disturbance observer is presented to increase the accuracy of proprioceptive force control estimates. This information is fused with other contact priors under a framework of Kalman Filtering to increase robustness of the method. This approach results in accurate contact detection with 99.3 % accuracy and a small 4-5ms delay. Using this new detector, an Event-Based Finite State Machine is implemented to deal with unexpected early and late contacts. This allows the robot to traverse cluttered environments by modifying the control actions for each individual leg based on the estimated contact state rather than adhering to a rigid time schedule regardless of actual contact state. Experiments with the MIT Cheetah 3 robot show the success of both the detection algorithm, as well as the Event-Based FSM while making unexpected contacts during trotting.
keywords: {Legged locomotion;Robot sensing systems;Force;Disturbance observers;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460904&isnumber=8460178

W. Zhang and K. Hauser, "Single-Image Footstep Prediction for Versatile Legged Locomotion," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4407-4413.
doi: 10.1109/ICRA.2018.8460999
Abstract: Walking and climbing robots need to plan longterm routes on both horizontal and vertical terrain, but onboard sensors take images from vantage points that provide strongly foreshortened images that cause the appearance of terrain features to vary greatly by distance and viewing angle. This paper presents a convolutional neural network (CNN) method for predicting valid handhold and foothold locations from single RGB+D images taken at arbitrary tilt angles. Experiments show that the method predicts holds more accurately than comparable learning techniques, and that a route planner based on these predictions generates plausible plans for flat ground, stairs, and walls in rock climbing gyms.
keywords: {Cameras;Legged locomotion;Planning;Robot kinematics;Three-dimensional displays;Rocks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460999&isnumber=8460178

R. Hartley et al., "Legged Robot State-Estimation Through Combined Forward Kinematic and Preintegrated Contact Factors," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4422-4429.
doi: 10.1109/ICRA.2018.8460748
Abstract: State-of-the-art robotic perception systems have achieved sufficiently good performance using Inertial Measurement Units (IMUs), cameras, and nonlinear optimization techniques, that they are now being deployed as technologies. However, many of these methods rely significantly on vision and often fail when visual tracking is lost due to lighting or scarcity of features. This paper presents a state-estimation technique for legged robots that takes into account the robot's kinematic model as well as its contact with the environment. We introduce forward kinematic factors and preintegrated contact factors into a factor graph framework that can be incrementally solved in real-time. The forward kinematic factor relates the robot's base pose to a contact frame through noisy encoder measurements. The preintegrated contact factor provides odometry measurements of this contact frame while accounting for possible foot slippage. Together, the two developed factors constrain the graph optimization problem allowing the robot's trajectory to be estimated. The paper evaluates the method using simulated and real sensory IMU and kinematic data from experiments with a Cassie-series robot designed by Agility Robotics. These preliminary experiments show that using the proposed method in addition to IMU decreases drift and improves localization accuracy, suggesting that its use can enable successful recovery from a loss of visual tracking.
keywords: {Robot sensing systems;Legged locomotion;Kinematics;Optimization;Foot;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460748&isnumber=8460178

E. C. Williams, N. Gopalan, M. Rhee and S. Tellex, "Learning to Parse Natural Language to Grounded Reward Functions with Weak Supervision," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4430-4436.
doi: 10.1109/ICRA.2018.8460937
Abstract: In order to intuitively and efficiently collaborate with humans, robots must learn to complete tasks specified using natural language. We represent natural language instructions as goal-state reward functions specified using lambda calculus. Using reward functions as language representations allows robots to plan efficiently in stochastic environments. To map sentences to such reward functions, we learn a weighted linear Combinatory Categorial Grammar (CCG) semantic parser. The parser, including both parameters and the CCG lexicon, is learned from a validation procedure that does not require execution of a planner, annotating reward functions, or labeling parse trees, unlike prior approaches. To learn a CCG lexicon and parse weights, we use coarse lexical generation and validation-driven perceptron weight updates using the approach of Artzi and Zettlemoyer [4]. We present results on the Cleanup World domain [18] to demonstrate the potential of our approach. We report an F1 score of 0.82 on a collected corpus of 23 tasks containing combinations of nested referential expressions, comparators and object properties with 2037 corresponding sentences. Our goal-condition learning approach enables an improvement of orders of magnitude in computation time over a baseline that performs planning during learning, while achieving comparable results. Further, we conduct an experiment with just 6 labeled demonstrations to show the ease of teaching a robot behaviors using our method. We show that parsing models learned from small data sets can generalize to commands not seen during training.
keywords: {Natural languages;Semantics;Task analysis;Planning;Robots;Trajectory;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460937&isnumber=8460178

Z. Erickson, H. M. Clever, G. Turk, C. K. Liu and C. C. Kemp, "Deep Haptic Model Predictive Control for Robot-Assisted Dressing," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4437-4444.
doi: 10.1109/ICRA.2018.8460656
Abstract: Robot-assisted dressing offers an opportunity to benefit the lives of many people with disabilities, such as some older adults. However, robots currently lack common sense about the physical implications of their actions on people. The physical implications of dressing are complicated by non-rigid garments, which can result in a robot indirectly applying high forces to a person's body. We present a deep recurrent model that, when given a proposed action by the robot, predicts the forces a garment will apply to a person's body. We also show that a robot can provide better dressing assistance by using this model with model predictive control. The predictions made by our model only use haptic and kinematic observations from the robot's end effector, which are readily attainable. Collecting training data from real world physical human-robot interaction can be time consuming, costly, and put people at risk. Instead, we train our predictive model using data collected in an entirely self-supervised fashion from a physics-based simulation. We evaluated our approach with a PR2 robot that attempted to pull a hospital gown onto the arms of 10 human participants. With a 0.2s prediction horizon, our controller succeeded at high rates and lowered applied force while navigating the garment around a persons fist and elbow without getting caught. Shorter prediction horizons resulted in significantly reduced performance with the sleeve catching on the participants' fists and elbows, demonstrating the value of our model's predictions. These behaviors of mitigating catches emerged from our deep predictive model and the controller objective function, which primarily penalizes high forces.
keywords: {Robot sensing systems;Haptic interfaces;End effectors;Clothing;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460656&isnumber=8460178

E. Lakomkin, M. A. Zamani, C. Weber, S. Magg and S. Wermter, "EmoRL: Continuous Acoustic Emotion Classification Using Deep Reinforcement Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4445-4450.
doi: 10.1109/ICRA.2018.8461058
Abstract: Acoustically expressed emotions can make communication with a robot more efficient. Detecting emotions like anger could provide a clue for the robot indicating unsafe/undesired situations. Recently, several deep neural network-based models have been proposed which establish new state-of-the-art results in affective state evaluation. These models typically start processing at the end of each utterance, which not only requires a mechanism to detect the end of an utterance but also makes it difficult to use them in a real-time communication scenario, e.g. human-robot interaction. We propose the EmoRL model that triggers an emotion classification as soon as it gains enough confidence while listening to a person speaking. As a result, we minimize the need for segmenting the audio signal for classification and achieve lower latency as the audio signal is processed incrementally. The method is competitive with the accuracy of a strong baseline model, while allowing much earlier prediction.
keywords: {Acoustics;Robots;Adaptation models;Logic gates;Feature extraction;Predictive models;Recurrent neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461058&isnumber=8460178

Z. Gong and Y. Zhang, "Temporal Spatial Inverse Semantics for Robots Communicating with Humans," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4451-4458.
doi: 10.1109/ICRA.2018.8460754
Abstract: Effective communication between humans often embeds both temporal and spatial context. While spatial context captures the geographic settings of objects in the environment, temporal context describes their changes over time. In this paper, we propose temporal spatial inverse semantics (TeSIS) to extend the inverse semantics approach to also consider the temporal context for robots communicating with humans. Inverse semantics generates natural language requests while taking into account how well the human listeners would interpret those requests given the current spatial context. Compared to inverse semantics, our approach incorporates also temporal context by referring to spatial context information in the past. To achieve this, we extend the sentence structure in inverse semantics to generate sentences that can refer to not only the current but also previous states of the environment. A new metric based on the extended sentence structure is developed by breaking a single sentence into multiple independent sentences that refer to environment states at different times. Using this approach, we are able to generate sentences such as “Please pick up the cup beside the oven that was on the dining table”. To evaluate our approach, we randomly generate scenarios in an experimental domain. Each scenario includes the description of the current and several immediate previous states. Natural language sentences are then generated for these scenarios using both inverse semantics that uses only the spatial context and our approach. Amazon MTurk is used to compare the sentences generated and results show that TeSIS achieves better accuracy, sometimes by a significant margin, than the baseline.
keywords: {Semantics;Grounding;Pallets;Natural languages;Tires;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460754&isnumber=8460178

G. Beraldo, M. Antonello, A. Cimolato, E. Menegatti and L. Tonin, "Brain-Computer Interface Meets ROS: A Robotic Approach to Mentally Drive Telepresence Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4459-4464.
doi: 10.1109/ICRA.2018.8460578
Abstract: This paper shows and evaluates a novel approach to integrate a non-invasive Brain-Computer Interface (BCI) with the Robot Operating System (ROS) to mentally drive a telepresence robot. Controlling a mobile device by using human brain signals might improve the quality of life of people suffering from severe physical disabilities or elderly people who cannot move anymore. Thus, the BCI user can actively interact with relatives and friends located in different rooms thanks to a video streaming connection to the robot. To facilitate the control of the robot via BCI, we explore new ROS-based algorithms for navigation and obstacle avoidance in order to make the system safer and more reliable. In this regard, the robot exploits two maps of the environment, one for localization and one for navigation, and both are used as additional visual feedback for the BCI user to control the robot position. Experimental results show a decrease of the number of commands needed to complete the navigation task, suggesting a reduction user's cognitive workload. The novelty of this work is to provide a first evidence of an integration between BCI and ROS that can simplify and foster the development of software for BCI driven robotics devices.
keywords: {Navigation;Robot sensing systems;Task analysis;Telepresence;Brain-computer interfaces},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460578&isnumber=8460178

K. Kumarasinghe, M. Owen, D. Taylor, N. Kasabov and C. Kit, "FaNeuRobot: A Framework for Robot and Prosthetics Control Using the NeuCube Spiking Neural Network Architecture and Finite Automata Theory," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4465-4472.
doi: 10.1109/ICRA.2018.8460197
Abstract: Limb amputation is a global problem. Prosthetic limbs can enhance the quality of life of amputees. To this end, anthropomorphic design and intuitive manipulation are two essential requirements. This paper presents a motor control framework for prosthetic control through Brain-Machine Interface (BMI) using Finite Automata Theory, and NeuCube Evolving Spiking Neural Network (SNN) architecture. Voluntary control of prosthetics requires decoding motor commands from the Central Nervous System of the amputee. Selection of the most suitable biomedical signal depends on many parameters such as level of amputation and muscle atrophy. Non-invasive BMI's have the possibility of supporting a wider range of amputees as it extracts the motor commands from the brain. In this paper, we present a proof of concept study on whether a cognitive computational model that is inspired by the motor control of the human body through muscle synergies combined with an anthropomorphic mechanical design, can result in accurate and robust prosthetic control through a noninvasive BMI. In future, learning of a complex Finite Automata that reflects complex upper limb motor behaviours will be investigated.
keywords: {Prosthetics;Muscles;Electroencephalography;DC motors;Grasping;Bones;Thumb},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460197&isnumber=8460178

L. Schiatti, J. Tessadori, N. Deshpande, G. Barresi, L. C. King and L. S. Mattos, "Human in the Loop of Robot Learning: EEG-Based Reward Signal for Target Identification and Reaching Task," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4473-4480.
doi: 10.1109/ICRA.2018.8460551
Abstract: Shared control and shared autonomy play an important role in assistive technologies, allowing the offloading of the cognitive burden required for control from the user to the intelligent robotic device. In this context, electrophysiological measures of error detection, directly measured from a person's brain activity as Error-related Potentials (ErrPs), can be exploited to provide passive adaptation of an external semi-autonomous system to the human. This concept was implemented in an online robot learning task, where user's evaluation of the robot's actions, in terms of detected ErrP, was exploited to update a reward function in a Reinforcement Learning (RL) framework. Results from both simulated and experimental studies show that the introduction of human evaluation in the robot learning loop allows for: (1) the acceleration of optimal policy learning in a target reaching task, (2) the introduction of a further degree of control in robot learning, namely identification of one among multiple targets, according to the user's will. Overall, presented results support the potential of human-robot co-adaptive and co-operative strategies to develop human-centered assistive technologies.
keywords: {Electroencephalography;Training;Graphical user interfaces;Microsoft Windows;Testing;Robot learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460551&isnumber=8460178

M. Wulfmeier, A. Bewley and I. Posner, "Incremental Adversarial Domain Adaptation for Continually Changing Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4489-4495.
doi: 10.1109/ICRA.2018.8460982
Abstract: Continuous appearance shifts such as changes in weather and lighting conditions can impact the performance of deployed machine learning models. While unsupervised domain adaptation aims to address this challenge, current approaches do not utilise the continuity of the occurring shifts. In particular, many robotics applications exhibit these conditions and thus facilitate the potential to incrementally adapt a learnt model over minor shifts which integrate to massive differences over time. Our work presents an adversarial approach for lifelong, incremental domain adaptation which benefits from unsupervised alignment to a series of intermediate domains which successively diverge from the labelled source domain. We empirically demonstrate that our incremental approach improves handling of large appearance changes, e.g. day to night, on a traversable-path segmentation task compared with a direct, single alignment step approach. Furthermore, by approximating the feature distribution for the source domain with a generative adversarial network, the deployment module can be rendered fully independent of retaining potentially large amounts of the related source training data for only a minor reduction in performance.
keywords: {Training;Task analysis;Adaptation models;Robots;Gallium nitride;Mathematical model;Lighting},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460982&isnumber=8460178

C. Chang, J. Zhao and L. Itti, "DeepVP: Deep Learning for Vanishing Point Detection on 1 Million Street View Images," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4496-4503.
doi: 10.1109/ICRA.2018.8460499
Abstract: We propose a novel approach to detect vanishing points in images using a convolutional neural network (CNN) trained on a newly collected Google street-view image dataset. By utilizing the camera parameters and road direction data from Google street view, we collected a total of 1,053,425 images with inferred ground-truth vanishing points, along 23 worldwide routes totaling 125,165 kilometers. We then formulate vanishing point detection as a CNN classification problem using an output layer with 225 discrete possible vanishing point locations. Experimental results show that our deep vanishing point system outperforms the state-of-the-art algorithmic vanishing point detector. We achieved 99% accuracy in recovering the horizon line and 92% in locating the vanishing point within a ±5-degree range.
keywords: {Roads;Cameras;Google;Machine learning;Videos;Image segmentation;Computer architecture},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460499&isnumber=8460178

V. Vaquero, A. Sanfeliu and F. Moreno-Noguer, "Deep Lidar CNN to Understand the Dynamics of Moving Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4504-4509.
doi: 10.1109/ICRA.2018.8460554
Abstract: Perception technologies in Autonomous Driving are experiencing their golden age due to the advances in Deep Learning. Yet, most of these systems rely on the semantically rich information of RGB images. Deep Learning solutions applied to the data of other sensors typically mounted on autonomous cars (e.g. lidars or radars) are not explored much. In this paper we propose a novel solution to understand the dynamics of moving vehicles of the scene from only lidar information. The main challenge of this problem stems from the fact that we need to disambiguate the proprio-motion of the “observer” vehicle from that of the external “observed” vehicles. For this purpose, we devise a CNN architecture which at testing time is fed with pairs of consecutive lidar scans. However, in order to properly learn the parameters of this network, during training we introduce a series of so-called pretext tasks which also leverage on image data. These tasks include semantic information about vehicleness and a novel lidar-flow feature which combines standard image-based optical flow with lidar scans. We obtain very promising results and show that including distilled image information only during training, allows improving the inference results of the network at test time, even when image data is no longer used.
keywords: {Laser radar;Task analysis;Vehicle dynamics;Three-dimensional displays;Dynamics;Machine learning;Semantics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460554&isnumber=8460178

P. Jund, A. Eitel, N. Abdo and W. Burgard, "Optimization Beyond the Convolution: Generalizing Spatial Relations with End-to-End Metric Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4510-4516.
doi: 10.1109/ICRA.2018.8460220
Abstract: To operate intelligently in domestic environments, robots require the ability to understand arbitrary spatial relations between objects and to generalize them to objects of varying sizes and shapes. In this work, we present a novel end-to-end approach to generalize spatial relations based on distance metric learning. We train a neural network to transform 3D point clouds of objects to a metric space that captures the similarity of the depicted spatial relations, using only geometric models of the objects. Our approach employs gradient-based optimization to compute object poses in order to imitate an arbitrary target relation by reducing the distance to it under the learned metric. Our results based on simulated and real-world experiments show that the proposed method enables robots to generalize spatial relations to unknown objects over a continuous spectrum.
keywords: {Measurement;Three-dimensional displays;Robots;Optimization;Transforms;Shape;Convolution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460220&isnumber=8460178

P. Parkhiya, R. Khawad, J. K. Murthy, B. Bhowmick and K. M. Krishna, "Constructing Category-Specific Models for Monocular Object-SLAM," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4517-4524.
doi: 10.1109/ICRA.2018.8460816
Abstract: We present a new paradigm for real-time object-oriented SLAM with a monocular camera. Contrary to previous approaches, that rely on object-level models, we construct category-level models from CAD collections which are now widely available. To alleviate the need for huge amounts of labeled data, we develop a rendering pipeline that enables synthesis of large datasets from a limited amount of manually labeled data. Using data thus synthesized, we learn category-level models for object deformations in 3D, as well as discriminative object features in 2D. These category models are instance-independent and aid in the design of object landmark observations that can be incorporated into a generic monocular SLAM framework. Where typical object-SLAM approaches usually solve only for object and camera poses, we also estimate object shape on-the-fty, allowing for a wide range of objects from the category to be present in the scene. Moreover, since our 2D object features are learned discriminatively, the proposed object-SLAM system succeeds in several scenarios where sparse feature-based monocular SLAM fails due to insufficient features or parallax. Also, the proposed category-models help in object instance retrieval, useful for Augmented Reality (AR) applications. We evaluate the proposed framework on multiple challenging real-world scenes and show - to the best of our knowledge - first results of an instance-independent monocular object-SLAM system and the benefits it enjoys over feature-based SLAM methods.
keywords: {Solid modeling;Simultaneous localization and mapping;Three-dimensional displays;Object oriented modeling;Pipelines;Two dimensional displays;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460816&isnumber=8460178

G. L. Oliveira, W. Burgard and T. Brox, "DPDB-Net: Exploiting Dense Connections for Convolutional Encoders," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4525-4531.
doi: 10.1109/ICRA.2018.8461089
Abstract: Densely connected networks for classification enable feature exploration and result in state-of-the-art performance on multiple classification tasks. The alternative to dense networks is the residual network which enables feature re-usage. In this work, we combine these orthogonal concepts for encoder-decoder architectures, which we call Dual-Path Dense-Block Network (DPDB-Net). We introduce a dense block which incorporates feature re-usage and new feature exploration in the encoder. Moreover, we discuss that feature re-usage by the residual network architecture leads to a feature map explosion in the decoder and, thus, is not advantageous in this part of the network. We evaluated our proposed architecture in multiple segmentation tasks and report state-of-the-art performance on the Freiburg Forest dataset and competitive results on the Cam Vid dataset.
keywords: {Decoding;Computer architecture;Semantics;Task analysis;Explosions;Image segmentation;Forestry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461089&isnumber=8460178

P. Nikdel, R. Shrestha and R. Vaughan, "The Hands-Free Push-Cart: Autonomous Following in Front by Predicting User Trajectory Around Obstacles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4548-4554.
doi: 10.1109/ICRA.2018.8461181
Abstract: This paper demonstrates an autonomous mobile robot that follows a walking user while staying ahead of them. Despite several useful applications for autonomous push-carts, this problem has received much less attention than the easier problem of following from behind. In contrast to previous work, we use multi-modal person detection and a human-motion model that considers obstacles to predict the future path of the user. We implement the system with a modular architecture of obstacle mapper, human tracker, human motion model, robot motion planner and robot motion controller. We report on the performance of the robot in real-world experiments. We believe that approaches to this largely overlooked problem could be useful in real industrial, domestic and entertainment applications in the near future.
keywords: {Robot sensing systems;Legged locomotion;Cameras;Tracking;Trajectory;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461181&isnumber=8460178

A. Virgona, A. Alempijevic and T. Vidal-Calleja, "Socially Constrained Tracking in Crowded Environments Using Shoulder Pose Estimates," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4555-4562.
doi: 10.1109/ICRA.2018.8461030
Abstract: Detecting and tracking people is a key requirement in the development of robotic technologies intended to operate in human environments. In crowded environments such as train stations this task is particularly challenging due the high numbers of targets and frequent occlusions. In this paper we present a framework for detecting and tracking humans in such crowded environments in terms of 2D pose ( x, y, θ). The main contributions are a method for extracting pose from the most visible parts of the body in a crowd, the head and shoulders, and a tracker which leverages social constraints regarding peoples orientation, movement and proximity to one another, to improve robustness in this challenging environment. The framework is evaluated on two datasets: one captured in a lab environment with ground truth obtained using a motion capture system, and the other captured in a busy inner city train station. Pose errors are reported against the ground truth and the tracking results are then compared with a state-of-the-art person tracking framework.
keywords: {Target tracking;Sensors;Cameras;Robustness;Task analysis;Head},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461030&isnumber=8460178

J. Bütepage, H. Kjellström and D. Kragic, "Anticipating Many Futures: Online Human Motion Prediction and Generation for Human-Robot Interaction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4563-4570.
doi: 10.1109/ICRA.2018.8460651
Abstract: Fluent and safe interactions of humans and robots require both partners to anticipate the others' actions. The bottleneck of most methods is the lack of an accurate model of natural human motion. In this work, we present a conditional variational autoencoder that is trained to predict a window of future human motion given a window of past frames. Using skeletal data obtained from RGB depth images, we show how this unsupervised approach can be used for online motion prediction for up to 1660 ms. Additionally, we demonstrate online target prediction within the first 300-500 ms after motion onset without the use of target specific training data. The advantage of our probabilistic approach is the possibility to draw samples of possible future motion patterns. Finally, we investigate how movements and kinematic cues are represented on the learned low dimensional manifold.
keywords: {Trajectory;Task analysis;Robot kinematics;Predictive models;Computational modeling;Training data},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460651&isnumber=8460178

A. Rudenko, L. Palmieri and K. O. Arras, "Joint Long-Term Prediction of Human Motion Using a Planning-Based Social Force Approach," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4571-4577.
doi: 10.1109/ICRA.2018.8460527
Abstract: The ability to perceive and predict future positions of dynamic objects is essential for mobile robots and intelligent vehicles in dynamic environments. In this paper, we present a novel planning-based approach for long-term human motion prediction that accounts for local interactions and can accurately predict joint motion of multiple agents. Long-term predictions are handled using an MDP formulation that computes a set of stochastic motion policies. To obtain distributions over future motion trajectories, we sample the policies with a weighted random walk algorithm in which each person is locally influenced by social forces from other nearby agents. Unlike related work, the algorithm is environment-aware, can account for individual agent velocities, requires no training phase and makes joint predictions for multiple agents. Experiments in simulation and with real data show that our method makes more accurate predictions than two state-of-the-art methods in terms of probabilistic and geometrical performance measures.
keywords: {Trajectory;Prediction algorithms;Force;Predictive models;Planning;Stochastic processes;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460527&isnumber=8460178

A. Cruz-Maya and A. Tapus, "Negotiating with a Robot: Analysis of Regulatory Focus Behavior," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4578-4594.
doi: 10.1109/ICRA.2018.8460611
Abstract: Companion robots are more and more taking the role of caregivers for elderly people. Elderly people sometimes take the advice given by their family members or caregivers as a criticism. In this context, persuasive communication skills could be helpful. A social psychology theory called Regulatory Focus states that people have one of two inclinations when taking decisions: Promotion or Prevention Focus. Also, based on these inclinations, people can be influenced by the way the message is sent, including the speed of the speech and the amplitude of body gestures. In this paper, we analyze the influence of Regulatory Focus on a negotiation scenario, using 3 conditions: (1) a robot with a promotion behavior, (2) a robot with a prevention behavior, and (3) a robot with a neutral behavior. Our results support the results found in the psychology literature related to Regulatory Focus, suggesting that Promotion participants were more influenced by the robot showing a Promotion based behavior. Moreover, Prevention participants were more relaxed on the condition with the robot showing a Prevention based behavior, and accepted the biggest concession between the initial and final offer.
keywords: {Robots;Senior citizens;Psychology;Games;Speech recognition;Tracking;Human-robot interaction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460611&isnumber=8460178

A. Tsiami, P. Koutras, N. Efthymiou, P. P. Filntisis, G. Potamianos and P. Maragos, "Multi3: Multi-Sensory Perception System for Multi-Modal Child Interaction with Multiple Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4585-4592.
doi: 10.1109/ICRA.2018.8461210
Abstract: Child-robot interaction is an interdisciplinary research area that has been attracting growing interest, primarily focusing on edutainment applications. A crucial factor to the successful deployment and wide adoption of such applications remains the robust perception of the child's multi-modal actions, when interacting with the robot in a natural and untethered fashion. Since robotic sensory and perception capabilities are platform-dependent and most often rather limited, we propose a multiple Kinect-based system to perceive the child-robot interaction scene that is robot-independent and suitable for indoors interaction scenarios. The audio-visual input from the Kinect sensors is fed into speech, gesture, and action recognition modules, appropriately developed in this paper to address the challenging nature of child-robot interaction. For this purpose, data from multiple children are collected and used for module training or adaptation. Further, information from the multiple sensors is fused to enhance module performance. The perception system is integrated in a modular multi-robot architecture demonstrating its flexibility and scalability with different robotic platforms. The whole system, called Multi3, is evaluated, both objectively at the module level and subjectively in its entirety, under appropriate child-robot interaction scenarios containing several carefully designed games between children and robots.
keywords: {Speech recognition;Trajectory;Robot sensing systems;Microphone arrays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461210&isnumber=8460178

Z. Talebpour and A. Martinoli, "Multi-Robot Coordination in Dynamic Environments Shared with Humans," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4593-4600.
doi: 10.1109/ICRA.2018.8460978
Abstract: This work addresses multi-robot coordination in social human-populated environments using a market-based framework for solving the Multi-Robot Task Allocation (MRTA) problem. Humans are considered in the proposed coordination mechanism by means of accounting for social costs in bid evaluations and requesting collaboration in socially blocking situations. Initially, the effect of a realistic environment with varying number of static/moving humans on the behavior and performance of our method is studied through an extensive suite of experiments in a high-fidelity simulator. Results show that the total traveled distance and time are increased when humans are present in the environments. Localization noise is also increased particularly in the case of static people. In the second series of experiments, a number of problematic cases resulting in longer modified paths, blocked passages, and long waits have been investigated. A comparative study targeting human-agnostic navigation and planning, human-aware navigation and human-agnostic planning, and human-aware navigation and planning has been conducted. Both simulated and real robot experiments confirm the effectiveness of accounting for humans at both team and individual levels. This leads to respecting social constraints as well as achieving a better performance based on MRTA metrics.
keywords: {Robot kinematics;Task analysis;Navigation;Planning;Resource management;Measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460978&isnumber=8460178

A. Vemula, K. Muelling and J. Oh, "Social Attention: Modeling Attention in Human Crowds," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4601-4607.
doi: 10.1109/ICRA.2018.8460504
Abstract: Robots that navigate through human crowds need to be able to plan safe, efficient, and human predictable trajectories. This is a particularly challenging problem as it requires the robot to predict future human trajectories within a crowd where everyone implicitly cooperates with each other to avoid collisions. Previous approaches to human trajectory prediction have modeled the interactions between humans as a function of proximity. However, that is not necessarily true as some people in our immediate vicinity moving in the same direction might not be as important as other people that are further away, but that might collide with us in the future. In this work, we propose Social Attention, a novel trajectory prediction model that captures the relative importance of each person when navigating in the crowd, irrespective of their proximity. We demonstrate the performance of our method against a state-of-the-art approach on two publicly available crowd datasets and analyze the trained attention model to gain a better understanding of which surrounding agents humans attend to, when navigating in a crowd.
keywords: {Trajectory;Navigation;Predictive models;Robots;Collision avoidance;Dynamics;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460504&isnumber=8460178

X. Han, J. Lu, C. Zhao and H. Li, "Fully Convolutional Neural Networks for Road Detection with Multiple Cues Integration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4608-4613.
doi: 10.1109/ICRA.2018.8460663
Abstract: Road detection from images is a key task in autonomous driving. The recent advent of deep learning (and in particular, CNN or convolutional neural networks) has greatly improved the performance of road detection algorithms. In this paper, we show how to fuse multiple different cues under the same convolutional network framework. Specifically, we adopt a pre-trained Resnet-lOl to extract feature maps from RGB images; we then connect it with three extra deconvolution layers. These deconvolution layers is trained conditioning on appropriate image cues, and in our case they are a height image (i.e. elevation map obtained by e.g. Lidar scanner), image gradient, and position map. We also design two skip layers to speed up the convergence. Experiments on KITTI benchmark show competitive performance of our new networks.
keywords: {Roads;Feature extraction;Laser radar;Three-dimensional displays;Task analysis;Fuses;Network architecture},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460663&isnumber=8460178

A. Ahmed and S. Roumeliotis, "A Visual-Inertial Approach to Human Gait Estimation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4614-4621.
doi: 10.1109/ICRA.2018.8460871
Abstract: This paper addresses the problem of gait estimation using visual and inertial data, as well as human motion models. Specifically, a batch least-squares (BLS) algorithm is presented that fuses data from a minimal set of sensors [two inertial measurement units (IMUs), one on each foot, and a head-mounted IMU-camera pair] along with motion constraints corresponding to the different walking states, to estimate the person's head and feet poses. Subsequently, gait models are employed to solve for the lower-body's posture and generate its animation. Experimental results against the VICON motion capture system demonstrate the accuracy of the proposed minimal sensors-based system for determining a person's motion.
keywords: {Foot;Trajectory;Computational modeling;Sensors;Legged locomotion;Visualization;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460871&isnumber=8460178

G. Sepulveda, J. C. Niebles and A. Soto, "A Deep Learning Based Behavioral Approach to Indoor Autonomous Navigation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4646-4653.
doi: 10.1109/ICRA.2018.8460646
Abstract: We present a semantically rich graph representation for indoor robotic navigation. Our graph representation encodes: semantic locations such as offices or corridors as nodes, and navigational behaviors such as enter office or cross a corridor as edges. In particular, our navigational behaviors operate directly from visual inputs to produce motor controls and are implemented with deep learning architectures. This enables the robot to avoid explicit computation of its precise location or the geometry of the environment, and enables navigation at a higher level of semantic abstraction. We evaluate the effectiveness of our representation by simulating navigation tasks in a large number of virtual environments. Our results show that using a simple sets of perceptual and navigational behaviors, the proposed approach can successfully guide the way of the robot as it completes navigational missions such as going to a specific office. Furthermore, our implementation shows to be effective to control the selection and switching of behaviors.
keywords: {Navigation;Semantics;Visualization;Simultaneous localization and mapping;Robustness;Measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460646&isnumber=8460178

D. Kanoulas et al., "Footstep Planning in Rough Terrain for Bipedal Robots Using Curved Contact Patches," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4662-4669.
doi: 10.1109/ICRA.2018.8460561
Abstract: Bipedal robots have gained a lot of locomotion capabilities the past few years, especially in the control level. Navigation over complex and unstructured environments using exteroceptive perception, is still an active research topic. In this paper, we present a footstep planning system to produce foothold placements, using visual perception and proper environment modeling, given a black box walking controller. In particular, we extend a state-of-the-art search-based planning approach (ARA*) that produces 6DoF footstep sequences in 3D space for flat uneven terrain, to also handle rough curved surfaces, e.g. rocks. This is achieved by integrating both a curved patch modeling system for rough local terrain surfaces and a flat foothold contact analysis based on visual range input data, into the existing planning framework. The system is experimentally validated using real-world point clouds, while rough terrain stepping demonstrations are presented on the WALK-MAN humanoid robot, in simulation.
keywords: {Planning;Three-dimensional displays;Rough surfaces;Surface roughness;Robot sensing systems;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460561&isnumber=8460178

G. Wan et al., "Robust and Precise Vehicle Localization Based on Multi-Sensor Fusion in Diverse City Scenes," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4670-4677.
doi: 10.1109/ICRA.2018.8461224
Abstract: We present a robust and precise localization system that achieves centimeter-level localization accuracy in disparate city scenes. Our system adaptively uses information from complementary sensors such as GNSS, LiDAR, and IMU to achieve high localization accuracy and resilience in challenging scenes, such as urban downtown, highways, and tunnels. Rather than relying only on LiDAR intensity or 3D geometry, we make innovative use of LiDAR intensity and altitude cues to significantly improve localization system accuracy and robustness. Our GNSS RTK module utilizes the help of the multi-sensor fusion framework and achieves a better ambiguity resolution success rate. An error-state Kalman filter is applied to fuse the localization measurements from different sources with novel uncertainty estimation. We validate, in detail, the effectiveness of our approaches, achieving 5-10cm RMS accuracy and outperforming previous state-of-the-art systems. Importantly, our system, while deployed in a large autonomous driving fleet, made our vehicles fully autonomous in crowded city streets despite road construction that occurred from time to time. A dataset including more than 60 km real traffic driving in various urban roads is used to comprehensively test our system.
keywords: {Laser radar;Three-dimensional displays;Estimation;Sensors;Global navigation satellite system;Autonomous vehicles;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461224&isnumber=8460178

M. Wang, Z. Wang, S. Paudel and M. Schwager, "Safe Distributed Lane Change Maneuvers for Multiple Autonomous Vehicles Using Buffered Input Cells," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4678-4684.
doi: 10.1109/ICRA.2018.8460898
Abstract: This paper introduces the Buffered Input Cell as a reciprocal collision avoidance method for multiple vehicles with high-order linear dynamics, extending recently proposed methods based on the Buffered Voronoi Cell [1] and generalized Voronoi diagrams [2]. We prove that if each vehicle's control input remains in its Buffered Input Cell at each time step, collisions will be avoided indefinitely. The method is fast, reactive, and only requires that each vehicle measures the relative position of neighboring vehicles. We incorporate this collision avoidance method as one layer of a complete lane change control stack for autonomous cars in a freeway driving scenario. The lane change control stack comprises a decision-making layer, a trajectory planning layer, a trajectory following feedback controller, and the Buffered Input Cell for collision avoidance. We show in simulations that collisions are avoided with multiple vehicles simultaneously changing lanes on a freeway. We also show in simulations that autonomous cars using the BIC method effectively avoid collisions with an aggressive human-driven car.
keywords: {Collision avoidance;Robots;Vehicle dynamics;Aerospace electronics;Traffic control;Autonomous vehicles;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460898&isnumber=8460178

M. Strickland, G. Fainekos and H. B. Amor, "Deep Predictive Models for Collision Risk Assessment in Autonomous Driving," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4685-4692.
doi: 10.1109/ICRA.2018.8461160
Abstract: In this paper, we investigate a predictive approach for collision risk assessment in autonomous and assisted driving. A deep predictive model is trained to anticipate imminent accidents from traditional video streams. In particular, the model learns to identify cues in RGB images that are predictive of hazardous upcoming situations. In contrast to previous work, our approach incorporates (a) temporal information during decision making, (b) multi-modal information about the environment, as well as the proprioceptive state and steering actions of the controlled vehicle, and (c) information about the uncertainty inherent to the task. To this end, we discuss Deep Predictive Models and present an implementation using a Bayesian Convolutional LSTM. Experiments in a simple simulation environment show that the approach can learn to predict impending accidents with reasonable accuracy, especially when multiple cameras are used as input sources.
keywords: {Predictive models;Accidents;Stochastic processes;Uncertainty;Bayes methods;Cameras;Tensile stress},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461160&isnumber=8460178

F. Codevilla, M. Müller, A. López, V. Koltun and A. Dosovitskiy, "End-to-End Driving Via Conditional Imitation Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4693-4700.
doi: 10.1109/ICRA.2018.8460487
Abstract: Deep networks trained on demonstrations of human driving have learned to follow roads and avoid obstacles. However, driving policies trained via imitation learning cannot be controlled at test time. A vehicle trained end-to-end to imitate an expert cannot be guided to take a specific turn at an upcoming intersection. This limits the utility of such systems. We propose to condition imitation learning on high-level command input. At test time, the learned driving policy functions as a chauffeur that handles sensorimotor coordination but continues to respond to navigational commands. We evaluate different architectures for conditional imitation learning in vision-based driving. We conduct experiments in realistic three-dimensional simulations of urban driving and on a 1/5 scale robotic truck that is trained to drive in a residential area. Both systems drive based on visual input yet remain responsive to high-level navigational commands.
keywords: {Robot sensing systems;Task analysis;Vehicles;Cameras;Roads;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460487&isnumber=8460178

M. Bojarski et al., "VisualBackProp: Efficient Visualization of CNNs for Autonomous Driving," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4701-4708.
doi: 10.1109/ICRA.2018.8461053
Abstract: This paper proposes a new method, that we call VisualBackProp, for visualizing which sets of pixels of the input image contribute most to the predictions made by the convolutional neural network (CNN). The method heavily hinges on exploring the intuition that the feature maps contain less and less irrelevant information to the prediction decision when moving deeper into the network. The technique we propose is dedicated for CNN-based systems for steering self-driving cars and is therefore required to run in real-time. This makes the proposed visualization method a valuable debugging tool which can be easily used during both training and inference. We justify our approach with theoretical arguments and confirm that the proposed method identifies sets of input pixels, rather than individual pixels, that collaboratively contribute to the prediction. We utilize the proposed visualization tool in the NVIDIA neural-network-based end-to-end learning system for autonomous driving, known as PilotNet. We demonstrate that VisualBackProp determines which elements in the road image most influence PilotNet's steering decision and indeed captures relevant objects on the road. The empirical evaluation furthermore shows the plausibility of the proposed approach on public road video data as well as in other applications and reveals that it compares favorably to the layer-wise relevance propagation approach, i.e. it obtains similar visualization results and achieves order of magnitude speed-ups.
keywords: {Neurons;Visualization;Deconvolution;Tools;Biological neural networks;Roads;Data visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461053&isnumber=8460178

U. Baumann, C. Guiser, M. Herman and J. M. Zollner, "Predicting Ego-Vehicle Paths from Environmental Observations with a Deep Neural Network," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4709-4716.
doi: 10.1109/ICRA.2018.8460704
Abstract: Advanced driver assistance systems allow for increasing user comfort and safety by sensing the environment and anticipating upcoming hazards. Often, this requires to accurately predict how situations will change. Recent approaches make simplifying assumptions on the predictive model of the Ego-Vehicle motion or assume prior knowledge, such as road topologies, to be available. However, in many urban areas this assumption is not satisfied. Furthermore, temporary changes (e.g. construction areas, vehicles parked on the street) are not considered by such models. Since many cars observe the environment with several different sensors, predictive models can benefit from them by considering environmental properties. In this work, we present an approach for an Ego-Vehicle path prediction from such sensor measurements of the static vehicle environment. Besides proposing a learned model for predicting the driver's multi-modal future path as a grid-based prediction, we derive an approach for extracting paths from it. In driver assistance systems both can be used to solve varying assistance tasks. The proposed approach is evaluated on real driving data and outperforms several baseline approaches.
keywords: {Predictive models;Vehicles;Sensors;Roads;Trajectory;Data models;Motion measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460704&isnumber=8460178

A. Amini, L. Paull, T. Balch, S. Karaman and D. Rus, "Learning Steering Bounds for Parallel Autonomous Systems," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4717-4724.
doi: 10.1109/ICRA.2018.8461253
Abstract: Deep learning has been successfully applied to “end-to-end” learning of the autonomous driving task, where a deep neural network learns to predict steering control commands from camera data input. However, the learned representations do not support higher-level decision making required for autonomous navigation, nor the uncertainty estimates required for parallel autonomy, where vehicle control is shared between human and robot. This paper tackles the problem of learning a representation to predict a continuous control probability distribution, and thus steering control options and bounds for those options, which can be used for autonomous navigation. Each mode of the distribution encodes a possible macro-action that the system could execute at that instant, and the covariances of the modes place bounds on safe steering control values. Our approach has the added advantage of being trained on unlabeled data collected from inexpensive cameras. The deep neural network based algorithm generates a probability distribution over the space of steering angles, from which we leverage Variational Bayesian methods to extract a mixture model and compute the different possible actions in the environment. A bound, which the autonomous vehicle must respect in our parallel autonomy setting, is then computed for each of these actions. We evaluate our approach on a challenging dataset containing a wide variety of driving conditions, and show that our algorithm is capable of parameterizing Gaussian Mixture Models for possible actions, and extract steering bounds with a mean error of only 2 degrees. Additionally, we demonstrate our system working on a full scale autonomous vehicle and evaluate its ability to successful handle various different parallel autonomy situations.
keywords: {Autonomous vehicles;Navigation;Neural networks;Probability distribution;Decision making;Machine learning;Bayes methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461253&isnumber=8460178

Z. Bing et al., "End to End Learning of Spiking Neural Network Based on R-STDP for a Lane Keeping Vehicle," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4725-4732.
doi: 10.1109/ICRA.2018.8460482
Abstract: Learning-based methods have demonstrated clear advantages in controlling robot tasks, such as the information fusion abilities, strong robustness, and high accuracy. Meanwhile, the on-board systems of robots have limited computation and energy resources, which are contradictory with state-of-the-art learning approaches. They are either too lightweight to solve complex problems or too heavyweight to be used for mobile applications. On the other hand, training spiking neural networks (SNNs) with biological plausibility has great potentials of performing fast computation and energy efficiency. However, the lack of effective learning rules for SNNs impedes their wide usage in mobile robot applications. This paper addresses the problem by introducing an end to end learning approach of spiking neural networks for a lane keeping vehicle. We consider the reward-modulated spike-timing-dependent-plasticity (R-STDP) as a promising solution in training SNNs, since it combines the advantages of both reinforcement learning and the well-known STDP. We test our approach in three scenarios that a Pioneer robot is controlled to keep lanes based on an SNN. Specifically, the lane information is encoded by the event data from a neuromorphic vision sensor. The SNN is constructed using R-STDP synapses in an all-to-all fashion. We demonstrate the advantages of our approach in terms of the lateral localization accuracy by comparing with other state-of-the-art learning algorithms based on SNNs.
keywords: {Voltage control;Task analysis;Robot sensing systems;Training;Synapses;Neurons},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460482&isnumber=8460178

B. Fang et al., "A Dual-Modal Vision-Based Tactile Sensor for Robotic Hand Grasping," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4740-4745.
doi: 10.1109/ICRA.2018.8461007
Abstract: Humans' fingertips can perceive not only the magnitude and the direction of force but also the texture of object. When we grasp an object, the surface texture sensing of the fingertip helps us recognize the object and the force feeling that is parallel to the skin helps us grasp stably. Focusing on these points, we have developed a dual-modal vision-based tactile sensor that can measure the texture of object and a distribution of force vectors. The tactile sensor consists of a transparent elastomer, a camera, a piece of transparent acrylic board, LEDs and supporting structures. A reflective membrane and markers array are on the surface of the elastomer. An applied force on the elastic body results in movements of the markers, which are acquired by the CCD camera. In addition, the shape and texture of the object's contact surface can be reflected by the membrane deformations. The distribution of force vectors is determined by the BP neural network. The local binary pattern algorithm using captured images calculates the texture information. This paper reports experimental evaluation results concerning accuracy of determination of magnitude, direction of force, and texture recognition rate.
keywords: {Force;Tactile sensors;Neurons;Cameras;Light emitting diodes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461007&isnumber=8460178

C. McGinn, E. Bourke, T. O'Kelly and M. F. Cullinan, "Adapting the Goals/Questions/Metrics (GQM) Method for Applications in Robot Design," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4746-4751.
doi: 10.1109/ICRA.2018.8460630
Abstract: Developing advanced robots can be a resource-intensive activity that creates many challenges for research teams. There is a need to formulate new techniques for systematically designing complex robot systems, especially in cases where high adaptability is needed and design metrics cannot be explicitly specified in advance. This research explores how the Goals/Questions/Metrics (GQM) method, a well-established technique for process measurement, can be modified for use as a design tool in robotics. To illustrate how a design-orientated GQM method may be used in practice, a sample use-case is given detailing how the approach was applied to the task of developing a bespoke robotic gripper for a service robot. The study provides an early indication that the adoption of GQM principles by designers can have significant benefits in robotics applications. However, further investigation is needed to better understand the magnitude and scope of any improvements.
keywords: {Measurement;Prototypes;Grippers;Service robots;Robot sensing systems;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460630&isnumber=8460178

A. K. Bozcuoğlu et al., "The Exchange of Knowledge Using Cloud Robotics," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4768-4775.
doi: 10.1109/ICRA.2018.8460187
Abstract: To enable robots to perform human-level tasks flexibly in varying conditions, we need a mechanism that allows them to exchange knowledge between themselves for crowd-sourcing the knowledge gap problem. One approach to achieve this is to equip a cloud application with a range of encyclopedic knowledge (i.e. ontologies) and execution logs of different robots performing the same tasks in different environments. In this paper, we show how knowledge exchange between robots can be done using OPENEASE as the cloud application. We equipped OPENEASE with ontologies about the kitchen domain, execution logs of three robots operating in two different kitchens, and semantic descriptions of both environments. By addressing two different use cases, we show that two PR2 robots and one Fetch robot can successfully adapt each other's plan parameters and sub symbolic data to the experiments that they are conducting.
keywords: {Robots;Ontologies;Semantics;Task analysis;Containers;Cloud computing;Cognition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460187&isnumber=8460178

V. Thangavelu, Y. Liu, M. Saboia and N. Napp, "Dry Stacking for Automated Construction with Irregular Objects," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4782-4789.
doi: 10.1109/ICRA.2018.8460562
Abstract: We describe a method for automatically building structures from stacked, irregularly shaped objects. This is a simplified model for the problem of building dry stacked structures (i.e. no mortar) from found stones. Although automating such construction methods would be ideally suited for disaster areas or remote environments, currently such structures need to be built by skilled masons. No practical methods for automating the assembly planning process are known. The problem is challenging since each assembly action can be drawn from a continuous space poses for an object and several local geometric and physical considerations strongly affect the overall stability. We show that structures that are built following a stacking order for perfect bricks can accommodate a limited amount of irregularity, however, their performance degrades quickly when objects deviate from their ideal shape. We present a strategy for stacking irregular shapes that first considers geometric and physical constraints to find a small set of feasible actions and then further refines this set by using heuristics gathered from instructional literature for masons. The proposed method of choosing assembly actions allows construction with objects that contain a significant amount of variation.
keywords: {Shape;Stacking;Planning;Stability analysis;Two dimensional displays;Building materials},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460562&isnumber=8460178

T. Aoyama, M. Hanabishi, T. Takaki, I. Ishii and Y. Hasegawa, "High-Speed Well-Focused Image-Capturing System for Moving Micro-Objects Based on Histograms of the Luminance," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4790-4795.
doi: 10.1109/ICRA.2018.8461238
Abstract: In recent years, vision-based analysis systems of micro-objects in a microchannel have been actively developed. However, it is difficult to focus on high-speed micro-objects in a microchannel because the general height of a microchannel is approximately 10-100 μm, whereas the depth of focus of the objective lens is approximately 1-4 μm. Therefore, we propose a high-speed well-focused image-capturing microscope, which is a system with an objective lens attached to a vibration machine that moves the focus position rapidly by oscillating it up and down to capture well-focused images using a histogram-based algorithm. The proposed microscope system is verified experimentally to capture well-focused images of moving micro- objects.
keywords: {Vibrations;Microscopy;Lenses;Histograms;Microchannels;Lighting;Machine vision},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461238&isnumber=8460178

F. Ma and S. Karaman, "Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single Image," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4796-4803.
doi: 10.1109/ICRA.2018.8460184
Abstract: We consider the problem of dense depth prediction from a sparse set of depth measurements and a single RGB image. Since depth estimation from monocular images alone is inherently ambiguous and unreliable, to attain a higher level of robustness and accuracy, we introduce additional sparse depth samples, which are either acquired with a low-resolution depth sensor or computed via visual Simultaneous Localization and Mapping (SLAM) algorithms. We propose the use of a single deep regression network to learn directly from the RGB-D raw data, and explore the impact of number of depth samples on prediction accuracy. Our experiments show that, compared to using only RGB images, the addition of 100 spatially random depth samples reduces the prediction root-mean-square error by 50% on the NYU-Depth-v2 indoor dataset. It also boosts the percentage of reliable prediction from 59 % to 92 % on the KITTI dataset. We demonstrate two applications of the proposed algorithm: a plug-in module in SLAM to convert sparse maps to dense maps, and super-resolution for LiDARs. Software22https://github.com/fangchangma/sparse-to-dense and video demonstration33https://www.youtube.com/watch?v=vNIIT_M7×7Y are publicly available.
keywords: {Training;Laser radar;Image reconstruction;Estimation;Prediction algorithms;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460184&isnumber=8460178

Y. -J. Lee and S. -W. Seo, "Real-Time Object Tracking in Sparse Point Clouds Based on 3D Interpolation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4804-4811.
doi: 10.1109/ICRA.2018.8460639
Abstract: While object tracking for 3D point clouds has been widely researched in recent years, most trackers employ a direct point-to-point matching method under the assumption that target object clouds are dense, although the method is not suitable for sparse point clouds. In this paper, we introduce a novel object-tracking strategy that enables even sparse point clouds to be tracked properly. The strategy involves estimating distributions, called as Estimation of Vertical Distributions (EVD), by the proposed interpolation method to augment data and by a point-to-distribution matching technique. The EVD step generates vertical distributions of unoccupied areas on a target object using the distributions of the occupied areas and then seeks the optimal solution through a coarse-to-fine grid search to guarantee real-time performance. In order to verify the proposed tracking algorithm, we have tested our tracker on real world data collected by our own platform, and the results have demonstrated that the tracker outperforms other trackers.
keywords: {Three-dimensional displays;Target tracking;Real-time systems;Solid modeling;Interpolation;Vehicle dynamics;Laser radar},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460639&isnumber=8460178

Z. Min, J. Wang and M. Q. . -H. Meng, "Robust Generalized Point Cloud Registration Using Hybrid Mixture Model," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4812-4818.
doi: 10.1109/ICRA.2018.8460825
Abstract: This paper introduces a robust point cloud registration method which utilizes not only positional but also the orientation information at each point. The proposed method takes a probabilistic approach which forms the problem as a hybrid mixture model, in which a Von-Mises-Fisher mixture model (FMM) is adopted to model the orientation part and a gaussian mixture model (GMM) is used to represent the position part. When two point clouds are optimally registered, the correspondence is the maximum of the posterior probability of the overall mixture model. Expectation-Maximization (EM) algorithm has been adopted to solve the optimization problem in an iterative manner to find the optimal rotation and translation between two point clouds. Extensive experiments under different noise levels and different outlier ratios have been carried out on a dataset of the femur CT images. Comparison results show that the proposed method outperforms the state-of-the-art methods under most of the experimental conditions, which indicates the validity of our method.
keywords: {Three-dimensional displays;Mixture models;Iterative closest point algorithm;Robustness;Probabilistic logic;Gaussian mixture model;Point cloud registration;Von-Mises-Fisher distribution;Gaussian mixture model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460825&isnumber=8460178

Y. Hu, Y. Gu, J. Yang and G. -Z. Yang, "Multi-Stage Suture Detection for Robot Assisted Anastomosis Based on Deep Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4826-4833.
doi: 10.1109/ICRA.2018.8461131
Abstract: The technique of robust suture detection is vital in many applications including trainee suturing skill evaluation, suture augmentation in robotic-assisted surgery and suture recognition for automatic suturing. Due to the complicated environment of surgery, the detection of a suture is challenged by high deformation and frequent occlusion. In this paper, we propose a deep multi-stage framework for suture detection. The fully convolutional neural networks are firstly used to predict a gradient map which not only serves as a segmentation mask, but also provides useful structure information for the following thread centerline reconstruction. An overlapping map is also predicted to improve the quality of the gradient map in self-intersection area. Based on the gradient map, multiple segments of the thread are extracted and linked to form the whole thread using a curvilinear structure detector. Experiments on two types of threads demonstrate that the proposed method is able to detect the thread with human level performance when the thread is no occlusion or under finite self-intersection.
keywords: {Yarn;Instruction sets;Surgery;Splines (mathematics);Image reconstruction;Robots;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461131&isnumber=8460178

W. Yuan, Y. Mo, S. Wang and E. H. Adelson, "Active Clothing Material Perception Using Tactile Sensing and Deep Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4842-4849.
doi: 10.1109/ICRA.2018.8461164
Abstract: Humans represent and discriminate the objects in the same category using their properties, and an intelligent robot should be able to do the same. In this paper, we build a robot system that can autonomously perceive the object properties through touch. We work on the common object category of clothing. The robot moves under the guidance of an external Kinect sensor, and squeezes the clothes with a GelSight tactile sensor, then it recognizes the 11 properties of the clothing according to the tactile data. Those properties include the physical properties, like thickness, fuzziness, softness and durability, and semantic properties, like wearing season and preferred washing methods. We collect a dataset of 153 varied pieces of clothes, and conduct 6616 robot exploring iterations on them. To extract the useful information from the high-dimensional sensory output, we applied Convolutional Neural Networks (CNN) on the tactile data for recognizing the clothing properties, and on the Kinect depth images for selecting exploration locations. Experiments show that using the trained neural networks, the robot can autonomously explore the unknown clothes and learn their properties. This work proposes a new framework for active tactile perception system with vision-touch system, and has potential to enable robots to help humans with varied clothing related housework.
keywords: {Clothing;Tactile sensors;Shape;Grippers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461164&isnumber=8460178

D. Kularatne, H. Hajieghrary and M. Ani Hsieh, "Optimal Path Planning in Time-Varying Flows with Forecasting Uncertainties," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4857-4864.
doi: 10.1109/ICRA.2018.8460221
Abstract: Uncertainties in flow models have to be explicitly considered for effective path planning in marine environments. In this paper, we present two methods to compute minimum expected cost policies and paths over an uncertain flow model. The first method based on a Markov Decision Process computes a minimum expected cost policy while the second graph search based method, computes a minimum expected cost path. A transition probability model is developed to compute the probability of transition from one state to another under a given action. In addition, a method to compute the expected cost of a path when it is executed in an uncertain flow field is also presented. The two methods are used to compute minimum energy paths in an ocean environment and the results are analyzed in simulations.
keywords: {Path planning;Computational modeling;Oceans;Predictive models;Forecast uncertainty;Drag},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460221&isnumber=8460178

S. McCammon and G. A. Hollinger, "Topological Hotspot Identification for Informative Path Planning with a Marine Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4865-4872.
doi: 10.1109/ICRA.2018.8460652
Abstract: In this work, we present a novel method for constructing a topological map of biological hotspots in an aquatic environment using a Fast Marching-based Voronoi segmentation. Using this topological map, we develop a closed form solution to the scheduling problem for any single path through the graph. Searching over the space of all paths allows us to compute a maximally informative path that traverses a subset of the hotspots, given some budget. Using a greedy-coverage algorithm we can then compute an informative path. We evaluate our method in a set of simulated trials, both with randomly generated environments and a real-world environment. In these trials, we show that our method produces a topological graph which more accurately captures features in the environment than standard thresholding techniques. Additionally, We show that our method can improve the performance of a greedy-coverage algorithm in the informative path planning problem by guiding it to different informative areas to help it escape from local maxima.
keywords: {Path planning;Monitoring;Oceans;Robot sensing systems;Task analysis;Frequency modulation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460652&isnumber=8460178

S. Manjanna, A. Q. Li, R. N. Smith, I. Rekleitis and G. Dudek, "Heterogeneous Multi-Robot System for Exploration and Strategic Water Sampling," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4873-4880.
doi: 10.1109/ICRA.2018.8460759
Abstract: Physical sampling of water for off-site analysis is necessary for many applications like monitoring the quality of drinking water in reservoirs, understanding marine ecosystems, and measuring contamination levels in fresh-water systems. In this paper, the focus is on algorithms for efficient measurement and sampling using a multi-robot, data-driven, water-sampling behavior, where autonomous surface vehicles plan and execute water sampling using the chlorophyll density as a cue for plankton-rich water samples. We use two Autonomous Surface Vehicles (ASVs), one equipped with a water quality sensor and the other equipped with a water-sampling apparatus. The ASV with the sensor acts as an explorer, measuring and building a spatial map of chlorophyll density in the given region of interest. The ASV equipped with the water sampling apparatus makes decisions in real time on where to sample the water based on the suggestions made by the explorer robot. We evaluate the system in the context of measuring chlorophyll distributions. We do this both in simulation based on real geophysical data from MODIS measurements, and on real robots in a water reservoir. We demonstrate the effectiveness of the proposed approach in several ways including in terms of mean error in the interpolated data as a function of distance traveled.
keywords: {Pollution measurement;Geophysical measurements;Robot sensing systems;Real-time systems;Time measurement;Water pollution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460759&isnumber=8460178

P. Bhanu Solanki and X. Tan, "Extended Kalman Filter-Based 3D Active-Alignment Control for LED Communication," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4881-4888.
doi: 10.1109/ICRA.2018.8460949
Abstract: LED-based optical communication is emerging as a low-cost, high-data-rate alternative to the traditional acoustics mode of underwater communication. However, it is challenging to establish and maintain Line-Of-Sight (LOS) between the receiver and the transmitter, especially when such systems are used by mobile robots. Hence, there is a need for an active alignment system that enables the receiver to constantly align itself towards the direction of the transmitting device. In this paper, we propose and implement an active alignment control system capable of tracking a transmitting source moving in the three-dimensional (3D) space. An extended Kalman filter is used to estimate the components of the angle between the receiver orientation and the receiver-transmitter line. Using the estimate, a proportional-integral (PI) controller is implemented to adjust the receiver orientation. The algorithm uses one measurement of the light intensity from a single photo-diode, where successive measurements are obtained via a circular scanning technique. The amplitude of the scanning is adapted to the alignment performance, to achieve a sound trade-off between estimation accuracy, signal strength, and energy consumption. Simulation and experimental results are presented to illustrate the effectiveness of the proposed approach.
keywords: {Receivers;Transmitters;Light emitting diodes;Robots;Three-dimensional displays;Estimation;Optical fiber communication},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460949&isnumber=8460178

S. Arnold and L. Medagoda, "Robust Model-Aided Inertial Localization for Autonomous Underwater Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4889-4896.
doi: 10.1109/ICRA.2018.8460839
Abstract: This paper presents a manifold based Unscented Kalman Filter that applies a novel strategy for inertial, model-aiding and Acoustic Doppler Current Profiler (ADCP) measurement incorporation. The filter is capable of observing and utilizing the Earth rotation for heading estimation with a tactical grade IMU, and utilizes information from the vehicle model during DVL drop outs. The drag and thrust model-aiding accounts for the correlated nature of vehicle model parameter error by applying them as states in the filter. ADCP-aiding provides further information for the model-aiding in the case of DVL bottom-lock loss. Additionally this work was implemented using the MTK and ROCK framework in C++, and is capable of running in real-time on computing available on the FlatFish AUV. The IMU biases are estimated in a fully coupled approach in the navigation filter. Heading convergence is shown on a real-world data set. Further experiments show that the filter is capable of consistent positioning, and data denial validates the method for DVL dropouts due to very low or high altitude scenarios.
keywords: {Navigation;Mathematical model;Accelerometers;Damping;Uncertainty;Acoustics;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460839&isnumber=8460178

Z. J. Harris and L. L. Whitcomb, "Preliminary Evaluation of Cooperative Navigation of Underwater Vehicles without a DVL Utilizing a Dynamic Process Model," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4897-4904.
doi: 10.1109/ICRA.2018.8460970
Abstract: This paper reports a preliminary study for use of a fully dynamic vehicle process model in combined underwater communication and navigation (cooperative navigation) of underwater vehicles equipped with an acoustic modem, attitude, and depth sensors, but lacking a Doppler velocity log (DVL), and a surface vehicle equipped with an acoustic modem and GPS. We report both simulation and at-sea experimental trials with the JHU Iver3 autonomous underwater vehicle (AUV). The case of underwater vehicle navigation without a DVL is of interest in several use-cases including (a) small and low-cost underwater vehicles for which DVLs may be impractical or infeasible due to their size and cost and (b) for missions in which the vehicle's altitude above the sea floor (or depth beneath overhead ice) exceeds the DVL acoustic bottom-lock range. To the best of our knowledge, all previous studies on cooperative navigation have reported use of a kinematic process model, which works well in the presence of frequent, high-accuracy velocity measurements, as is the case when the vehicle is equipped with a DVL. This preliminary study suggests that the dynamical process model may offer a significant advantage over the purely kinematic model in the absence of frequent, high-accuracy velocity measurements, as is the case when the submerged vehicle is not equipped with a DVL.
keywords: {Acoustics;Underwater vehicles;Kinematics;Global Positioning System;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460970&isnumber=8460178

O. Limoyo, T. Ablett, F. Marić, L. Volpatti and J. Kelly, "Self-Calibration of Mobile Manipulator Kinematic and Sensor Extrinsic Parameters Through Contact-Based Interaction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4913-4920.
doi: 10.1109/ICRA.2018.8460658
Abstract: We present a novel approach for mobile manipulator self-calibration using contact information. Our method, based on point cloud registration, is applied to estimate the extrinsic transform between a fixed vision sensor mounted on a mobile base and an end effector. Beyond sensor calibration, we demonstrate that the method can be extended to include manipulator kinematic model parameters, which involves a nonrigid registration process. Our procedure uses on-board sensing exclusively and does not rely on any external measurement devices, fiducial markers, or calibration rigs. Further, it is fully automatic in the general case. We experimentally validate the proposed method on a custom mobile manipulator platform, and demonstrate centimetre-level post-calibration accuracy in positioning of the end effector using visual guidance only. We also discuss the stability properties of the registration algorithm, in order to determine the conditions under which calibration is possible.
keywords: {Robot sensing systems;Three-dimensional displays;Manipulators;Calibration;Cameras;Kinematics;Transforms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460658&isnumber=8460178

T. Messay-Kebede, G. Sutton and O. Djaneye-Boundjou, "Geometry Based Self Kinematic Calibration Method for Industrial Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4921-4926.
doi: 10.1109/ICRA.2018.8460764
Abstract: Accuracy of robots is an important facet in an industrial setting. In this paper, we present a novel kinematic calibration methodology. Traditional calibration techniques require an external metrology device. Unlike those, the presented product here is highly practical in that it does not require a metrology device. The kinematic calibration model is formulated by making use of the robot itself as a metrology device to measure the geometry of a known artifact. The optimal parameters/characteristics of the model are identified using a Particle Swarm Optimization (PSO) technique. Our experimental results show that this new approach provides results comparable to those generated using spatial information provided by a Coordinate Measurement Machine (CMM). Using this new approach (GageCAL), the Yaskawa Motoman “MHS-Hi” robot is calibrated. Our experimental testing also indicates that this methodology can be extended to a wide variety of anthropomorphic robots.
keywords: {Robot kinematics;Calibration;Probes;Metrology;Bars;Data acquisition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460764&isnumber=8460178

V. Bonnet, A. Crosnier, G. Venture, M. Gautier and P. Fraisse, "Inertial Parameters Identification of a Humanoid Robot Hanged to a Fix Force Sensor," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4927-4932.
doi: 10.1109/ICRA.2018.8461112
Abstract: Knowledge of the mass and inertial parameters of a humanoid robot is crucial for the development of model-based controller and motion planning in dynamics situation. Parameters are usually provided from Computer Aided Design (CAD) data and thus inaccurate specially if the robot is modified over time. In this paper, a practical method consisting of hanging a humanoid robot to a fix force sensor to perform its dynamic identification is proposed. This allows, contrary to the literature, to generate very exciting and dynamic motions to identify most of the elements of the inertia tensors in a reduced amount of time. This procedure transforms an instable floating base legged humanoid robot to a safe fix base tree structure robot which makes easier to generate optimal exciting motions. Because of a better excitation the overall trajectory lasts for less than a minute. The method was experimentally validated with a HOAP3 humanoid robot and using a 6-axis force sensor. A reduction of 3 times in average of the RMS difference between measured external reaction forces and moments and their estimates from CAD data was obtained with a single minute of optimal exciting motions.
keywords: {Humanoid robots;Force sensors;Dynamics;Robot sensing systems;Mathematical model;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461112&isnumber=8460178

S. Aghli and C. Heckman, "Online System Identification and Calibration of Dynamic Models for Autonomous Ground Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4933-4939.
doi: 10.1109/ICRA.2018.8460691
Abstract: This paper is concerned with system identification and the calibration of parameters of dynamic models used in different robotic platforms. A constant time algorithm has been developed in order to automatically calibrate the parameters of a high-fidelity dynamical model for a robotic platform. The presented method is capable of choosing informative motion segments in order to calibrate model parameters in constant time while also calculating a confidence level on each estimated parameter. Simulations and experiments with a ⅛ th scale four wheel drive vehicle are performed to calibrate two of the parameters of test vehicle which demonstrate the accuracy and efficiency of the approach.
keywords: {Calibration;Vehicle dynamics;Motion segmentation;Dynamics;Wheels;Friction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460691&isnumber=8460178

K. Huang and C. Stachniss, "On Geometric Models and Their Accuracy for Extrinsic Sensor Calibration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4948-4954.
doi: 10.1109/ICRA.2018.8461029
Abstract: Extrinsic sensor calibration is an important task in robotics. There are various ways to perform the calibration task, but it often remains unclear which methods are better than the others. In this paper, we provide a systematic study about the calibration accuracy of three types of calibration methods, each represented by an abstract geometric model based on the sensor configuration and the calibration setup. We discuss the advantages and disadvantages of each model and perform a rigorous study on their noise sensitivity from a geometric perspective. As a result, we can reveal and quantify the relative calibration accuracies of the three models, thus answering the question of “which model is better and why?”. Beside our analytical analysis, we also provide numerical simulation experiments that validate our findings.
keywords: {Calibration;Cameras;Estimation;Task analysis;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461029&isnumber=8460178

F. Leborne, V. Creuze, A. Chemori and L. Brignone, "Dynamic Modeling and Identification of an Heterogeneously Actuated Underwater Manipulator Arm," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4955-4960.
doi: 10.1109/ICRA.2018.8460963
Abstract: This paper deals with the dynamic modeling and identification of an electrically driven underwater robot manipulator. The proposed study includes the dynamic modeling of the actuators of the arm as well as the identification of the parameters of the model. The proposed method deals with the specific case of heterogeneously actuated arms, namely arms with actuators behaving differently for each joint, being considered at the kinematic level. Indeed, we show how to estimate the arms parameters when some of their revolute joints are directly actuated by geared motors, while the others are actuated by linear actuators. A minimum set of identifiable parameters is determined, and adequate excitation trajectories are generated and used in the identification procedure. Realtime experimental validation on the manipulator arms of Ifremer's HROV (Hybrid Remotely Operated Vehicle) Ariane underwater vehicle demonstrates that the proposed method improves the estimation of the dynamic model.
keywords: {Manipulator dynamics;Actuators;Vehicle dynamics;Gears;Friction;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460963&isnumber=8460178

B. Della Corte, I. Bogoslavskyi, C. Stachniss and G. Grisetti, "A General Framework for Flexible Multi-Cue Photometric Point Cloud Registration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4969-4976.
doi: 10.1109/ICRA.2018.8461049
Abstract: The ability to build maps is a key functionality for the majority of mobile robots. A central ingredient to most mapping systems is the registration or alignment of the recorded sensor data. In this paper, we present a general methodology for photometric registration that can deal with multiple different cues. We provide examples for registering RGBD as well as 3D LIDAR data. In contrast to popular point cloud registration approaches such as ICP our method does not rely on explicit data association and exploits multiple modalities such as raw range and image data streams. Color, depth, and normal information are handled in an uniform manner and the registration is obtained by minimizing the pixel-wise difference between two multi-channel images. We developed a flexible and general framework and implemented our approach inside that framework. We also released our implementation as open source C++ code. The experiments show that our approach allows for an accurate registration of the sensor data without requiring an explicit data association or model-specific adaptations to datasets or sensors. Our approach exploits the different cues in a natural and consistent way and the registration can be done at framerate for a typical range or imaging sensor.
keywords: {Three-dimensional displays;Robot sensing systems;Cameras;Iterative closest point algorithm;Minimization;Integrated circuit modeling;Laser radar},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461049&isnumber=8460178

C. S. Weerasekera, T. Dharmasiri, R. Garg, T. Drummond and I. Reid, "Just-in-Time Reconstruction: Inpainting Sparse Maps Using Single View Depth Predictors as Priors," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4977-4984.
doi: 10.1109/ICRA.2018.8460549
Abstract: We present “just-in-time reconstruction” as realtime image-guided inpainting of a map with arbitrary scale and sparsity to generate a fully dense depth map for the image. In particular, our goal is to inpaint a sparse map - obtained from either a monocular visual SLAM system or a sparse sensor - using a single-view depth prediction network as a virtual depth sensor. We adopt a fairly standard approach to data fusion, to produce a fused depth map by performing inference over a novel fully-connected Conditional Random Field (CRF) which is parameterized by the input depth maps and their pixel-wise confidence weights. Crucially, we obtain the confidence weights that parameterize the CRF model in a data-dependent manner via Convolutional Neural Networks (CNNs) which are trained to model the conditional depth error distributions given each source of input depth map and the associated RGB image. Our CRF model penalises absolute depth error in its nodes and pairwise scale-invariant depth error in its edges, and the confidence-based fusion minimizes the impact of outlier input depth values on the fused result. We demonstrate the flexibility of our method by real-time inpainting of ORB-SLAM, Kinect, and LIDAR depth maps acquired both indoors and outdoors at arbitrary scale and varied amount of irregular sparsity.
keywords: {Image reconstruction;Simultaneous localization and mapping;Visualization;Three-dimensional displays;Real-time systems;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460549&isnumber=8460178

P. Amayo, P. Piniés, L. M. Paz and P. Newman, "Fast Global Labelling for Depth-Map Improvement Via Architectural Priors," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4985-4992.
doi: 10.1109/ICRA.2018.8460192
Abstract: Depth map estimation techniques from cameras often struggle to accurately estimate the depth of large textureless regions. In this work we present a vision-only method that accurately extracts planar priors from a viewed scene without making any assumptions of the underlying scene layout. Through a fast global labelling, these planar priors can be associated to the individual pixels leading to more complete depth-maps specifically over large, plain and planar regions that tend to dominate the urban environment. When these depth-maps are deployed to the creation of a vision only dense reconstruction over large scales, we demonstrate reconstructions that yield significantly better results in terms of coverage while still maintaining high accuracy.
keywords: {Labeling;Estimation;Minimization;Image reconstruction;Cameras;Pipelines;Surface texture},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460192&isnumber=8460178

M. Mielle, M. Magnusson and A. J. Lilienthal, "A Method to Segment Maps from Different Modalities Using Free Space Layout MAORIS: Map of Ripples Segmentation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 4993-4999.
doi: 10.1109/ICRA.2018.8461128
Abstract: How to divide floor plans or navigation maps into semantic representations, such as rooms and corridors, is an important research question in fields such as human-robot interaction, place categorization, or semantic mapping. While most works focus on segmenting robot built maps, those are not the only types of map a robot, or its user, can use. We present a method for segmenting maps from different modalities, focusing on robot built maps and hand-drawn sketch maps, and show better results than state of the art for both types. Our method segments the map by doing a convolution between the distance image of the map and a circular kernel, and grouping pixels of the same value. Segmentation is done by detecting ripple-like patterns where pixel values vary quickly, and merging neighboring regions with similar values. We identify a flaw in the segmentation evaluation metric used in recent works and propose a metric based on Matthews correlation coefficient (MCC). We compare our results to ground-truth segmentations of maps from a publicly available dataset, on which we obtain a better MCC than the state of the art with 0.98 compared to 0.65 for a recent Voronoi-based segmentation method and 0.70 for the DuDe segmentation method. We also provide a dataset of sketches of an indoor environment, with two possible sets of ground truth segmentations, on which our method obtains an MCC of 0.56 against 0.28 for the Voronoi-based segmentation method and 0.30 for DuDe.
keywords: {Image segmentation;Merging;Robot kinematics;Robot sensing systems;Measurement;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461128&isnumber=8460178

D. Droeschel and S. Behnke, "Efficient Continuous-Time SLAM for 3D Lidar-Based Online Mapping," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5000-5007.
doi: 10.1109/ICRA.2018.8461000
Abstract: Modern 3D laser-range scanners have a high data rate, making online simultaneous localization and mapping (SLAM) computationally challenging. Recursive state estimation techniques are efficient but commit to a state estimate immediately after a new scan is made, which may lead to misalignments of measurements. We present a 3D SLAM approach that allows for refining alignments during online mapping. Our method is based on efficient local mapping and a hierarchical optimization back-end. Measurements of a 3D laser scanner are aggregated in local multiresolution maps by means of surfel-based registration. The local maps are used in a multi-level graph for allocentric mapping and localization. In order to incorporate corrections when refining the alignment, the individual 3D scans in the local map are modeled as a sub-graph and graph optimization is performed to account for drift and misalignments in the local maps. Furthermore, in each sub-graph, a continuous-time representation of the sensor trajectory allows to correct measurements between scan poses. We evaluate our approach in multiple experiments by showing qualitative results. Furthermore, we quantify the map quality by an entropy-based measure.
keywords: {Three-dimensional displays;Measurement by laser beam;Optimization;Trajectory;Laser modes;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461000&isnumber=8460178

C. Wang, T. Li, M. Q. . -H. Meng and C. De Silva, "Efficient Mobile Robot Exploration with Gaussian Markov Random Fields in 3D Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5015-5021.
doi: 10.1109/ICRA.2018.8460788
Abstract: In this paper, we study the problem of autonomous exploration in unknown indoor environments using mobile robot. We use mutual information (MI) to evaluate the information the robot would get at a certain location. In order to get the most informative sensing location, we first propose a sampling method that can get random sensing patches in free space. Each sensing patch is extended to informative locations to collect information with true values. Then we use Gaussian Markov Random Fields (GMRF) to model the distribution of MI in environment. Compared with the traditional methods that employ Gaussian Process (GP) model, GMRF is more efficient. MI of every sensing location can be estimated using the training sample patches and the established GMRF model. We utilize an efficient computation algorithm to estimate the GMRF model hyperparameters so as to speed up the computation. Besides the information gain of the candidates regions, the path cost is also considered in this work. We propose a utility function that can balance the path cost and the information gain the robot would collect. We tested our algorithm in both simulated and real experiment. The experiment results demonstrate that our proposed method can explore the environment efficiently with relatively shorter path length.
keywords: {Robot sensing systems;Computational modeling;Mathematical model;Training;Mutual information},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460788&isnumber=8460178

C. Sarkar, H. S. Paul and A. Pal, "A Scalable Multi-Robot Task Allocation Algorithm," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5022-5027.
doi: 10.1109/ICRA.2018.8460886
Abstract: In modern warehouses, robots are being deployed to perform complex tasks such as fetching a set of objects from various locations in a warehouse to a docking station. This requires a careful task allocation along with route planning such that the total distance traveled (cost) is minimized. The number of tasks that can be performed by a robot on a single route depends on the maximum capacity of the robot and the combined weight of the objects it picks on the route. This task allocation problem is an instance of the Capacity-constrained Vehicle Routing Problem (CVRP), which is known to be NP-hard. Although, there exist a number of heuristics that provide near-optimal solutions to a CVRP instance, they do not scale well with the task size (number of nodes). In this paper, we present a heuristic, called nearest-neighbor based Clustering And Routing <tex>$(nCAR)$</tex>, which has better execution time compared to the state-of-the-art heuristics. Also, our heuristic reduces cost of the solutions when there are a large number of nodes. We compare the performance of <tex>$nCAR$</tex> with the Google OR-Tools and found a speedup of 6 in runtime when task size is 2000. Though OR-Tools provides a low-cost solution for small number of tasks, it&#x0027;s execution time and number of routes is 1.5 times that of nCAR.
keywords: {Task analysis;Heuristic algorithms;Clustering algorithms;Resource management;Routing;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460886&isnumber=8460178

Y. Kantaros and M. M. Zavlanos, "Distributed Intermittent Communication Control of Mobile Robot Networks Under Time-Critical Dynamic Tasks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5028-5033.
doi: 10.1109/ICRA.2018.8460570
Abstract: In this paper, we develop a distributed intermittent communication framework for teams of mobile robots that are responsible for accomplishing time-critical dynamic tasks and sharing the collected information with all other robots and possibly also with a user. Specifically, we consider situations where the robot communication capabilities are not sufficient to maintain reliable and connected networks while the robots move to accomplish their tasks. In this case, intermittent communication protocols are necessary that allow the robots to temporarily disconnect from the network in order to accomplish their tasks free of communication constraints. We assume that the robots can only communicate with each other when they meet at common locations in space. Our proposed distributed control framework determines offline schedules of communication events and integrates them online with task planning. The resulting paths ensure task accomplishment and exchange of information among robots infinitely often at locations that minimize a user-specified metric. Simulation results corroborate the proposed distributed control framework.
keywords: {Task analysis;Robot sensing systems;Time factors;Schedules;Communication networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460570&isnumber=8460178

R. Ramaithititima and S. Bhattacharya, "Landmark-based Exploration with Swarm of Resource Constrained Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5034-5041.
doi: 10.1109/ICRA.2018.8460884
Abstract: In this paper we consider the problem of autonomous exploration of an unknown, GPS-denied environment using a swarm of robots with very limited resources and limited sensing capabilities. To that end we use a landmark complex, a simplicial complex utilizing an observation of landmarks, as a topological representation of the environment. Each robot is equipped with an omni-directional, limited-range sensor that can identify landmarks in the robot's neighborhood. The robots use the bearing angles to the landmarks for local navigation. Given a collection of identifiable landmarks, a landmark complex can then be cumulatively constructed to encapsulate the topological information of the environment. Under the assumption of sufficiently dense landmarks, we propose an exploration and exploitation strategy that guides the swarm of robots to explore an environment using only bearing measurements without any metric information. Lastly, we demonstrate the coordinate-free and localization-free navigation in the environment using the constructed landmark complex.
keywords: {Robot kinematics;Robot sensing systems;Navigation;Dispersion;Measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460884&isnumber=8460178

G. Notomista and M. Egerstedt, "Coverage Control for Wire-Traversing Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5042-5047.
doi: 10.1109/ICRA.2018.8461123
Abstract: In this paper we consider the coverage control problem for a team of wire-traversing robots. The two-dimensional motion of robots moving in a planar environment has to be projected to one-dimensional manifolds representing the wires. Starting from Lloyd's descent algorithm for coverage control, a solution that generates continuous motion of the robots on the wires is proposed. This is realized by means of a Continuous Onto Wires (COW) map: the robots' workspace is mapped onto the wires on which the motion of the robots is constrained to be. A final projection step is introduced to ensure that the configuration of the robots on the wires is a local minimizer of the constrained locational cost. An algorithm for the continuous constrained coverage control problem is proposed and it is tested both in simulation and on a team of mobile robots.
keywords: {Wires;Minimization;Robot sensing systems;Optimization;Motion control;Power transmission lines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461123&isnumber=8460178

Y. Hirata, K. Kimura, S. Matsuzaki, N. Ogawa and T. Kubota, "Control of Multiple Passive-Follower Type Robots Based on Feasible Braking Control Region Analysis," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5056-5061.
doi: 10.1109/ICRA.2018.8460637
Abstract: Ahstract- In this study, we propose a development and formation control of a passive mobile robot equipped only with servo brakes and no motors. The developed passive mobile robot can move forward by utilizing an external pulling force, and steers itself by controlling the servo brakes attached to each wheel. Systems composed of multiple mobile robots are very effective at exploring vast areas. However the coordination and simultaneous control of several robots utilizing simple information is a difficult task. Therefore we propose a leader follower architecture composed of multiple passive follower robots tethered to one active leader. In this paper, we first introduce the developed passive mobile robot. Then, we analyze the fundamental control method of this passive mobile robot from the perspective of the feasible braking control region, which considers the slip of the passive robot and the limitation of the external pulling force from the active leader. Lastly, a control law for the servo brakes attached to each wheel is proposed, followed by a feasibility study to determine whether the passive followers can stay in formation by controlling the servo brakes with the proposed control law.
keywords: {Mobile robots;Force;Wheels;Robot kinematics;Brakes;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460637&isnumber=8460178

O. Arslan, H. Min and D. E. Koditschek, "Voronoi-Based Coverage Control of Pan/Tilt/Zoom Camera Networks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5062-5069.
doi: 10.1109/ICRA.2018.8460701
Abstract: A challenge of pan/tilt/zoom (PTZ) camera networks for efficient and flexible visual monitoring is automated active network reconfiguration in response to environmental stimuli. In this paper, given an event/activity distribution over a convex environment, we propose a new provably correct reactive coverage control algorithm for PTZ camera networks that continuously (re) configures camera orientations and zoom levels (i.e., angles of view) in order to locally maximize their total coverage quality. Our construction is based on careful modeling of visual sensing quality that is consistent with the physical nature of cameras, and we introduce a new notion of conic Voronoi diagrams, based on our sensing quality measures, to solve the camera network allocation problem: that is, to determine where each camera should focus in its field of view given all the other cameras' configurations. Accordingly, we design simple greedy gradient algorithms for both continuous-and discrete-time first-order PTZ camera dynamics that asymptotically converge a locally optimal coverage configuration. Finally, we provide numerical and experimental evidence demonstrating the effectiveness of the proposed coverage algorithms.
keywords: {Cameras;Sensors;Heuristic algorithms;Visualization;Resource management;Image resolution;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460701&isnumber=8460178

S. Heim, F. Ruppert, A. A. Sarvestani and A. Spröwitz, "Shaping in Practice: Training Wheels to Learn Fast Hopping Directly in Hardware," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5076-5081.
doi: 10.1109/ICRA.2018.8460984
Abstract: Learning instead of designing robot controllers can greatly reduce engineering effort required, while also emphasizing robustness. Despite considerable progress in simulation, applying learning directly in hardware is still challenging, in part due to the necessity to explore potentially unstable parameters. We explore the concept of shaping the reward landscape with training wheels; temporary modifications of the physical hardware that facilitate learning. We demonstrate the concept with a robot leg mounted on a boom learning to hop fast. This proof of concept embodies typical challenges such as instability and contact, while being simple enough to empirically map out and visualize the reward landscape. Based on our results we propose three criteria for designing effective training wheels for learning in robotics. A video synopsis can be found at https://youtu.be/6iH5E3LrYh8.
keywords: {Legged locomotion;Training;Wheels;Hardware;Hip},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460984&isnumber=8460178

M. Hazara and V. Kyrki, "Speeding Up Incremental Learning Using Data Efficient Guided Exploration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5082-5089.
doi: 10.1109/ICRA.2018.8461241
Abstract: To cope with varying conditions, motor primitives (MPs) must support generalization over task parameters to avoid learning separate primitives for each situation. In this regard, deterministic and probabilistic models have been proposed for generalizing MPs to new task parameters, thus providing limited generalization. Although generalization of MPs using probabilistic models has been studied, it is not clear how such generalizable models can be learned efficiently. Reinforcement learning can be more efficient when the exploration process is tuned with data uncertainty, thus reducing unnecessary exploration in a data-efficient way. We propose an empirical Bayes method to predict uncertainty and utilize it for guiding the exploration process of an incremental learning framework. The online incremental learning framework uses a single human demonstration for constructing a database of MPs. The main ingredients of the proposed framework are a global parametric model (GPDMP) for generalizing MPs for new situations, a model-free policy search agent for optimizing the failed predicted MPs, model selection for controlling the complexity of GPDMp, and empirical Bayes for extracting the uncertainty of MPs prediction. Experiments with a ball-in-a-cup task demonstrate that the global GPDMP model generalizes significantly better than linear models and Locally Weighted Regression especially in terms of extrapolation capability. Furthermore, the model selection has successfully identified the required complexity of GPDMP even with few training samples while satisfying the Occam Razor's prinicple. Above all, the uncertainty predicted by the proposed empirical Bayes approach successfully guided the exploration process of the model-free policy search. The experiments indicated statistically significant improvement of learning speed over covariance matrix adaptation (CMA) with a significance of p=0.002.
keywords: {Task analysis;Uncertainty;Covariance matrices;Adaptation models;Computational modeling;Parametric statistics;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461241&isnumber=8460178

V. Barbaros, H. van Hoof, A. Abdolmaleki and D. Megerl, "Eager and Memory-Based Non-Parametric Stochastic Search Methods for Learning Control," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5090-5096.
doi: 10.1109/ICRA.2018.8460633
Abstract: Direct policy search has shown to be a successful method to optimize robot controller parameters. However, defining a good parametric form for the controller can be challenging for complex problems. Non-parametric methods provide a flexible alternative and are thus a promising tool in robot skill learning. In this paper, we investigate two nonparametric methods based on similar principles but utilizing differing computing schedules: an eager learner and a memory-based learner. We compare the methods experimentally on two different control problems. Furthermore, we define and evaluate a new `hybrid' controller that combines the strong points of both of these methods.
keywords: {Stochastic processes;Robots;Search methods;Task analysis;Entropy;Computational modeling;Kernel},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460633&isnumber=8460178

E. Derner, J. Kubalík and R. Babuška, "Data-driven Construction of Symbolic Process Models for Reinforcement Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5105-5112.
doi: 10.1109/ICRA.2018.8461182
Abstract: Reinforcement learning (RL) is a suitable approach for controlling systems with unknown or time-varying dynamics. RL in principle does not require a model of the system, but before it learns an acceptable policy, it needs many unsuccessful trials, which real robots usually cannot withstand. It is well known that RL can be sped up and made safer by using models learned online. In this paper, we propose to use symbolic regression to construct compact, parsimonious models described by analytic equations, which are suitable for realtime robot control. Single node genetic programming (SNGP) is employed as a tool to automatically search for equations fitting the available data. We demonstrate the approach on two benchmark examples: a simulated mobile robot and the pendulum swing-up problem; the latter both in simulations and real-time experiments. The results show that through this approach we can find accurate models even for small batches of training data. Based on the symbolic model found, RL can control the system well.
keywords: {Mathematical model;Data models;Learning (artificial intelligence);Computational modeling;Mobile robots;Genetic programming;Model learning for control;AI-based methods;symbolic regression;reinforcement learning;optimal control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461182&isnumber=8460178

A. Faust et al., "PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-Based Planning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5113-5120.
doi: 10.1109/ICRA.2018.8461096
Abstract: We present PRM-RL, a hierarchical method for long-range navigation task completion that combines sampling-based path planning with reinforcement learning (RL). The RL agents learn short-range, point-to-point navigation policies that capture robot dynamics and task constraints without knowledge of the large-scale topology. Next, the sampling-based planners provide roadmaps which connect robot configurations that can be successfully navigated by the RL agent. The same RL agents are used to control the robot under the direction of the planning, enabling long-range navigation. We use the Probabilistic Roadmaps (PRMs) for the sampling-based planner. The RL agents are constructed using feature-based and deep neural net policies in continuous state and action spaces. We evaluate PRM-RL, both in simulation and on-robot, on two navigation tasks with non-trivial robot dynamics: end-to-end differential drive indoor navigation in office environments, and aerial cargo delivery in urban environments with load displacement constraints. Our results show improvement in task completion over both RL agents on their own and traditional sampling-based planners. In the indoor navigation task, PRM-RL successfully completes up to 215 m long trajectories under noisy sensor conditions, and the aerial cargo delivery completes flights over 1000 m without violating the task constraints in an environment 63 million times larger than used in training.
keywords: {Task analysis;Robot sensing systems;Indoor navigation;Aerospace electronics;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461096&isnumber=8460178

K. Chatzilygeroudis and J. Mouret, "Using Parameterized Black-Box Priors to Scale Up Model-Based Policy Search for Robotics," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5121-5128.
doi: 10.1109/ICRA.2018.8461083
Abstract: The most data-efficient algorithms for reinforcement learning in robotics are model-based policy search algorithms, which alternate between learning a dynamical model of the robot and optimizing a policy to maximize the expected return given the model and its uncertainties. Among the few proposed approaches, the recently introduced Black-DROPS algorithm exploits a black-box optimization algorithm to achieve both high data-efficiency and good computation times when several cores are used; nevertheless, like all model-based policy search approaches, Black-DROPS does not scale to high dimensional state/action spaces. In this paper, we introduce a new model learning procedure in Black-DROPS that leverages parameterized black-box priors to (1) scale up to high-dimensional systems, and (2) be robust to large inaccuracies of the prior information. We demonstrate the effectiveness of our approach with the “pendubot” swing-up task in simulation and with a physical hexapod robot (48D state space, 18D action space) that has to walk forward as fast as possible. The results show that our new algorithm is more data-efficient than previous model-based policy search algorithms (with and without priors) and that it can allow a physical 6-legged robot to learn new gaits in only 16 to 30 seconds of interaction time.
keywords: {Robots;Data models;Mathematical model;Computational modeling;Heuristic algorithms;Analytical models;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461083&isnumber=8460178

G. Kahn, A. Villaflor, B. Ding, P. Abbeel and S. Levine, "Self-Supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5129-5136.
doi: 10.1109/ICRA.2018.8460655
Abstract: Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and N-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg.
keywords: {Computational modeling;Navigation;Learning (artificial intelligence);Robots;Task analysis;Prediction algorithms;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460655&isnumber=8460178

S. -J. Li, B. Ren, Y. Liu, M. -M. Cheng, D. Frost and V. A. Prisacariu, "Direct Line Guidance Odometry," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5137-5143.
doi: 10.1109/ICRA.2018.8461003
Abstract: Modern visual odometry algorithms utilize sparse point-based features for tracking due to their low computational cost. Current state-of-the-art methods are split between indirect methods that process features extracted from the image, and indirect methods that deal directly on pixel intensities. In recent years, line-based features have been used in SLAM and have shown an increase in performance albeit with an increase in computational cost. In this paper, we propose an extension to a point-based direct monocular visual odometry method. Here we that uses lines to guide keypoint selection rather than acting as features. Points on a line are treated as stronger keypoints than those in other parts of the image, steering point-selection away from less distinctive points and thereby increasing efficiency. By combining intensity and geometry information from a set of points on a line, accuracy may also be increased.
keywords: {Feature extraction;IP networks;Cameras;Optimization;Visual odometry;Simultaneous localization and mapping;Computational efficiency},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461003&isnumber=8460178

Y. Shin, Y. S. Park and A. Kim, "Direct Visual SLAM Using Sparse Depth for Camera-LiDAR System," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5144-5151.
doi: 10.1109/ICRA.2018.8461102
Abstract: This paper describes a framework for direct visual simultaneous localization and mapping (SLAM) combining a monocular camera with sparse depth information from Light Detection and Ranging (LiDAR). To ensure realtime performance while maintaining high accuracy in motion estimation, we present (i) a sliding window-based tracking method, (ii) strict pose marginalization for accurate pose-graph SLAM and (iii) depth-integrated frame matching for large-scale mapping. Unlike conventional feature-based visual and LiDAR mapping, the proposed approach is direct, eliminating the visual feature in the objective function. We evaluated results using our portable camera-LiDAR system as well as KITTI odometry benchmark datasets. The experimental results prove that the characteristics of two complementary sensors are very effective in improving real-time performance and accuracy. Via validation, we achieved low drift error of 0.98 % in the KITTI benchmark including various environments such as a highway and residential areas.
keywords: {Cameras;Laser radar;Three-dimensional displays;Visualization;Simultaneous localization and mapping;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461102&isnumber=8460178

E. Sucar and J. Hayet, "Bayesian Scale Estimation for Monocular SLAM Based on Generic Object Detection for Correcting Scale Drift," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5152-5158.
doi: 10.1109/ICRA.2018.8461178
Abstract: We propose a novel real-time algorithm for estimating the local scale correction of a monocular SLAM system, to obtain a correctly scaled version of the 3D map and of the camera trajectory. Within a Bayesian framework, it integrates observations from a deep-learning based generic object detector and landmarks from the map whose projection lie inside a detection region, to produce scale correction estimates from single frames. For each observation, a prior distribution on the height of the detected object class is used to define the observation's likelihood. Due to the scale drift inherent to monocular SLAM systems, we also incorporate a rough model on the dynamics of scale drift. Quantitative evaluations are presented on the KITTI dataset, and compared with different approaches. The results show a superior performance of our proposal in terms of relative translational error when compared to other monocular systems based on object detection.
keywords: {Simultaneous localization and mapping;Cameras;Three-dimensional displays;Trajectory;Bayes methods;Object detection;Image reconstruction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461178&isnumber=8460178

Y. Chen, S. Huang, R. Fitch and J. Yu, "Efficient Active SLAM Based on Submap Joining, Graph Topology and Convex Optimization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5159-5166.
doi: 10.1109/ICRA.2018.8460864
Abstract: The active SLAM problem considered in this paper aims to plan a robot trajectory for simultaneous localization and mapping (SLAM) as well as for an area coverage task with robot pose uncertainty. Based on a model predictive control (MPC) framework, these two problems are solved respectively by different methods. For the uncertainty minimization MPC problem, based on the graphical structure of the 2D feature-based SLAM, a non-convex constrained least-squares problem is presented to approximate the original problem. Then, using variable substitutions, it is further transformed into a convex problem, and then solved by a convex optimization method. For the coverage task considering robot pose uncertainty, it is formulated and solved by the MPC framework and the sequential quadratic programming (SQP) method. In the whole process, considering the computation complexity, we use linear SLAM, which is a submap joining approach, to reduce the time for planning and estimation. Finally, various simulations are presented to validate the effectiveness of the proposed approach.
keywords: {Optimized production technology;Simultaneous localization and mapping;Uncertainty;Task analysis;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460864&isnumber=8460178

Z. Alsayed, G. Bresson, A. Verroust-Blondet and F. Nashashibi, "2D SLAM Correction Prediction in Large Scale Urban Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5167-5174.
doi: 10.1109/ICRA.2018.8460773
Abstract: Simultaneous Localization And Mapping (SLAM) is one of the major bricks needed to build truly autonomous mobile robots. The probabilistic formulation of SLAM is based on two models: the motion model and the observation model. In practice, these models, together with the SLAM map representation, do not model perfectly the robot's real dynamics, the sensor measurement errors and the environment. Consequently, systematic errors affect SLAM estimations. In this paper, we propose two approaches to predict corrections to be applied to SLAM estimations. Both are based on the Ensemble Multilayer Perceptron model. The first approach uses successive estimated poses to predict the errors, with no assumptions on the underlying SLAM process or sensor used. The second method is specific to 2D likelihood SLAM approaches, thus, the likelihood distributions are used to predict the corrections, making this second approach independent of the sensor used. We also build a hybrid correction module based on successive estimated poses and the likelihood distributions. The validity of both approaches is evaluated through two experiments using different evaluation metrics and sensor configurations.
keywords: {Simultaneous localization and mapping;Two dimensional displays;Estimation;Neural networks;Predictive models;Kalman filters},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460773&isnumber=8460178

S. Siva and H. Zhang, "Omnidirectional Multisensory Perception Fusion for Long-Term Place Recognition," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5175-5181.
doi: 10.1109/ICRA.2018.8461042
Abstract: Over the recent years, long-term place recognition has attracted an increasing attention to detect loops for largescale Simultaneous Localization and Mapping (SLAM) in loopy environments during long-term autonomy. Almost all existing methods are designed to work with traditional cameras with a limited field of view. Recent advances in omnidirectional sensors offer a robot an opportunity to perceive the entire surrounding environment. However, no work has existed thus far to research how omnidirectional sensors can help long-term place recognition, especially when multiple types of omnidirectional sensory data are available. In this paper, we propose a novel approach to integrate observations obtained from multiple sensors from different viewing angles in the omnidirectional observation in order to perform multi-directional place recognition in longterm autonomy. Our approach also answers two new questions when omnidirectional multisensory data is available for place recognition, including whether it is possible to recognize a place with long-term appearance variations when robots approach it from various directions, and whether observations from various viewing angles are the same informative. To evaluate our approach and hypothesis, we have collected the first large-scale dataset that consists of omnidirectional multisensory (intensity and depth) data collected in urban and suburban environments across a year. Experimental results have shown that our approach is able to achieve multi-directional long-term place recognition, and identifies the most discriminative viewing angles from the omnidirectional observation.
keywords: {Feature extraction;Sensor phenomena and characterization;Simultaneous localization and mapping;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461042&isnumber=8460178

W. Huang and H. Liu, "Online Initialization and Automatic Camera-IMU Extrinsic Calibration for Monocular Visual-Inertial SLAM," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5182-5189.
doi: 10.1109/ICRA.2018.8460206
Abstract: Most of the existing monocular visual-inertial SLAM techniques assume that the camera-IMU extrinsic parameters are known, therefore these methods merely estimate the initial values of velocity, visual scale, gravity, biases of gyroscope and accelerometer in the initialization stage. However, it's usually a professional work to carefully calibrate the extrinsic parameters, and it is required to repeat this work once the mechanical configuration of the sensor suite changes slightly. To tackle this problem, we propose an online initialization method to automatically estimate the initial values and the extrinsic parameters without knowing the mechanical configuration. The biases of gyroscope and accelerometer are considered in our method, and a convergence criteria for both orientation and translation calibration is introduced to identify the convergence and to terminate the initialization procedure. In the three processes of our method, an iterative strategy is firstly introduced to iteratively estimate the gyroscope bias and the extrinsic orientation. Secondly, the scale factor, gravity, and extrinsic translation are approximately estimated without considering the accelerometer bias. Finally, these values are further optimized by a refinement algorithm in which the accelerometer bias and the gravitational magnitude are taken into account. Extensive experimental results show that our method achieves competitive accuracy compared with the state-of-the-art with less calculation.
keywords: {Gyroscopes;Cameras;Quaternions;Accelerometers;Calibration;Simultaneous localization and mapping;Gravity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460206&isnumber=8460178

S. Rahman, A. Q. Li and I. Rekleitis, "Sonar Visual Inertial SLAM of Underwater Structures," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5190-5196.
doi: 10.1109/ICRA.2018.8460545
Abstract: This paper presents an extension to a state of the art Visual-Inertial state estimation package (OKVIS) in order to accommodate data from an underwater acoustic sensor. Mapping underwater structures is important in several fields, such as marine archaeology, search and rescue, resource management, hydrogeology, and speleology. Collecting the data, however, is a challenging, dangerous, and exhausting task. The underwater domain presents unique challenges in the quality of the visual data available; as such, augmenting the exteroceptive sensing with acoustic range data results in improved reconstructions of the underwater structures. Experimental results from underwater wrecks, an underwater cave, and a submerged bus demonstrate the performance of our approach.
keywords: {Sonar;Cameras;Visualization;Sonar navigation;Simultaneous localization and mapping;Underwater structures},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460545&isnumber=8460178

B. Morrell et al., "Differential Flatness Transformations for Aggressive Quadrotor Flight," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5204-5210.
doi: 10.1109/ICRA.2018.8460838
Abstract: Aggressive maneuvering amongst obstacles could enable advanced capabilities for quadrotors in applications such as search and rescue, surveillance, inspection, and situations where rapid flight is required in cluttered environments. Previous works have treated quadrotors as differentially flat systems, and this property has been exploited widely to design simple algorithms that generate dynamically feasible trajectories and to enable hierarchical control. The differentially flat property allows the full state of the quadrotor to be extracted from the reduced dimensional space of x, y, z, yaw and their derivatives. This differential flatness transformation has a number of singularities, however, as well as stability issues when controlling near these singularities. Many methods have been described in the literature to address these; however, they all have limitations when exploring the full flight envelope of a quadrotor, including roll or pitch angles past 90°, and during inverted flight. In this paper, we review these existing methods and then introduce our method, which combines multiple methods to provide a highly-robust differential flatness transformation that addresses most of these issues. Our approach is demonstrated enabling highly-aggressive quadrotor flight in both simulations and real-world experiments.
keywords: {Trajectory;Attitude control;Standards;Acceleration;Aerospace electronics;Australia;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460838&isnumber=8460178

D. R. McArthur, A. B. Chowdhury and D. J. Cappelleri, "Autonomous Control of the Interacting-BoomCopter UAV for Remote Sensor Mounting," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5219-5224.
doi: 10.1109/ICRA.2018.8461119
Abstract: This paper presents a novel approach for autonomously mounting a sensor package on a vertical surface with an unmanned aerial vehicle (UAV). The Interacting-BoomCopter (I-BC) UAV uses an on-board webcam and computer along with a horizontally-mounted reversible propeller on its front boom to autonomously perform the aerial manipulation task. An overview of the vehicle design is presented along with the image processing algorithms used for target tracking, and the implementation of an extended finite state machine (EFSM) for carrying out the high-level autonomous control. The effectiveness of the autonomous control strategy and I-BC platform are examined through the performance of several autonomous sensor mounting flight tests.
keywords: {Task analysis;Propellers;Webcams;Unmanned aerial vehicles;Inspection;Force;Control systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461119&isnumber=8460178

C. Y. Son, H. Seo, T. Kim and H. Jin Kim, "Model Predictive Control of a Multi-Rotor with a Suspended Load for Avoiding Obstacles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5233-5238.
doi: 10.1109/ICRA.2018.8460749
Abstract: This paper investigates a multi-rotor with a suspended load in perspectives of 1) real-time path planning, 2) obstacle avoidance, and 3) transportation of a suspended object. A suspended load cannot be controlled with conventional controllers designed for nominal multi-rotors due to the dynamic coupling between the multi-rotor and load. Although several control and planning algorithms have been proposed based on elaborately derived dynamic equations, most existing studies separate control and path planning problems by following predefined trajectories after trajectory generation. Moreover, many state-of-the-art trajectory generation algorithms cannot work real-time for a system with high degrees of freedom, which makes it not suitable to operate the system in dynamic environments where obstacles appear abruptly or move unexpectedly. With this in mind, we apply Model Predictive Control (MPC) with Sequential Linear Quadratic (SLQ) solver to compute feasible and optimal trajectory real-time and to operate a multi-rotor with a suspended load in dynamic environments. We design an obstacle-avoidance algorithm suitable for the current platform flying in cluttered environments. Flight experiments shows that the proposed algorithm successfully controls the multi-rotor and allows to avoid obstacles simultaneously.
keywords: {Heuristic algorithms;Trajectory;Cost function;Mathematical model;Vehicle dynamics;Load modeling;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460749&isnumber=8460178

P. O. Pereira, P. Roque and D. V. Dimarogonas, "Asymmetric Collaborative Bar Stabilization Tethered to Two Heterogeneous Aerial Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5247-5253.
doi: 10.1109/ICRA.2018.8460529
Abstract: We consider a system composed of a bar tethered to two unmanned aerial vehicles (UAVs), where the cables behave as rigid links under tensile forces, and with the control objective of stabilizing the bar's pose around a desired pose. Each UAV is equipped with a PID control law, and we verify that the bar's motion is decomposable into three decoupled motions, namely a longitudinal, a lateral and a vertical. We then provide relations between the UAV s' gains, which, if satisfied, allows us to decompose each of those motions into two cascaded motions; the latter relations between the UAV s' gains are found so as to counteract the system asymmetries, such as the different cable lengths and the different UAV s' weights. Finally, we provide conditions, based on the system's physical parameters, that describe good and bad types of asymmetries. We present experiments that demonstrate the stabilization of the bar's pose.
keywords: {Bars;Force;Unmanned aerial vehicles;Dynamics;Mathematical model;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460529&isnumber=8460178

L. Schoevaerdts et al., "Innovative Bio-Impedance Sensor Towards Puncture Detection in Eye Surgery for Retinal Vein Occlusion Treatment," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5343-5348.
doi: 10.1109/ICRA.2018.8460205
Abstract: At the moment, surgeons struggle curing a widespread eye disease known as retinal vein occlusion where clots obstruct the retinal vessels. Latter vascular disorder involves black spots in people's eyesight and lead eventually to blindness. A recent promising treatment consists in flushing a thrombolytic agent inside the clotted retinal vessels. The surgery implies puncturing vessels ranging from 50 to 400 microns diameter on the backside of the eye, namely the retina. Latest research succeeded in tackling several challenges around this operation: the surgeon's hand tremor and the high precision required amongst other requirements. Despite several breakthroughs, the surgeon only relies on a microscope to perform the surgery through the patient eye's lens, giving poor depth perception to properly puncture the retinal vessels. This way, the surgeon is most likely to pierce through the vessel and inject the thrombolytic drug under the retina, which would endanger the person's eyesight. In this paper, we investigate the use of a novel bio-impedance sensor developed for eye surgery. Together with this new sensor, a detection algorithm has been developed to detect the puncture and double puncture events to give a feedback to the operator of the system. As far as we are aware of, such technology doesn't exist yet in eye surgery to tackle the depth perception question. This paper aims at demonstrating the benefits of this technology.
keywords: {Surgery;Needles;Probes;Retina;Impedance;Biosensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460205&isnumber=8460178

W. Lai, L. Cao, Z. Xu, P. T. Phan, P. Shum and S. J. Phee, "Distal End Force Sensing with Optical Fiber Bragg Gratings for Tendon-Sheath Mechanisms in Flexible Endoscopic Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5349-5255.
doi: 10.1109/ICRA.2018.8461090
Abstract: Accurate haptic feedback is a critical challenge for surgical robots, especially for flexible endoscopic surgical robots whose transmission systems are Tendon-Sheath Mechanisms (TSMs) with highly nonlinear friction profiles and force hysteresis. For distal end haptic sensing of TSMs, this paper, for the first time, proposes to measure the compression force on the sheath at the distal end so that the tension force on the tendon, which equals the compression force on the sheath, can be obtained. A new force sensor, i.e., a nitinol tube attached with an optical Fiber Bragg Grating (FBG) fiber, is proposed to measure the compression force on the sheath. This sensor, with similar diameter and configuration (hollow) as the sheath, can be compactly integrated with TSMs and surgical end-effectors. In this paper, mechanics analysis and verification tests are presented to reveal the relationship between the tension force on the tendon and the compression force on the sheath. The proposed force sensor was calibrated in tests with a sensitivity of 24.28 pm/N and integrated with a tendon-sheath driven grasper to demonstrate the effectiveness of the proposed approach and sensor. The proposed approach and sensor can also be applied for a variety of TSMs-driven systems, such as robotic fingers/hands, wearable devices, and rehabilitation devices.
keywords: {Force;Robot sensing systems;Tendons;Fiber gratings;Haptic Sensing;Fiber Bragg Gratings;Flexible Surgical Endoscopic Robot;Tendon-Sheath Mechanisms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461090&isnumber=8460178

H. Salman et al., "Trajectory-Optimized Sensing for Active Search of Tissue Abnormalities in Robotic Surgery," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5356-5363.
doi: 10.1109/ICRA.2018.8460936
Abstract: In this work, we develop an approach for guiding robots to automatically localize and find the shapes of tumors and other stiff inclusions present in the anatomy. Our approach uses Gaussian processes to model the stiffness distribution and active learning to direct the palpation path of the robot. The palpation paths are chosen such that they maximize an acquisition function provided by an active learning algorithm. Our approach provides the flexibility to avoid obstacles in the robot's path, incorporate uncertainties in robot position and sensor measurements, include prior information about location of stiff inclusions while respecting the robot-kinematics. To the best of our knowledge this is the first work in literature that considers all the above conditions while localizing tumors. The proposed framework is evaluated via simulation and experimentation on three different robot platforms: 6-DoF industrial arm, da Vinci Research Kit (dVRK), and the Insertable Robotic Effector Platform (IREP). Results show that our approach can accurately estimate the locations and boundaries of the stiff inclusions while reducing exploration time.
keywords: {Trajectory;Robot sensing systems;Optimization;Uncertainty;Bayes methods;Tumors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460936&isnumber=8460178

M. M. Marinho, B. V. Adorno, K. Harada and M. Mitsuishi, "Active Constraints Using Vector Field Inequalities for Surgical Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5364-5371.
doi: 10.1109/ICRA.2018.8461105
Abstract: Robotic assistance allows surgeons to perform dexterous and tremor-free procedures, but is still underrepresented in deep brain neurosurgery and endonasal surgery where the workspace is constrained. In these conditions, the vision of surgeons is restricted to areas near the surgical tool tips, which increases the risk of unexpected collisions between the shafts of the instruments and their surroundings, in particular in areas outside the surgical field-of-view. Active constraints can be used to prevent the tools from entering restricted zones and thus avoid collisions. In this paper, a vector field inequality is proposed that guarantees that tools do not enter restricted zones. Moreover, in contrast with early techniques, the proposed method limits the tool approach velocity in the direction of the forbidden zone boundary, guaranteeing a smooth behavior and that tangential velocities will not be disturbed. The proposed method is evaluated in simulations featuring two eight degrees-of-freedom manipulators that were custom-designed for deep neurosurgery. The results show that both manipulator-manipulator and manipulator-boundary collisions can be avoided using the vector field inequalities.
keywords: {Quaternions;Surgery;Tools;Task analysis;Kinematics;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461105&isnumber=8460178

N. Thatte, H. Duan and H. Geyer, "A Method for Online Optimization of Lower Limb Assistive Devices with High Dimensional Parameter Spaces," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5380-5385.
doi: 10.1109/ICRA.2018.8460953
Abstract: We propose a method for optimizing control policies for assistive lower-limb devices. The method frames parameter selection as a dueling bandits problem in which a user indicates his or her qualitative preferences between pairs of parameter sets chosen from a library. We generate the library through an offline optimization procedure that seeks to reproduce the varied gaits of healthy human subjects. By separating the parameter selection process into online and offline portions, the method can handle high-dimensional parameter spaces and produces policies that can generalize to different gait scenarios such as speed variation. We evaluate the method on five subjects walking on a powered knee and ankle prosthesis governed by a neuromuscular control policy that has 43 parameters. We find the five subjects preferred four different parameter sets from the library and that the resulting optima resemble intact subject gait data. This result suggests the offline portion of the optimization method indeed produces control parameters that can adapt to different gaits. Moreover, we find that for three out of the four parameter sets we tested, the procedure also generates parameters that improve the ability of the prosthesis to adapt to increasing gait speed by increasing ankle net work production. The results encourage further research and exploration in clinical settings toward advanced prosthesis controls that employ online learning.
keywords: {Knee;Prosthetics;Optimization;Torque;Neuromuscular;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460953&isnumber=8460178

M. Turan, Y. Almalioglu, H. B. Gilbert, A. E. Sari, U. Soylu and M. Sitti, "Endo-VMFuseNet: A Deep Visual-Magnetic Sensor Fusion Approach for Endoscopic Capsule Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5386-5392.
doi: 10.1109/ICRA.2018.8461129
Abstract: In the last decade, researchers and medical device companies have made major advances towards transforming passive capsule endoscopes into active medical robots. One of the major challenges is to endow capsule robots with accurate perception of the environment inside the human body, which will provide necessary information and enable improved medical procedures. We extend the success of deep learning approaches from various research fields to the problem of sensor fusion for endoscopic capsule robots in the case of asynchronous and asymmetric sensor data without any need of calibration between sensors. The results performed on real pig stomach datasets show that our method achieves high precision for both translational and rotational movements and contains various advantages over traditional sensor fusion techniques.
keywords: {Robot sensing systems;Magnetic separation;Magnetic levitation;Sensor fusion;Magnetic cores;Magnetic resonance imaging},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461129&isnumber=8460178

M. Turan, Y. Almalioglu, H. Gilbert, H. Araujo, T. Cemgil and M. Sitti, "EndoSensorFusion: Particle Filtering-Based Multi-Sensory Data Fusion with Switching State-Space Model for Endoscopic Capsule Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5393-5400.
doi: 10.1109/ICRA.2018.8460472
Abstract: A reliable, real time, multi-sensor fusion functionality is crucial for localization of actively controlled capsule endoscopy robots, which are an emerging, minimally invasive diagnostic and therapeutic technology for the gastrointestinal (GI) tract. In this study, we propose a novel multi-sensor fusion approach based on a particle filter that incorporates an online estimation of sensor reliability and a non-linear kinematic model learned by a recurrent neural network. Our method sequentially estimates the true robot pose from noisy pose observations delivered by multiple sensors. We experimentally test the method using 5 degree-of-freedom (5-DoF) absolute pose measurement by a magnetic localization system and a 6-DoF relative pose measurement by visual odometry. In addition, the proposed method is capable of detecting and handling sensor failures by ignoring corrupted data, providing the robustness expected of a medical device. Detailed analyses and evaluations are presented using ex vivo experiments on a porcine stomach model, proving that our system achieves high translational and rotational accuracies for different types of endoscopic capsule robot trajectories.
keywords: {Robot sensing systems;Switches;Kalman filters;Proposals;Endoscopes;Magnetic resonance imaging},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460472&isnumber=8460178

H. Lee, S. Kwak and S. Oh, "Force Control of Series Elastic Actuators-Driven Parallel Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5401-5406.
doi: 10.1109/ICRA.2018.8460768
Abstract: This paper proposes a novel parallel robot - Virtual Ground Robot (VGR) - that is driven by three Series Elastic Actuators (SEAs) to interact with a human. The proposed Virtual Ground Robot provides a virtual ground on which a human can stand on and interact in three directions: the pitch, the roll and the height directions. The most significant features of the proposed VGR are that 1) it is driven by RFSEAs (Reaction Force-sensing Series Elastic Actuator), and thus it can provide precise forces and torques, 2) the size of the VGR is small enough for a human to stand on with ease, and 3) it can generate torque/force large to support a weight of a human. Taking advantage of RFSEAs utilized in the proposed VGR, Spatial Force control algorithm is proposed in this paper. In order to design this controller, the motions of VGR are defined in the task space, the joint space and the RFSEA level. Based on the Kinematics, force control of VGR in the task level, which is named Spatial Force Control is designed and verified using experiments.
keywords: {Legged locomotion;Force control;Parallel robots;Force;Aerospace electronics;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460768&isnumber=8460178

P. Rao and A. D. Deshpande, "Analyzing and Improving Cartesian Stiffness Control Stability of Series Elastic Tendon-Driven Robotic Hands," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5415-5420.
doi: 10.1109/ICRA.2018.8460956
Abstract: Robust and dexterous manipulation is identified as one of the critical challenges in the field of robotic hand design and control. A key requirement of dexterous manipulation is the ability to modulate fingertip force directions and magnitudes. Cartesian stiffness control is a strategy to generate position dependent fingertip forces. However the stability conditions for the Cartesian stiffness controllers vary nonlinearly because of dependency on the manipulator's configuration and loading forces. The challenge is enhanced in case of tendon-driven robotic hands due to passive joint coupling. In this work, we derive a generalized passivity based stability boundary for Cartesian stiffness. We then present a methodology to analyze the stability boundaries of Cartesian stiffness controlled series elastic tendon-driven robotic fingers. We also present a solution to improve stability by optimizing the arrangement of optimized passive compliance in parallel to the actuators based on the stability criteria. Our analysis not only allows for informed design of new robotic hands but also applies to improving performance of existing robotic hands.
keywords: {Stability criteria;Robots;Tendons;Force;Loading;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460956&isnumber=8460178

H. -C. Lin, J. Smith, K. K. Babarahmati, N. Dehio and M. Mistry, "A Projected Inverse Dynamics Approach for Multi-Arm Cartesian Impedance Control," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5421-5428.
doi: 10.1109/ICRA.2018.8461202
Abstract: We propose a model-based control framework for multi-arm manipulation of a rigid object subject to external disturbances. The control framework, based on projected inverse dynamics, decomposes the control law into constrained and unconstrained subspaces. Unconstrained components accomplish the motion task with a desired 6-DOF Cartesian impedance behaviour against external disturbances. Meanwhile, the constrained component enforces contact and friction constraints by optimising for contact forces within the constrained subspace. External disturbances are explicitly compensated for without using force/torque sensors at the contact points. The approach is evaluated on a dual-arm platform manipulating a rigid object while coping with unknown object dynamics and human interaction.
keywords: {Dynamics;Impedance;Force;Aerospace electronics;Robots;Task analysis;Jacobian matrices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461202&isnumber=8460178

M. Kollmitz, D. Büscher, T. Schubert and W. Burgard, "Whole-Body Sensory Concept for Compliant Mobile Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5429-5435.
doi: 10.1109/ICRA.2018.8460510
Abstract: Most of the conventional approaches to mobile robot navigation avoid any kind of contact with the environment or with humans. As nowadays distance sensors typically have a limited - and often only two-dimensional - field of view, collisions with the environment or contacts with humans cannot be fully avoided in practical mobile robot applications. On the other hand, direct physical contact can be used for intuitive communication between a robot and humans. In this paper, we present a whole-body sensory concept based on a 6-DoF force-torque sensor to perceive physical interaction between the robot and humans. To distinguish between external contact and disturbance forces that result from the motion of the mobile platform or oscillations, we present a novel model-free filtering approach based on a neural network. In extensive experiments carried out with our robot Canny we demonstrate the effectiveness and advantages of the neural network approach, which clearly outperforms a classical model-based one.
keywords: {Robot sensing systems;Force;Mobile robots;Collision avoidance;Oscillators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460510&isnumber=8460178

F. Wirnshofer, P. S. Schmitt, W. Feiten, G. v. Wichert and W. Burgard, "Robust, Compliant Assembly via Optimal Belief Space Planning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5436-5443.
doi: 10.1109/ICRA.2018.8460995
Abstract: In automated manufacturing, robots must reliably assemble parts of various geometries and low tolerances. Ideally, they plan the required motions autonomously. This poses a substantial challenge due to high-dimensional state spaces and non-linear contact-dynamics. Furthermore, object poses and model parameters, such as friction, are not exactly known and a source of uncertainty. The method proposed in this paper models the task of parts assembly as a belief space planning problem over an underlying impedance-controlled, compliant system. To solve this planning problem we introduce an asymptotically optimal belief space planner by extending an optimal, randomized, kinodynamic motion planner to nondeterministic domains. Under an expansiveness assumption we establish probabilistic completeness and asymptotic optimality. We validate our approach in thorough, simulated and realworld experiments of multiple assembly tasks. The experiments demonstrate our planner's ability to reliably assemble objects, solely based on CAD models as input.
keywords: {Planning;Robots;Trajectory;Uncertainty;Task analysis;Aerospace electronics;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460995&isnumber=8460178

D. Almeida and Y. Karayiannidis, "Cooperative Manipulation and Identification of a 2-DOF Articulated Object by a Dual-Arm Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5445-5451.
doi: 10.1109/ICRA.2018.8460511
Abstract: In this work, we address the dual-arm manipulation of a two degrees-of-freedom articulated object that consists of two rigid links. This can include a linkage constrained along two motion directions, or two objects in contact, where the contact imposes motion constraints. We formulate the problem as a cooperative task, which allows the employment of coordinated task space frameworks, thus enabling redundancy exploitation by adjusting how the task is shared by the robot arms. In addition, we propose a method that can estimate the joint location and the direction of the degrees-of-freedom, based on the contact forces and the motion constraints imposed by the object. Experimental results demonstrate the performance of the system in its ability to estimate the two degrees of freedom independently or simultaneously.
keywords: {Task analysis;Robot kinematics;Manipulators;Uncertainty;Kinematics;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460511&isnumber=8460178

E. Suarez, J. J. Huaroto, A. A. Reymundo, D. Holland, C. Walsh and E. Vela, "A Soft Pneumatic Fabric-Polymer Actuator for Wearable Biomedical Devices: Proof of Concept for Lymphedema Treatment," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5452-5458.
doi: 10.1109/ICRA.2018.8460790
Abstract: Soft actuators are ideal candidates for wearable biomedical devices, their inherent compliance, robustness, lightweight and the possibility to be washable take advantage over rigid actuators. Thus, a soft pneumatic fabric-polymer bending actuator as a base component for a robotic device for lymphedema treatment is reported in this work. The actuator is composed of two mechanical elements, one made of fabric and the other one made of a hyperelastic polymer which is stuck on the fabric element. The fabric element is designed and fabricated with a curved shape longer than the polymer element, that is a hyperelastic beam. To assemble both elements, the fabric element was folded before sticking in order to match the length of the polymer beam. Once the air is pumped into the fabric, it bends towards its original curved shape. Once the air is removed, the hyperelastic beam allows the actuator to recover its initial position. This actuator is capable of exerting compression and lateral force on a human arm mimicking manual lymphatic drainage. A mathematical model is presented which is in good agreement with the experimental data, it could serve to predict the actuator motion. An end-tip free bending displacement of about 2.2 cm and a bending force of about 0.35 N were achieved at 12.5 kPa. A proof-of-concept system for lymphedema treatment is presented as well.
keywords: {Iron;Actuators;Skin;Fabrics;Force;Shape;Strain},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460790&isnumber=8460178

C. J. Payne et al., "Force Control of Textile-Based Soft Wearable Robots for Mechanotherapy," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5459-5465.
doi: 10.1109/ICRA.2018.8461059
Abstract: Soft robotic devices have been utilized in a number of biomedical applications involving human interaction. An emerging opportunity for soft robotic wearable devices is in mechanotherapeutic applications for the recovery and regeneration of soft tissues. Previous studies have implied that judicious force application during mechanotherapy plays an important role in the functional outcome of tissue regeneration. In this paper, we propose soft robotic devices with closed-loop force control to precisely manipulate muscular tissue. The developed devices incorporate fully soft sensors and actuators using textile-based materials and fabrication methods. The closed-loop force control system is demonstrated in bench studies to regulate massage-magnitude forces at frequencies akin to those expected in manual mechanotherapy practices. Testing of the device on human limbs demonstrates the precision and accuracy of the closed-loop force control methodology across different body shapes and types. When commanded to regulate sinusoidal force profiles (with amplitudes of 30N, 45N and 60N), the soft robotic force control device could regulate peak compressive loads to within 0.7N of the desired force. Conversely, open-loop pressure-based control resulted in up to +/-6.6N force tracking variability between participants. A soft robotic system with independently actuatable modules was also fabricated to demonstrate force-controlled actuation patterns to mimic manual massage techniques.
keywords: {Sensors;Soft robotics;Force;Muscles;Biological tissues;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461059&isnumber=8460178

N. Agharese et al., "HapWRAP: Soft Growing Wearable Haptic Device," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5466-5472.
doi: 10.1109/ICRA.2018.8460891
Abstract: Soft robotics and pneumatic actuation present opportunities for lightweight wearable haptic devices that provide distributed touch feedback to the skin. Ideally, such devices would be easily donned and doffed, since permanent coverage of a large area of the skin is undesirable. Here we present the design and evaluation of a concept device called HapWRAP: a growing haptic device constructed from flexible low density polyethylene. Controlled air flow through tubes and pouches allows HapWRAP to grow out of a compact housing unit and provide a combination of directional and force feedback to a user. When activated, HapWRAP grows up and around the forearm; its loops form a temporary sleeve. After growth, pneumatic actuators inflate and deflate to stimulate mechanoreceptors in the skin at distinguishable locations. This paper describes the design and manufacturing of HapWRAP, reports its performance metrics, and tests its suitability as a haptic feedback device. Participants were able to interpret force and direction cues from HapWRAP with 92.5% accuracy. These findings suggest that HapWRAP can be successfully used for applications where both force and direction cues are necessary.
keywords: {Actuators;Haptic interfaces;Soft robotics;Skin;Electron tubes;Pneumatic systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460891&isnumber=8460178

J. Kim et al., "Autonomous and Portable Soft Exosuit for Hip Extension Assistance with Online Walking and Running Detection Algorithm," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5473-5480.
doi: 10.1109/ICRA.2018.8460474
Abstract: We present an autonomous and portable hip-only soft exosuit, for augmenting human walking and running that assists hip extension by delivering peak forces of 300N to the user. Different fixed assistance profiles for walking and running were applied based on an online classification algorithm. The approach is based on the biomechanical understanding that the center of mass potential energy fluctuations during walking and running are out of phase. Specifically, we monitor the vertical acceleration with an abdomen-mounted IMU at the moment of maximum hip extension. Validation is demonstrated with six subjects on the treadmill and with eight subjects outdoors. Our results demonstrated a 99.99% accuracy on average over the fourteen participants for various speeds (0.5 - 4m/s), slopes (-10 -20%), treadmill and overground terrain, loaded (13.6 kg) and unloaded, Exo On and Exo Off conditions, and different shoe types. Results from an evaluation outdoors overground on the energetics of eight subjects demonstrated a significant reduction for running when comparing Exo On to No Exo (3.9%) and for walking and running when comparing Exo On to Exo Off (12.2% and 8.2% respectively). This study represents the first demonstration of an autonomous wearable robot reducing the energy cost of running. Significant variation in response across subjects was observed, highlighting further improvements may be possible via assistance profile individualization with human-in-the-Ioop optimization.
keywords: {Legged locomotion;Hip;Thigh;Exoskeletons;Acceleration;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460474&isnumber=8460178

V. Vatsal and G. Hoffman, "Design and Analysis of a Wearable Robotic Forearm," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5489-5496.
doi: 10.1109/ICRA.2018.8461212
Abstract: This paper presents the design of a wearable robotic forearm for close-range human-robot collaboration. The robot's function is to serve as a lightweight supernumerary third arm for shared workspace activities. We present a functional prototype resulting from an iterative design process including several user studies. An analysis of the robot's kinematics shows an increase in reachable workspace by 246 % compared to the natural human reach. The robot's degrees of freedom and range of motion support a variety of usage scenarios with the robot as a collaborative tool, including self-handovers, fetching objects while the human's hands are occupied, assisting human-human collaboration, and stabilizing an object. We analyze the bio-mechanical loads for these scenarios and find that the design is able to operate within human ergonomic wear limits. We then report on a pilot human-robot interaction study that indicates robot autonomy is more task-time efficient and preferred by users when compared to direct voice-control. These results suggest that the design presented here is a promising configuration for a lightweight wearable robotic augmentation device, and can serve as a basis for further research into human-wearable collaboration.
keywords: {Solid modeling;Collaboration;Manipulators;Elbow;Load modeling;Prototypes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461212&isnumber=8460178

Y. E. Bayiz, L. Chen, S. -J. Hsu, P. Liu, A. N. Aguiles and B. Cheng, "Real-Time Learning of Efficient Lift Generation on a Dynamically Scaled Flapping Wing Using Policy Search," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5519-5525.
doi: 10.1109/ICRA.2018.8460781
Abstract: In this work, we present a successful application of a policy search algorithm to a real-time robotic learning problem, where the goal is to maximize the efficiency of lift generation on a dynamically scaled flapping robotic wing. The robotic wing has two degrees-of-freedom, i.e., stroke and pitch, and operates in a tank filled with mineral oil. For all experiments, the Reynolds number is maintained constant at 1000, where learning is performed for different prescribed stroke amplitudes to find the optimal wing pitching amplitude and the stroke-pitch phase difference that maximize the power loading (PL) of lift generation, a measure of aerodynamic efficiency. For the investigated stroke amplitude range (30°-90°), the efficiency is observed to increase with the stroke amplitude and the lift is mainly generated through the delayed stall, a quasi-steady aerodynamic mechanism. Furthermore, the wing rotation becomes more asymmetric with respect to stroke reversal as the stroke amplitude decreases, indicating an increased use of unsteady lift generation mechanisms at lower stroke amplitudes.
keywords: {Trajectory;Heuristic algorithms;Servomotors;Real-time systems;Aerodynamics;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460781&isnumber=8460178

M. Wooten, C. Frazelle, I. D. Walker, A. Kapadia and J. H. Lee, "Exploration and Inspection with Vine-Inspired Continuum Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5526-5533.
doi: 10.1109/ICRA.2018.8461132
Abstract: In this paper, we show how structures and strategies employed by thin-stemmed plants can be adapted to improve robot access to unstructured and congested environments. Specifically, we show how the use of vine-inspired movement strategies can enhance long thin continuum robot exploration and inspection operations. We introduce a new theoretical plant growth-inspired approach for modeling and motion generation of continuum robot backbones. The approach is demonstrated in numerous experiments including inspection within a high fidelity, full-scale mock-up of the International Space Station at NASA Johnson Space Center, using novel robot tendril hardware.
keywords: {Tendons;Strain;Adaptation models;Hardware;Robot kinematics;Inspection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461132&isnumber=8460178

J. Colorado, C. Rossi, A. Barrientos, A. Parra, C. Devia and D. Patino, "The Role of Massive Morphing Wings for Maneuvering a Bio-Inspired Bat-Like Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5534-5539.
doi: 10.1109/ICRA.2018.8460829
Abstract: In this paper we present an approach for analyzing the inertial effects of changing the wing shape for steering a bat-like robot. Using BaTboT, a robotic platform with massive morphing-wings, we have estimated the generation of pitching and rolling torques, which are directly related to forward and turning maneuvers. Results let us conclude that faster retraction of the wings during the upstroke, and slower extension during the downstroke increase both pitching and rolling torques in about 50% compared to those wingbeats with equal periods for retraction/extension. Also, we determined that the pitch torque generation is proportional to 0.6m1/f, whereas the rolling torque is promotional to 0.1m1/f, being m the mass of the robot and f the flapping frequency of the wings.
keywords: {Robots;Aerodynamics;Trajectory;Heuristic algorithms;Elbow},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460829&isnumber=8460178

S. Bazzi, J. Ebert, N. Hogan and D. Sternad, "Stability and Predictability in Dynamically Complex Physical Interactions," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5540-5545.
doi: 10.1109/ICRA.2018.8460774
Abstract: This study examines human control of physical interaction with objects that exhibit complex (nonlinear, chaotic, underactuated) dynamics. We hypothesized that humans exploited stability properties of the human-object interaction. Using a simplified 2D model for carrying a “cup of coffee”, we developed a virtual implementation to identify human control strategies. Transporting a cup of coffee was modeled as a cart with a suspended pendulum, where humans moved the cart on a horizontal line via a robotic manipulandum. The specific task was to transport the cart-pendulum system to a target, as fast as possible, while accommodating assistive and resistive perturbations. To assess trajectory stability, we applied contraction analysis. We showed that when the perturbation was assistive, humans absorbed the perturbation by controlling cart trajectories into a contraction region prior to the perturbation. When the perturbation was resistive, subjects passed through a contraction region following the perturbation. Entering a contraction region stabilizes performance and makes the dynamics more predictable. This human control strategy could inspire more robust control strategies for physical interaction in robots.
keywords: {Perturbation methods;Task analysis;Trajectory;Robots;Mathematical model;Stability analysis;Jacobian matrices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460774&isnumber=8460178

K. Y. W. Scheper, M. Karásek, C. De Wagter, B. D. W. Remes and G. C. H. E. De Croon, "First Autonomous Multi-Room Exploration with an Insect-Inspired Flapping Wing Vehicle," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5546-5552.
doi: 10.1109/ICRA.2018.8460702
Abstract: One of the emerging tasks for Micro Air Vehicles (MAVs) is autonomous indoor navigation. While commonly employed platforms for such tasks are micro-quadrotors, insect-inspired flapping wing MAVs can offer many advantages, such as being inherently safe due to their low inertia, reciprocating wings bouncing of objects or potentially lower noise levels compared to rotary wings. Here, we present the first flapping wing MAV to perform an autonomous multi-room exploration task. Equipped with an on-board autopilot and a 4 g stereo vision system, the DelFly Explorer succeeded in combining the two most common tasks of an autonomous indoor exploration mission: room exploration and door passage. During the room exploration, the vehicle uses stereo-vision based droplet algorithm to avoid and navigate along the walls and obstacles. Simultaneously, it is running a newly developed monocular color based Snake-gate algorithm to locate doors. A successful detection triggers the heading-based door passage algorithm. In the real-world test, the vehicle could successfully navigate, multiple times in a row, between two rooms separated by a corridor, demonstrating the potential of flapping wing vehicles for autonomous exploration tasks.
keywords: {Task analysis;Robot sensing systems;Navigation;Collision avoidance;Cameras;Image color analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460702&isnumber=8460178

A. R. Chowdhury, G. S. Soh, S. H. Foong and K. L. Wood, "Evaluating Robust Trajectory Control of a Miniature Rolling and Spinning Robot in Outdoor Conditions," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5553-5560.
doi: 10.1109/ICRA.2018.8460594
Abstract: This paper presents trajectory following control experiments of a miniature spherical rolling and spinning robot mechanism on three different types of outdoor surfaces. The research is inspired from the efficient locomotory rolling patterns of various insects in unstructured environment. A nonlinear adaptive sliding mode (ASMC) feedback method maintains the robot stability and robustness in the presence of parameter uncertainties and external disturbances. The proposed trajectory following control policy is developed, implemented and tested for the miniature spherical robot on three different types of irregular surfaces in outdoors. Trajectory following accuracy, roll angle stability and wheel velocity response are three parameters measured to evaluate robot performance. ASMC controller is compared with an integral sliding (ISMC) controller. Experimental results show that proposed control policy is able to manage an accurate trajectory following amidst robust control of a rolling and spinning robot on three types of irregular surface in practical outdoor conditions.
keywords: {Trajectory;Wheels;Spinning;Mobile robots;Mathematical model;Robustness;Spherical Robot;Rolling gait;Central Pattern Generator (CPG);Trajectory following;Adaptive sliding mode (ASMC) Control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460594&isnumber=8460178

E. Jung et al., "Bio-Inspired Tensegrity Flexural Joints," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5561-5566.
doi: 10.1109/ICRA.2018.8461027
Abstract: Most robotics literature model the human's knee and hip as a revolute joint with limited range of rotation. Although somehow close to reality, this approach neglects a critical aspect of these joints, which is their internal flexibility. This paper presents a prototype tensegrity flexural manipulator whose kinematic behavior is inspired by human leg's gait. This prototype, which considers a hybrid (flexible-rigid) structure of the knee and hip would be able to better approximate real behavior and hopefully lead to a better design of artificial (prosthetic) knees and hips. The behavior of the proposed tensegrity manipulator was firstly predicted using OpenSim simulation environment. The paper reports the comparisons between the simulations, physical prototypes and human leg behavior for a variety of ranges of motions and tension analysis.
keywords: {Knee;Legged locomotion;Joints;Biological system modeling;Hip;Muscles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461027&isnumber=8460178

S. Liu and S. Carpin, "Grasp Quality Evaluation with Whole Arm Kinematic Noise Propagation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5575-5581.
doi: 10.1109/ICRA.2018.8460715
Abstract: In this paper we propose a new approach to evaluate grasps that accounts for both the kinematic structure of the robot and the noise at its joints. Our starting observation is that with a redundant robot the same grasp can be implemented with different arm configurations, and these may display significant differences in terms of robustness to disturbances. Consequently, the grasp quality metric is seen as a random variable depending on the arm configuration. Starting from a first order approximation for the error, we introduce the high probability force closure region as a tool to evaluate the local robustness of an arm configuration, and we then introduce a new metric Qarm to rank different configurations according to the robustness to noise. By combining this method in an offline/online framework, we demonstrate through large scale simulations that this approach successfully captures aspects that were neglected in former literature regarding grasp evaluation, and can successfully be integrated into future grasp planners.
keywords: {Measurement;Force;Kinematics;Manipulators;Ellipsoids;Random variables},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460715&isnumber=8460178

Z. Pan and D. Manocha, "Realtime Planning for High-DOF Deformable Bodies Using Two-Stage Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5582-5589.
doi: 10.1109/ICRA.2018.8460602
Abstract: We present a method for planning the motion of arbitrarily-shaped volumetric deformable bodies or robots through complex environments. Such robots have very high-dimensional configuration spaces and we compute trajectories that satisfy the dynamics constraints using a two-stage learning method. First, we train a multitask controller parameterized using dynamic movement primitives (DMP), which encodes various locomotion or movement skills. Next, we train a neural-network controller to select the DMP task to navigate the robot through environments while avoiding obstacles. By combining the finite element method (FEM), model reduction, and contact invariant optimization (CIO), the DMP controller's parameters can be optimized efficiently using a gradient-based method, while the neural-network's parameters are optimized using Deep Q-Learning (DQL). This two-stage learning algorithm also allows us to reuse the trained DMP controller for different navigation tasks, such as moving through different environmental types and to different goal positions. Our results show that the learned motion planner can navigate swimming and walking deformable robots with thousands of DOFs at realtime.
keywords: {Planning;Deformable models;Robots;Finite element analysis;Strain;Computational modeling;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460602&isnumber=8460178

I. Sarantopoulos, Y. Koveos and Z. Doulgeri, "Grasping Flat Objects by Exploiting Non-Convexity of the Object and Support Surface," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5606-5611.
doi: 10.1109/ICRA.2018.8461192
Abstract: In this paper we propose a grasp strategy which exploits environmental contact for grasping domestic flat objects placed or hinged on support surfaces. The proposed grasp strategy considers the non-convex geometry of the object-surface combination, as this appears in objects like plates on tables or handles on cupboards. Following the fact that state-of-the-art grasp planners fail to produce candidate grasps for flat objects due to the environmental constraint of the support surface, this work utilizes compliant interaction of the hand with the support surface, inspired by human grasp strategies.
keywords: {Grasping;Robots;Three-dimensional displays;Color;Geometry;Grippers;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461192&isnumber=8460178

J. Liu, S. Xin, Z. Gao, K. Xu, C. Tu and B. Chen, "Caging Loops in Shape Embedding Space: Theory and Computation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5612-5619.
doi: 10.1109/ICRA.2018.8461206
Abstract: We propose to synthesize feasible caging grasps for a target object through computing Caging Loops, a closed curve defined in the shape embedding space of the object. Different from the traditional methods, our approach decouples caging loops from the surface geometry of target objects through working in the embedding space. This enables us to synthesize caging loops encompassing multiple topological holes, instead of always tied with one specific handle which could be too small to be graspable by the robot gripper. Our method extracts caging loops through a topological analysis of the distance field defined for the target surface in the embedding space, based on a rigorous theoretical study on the relation between caging loops and the field topology. Due to the decoupling, our method can tolerate incomplete and noisy surface geometry of an unknown target object captured on-the-fly. We implemented our method with a robotic gripper and demonstrate through extensive experiments that our method can synthesize reliable grasps for objects with complex surface geometry and topology and in various scales.
keywords: {Grasping;Grippers;Robots;Shape;Geometry;Topology;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461206&isnumber=8460178

J. Mahler, M. Matl, X. Liu, A. Li, D. Gealy and K. Goldberg, "Dex-Net 3.0: Computing Robust Vacuum Suction Grasp Targets in Point Clouds Using a New Analytic Model and Deep Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5620-5627.
doi: 10.1109/ICRA.2018.8460887
Abstract: Vacuum-based end effectors are widely used in industry and are often preferred over parallel-jaw and multifinger grippers due to their ability to lift objects with a single point of contact. Suction grasp planners often target planar surfaces on point clouds near the estimated centroid of an object. In this paper, we propose a compliant suction contact model that computes the quality of the seal between the suction cup and local target surface and a measure of the ability of the suction grasp to resist an external gravity wrench. To characterize grasps, we estimate robustness to perturbations in end-effector and object pose, material properties, and external wrenches. We analyze grasps across 1,500 3D object models to generate Dex-Net 3.0, a dataset of 2.8 million point clouds, suction grasps, and grasp robustness labels. We use Dex-Net 3.0 to train a Grasp Quality Convolutional Neural Network (GQ-CNN) to classify robust suction targets in point clouds containing a single object. We evaluate the resulting system in 350 physical trials on an ABB YuMi fitted with a pneumatic suction gripper. When evaluated on novel objects that we categorize as Basic (prismatic or cylindrical), Typical (more complex geometry), and Adversarial (with few available suction-grasp points) Dex-Net 3.0 achieves success rates of 98%, 82%, and 58% respectively, improving to 81% in the latter case when the training set includes only adversarial objects. Code, datasets, and supplemental material can be found at http://berkeleyautomation.github.io/dex-net.
keywords: {Three-dimensional displays;Robustness;Robots;Analytical models;Seals;Computational modeling;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460887&isnumber=8460178

T. Zhang et al., "Deep Imitation Learning for Complex Manipulation Tasks from Virtual Reality Teleoperation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5628-5635.
doi: 10.1109/ICRA.2018.8461249
Abstract: Imitation learning is a powerful paradigm for robot skill acquisition. However, obtaining demonstrations suitable for learning a policy that maps from raw pixels to actions can be challenging. In this paper we describe how consumer-grade Virtual Reality headsets and hand tracking hardware can be used to naturally teleoperate robots to perform complex tasks. We also describe how imitation learning can learn deep neural network policies (mapping from pixels to actions) that can acquire the demonstrated skills. Our experiments showcase the effectiveness of our approach for learning visuomotor skills.
keywords: {Robots;Task analysis;Neural networks;Three-dimensional displays;Head;Visualization;Grippers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461249&isnumber=8460178

G. E. Mullins, A. G. Dress, P. G. Stankiewicz, J. D. Appler and S. K. Gupta, "Accelerated Testing and Evaluation of Autonomous Vehicles via Imitation Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5636-5642.
doi: 10.1109/ICRA.2018.8460965
Abstract: In this paper, we investigate the use of surrogate agents to accelerate test scenario generation for autonomous vehicles. Our goal is to train the surrogate to replicate the true performance modes of the system. We create these surrogates by utilizing imitation learning with deep neural networks. By using imitator surrogates in place of the true agent, we are capable of predicting mission performance more quickly, gaining greater throughput for simulation-based testing. We demonstrate that using on-line imitation learning with Dataset Aggregation (DAgger) can not only correctly encode a policy that executes a complex mission, but can also encode multiple different behavioral modes. To improve performance for the target vehicle and mission, we manipulate the training set during each iteration to remove samples which do not contribute to the final policy. We call this approach Quantile-DAgger (Q-DAgger) and demonstrate its ability to replicate the behaviors of an autonomous vehicle in a collision avoidance scenario.
keywords: {Testing;Training;Autonomous vehicles;Trajectory;Adaptation models;History},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460965&isnumber=8460178

J. Stüber, M. Kopicki and C. Zito, "Feature-Based Transfer Learning for Robotic Push Manipulation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5643-5650.
doi: 10.1109/ICRA.2018.8460989
Abstract: This paper presents a data-efficient approach to learning transferable forward models for robotic push manipulation. Our approach extends our previous work on contact-based predictors by leveraging information on the pushed object's local surface features. We test the hypothesis that, by conditioning predictions on local surface features, we can achieve generalisation across objects of different shapes. In doing so, we do not require a CAD model of the object but rather rely on a point cloud object model (PCOM). Our approach involves learning motion models that are specific to contact models. Contact models encode the contacts seen during training time and allow generating similar contacts at prediction time. Predicting on familiar ground reduces the motion models' sample complexity while using local contact information for prediction increases their transferability. In extensive experiments in simulation, our approach is capable of transfer learning for various test objects, outperforming a baseline predictor. We support those results with a proof of concept on a real robot.
keywords: {Robots;Three-dimensional displays;Predictive models;Solid modeling;Kernel;Probability density function;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460989&isnumber=8460178

R. Lioutikov, G. Maeda, F. Veiga, K. Kersting and J. Peters, "Inducing Probabilistic Context-Free Grammars for the Sequencing of Movement Primitives," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5651-5658.
doi: 10.1109/ICRA.2018.8460190
Abstract: Movement Primitives are a well studied and widely applied concept in modern robotics. Composing primitives out of an existing library, however, has shown to be a challenging problem. We propose the use of probabilistic context-free grammars to sequence a series of primitives to generate complex robot policies from a given library of primitives. The rule-based nature of formal grammars allows an intuitive encoding of hierarchically and recursively structured tasks. This hierarchical concept strongly connects with the way robot policies can be learned, organized, and re-used. However, the induction of context-free grammars has proven to be a complicated and yet unsolved challenge. In this work, we exploit the physical nature of robot movement primitives to restrict and efficiently search the grammar space. The grammar is learned applying a Markov Chain Monte Carlo optimization over the posteriors of the grammars given the observations. The proposal distribution is defined as a mixture over the probabilities of the operators connecting the search space. Restrictions to these operators guarantee continuous sequences while reducing the grammar space. We validate our method on a redundant 7 degree-of-freedom lightweight robotic arm on tasks that require the generation of complex sequences consisting of simple movement primitives.
keywords: {Grammar;Robots;Task analysis;Probabilistic logic;Sequential analysis;Markov processes;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460190&isnumber=8460178

J. Tremblay, T. To, A. Molchanov, S. Tyree, J. Kautz and S. Birchfield, "Synthetically Trained Neural Networks for Learning Human-Readable Plans from Real-World Demonstrations," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5659-5666.
doi: 10.1109/ICRA.2018.8460642
Abstract: We present a system to infer and execute a human-readable program from a real-world demonstration. The system consists of a series of neural networks to perform perception, program generation, and program execution. Leveraging convolutional pose machines, the perception network reliably detects the bounding cuboids of objects in real images even when severely occluded, after training only on synthetic images using domain randomization. To increase the applicability of the perception network to new scenarios, the network is formulated to predict in image space rather than in world space. Additional networks detect relationships between objects, generate plans, and determine actions to reproduce a real-world demonstration. The networks are trained entirely in simulation, and the system is tested in the real world on the pick-and-place problem of stacking colored cubes using a Baxter robot.
keywords: {Task analysis;Training;Neural networks;Robot sensing systems;Robustness;Stacking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460642&isnumber=8460178

Y. Huang, J. Silvério, L. Rozo and D. G. Caldwell, "Generalized Task-Parameterized Skill Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5667-5474.
doi: 10.1109/ICRA.2018.8461079
Abstract: Programming by demonstration has recently gained much attention due to its user-friendly and natural way to transfer human skills to robots. In order to facilitate the learning of multiple demonstrations and meanwhile generalize to new situations, a task-parameterized Gaussian mixture model (TP-GMM) has been recently developed. This model has achieved reliable performance in areas such as human-robot collaboration and dual-arm manipulation. However, the crucial task frames and associated parameters in this learning framework are often set by the human teacher, which renders three problems that have not been addressed yet: (i) task frames are treated equally, without considering their individual importance, (ii) task parameters are defined without taking into account additional task constraints, such as robot joint limits and motion smoothness, and (iii) a fixed number of task frames are pre-defined regardless of whether some of them may be redundant or even irrelevant for the task at hand. In this paper, we generalize the task-parameterized learning by addressing the aforementioned problems. Moreover, we provide a novel learning perspective which allows the robot to refine and adapt previously learned skills in a low dimensional space. Several examples are studied in both simulated and real robotic systems, showing the applicability of our approach.
keywords: {Task analysis;Trajectory;Robot kinematics;Optimization;Feature extraction;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461079&isnumber=8460178

A. Sena, Y. Zhao and M. J. Howard, "Teaching Human Teachers to Teach Robot Learners," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5675-5681.
doi: 10.1109/ICRA.2018.8461194
Abstract: Using Programming by Demonstration to teach robot learners generalisable skills relies on having effective human teachers. This paper aims to address two problems commonly observed in demonstration data sets that arise due to poor teaching strategies; undemonstrated states and ambiguous demonstrations. Overcoming these issues through the use of visual feedback and simple heuristic rules is investigated as a potential way of guiding novice users to more effectively teach robot learners to generalise a task. The proposed method intends to offer the user a more transparent understanding of the robot learner's model state during the teaching phase, to create a more interactive and robust teaching process. Results from a single-factor, three-phase repeated measures study with n=30 participants, comparing the proposed feedback and heuristic rules set against an unguided condition, show a statistically significant (F(2,58)=7.952,p=0.001) improvement of user teaching efficiency of approximately 180% when using the proposed feedback visualisation.
keywords: {Task analysis;Education;Trajectory;Robot sensing systems;Visualization;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461194&isnumber=8460178

V. Vasilopoulos, W. Vega-Brown, O. Arslan, N. Roy and D. E. Koditschek, "Sensor-Based Reactive Symbolic Planning in Partially Known Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5683-5690.
doi: 10.1109/ICRA.2018.8460861
Abstract: This paper considers the problem of completing assemblies of passive objects in nonconvex environments, cluttered with convex obstacles of unknown position, shape and size that satisfy a specific separation assumption. A differential drive robot equipped with a gripper and a LIDAR sensor, capable of perceiving its environment only locally, is used to position the passive objects in a desired configuration. The method combines the virtues of a deliberative planner generating high-level, symbolic commands, with the formal guarantees of convergence and obstacle avoidance of a reactive planner that requires little onboard computation and is used online. The validity of the proposed method is verified both with formal proofs and numerical simulations.
keywords: {Robot sensing systems;Planning;Task analysis;Grippers;Laser radar;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460861&isnumber=8460178

G. Flaspohler, N. Roy and Y. Girdhar, "Near-optimal Irrevocable Sample Selection for Periodic Data Streams with Applications to Marine Robotics," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5691-5698.
doi: 10.1109/ICRA.2018.8460709
Abstract: We consider the task of monitoring spatiotemporal phenomena in real-time by deploying limited sampling resources at locations of interest irrevocably and without knowledge of future observations. This task can be modeled as an instance of the classical secretary problem. Although this problem has been studied extensively in theoretical domains, existing algorithms require that data arrive in random order to provide performance guarantees. These algorithms will perform arbitrarily poorly on data streams such as those encountered in robotics and environmental monitoring domains, which tend to have spatiotemporal structure. We focus on the problem of selecting representative samples from phenomena with periodic structure and introduce a novel sample selection algorithm that recovers a near-optimal sample set according to any monotone submodular utility function. We evaluate our algorithm on a seven-year environmental dataset collected at the Martha's Vineyard Coastal Observatory and show that it selects phytoplankton sample locations that are nearly optimal in an information-theoretic sense for predicting phytoplankton concentrations in locations that were not directly sampled. The proposed periodic secretary algorithm can be used with theoretical performance guarantees in many real-time sensing and robotics applications for streaming, irrevocable sample selection from periodic data streams.
keywords: {Entropy;Mutual information;Robot sensing systems;Prediction algorithms;Real-time systems;Periodic structures},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460709&isnumber=8460178

A. Quraishi, A. Bahr, F. Schill and A. Martinoli, "Autonomous Feature Tracing and Adaptive Sampling in Real-World Underwater Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5699-5704.
doi: 10.1109/ICRA.2018.8460627
Abstract: Applications of robots for gathering data in underwater environments has been limited due to the challenges posed by the medium. We have developed a miniature, agile, easy to carry and deploy Autonomous Underwater Vehicle (AUV) equipped with a suite of sensors for underwater environmental sensing. We have also developed a compact high resolution fast temperature sensing module for the AUV for microstructure and turbulence measurements in water bodies. In this paper, we describe a number of algorithms and subsystems of the AUV that enable autonomous real-world operation, and present the data gathered in an experimental campaign in collaboration with limnologists. We demonstrate adaptive sampling missions where the AUV could autonomously locate a zone of interest and adapt its trajectory to stay in it. Further, it could execute specific behaviors to accommodate special sensing requirements necessary to enhance the quality of the data collected. In these missions, the AUV could autonomously trace a feature and capture horizontal variation in various quantities, including turbidity and temperature fluctuations, allowing limnologists to study lake phenomena in an additional dimension.
keywords: {Temperature measurement;Lakes;Microorganisms;Robot sensing systems;Trajectory;Temperature sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460627&isnumber=8460178

A. Pierson, W. Schwarting, S. Karaman and D. Rus, "Navigating Congested Environments with Risk Level Sets," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5712-5719.
doi: 10.1109/ICRA.2018.8460697
Abstract: In this paper, we address the problem of navigating in a cluttered environment by introducing a congestion cost that maps the density and motion of objects to an occupancy risk. We propose that an agent can choose a “risk level set” from this cost function and construct a planning space from this set. In choosing different levels of risk, the agent adjusts its interactions with the other agents. From the assumption that agents are self-preserving, we show that any agent planning within their risk level set will avoid collisions with other agents. We then present an application of planning with risk level sets in the framework of an autonomous vehicle driving along a highway. Using the risk level sets, the agent can determine safe zones when planning a sequence of lane changes. Through simulations in Matlab, we demonstrate how the choice of risk threshold manifests as aggressive or conservative behavior.
keywords: {Planning;Level set;Navigation;Vehicle dynamics;Autonomous vehicles;Collision avoidance;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460697&isnumber=8460178

K. Yu, A. K. Budhiraja and P. Tokekar, "Algorithms for Routing of Unmanned Aerial Vehicles with Mobile Recharging Stations," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5720-5725.
doi: 10.1109/ICRA.2018.8460819
Abstract: We study the problem of finding a tour for an energy-limited Unmanned Aerial Vehicle (UAV) to visit a set of sites in the least amount of time. We envision scenarios where the UAV can be recharged along the way either by landing on stationary recharging stations or on Unmanned Ground Vehicles (UGVs) acting as mobile recharging stations. This leads to a new variant of the Traveling Salesperson Problem (TSP). We present an algorithm that finds not only the order in which to visit the sites but also when and where to land on the charging stations to recharge. Our algorithm plans tours for the UGVs as well as determines best locations to place stationary charging stations. While the problems we study are NP-Hard, we present a practical solution using Generalized TSP that finds the optimal solution. If the UGVs are slower, the algorithm also finds the minimum number of UGVs required to support the UAV mission such that the UAV is not required to wait for the UGV. Our simulation results show that the running time is acceptable for reasonably sized instances.
keywords: {Batteries;Unmanned aerial vehicles;Charging stations;Land vehicles;Optimization;Monitoring;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460819&isnumber=8460178

A. Kitanov and V. Indelman, "Topological Multi-Robot Belief Space Planning in Unknown Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5726-5732.
doi: 10.1109/ICRA.2018.8460772
Abstract: In this paper we introduce a novel concept, topological belief space planning (BSP), that uses topological properties of the underlying factor graph representation of future posterior beliefs to direct the search for an optimal solution. This concept deviates from state-of-the-art BSP approaches and is motivated by recent results which indicated, in the context of graph pruning, that topological properties of factor graphs dominantly determine the estimation accuracy. Topological space is also often less dimensional than the embedded state space. In particular, we show how this novel concept can be used in multi-robot belief space planning in high-dimensional state spaces to overcome drawbacks of state-of-the-art approaches: computational intractability of an exhaustive objective evaluation for all candidate path combinations from different robots and dependence on the initial guess in the announced path approach, which can lead to a local minimum of the objective function. We demonstrate our approach in a synthetic simulation.
keywords: {Planning;Robot kinematics;Simultaneous localization and mapping;Linear programming;Aerospace electronics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460772&isnumber=8460178

A. Smyrli, G. A. Bertos and E. Papadopoulos, "Efficient Stabilization of Zero-Slope Walking for Bipedal Robots Following Their Passive Fixed-Point Trajectories," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5733-5738.
doi: 10.1109/ICRA.2018.8460845
Abstract: This paper presents an efficient method of stabilizing the gait of an underactuated biped with compliant legs and semicircular feet. First, the model is defined, incorporating elements that are often present in experimental biped robots. The biped's passive behavior is studied through numerical simulations that provide insight into the gravity's contribution as an energy input to the system. Based on this study, it is shown that an augmented biped -with the addition of a counterweight joint at the hip- is able to perform stable gaits with minimal input. This design is implemented easily as it does not require ankle torques; instead, both motors are mounted at the biped's hip. The control law used for the stabilization is the combination of virtual-gravity components with non-linear PD terms. The stable gaits performed by the augmented biped on level floor strongly resemble the passive gaits of the original biped walking on a slope, resulting in an efficient, natural-like motion of low transport cost.
keywords: {Legged locomotion;Foot;Gravity;Hip;Damping;Torso;Stability analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460845&isnumber=8460178

R. J. Griffin, G. Wiedebach, S. Bertrand, A. Leonessa and J. Pratt, "Straight-Leg Walking Through Underconstrained Whole-Body Control," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5747-5754.
doi: 10.1109/ICRA.2018.8460751
Abstract: We present an approach for achieving a natural, efficient gait on bipedal robots using straightened legs and toe-off. Our algorithm avoids complex height planning by allowing a whole-body controller to determine the straightest possible leg configuration at run-time. The controller solutions are biased towards a straight leg configuration by projecting leg joint angle objectives into the null-space of the other quadratic program motion objectives. To allow the legs to remain straight throughout the gait, toe-off was utilized to increase the kinematic reachability of the legs. The toe-off motion is achieved through underconstraining the foot position, allowing it to emerge naturally. We applied this approach of under-specifying the motion objectives to the Atlas humanoid, allowing it to walk over a variety of terrain. We present both experimental and simulation results and discuss performance limitations and potential improvements.
keywords: {Legged locomotion;Iterative closest point algorithm;Trajectory;Planning;Acceleration;Foot},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460751&isnumber=8460178

M. F. Hale, J. L. Du Bois and P. Iravani, "Agile and Adaptive Hopping Height Control for a Pneumatic Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5755-5760.
doi: 10.1109/ICRA.2018.8460557
Abstract: This paper presents a controller for the vertical height of a hopping robot. The ability to accurately change the hop height every step will contribute toward the traversal of discontinuous terrain with limited safe footholds, with application to bipedal or quadrupedal running. A key feature of the approach presented is the use of information from previous hops/steps to inform the control of the current step. As well as avoiding modelling errors, this allows the robot to make on-line adjustments in response to changes in system parameters or the environment. The algorithm is simple enough to be easily implemented on a low power hardware, not requiring computationally demanding optimisation or numerical simulation. The effectiveness of this approach has been demonstrated for constrained vertical hopping in simulation and on a pneumatically actuated hopper.
keywords: {Legged locomotion;Valves;Computational modeling;Actuators;Atmospheric modeling;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460557&isnumber=8460178

P. Fankhauser, M. Bjelonic, C. Dario Bellicoso, T. Miki and M. Hutter, "Robust Rough-Terrain Locomotion with a Quadrupedal Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5761-5768.
doi: 10.1109/ICRA.2018.8460731
Abstract: Robots working in natural, urban, and industrial settings need to be able to navigate challenging environments. In this paper, we present a motion planner for the perceptive rough-terrain locomotion with quadrupedal robots. The planner finds safe footholds along with collision-free swing-leg motions by leveraging an acquired terrain map. To this end, we present a novel pose optimization approach that enables the robot to climb over significant obstacles. We experimentally validate our approach with the quadrupedal robot ANYmal by autonomously traversing obstacles such steps, inclines, and stairs. The locomotion planner re-plans the motion at every step to cope with disturbances and dynamic environments. The robot has no prior knowledge of the scene, and all mapping, state estimation, control, and planning is performed in real-time onboard the robot.
keywords: {Legged locomotion;Robot sensing systems;Planning;Collision avoidance;Surface treatment},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460731&isnumber=8460178

G. Sartoretti, S. Shaw, K. Lam, N. Fan, M. Travers and H. Choset, "Central Pattern Generator With Inertial Feedback for Stable Locomotion and Climbing in Unstructured Terrain," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5769-5775.
doi: 10.1109/ICRA.2018.8461013
Abstract: Inspired by the locomotor nervous system of vertebrates, central pattern generator (CPG) models can be used to design gaits for articulated robots, such as crawling, swimming or legged robots. Incorporating sensory feedback for gait adaptation in these models can improve the locomotive performance of such robots in challenging terrain. However, many CPG models to date have been developed exclusively for open-loop gait generation for traversing level terrain. In this paper, we present a novel approach for incorporating inertial feedback into the CPG framework for the control of body posture during legged locomotion on steep, unstructured terrain. That is, we adapt the limit cycle of each leg of the robot with time to simultaneously produce locomotion and body posture control. We experimentally validate our approach on a hexapod robot, locomoting in a variety of steep, challenging terrains (grass, rocky slide, stairs). We show how our approach can be used to level the robot's body, allowing it to locomote at a relatively constant speed, even as terrain steepness and complexity prevents the use of an open-loop control strategy.
keywords: {Legged locomotion;Robot sensing systems;Limit-cycles;Robot kinematics;Adaptation models;Oscillators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461013&isnumber=8460178

B. Ponton, A. Herzog, A. Del Prete, S. Schaal and L. Righetti, "On Time Optimization of Centroidal Momentum Dynamics," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5776-5782.
doi: 10.1109/ICRA.2018.8460537
Abstract: Recently, the centroidal momentum dynamics has received substantial attention to plan dynamically consistent motions for robots with arms and legs in multi-contact scenarios. However, it is also non convex which renders any optimization approach difficult and timing is usually kept fixed in most trajectory optimization techniques to not introduce additional non convexities to the problem. But this can limit the versatility of the algorithms. In our previous work, we proposed a convex relaxation of the problem that allowed to efficiently compute momentum trajectories and contact forces. However, our approach could not minimize a desired angular momentum objective which seriously limited its applicability. Noticing that the non-convexity introduced by the time variables is of similar nature as the centroidal dynamics one, we propose two convex relaxations to the problem based on trust regions and soft constraints. The resulting approaches can compute time-optimized dynamically consistent trajectories sufficiently fast to make the approach realtime capable. The performance of the algorithm is demonstrated in several multi-contact scenarios for a humanoid robot. In particular, we show that the proposed convex relaxation of the original problem finds solutions that are consistent with the original non-convex problem and illustrate how timing optimization allows to find motion plans that would be difficult to plan with fixed timing ††Implementation details and demos can be found in the source code available at https://git-amd.tuebingen.mpg.de/bponton/timeoptimization.
keywords: {Optimization;Dynamics;Robots;Kinematics;Torque;Mathematical model;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460537&isnumber=8460178

Z. Wang, I. Reed and A. M. Fey, "Toward Intuitive Teleoperation in Surgery: Human-Centric Evaluation of Teleoperation Algorithms for Robotic Needle Steering," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5799-5806.
doi: 10.1109/ICRA.2018.8460729
Abstract: The effectiveness of control algorithms for teleoperated systems is typically evaluated through experimental performance measures, post-experimental user surveys, and theoretical analysis. However, none of these methods provide an objective assessment of teleoperation algorithms with respect to the real-time changes of human users during teleoperated tasks in terms of physiological, kinematic, or cognitive metrics. In this study, we recruited subjects to control robotically steered needles in a randomized experiment, using four different teleoperation mappings (joint space control, steering control, and Cartesian space control with and without force feedback). We investigated how the choice of these algorithms affect both performance and user response. Our novel steering control mapping, which mimics hub-centered steering, is significantly correlated with decreased cognitive stress and improved teleoperation performance when compared to joint space control. Overall, user experience and teleoperation performance were significantly improved with Cartesian space control, resulting in faster needle insertion, higher targeting accuracy, lower cognitive load, and smoother movements. Furthermore, while additional haptic feedback in Cartesian space provided an improved performance, it may increase user cognitive workload and muscle fatigue. These results highlight the importance of considering human-centric metrics when designing novel teleoperation strategies for complex systems.
keywords: {Needles;Aerospace electronics;Task analysis;Kinematics;Haptic interfaces;Measurement;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460729&isnumber=8460178

Q. M. Ta, S. Lyu and C. C. Cheah, "Human-guided Optical Manipulation of Multiple Microscopic Objects," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5807-5812.
doi: 10.1109/ICRA.2018.8461258
Abstract: Existing control systems for optical manipulation of multiple micro-objects do not allow users to interact with the systems during manipulation to deal with unexpected events, while ensuring stability of the overall control systems. In this paper, we propose a robotic control technique for human-guided optical manipulation of multiple micro-objects using robotic tweezers. Humans, when necessary, are able to interact or intervene with an automated optical manipulation system in a stable manner, and thus guiding a group of micro-objects to be manipulated towards a desired region while ensuring collision avoidance during manipulation. Both the ability of humans, in term of decision making, when needed, and the advantages of an automated optical manipulation system which provides precise and productive manipulation of micro-objects, are consolidated into one single technique. A theoretical foundation is developed and investigated to achieve the control objective. Experimental results are presented to illustrate the effectiveness of the proposed control technique.
keywords: {Robots;Microscopy;Optical microscopy;Potential energy;Biomedical optical imaging;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461258&isnumber=8460178

L. Muratore et al., "Enhanced Tele-interaction in Unknown Environments Using Semi-Autonomous Motion and Impedance Regulation Principles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5813-5820.
doi: 10.1109/ICRA.2018.8460559
Abstract: Robotics teleoperation has been extensively studied and considered in the past in several task scenarios where direct human intervention is not possible due to the hazardous environments. In such applications, both communication degradation and reduced perception of the remote environment are practical issues that can challenge the human operator while controlling the robot and attempting to physically interact within the remote workspace. To address this challenge, we introduce a novel shared-autonomy Tele-Interaction control approach that blends the motion commands from the pilot (master side) with locally (slave side) executed autonomous motion and impedance modulators. This enables a remote robot to handle and autonomously avoid physical obstacles during manoeuvring, reduce interaction forces during contacts, and finally accommodate different payload conditions while at the same time operating with a “default” low impedance setting. We implemented and experimentally validated the proposed method both on simulation and on a real robot platform called CENTAURO. A series of tasks, such as maneuvering through the physical constraints of the remote environment in an autonomous manner, pushing and lifting heavy objects with autonomous impedance regulation and colliding with the rigid geometry of the remote environment were executed. The obtained results demonstrate the effectiveness of the shared-autonomy control principles that eventually aim to reduce the level of attention and stress of human pilot while manoeuvring the slave robot, and at the same time to enhance the robustness of the robot during physical interactions even if accidentally occurred.
keywords: {Robots;Impedance;Task analysis;Collision avoidance;Payloads;Trajectory;Correlation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460559&isnumber=8460178

C. Meeker, T. Rasmussen and M. Ciocarlie, "Intuitive Hand Teleoperation by Novice Operators Using a Continuous Teleoperation Subspace," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5821-5827.
doi: 10.1109/ICRA.2018.8460506
Abstract: Human-in-the-loop manipulation is useful in when autonomous grasping is not able to deal sufficiently well with corner cases or cannot operate fast enough. Using the teleoperator's hand as an input device can provide an intuitive control method but requires mapping between pose spaces which may not be similar. We propose a low-dimensional and continuous teleoperation subspace which can be used as an intermediary for mapping between different hand pose spaces. We present an algorithm to project between pose space and teleoperation subspace. We use a non-anthropomorphic robot to experimentally prove that it is possible for teleoperation subspaces to effectively and intuitively enable teleoperation. In experiments, novice users completed pick and place tasks significantly faster using teleoperation subspace mapping than they did using state of the art teleoperation methods.
keywords: {Aerospace electronics;Grasping;Kinematics;Task analysis;Teleoperators;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460506&isnumber=8460178

Y. Che, C. T. Sun and A. M. Okamura, "Avoiding Human-Robot Collisions Using Haptic Communication," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5828-5834.
doi: 10.1109/ICRA.2018.8460946
Abstract: Fully autonomous navigation in populated environments is still a challenging problem for mobile robots. This paper explores the idea of using active human-robot communication to facilitate navigation tasks. We propose to convey a robot's intent to human users via a wearable haptic interface. The interface can display distinct haptic cues by modulating vibration amplitudes and patterns. We applied the concept to a single human/single robot orthogonal encounter scenario, where one of the two parties has to yield the right of way to avoid collision. Under certain conditions, the robot's intent (to yield to the human or not) is revealed to the human via the haptic interface prior to the interaction. We conducted an experiment with 10 users, in which the robot was teleoperated as a substitute for autonomy. Results show that, when given priority, users become more risk-accepting and use different strategies to navigate the collision scenario than when the robot takes priority or there is no haptic communication channel. In addition, we propose a social-force based model to predict human movement during navigation. The effect of communication can be explained as a shift in the user's safety buffer and expectation of the robot's future velocity.
keywords: {Collision avoidance;Haptic interfaces;Robot kinematics;Navigation;Legged locomotion;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460946&isnumber=8460178

Y. Ishiguro et al., "High Speed Whole Body Dynamic Motion Experiment with Real Time Master-Slave Humanoid Robot System," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5835-5841.
doi: 10.1109/ICRA.2018.8461207
Abstract: In this paper, we propose novel methods suitable for online real time whole body master-slave control with real life-sized humanoid robot. We conducted some dynamic whole body master-slave experiment with life-sized humanoid robot, and we achieved speedier and flexible master-slave operation compared to conventional study. Conventionally, master-slave operations with humanoid robots were available with only the upper body of the humanoid robot, and the COM movement was limited to be static. In our previous study, we introduced LIP model based restrictions to ensure the balance stability. In this study, we extend the safety restrictions by introducing foot landing delay prediction and trajectory smoothing method suitable for real robot. We conducted master-slave tennis swing experiment and high kick motion experiment with life-sized humanoid robot “JAXON”, and we evaluated the effectiveness of our proposed methods and system.
keywords: {Foot;Master-slave;Humanoid robots;Interpolation;Dynamics;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461207&isnumber=8460178

T. -K. Chuang et al., "Deep Trail-Following Robotic Guide Dog in Pedestrian Environments for People who are Blind and Visually Impaired - Learning from Virtual and Real Worlds," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5849-5855.
doi: 10.1109/ICRA.2018.8460994
Abstract: Navigation in pedestrian environments is critical to enabling independent mobility for the blind and visually impaired (BVI) in their daily lives. White canes have been commonly used to obtain contact feedback for following walls, curbs, or man-made trails, whereas guide dogs can assist in avoiding physical contact with obstacles or other pedestrians. However, the infrastructures of tactile trails or guide dogs are expensive to maintain. Inspired by the autonomous lane following of self-driving cars, we wished to combine the capabilities of existing navigation solutions for BVI users. We proposed an autonomous, trail-following robotic guide dog that would be robust to variances of background textures, illuminations, and interclass trail variations. A deep convolutional neural network (CNN) is trained from both the virtual and realworld environments. Our work included major contributions: 1) conducting experiments to verify that the performance of our models trained in virtual worlds was comparable to that of models trained in the real world; 2) conducting user studies with 10 blind users to verify that the proposed robotic guide dog could effectively assist them in reliably following man-made trails.
keywords: {Dogs;Cameras;Robot vision systems;Navigation;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460994&isnumber=8460178

K. Gupta, S. A. Javed, V. Gandhi and K. M. Krishna, "MergeNet: A Deep Net Architecture for Small Obstacle Discovery," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5856-5862.
doi: 10.1109/ICRA.2018.8461065
Abstract: We present here, a novel network architecture called MergeNet for discovering small obstacles for on-road scenes in the context of autonomous driving. The basis of the architecture rests on the central consideration of training with less amount of data since the physical setup and the annotation process for small obstacles is hard to scale. For making effective use of the limited data, we propose a multi-stage training procedure involving weight-sharing, separate learning of low and high level features from the RGBD input and a refining stage which learns to fuse the obtained complementary features. The model is trained and evaluated on the Lost and Found dataset and is able to achieve state-of-art results with just 135 images in comparison to the 1000 images used by the previous benchmark. Additionally, we also compare our results with recent methods trained on 6000 images and show that our method achieves comparable performance with only 1000 training samples.
keywords: {Roads;Image segmentation;Strips;Semantics;Training;Autonomous vehicles;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461065&isnumber=8460178

R. Pahič, A. Gams, A. Ude and J. Morimoto, "Deep Encoder-Decoder Networks for Mapping Raw Images to Dynamic Movement Primitives," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5863-5868.
doi: 10.1109/ICRA.2018.8460954
Abstract: In this paper we propose a new approach for learning perception-action couplings. We show that by collecting a suitable set of raw images and the associated movement trajectories, a deep encoder-decoder network can be trained that takes raw images as input and outputs the corresponding dynamic movement primitives. We propose suitable cost functions for training the network and describe how to calculate their gradients to enable effective training by back-propagation. We tested the proposed approach both on a synthetic dataset and on a widely used MNIST database to generate handwriting movements from raw images of digits. The calculated movements were also applied for digit writing with a real robot.
keywords: {Trajectory;Differential equations;Neural networks;Cost function;Training;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460954&isnumber=8460178

I. Bozcan, Y. Oymak, İ. Z. Alemdar and S. Kalkan, "What is (Missing or Wrong) in the Scene? A Hybrid Deep Boltzmann Machine for Contextualized Scene Modeling," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5869-5874.
doi: 10.1109/ICRA.2018.8460828
Abstract: Scene models allow robots to reason about what is in the scene, what else should be in it, and what should not be in it. In this paper, we propose a hybrid Boltzmann Machine (BM) for scene modeling where relations between objects are integrated. To be able to do that, we extend BM to include tri-way edges between visible (object) nodes and make the network to share the relations across different objects. We evaluate our method against several baseline models (Deep Boltzmann Machines, and Restricted Boltzmann Machines) on a scene classification dataset, and show that it performs better in several scene reasoning tasks.
keywords: {Training;Task analysis;Robots;Computational modeling;Context modeling;Estimation;Cognition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460828&isnumber=8460178

H. Sun, Z. Meng, P. Y. Tao and M. H. Ang, "Scene Recognition and Object Detection in a Unified Convolutional Neural Network on a Mobile Manipulator," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5875-5881.
doi: 10.1109/ICRA.2018.8460535
Abstract: Environment understanding, object detection and recognition are crucial skills for robots operating in the real world. In this paper, we propose a Convolutional Neural Network with multi-task objectives: object detection and scene classification in one unified architecture. The proposed network reasons globally about an image to understand the scene, hypothesize object locations, and encodes global scene features with regional object features to improve object recognition. We evaluate our network on the standard SUN RGBD dataset. Experiments show that our approach outperforms state-of-the-arts. Network predictions are further transformed into continuous robot beliefs to ensure temporal coherence and extended to 3D space for robotics applications. We embed the whole framework in Robot Operating System, and evaluate its performance on a real robot for semantic mapping and grasp detection.
keywords: {Proposals;Robots;Object detection;Object recognition;Three-dimensional displays;Semantics;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460535&isnumber=8460178

T. -T. Do, A. Nguyen and I. Reid, "AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5882-5889.
doi: 10.1109/ICRA.2018.8460902
Abstract: We propose AffordanceNet, a new deep learning approach to simultaneously detect multiple objects and their affordances from RGB images. Our AffordanceNet has two branches: an object detection branch to localize and classify the object, and an affordance detection branch to assign each pixel in the object to its most probable affordance label. The proposed framework employs three key components for effectively handling the multiclass problem in the affordance mask: a sequence of deconvolutional layers, a robust resizing strategy, and a multi-task loss function. The experimental results on the public datasets show that our AffordanceNet outperforms recent state-of-the-art methods by a fair margin, while its end-to-end architecture allows the inference at the speed of 150ms per image. This makes our AffordanceNet well suitable for real-time robotic applications. Furthermore, we demonstrate the effectiveness of AffordanceNet in different testing environments and in real robotic applications. The source code is available at https://github.com/nqanh/affordance-net.
keywords: {Feature extraction;Robots;Computer architecture;Object detection;Training;Image segmentation;Machine learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460902&isnumber=8460178

M. Patel, B. Emery and Y. -Y. Chen, "ContextualNet: Exploiting Contextual Information Using LSTMs to Improve Image-Based Localization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5890-5896.
doi: 10.1109/ICRA.2018.8461124
Abstract: Convolutional Neural Networks (CNN) have successfully been utilized for localization using a single monocular image [1]. Most of the work to date has either focused on reducing the dimensionality of data for better learning of parameters during training or on developing different variations of CNN models to improve pose estimation. Many of the best performing works solely consider the content in a single image, while the context from historical images is ignored. In this paper, we propose a combined CNN-LSTM which is capable of incorporating contextual information from historical images to better estimate the current pose. Experimental results achieved using a dataset collected in an indoor office space improved the overall system results to 0.8 m & 2.5° at the third quartile of the cumulative distribution as compared with 1.5 m & 3.0° achieved by PoseNet [1]. Furthermore, we demonstrate how the temporal information exploited by the CNN-LSTM model assists in localizing the robot in situations where image content does not have sufficient features.
keywords: {Feature extraction;Cameras;Context modeling;Computer vision;Logic gates;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461124&isnumber=8460178

N. Pérez-Higueras, F. Caballero and L. Merino, "Learning Human-Aware Path Planning with Fully Convolutional Networks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5897-5902.
doi: 10.1109/ICRA.2018.8460851
Abstract: This work presents an approach to learn path planning for robot social navigation by demonstration. We make use of Fully Convolutional Neural Networks (FCNs) to learn from expert's path demonstrations a map that marks a feasible path to the goal as a classification problem. The use of FCNs allows us to overcome the problem of manually designing/identifying the cost-map and relevant features for the task of robot navigation. The method makes use of optimal Rapidly-exploring Random Tree planner (RRT*) to overcome eventual errors in the path prediction; the FCNs prediction is used as cost-map and also to partially bias the sampling of the configuration space, leading the planner to behave similarly to the learned expert behavior. The approach is evaluated in experiments with real trajectories and compared with Inverse Reinforcement Learning algorithms that use RRT* as underlying planner.
keywords: {Robots;Navigation;Task analysis;Trajectory;Cost function;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460851&isnumber=8460178

E. Rehder, F. Wirth, M. Lauer and C. Stiller, "Pedestrian Prediction by Planning Using Deep Neural Networks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5903-5908.
doi: 10.1109/ICRA.2018.8460203
Abstract: Accurate traffic participant prediction is the prerequisite for collision avoidance of autonomous vehicles. In this work, we propose to predict pedestrians using goal-directed planning. For this, we infer a mixture density function for possible destinations. We use these destinations as the goal states of a planning stage that performs motion prediction based on common behavior patterns. The patterns are learned by a fully convolutional network operating on maps of the environment. We show that this entire system can be modeled as one monolithic neural network and trained via inverse reinforcement learning. Experimental validation on real world data shows the system's ability to predict both, destinations and trajectories accurately.
keywords: {Planning;Network topology;Topology;Convolution;Learning (artificial intelligence);Trajectory;Prediction algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460203&isnumber=8460178

P. Schydlo, M. Rakovic, L. Jamone and J. Santos-Victor, "Anticipation in Human-Robot Cooperation: A Recurrent Neural Network Approach for Multiple Action Sequences Prediction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5909-5914.
doi: 10.1109/ICRA.2018.8460924
Abstract: Close human-robot cooperation is a key enabler for new developments in advanced manufacturing and assistive applications. Close cooperation require robots that can predict human actions and intent, understanding human non-verbal cues. Recent approaches based on neural networks have led to encouraging results in the human action prediction problem both in continuous and discrete spaces. Our approach extends the research in this direction. Our contributions are three-fold. First, we validate the use of gaze and body pose cues as a means of predicting human action through a feature selection method. Next, we address two shortcomings of existing literature: predicting multiple and variable-length action sequences. This is achieved by applying an encoder-decoder recurrent neural network topology in the discrete action prediction problem. In addition, we theoretically demonstrate the importance of predicting multiple action sequences as a means of estimating the stochastic reward in a human robot cooperation scenario. Finally, we show the ability to effectively train the prediction model on an action prediction dataset, involving human motion data, and explore the influence of the model's parameters on its performance.
keywords: {Predictive models;Decoding;Hidden Markov models;Recurrent neural networks;Robot kinematics;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460924&isnumber=8460178

H. Ahn, T. Ha, Y. Choi, H. Yoo and S. Oh, "Text2Action: Generative Adversarial Synthesis from Language to Action," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5915-5920.
doi: 10.1109/ICRA.2018.8460608
Abstract: In this paper, we propose a generative model which learns the relationship between language and human action in order to generate a human action sequence given a sentence describing human behavior. The proposed generative model is a generative adversarial network (GAN), which is based on the sequence to sequence (SEQ2SEQ) model. Using the proposed generative network, we can synthesize various actions for a robot or a virtual agent using a text encoder recurrent neural network (RNN) and an action decoder RNN. The proposed generative network is trained from 29,770 pairs of actions and sentence annotations extracted from MSR-Video-to-Text (MSR-VTT), a large-scale video dataset. We demonstrate that the network can generate human-like actions which can be transferred to a Baxter robot, such that the robot performs an action based on a provided sentence. Results show that the proposed generative network correctly models the relationship between language and action and can generate a diverse set of actions from the same sentence.
keywords: {Decoding;Gallium nitride;Hidden Markov models;Generative adversarial networks;Robots;Recurrent neural networks;Generators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460608&isnumber=8460178

M. Pfeiffer, G. Paolo, H. Sommer, J. Nieto, R. Siegwart and C. Cadena, "A Data-driven Model for Interaction-Aware Pedestrian Motion Prediction in Object Cluttered Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5921-5928.
doi: 10.1109/ICRA.2018.8461157
Abstract: This paper reports on a data-driven, interaction-aware motion prediction approach for pedestrians in environments cluttered with static obstacles. When navigating in such workspaces shared with humans, robots need accurate motion predictions of the surrounding pedestrians. Human navigation behavior is mostly influenced by their surrounding pedestrians and by the static obstacles in their vicinity. In this paper we introduce a new model based on Long-Short Term Memory (LSTM) neural networks, which is able to learn human motion behavior from demonstrated data. To the best of our knowledge, this is the first approach using LSTMs, that incorporates both static obstacles and surrounding pedestrians for trajectory forecasting. As part of the model, we introduce a new way of encoding surrounding pedestrians based on a 1d-grid in polar angle space. We evaluate the benefit of interaction-aware motion prediction and the added value of incorporating static obstacles on both simulation and real-world datasets by comparing with state-of-the-art approaches. The results show, that our new approach outperforms the other approaches while being very computationally efficient and that taking into account static obstacles for motion predictions significantly improves the prediction accuracy, especially in cluttered environments.
keywords: {Predictive models;Robots;Trajectory;Adaptation models;Navigation;Planning;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461157&isnumber=8460178

J. Owoyemi and K. Hashimoto, "Spatiotemporal Learning of Dynamic Gestures from 3D Point Cloud Data," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5929-5934.
doi: 10.1109/ICRA.2018.8460910
Abstract: In this paper, we demonstrate an end-to-end spatiotemporal gesture learning approach for 3D point cloud data using a new gestures dataset of point clouds acquired from a 3D sensor. Nine classes of gestures were learned from gestures sample data. We mapped point cloud data into dense occupancy grids, then time steps of the occupancy grids are used as inputs into a 3D convolutional neural network which learns the spatiotemporal features in the data without explicit modeling of gesture dynamics. We also introduced a 3D region of interest jittering approach for point cloud data augmentation. This resulted in an increased classification accuracy of up to 10% when the augmented data is added to the original training data. The developed model is able to classify gestures from the dataset with 84.44% accuracy. We propose that point cloud data will be a more viable data type for scene understanding and motion recognition, as 3D sensors become ubiquitous in years to come.
keywords: {Three-dimensional displays;Robot sensing systems;Feature extraction;Solid modeling;Training data;Spatiotemporal phenomena;Hidden Markov models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460910&isnumber=8460178

D. Paulius, A. B. Jelodar and Y. Sun, "Functional Object-Oriented Network: Construction & Expansion," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5935-5941.
doi: 10.1109/ICRA.2018.8460200
Abstract: We build upon the functional object-oriented network (FOON), a structured knowledge representation which is constructed from observations of human activities and manipulations. A FOON can be used for representing object-motion affordances. Knowledge retrieval through graph search allows us to obtain novel manipulation sequences using knowledge spanning across many video sources, hence the novelty in our approach. However, we are limited to the sources collected. To further improve the performance of knowledge retrieval as a follow up to our previous work, we discuss generalizing knowledge to be applied to objects which are similar to what we have in FOON without manually annotating new sources of knowledge. We discuss two means of generalization: 1) expanding our network through the use of object similarity to create new functional units from those we already have, and 2) compressing the functional units by object categories rather than specific objects. We discuss experiments which compare the performance of our knowledge retrieval algorithm with both expansion and compression by categories.
keywords: {Task analysis;Robots;Merging;Sun;Knowledge representation;Mirrors;Neurons},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460200&isnumber=8460178

L. Sun, Z. Yan, S. M. Mellado, M. Hanheide and T. Duckett, "3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5942-5948.
doi: 10.1109/ICRA.2018.8461228
Abstract: This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of 2D positions in monocular camera images, our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-Pose-LSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.
keywords: {Trajectory;Cameras;Robot kinematics;Robot vision systems;Two dimensional displays;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461228&isnumber=8460178

X. Shen, M. H. Ang and D. Rus, "Conditional Compatibility Branch and Bound for Feature Cloud Matching," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5965-5970.
doi: 10.1109/ICRA.2018.8460711
Abstract: In this paper, we consider the problem of data association in feature cloud matching. While Joint Compatibility (JC) test is a widely adopted technique for searching the global optimal data association, it becomes less restrictive as more features are well matched. The early well-matched features contribute little to total matching cost while the gating threshold increases in the chi-square test, which allows the acceptance of bad feature pairings in the last step. In this paper, we propose the Conditional Compatibility (CC) test, which is not only more restrictive than JC test, but also probabilistically sound. The proposed test of a new feature pairing is based on the conditional probability distribution of feature locations given the early pairings. CC test can be added into any JC test based search algorithm, such as Joint Compatibility Branch and Bound (JCBB), Incremental Posterior Joint Compatibility (IPJC) and FastJCBB, without increasing much computational complexity. The more restrictive criterion of accepting a feature pairing, not only helps to reject bad associations, but also bounds the search space, which substantially improves the search efficiency. The real matching experiments justify that our algorithm produces better feature cloud matching results in a more efficient manner.
keywords: {Probabilistic logic;Robots;Measurement errors;Computational complexity;Probability distribution;Integrated circuits;Feature Cloud Matching;Scan Matching;Data Association;Conditional Compatibility Test},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460711&isnumber=8460178

K. A. Tsintotas, L. Bampis and A. Gasteratos, "Assigning Visual Words to Places for Loop Closure Detection," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5979-5985.
doi: 10.1109/ICRA.2018.8461146
Abstract: Place recognition of pre-visited areas, widely known as Loop Closure Detection (LCD), constitutes one of the most important components in robotic applications, where the robot needs to estimate its pose while navigating through the field (e.g., simultaneous localization and mapping). In this paper, we present a novel approach for LCD based on the assignment of Visual Words (VWs) to particular places of the traversed path. The system operates in real time and does not require any pre-training procedure, such as visual vocabulary construction or descriptor-space dimensionality reduction. A place is defined through a dynamic segmentation of the incoming image stream and is assigned with VWs through the usage of an on-line clustering algorithm. At query time, image descriptors are converted into VWs on the map accumulating votes to the corresponding places. By means of a probability function, the mechanism is capable of identifying a loop closing candidate place. A nearest neighbor voting scheme on the descriptors' space allows the system to select the most appropriate image match at the chosen place. Geometrical and temporal consistency checks are applied on the proposed loop closing pair increasing the system's performance. Evaluation took place on several publicly available and challenging datasets offering high precision and recall scores as compared to other state-of-the-art approaches.
keywords: {Visualization;Liquid crystal displays;Robots;Databases;Pipelines;Feature extraction;Vocabulary},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461146&isnumber=8460178

Y. Zhang, J. Yang, J. Ponce and H. Kong, "Dijkstra Model for Stereo-Vision Based Road Detection: A Non-Parametric Method," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5986-5993.
doi: 10.1109/ICRA.2018.8461071
Abstract: This paper proposes a new method for detecting a road from a stereo pair of images. First, the horizon is accurately estimated by a robust, weighted-sampling RANSAC-like method in the improved v-disparity map. The vanishing point of the road region is located using both the horizon information and road flatness constraints. Then it is used as the source node of a weighted graph formed by the pixels of the left stereo-image and their adjacency relationships. The weight of each edge measures the inconsistency of adjacent pixels, and is computed using both the gray-scale and disparity information. Detecting road borders is thus reduced to finding two shortest paths from the source node to the bottom row of the image by the Dijkstra algorithm. The proposed method has been tested on 2621 image pairs of different road scenes from the KITTI dataset. Our experiments demonstrate that this training free approach detects horizon, vanishing point, and road region accurately and robustly, and compares favorably with the state of the art on the KITTI benchmark.
keywords: {Roads;Robustness;Three-dimensional displays;Stereo vision;Splines (mathematics);Cameras;Image edge detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461071&isnumber=8460178

P. Geneva, K. Eckenhoff and G. Huang, "Asynchronous Multi-Sensor Fusion for 3D Mapping and Localization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5994-5999.
doi: 10.1109/ICRA.2018.8460204
Abstract: In this paper, we address the problem of optimally fusing multiple heterogeneous and asynchronous sensors for use in 3D mapping and localization of autonomous vehicles. To this end, based on the factor graph-based optimization framework, we design a modular sensor-fusion system that allows for efficient and accurate incorporation of multiple navigation sensors operating at different sampling rates. In particular, we develop a general method of out-of-sequence (asynchronous) measurement alignment to incorporate heterogeneous sensors into a factor graph for mapping and localization in 3D, without requiring the addition of new graph nodes, thus allowing the graph to have an overall reduced complexity. The proposed sensor-fusion system is validated on a real-world experimental dataset, in which the asynchronous-measurement alignment is shown to have an improved performance when compared to a naive approach without alignment.
keywords: {Sensors;Three-dimensional displays;Optimization;Atmospheric measurements;Particle measurements;Frequency measurement;Laser radar},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460204&isnumber=8460178

S. B. Nashed, D. M. Ilstrup and J. Biswas, "Localization Under Topological Uncertainty for Lane Identification of Autonomous Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6000-6005.
doi: 10.1109/ICRA.2018.8461185
Abstract: Autonomous vehicles (AVs) require accurate metric and topological location estimates for safe, effective navigation and decision-making. Although many high-definition (HD) roadmaps exist, they are not always accurate since public roads are dynamic, shaped unpredictably by both human activity and nature. Thus, AVs must be able to handle situations in which the topology specified by the map does not agree with reality. We present the Variable Structure Multiple Hidden Markov Model (VSM-HMM) as a framework for localizing in the presence of topological uncertainty, and demonstrate its effectiveness on an AV where lane membership is modeled as a topological localization process. VSM-HMMs use a dynamic set of HMMs to simultaneously reason about location within a set of most likely current topologies and therefore may also be applied to topological structure estimation as well as AV lane estimation. In addition, we present an extension to the Earth Mover's Distance which allows uncertainty to be taken into account when computing the distance between belief distributions on simplices of arbitrary relative sizes.
keywords: {Hidden Markov models;Computational modeling;Topology;Roads;Uncertainty;Measurement;Vehicle dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461185&isnumber=8460178

C. Wu, A. M. Bayen and A. Mehta, "Stabilizing Traffic with Autonomous Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6012-6018.
doi: 10.1109/ICRA.2018.8460567
Abstract: Autonomous vehicles promise safer roads, energy savings, and more efficient use of existing infrastructure, among many other benefits. Although the effect of autonomous vehicles has been studied in the limits (near-zero or full penetration), the transition range requires new formulations, mathematical modeling, and control analysis. In this article, we study the ability of small numbers of autonomous vehicles to stabilize a single-lane system of human-driven vehicles. We formalize the problem in terms of linear string stability, derive optimality conditions from frequency-domain analysis, and pose the resulting nonlinear optimization problem. In particular, we introduce two conditions which simultaneously stabilize traffic while imposing a safety constraint on the autonomous vehicle and limiting degradation of performance. With this optimal linear controller in a system with typical human driver behavior, we can numerically determine that only a 6% uniform penetration of autonomously controlled vehicles (i.e. one per string of up to 16 human-driven vehicles) is necessary to stabilize traffic across all traffic conditions.
keywords: {Autonomous vehicles;Vehicle dynamics;Stability criteria;Optimization;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460567&isnumber=8460178

R. Iglesias, F. Rossi, K. Wang, D. Hallac, J. Leskovec and M. Pavone, "Data-Driven Model Predictive Control of Autonomous Mobility-on-Demand Systems," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6019-6025.
doi: 10.1109/ICRA.2018.8460966
Abstract: The goal of this paper is to present an end-to-end, data-driven framework to control Autonomous Mobility-on-Demand systems (AMoD, i.e. fleets of self-driving vehicles). We first model the AMoD system using a time-expanded network, and present a formulation that computes the optimal rebalancing strategy (i.e., preemptive repositioning) and the minimum feasible fleet size for a given travel demand. Then, we adapt this formulation to devise a Model Predictive Control (MPC) algorithm that leverages short-term demand forecasts based on historical data to compute rebalancing strategies. Using simulations based on real customer data from DiDi Chuxing, we test the end-to-end performance of this controller with a state-of-the-art LSTM neural network to predict customer demand: we show that this approach scales very well for large systems (indeed, the computational complexity of the MPC algorithm does not depend on the number of customers and of vehicles in the system) and outperforms state-of-the-art rebalancing strategies by reducing the mean customer wait time by up to to 89.6 %.
keywords: {Prediction algorithms;Predictive control;Transportation;Pricing;Control systems;Steady-state;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460966&isnumber=8460178

G. Dabisias, E. Ruffaldi, H. Grimmett and P. Ondruska, "VALUE: Large Scale Voting-Based Automatic Labelling for Urban Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6033-6038.
doi: 10.1109/ICRA.2018.8460196
Abstract: This paper presents a simple and robust method for the automatic localisation of static 3D objects in large-scale urban environments. By exploiting the potential to merge a large volume of noisy but accurately localised 2D image data, we achieve superior performance in terms of both robustness and accuracy of the recovered 3D information. The method is based on a simple distributed voting schema which can be fully distributed and parallelised to scale to large-scale scenarios. To evaluate the method we collected city-scale data sets from New York City and San Francisco consisting of almost 400k images spanning the area of 40 km2 and used it to accurately recover the 3D positions of traffic lights. We demonstrate a robust performance and also show that the solution improves in quality over time as the amount of data increases.
keywords: {Three-dimensional displays;Two dimensional displays;Urban areas;Cameras;Robustness;Noise measurement;Semantics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460196&isnumber=8460178

W. Zhou, S. Worrall, A. Zyner and E. Nebot, "Automated Process for Incorporating Drivable Path into Real-Time Semantic Segmentation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6039-6044.
doi: 10.1109/ICRA.2018.8460486
Abstract: Vision systems are widely used in autonomous vehicle systems due to the rich information that camera sensors provide of the surrounding environment. This paper presents an automatic algorithm to obtain the drivable path of a vehicle operating in urban roads with or without clear lane markings. The developed system projects trajectories obtained during human operation of the vehicle and utilizes these to generate automatic labels for training a semantic based path prediction model. The system segments an urban scenario into 13 categories including vehicles, pedestrian, undrivable road, other categories relevant to urban roads, and a new class for a path proposal. The drivable path information is essential particularly in unstructured scenarios, and is critical for an intelligent vehicle system to make sound driving decisions. The path proposal category is a car-width drivable lane estimated to be safe to drive for the vehicle under consideration. The data collection, model training and inference process requires only images from a monocular camera and odometry from a low-cost IMU combined with a wheel encoder. The algorithm has been successfully demonstrated on the Sydney University campus, which is a challenging environment without clear road markings. The algorithm was demonstrated to run in real-time, proving its applicability for intelligent vehicles.
keywords: {Semantics;Cameras;Roads;Image segmentation;Sensors;Proposals;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460486&isnumber=8460178

S. H. Cen and P. Newman, "Precise Ego-Motion Estimation with Millimeter-Wave Radar Under Diverse and Challenging Conditions," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6045-6052.
doi: 10.1109/ICRA.2018.8460687
Abstract: In contrast to cameras, lidars, GPS, and proprioceptive sensors, radars are affordable and efficient systems that operate well under variable weather and lighting conditions, require no external infrastructure, and detect long-range objects. In this paper, we present a reliable and accurate radar-only motion estimation algorithm for mobile autonomous systems. Using a frequency-modulated continuous-wave (FMCW) scanning radar, we first extract landmarks with an algorithm that accounts for unwanted effects in radar returns. To estimate relative motion, we then perform scan matching by greedily adding point correspondences based on unary descriptors and pairwise compatibility scores. Our radar odometry results are robust under a variety of conditions, including those under which visual odometry and GPS/INS fail.
keywords: {Sensors;Feature extraction;Radar imaging;Azimuth;Motion estimation;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460687&isnumber=8460178

O. Mendez, S. Hadfield, N. Pugeault and R. Bowden, "SeDAR - Semantic Detection and Ranging: Humans can Localise without LiDAR, can Robots?," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6053-6060.
doi: 10.1109/ICRA.2018.8461074
Abstract: How does a person work out their location using a floorplan? It is probably safe to say that we do not explicitly measure depths to every visible surface and try to match them against different pose estimates in the floorplan. And yet, this is exactly how most robotic scan-matching algorithms operate. Similarly, we do not extrude the 2D geometry present in the floorplan into 3D and try to align it to the real-world. And yet, this is how most vision-based approaches localise. Humans do the exact opposite. Instead of depth, we use high level semantic cues. Instead of extruding the floorplan up into the third dimension, we collapse the 3D world into a 2D representation. Evidence of this is that many of the floorplans we use in everyday life are not accurate, opting instead for high levels of discriminative landmarks. In this work, we use this insight to present a global localisation approach that relies solely on the semantic labels present in the floorplan and extracted from RGB images. While our approach is able to use range measurements if available, we demonstrate that they are unnecessary as we can achieve results comparable to state-of-the-art without them.
keywords: {Semantics;Robot sensing systems;Three-dimensional displays;Two dimensional displays;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461074&isnumber=8460178

W. Roozing, Z. Ren and N. G. Tsagarakis, "Design of a Novel 3-DoF Leg with Series and Parallel Compliant Actuation for Energy Efficient Articulated Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6068-6075.
doi: 10.1109/ICRA.2018.8460493
Abstract: This work presents the development of a 3-DoF leg with series and parallel compliant actuation. Series-elastic main actuators are combined with parallel high efficiency energy storage branches, to substantially improve energy efficiency. The leg design is semi-anthropomorphic, with similar mass and mass distribution to the human limb, and includes a biarticulated actuation configuration. The parallel branches are driven by secondary motors and their design parameters are optimised. The mechanical design of the prototype leg is presented, introducing details of the actuation configuration principles employed. Preliminary experimental data are presented, in which a baseline series-elastic-only configuration is compared with configurations with mono- and biarticulated parallel branches, respectively. The results effectively demonstrate the concept's potential, showing improvements of 53% and 60% in electrical power consumption while the leg is executing loaded cyclic motion profiles.
keywords: {Legged locomotion;Actuators;Knee;Pulleys;Torque;Energy storage},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460493&isnumber=8460178

K. G. Gim, J. Kim and K. Yamane, "Design of a Serial-Parallel Hybrid Leg for a Humanoid Robot," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6076-6081.
doi: 10.1109/ICRA.2018.8460733
Abstract: This paper presents a 6 DOF leg mechanism for a humanoid robot. The proposed Hybrid Leg is designed to combine serial and parallel mechanisms and consists of a pair of twin 3 DOF serial chains in parallel. A 5-bar-linkage mechanism is implemented to the serial mechanism to generate 2 DOF motion regarding hip and knee pitch rotation. The hardware prototype is designed by matching the kinematic specification of a commercial robot's leg to compare the proposed mechanism with a conventional serial leg. We derive the analytical expressions of its forward and inverse kinematics. End-effector workspaces are shown with plots and inverse dynamics analysis of Hybrid Leg and serial leg with a given walking gait trajectory is presented. Hardware experiment is conducted with a prototype to verify the simulated workspace and trajectory tracking performance.
keywords: {Legged locomotion;Kinematics;Couplings;Prototypes;Hip;Hardware},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460733&isnumber=8460178

J. S. Lee, M. Plecnik, J. -H. Yang and R. S. Fearing, "Self-Engaging Spined Gripper with Dynamic Penetration and Release for Steep Jumps," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6082-6089.
doi: 10.1109/ICRA.2018.8460933
Abstract: Due to high impact forces and low duty cycles, monopedal jumping robots are particularly susceptible to failure from a slipping foot. Spines provide a solution to reduce slip, but there has been little research on how to effectively engage them into a surface with a dynamic jumping robot. Previous robots utilizing spines operate in different regimes of surface approach speed and cycle time. For a penetrable substrate, spines must be directed into the surface at suitable holding angles, then extracted before the foot leaves the ground. We accomplished this by designing a gripper mechanism for the robot Salto that pushes in angled spines along their length and is kinematically constrained to engage/disengage with leg crouch/extension. The resulting mechanism introduces no new actuators, enables jumping on penetrable inclines up to 60°, and enables static adhesion to hold 7.5 times the robot's weight from a ceiling.
keywords: {Grippers;Pins;Robot kinematics;Legged locomotion;Couplings;Substrates},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460933&isnumber=8460178

G. M. Plaizier, E. Andersen, B. Truong, X. He, S. Roundy and K. K. Leang, "Design, Modeling, and Analysis of Inductive Resonant Coupling Wireless Power Transfer for Micro Aerial Vehicles (MAVs)," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6104-6109.
doi: 10.1109/ICRA.2018.8461162
Abstract: This paper presents the design, modeling, analysis, and experimental validation of an inductive resonant wireless power transfer (WPT) system to power a micro aerial vehicle (MAV). Using WPT, in general, enables longer flight times, virtually eliminates the need for batteries, and minimizes down time for recharging or replacing batteries. The proposed WPT system consists of a transmit coil, which can either be fixed to ground or placed on a mobile platform, and a receive coil carried by the MAV. The details of the WPT circuit design are presented. A power-transfer model is developed for the two-coil system, where the model is used to select suitable coil geometries to maximize the power received by the MAV for hovering. Analysis, simulation, and experimental results are presented to demonstrate the effectiveness of the WPT circuitry. Finally, a wirelessly powered MAV that hovers above the transmit coil is demonstrated in a laboratory setting.
keywords: {Batteries;Magnetic resonance;Integrated circuit modeling;Geometry;Analytical models;Couplings;Wireless power transfer},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461162&isnumber=8460178

Z. Li, S. Suntharasantic and P. Chirarattananon, "Simplified Quasi-Steady Aeromechanic Model for Flapping-Wing Robots with Passively Rotating Hinges," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6110-6115.
doi: 10.1109/ICRA.2018.8461020
Abstract: At millimeter and centimeter scales, flapping-wing robots often employ flexural passive wing hinges to eliminate extra actuation and mechanical complexity. In this paper, we propose a modified quasi-steady model for predicting aerodynamic forces from a flapping wing with a passively rotating hinge. The model is based on a simplifying assumption of balanced torque (aerodynamic torque equals to the restoring torque from the hinge). The resulting lift and drag can then be accurately predicted by the modified quasi-steady model without direct knowledge of the angle of attack of the wing. Approximate expression of stroke-averaged forces are also derived. We performed flapping experiments on a centimeter-scale device and the measured lifts show good agreement with the model predictions.
keywords: {Aerodynamics;Torque;Robots;Fasteners;Predictive models;Drag;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461020&isnumber=8460178

R. Border, J. D. Gammell and P. Newman, "Surface Edge Explorer (see): Planning Next Best Views Directly from 3D Observations," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6116-6123.
doi: 10.1109/ICRA.2018.8461098
Abstract: Surveying 3D scenes is a common task in robotics. Systems can do so autonomously by iteratively obtaining measurements. This process of planning observations to improve the model of a scene is called Next Best View (NBV) planning. NBV planning approaches often use either volumetric (e.g., voxel grids) or surface (e.g., triangulated meshes) representations. Volumetric approaches generalise well between scenes as they do not depend on surface geometry but do not scale to high-resolution models of large scenes. Surface representations can obtain high-resolution models at any scale but often require tuning of unintuitive parameters or multiple survey stages. This paper presents a scene-model-free NBV planning approach with a density representation. The Surface Edge Explorer (SEE) uses the density of current measurements to detect and explore observed surface boundaries. This approach is shown experimentally to provide better surface coverage in lower computation time than the evaluated state-of-the-art volumetric approaches while moving equivalent distances.
keywords: {Planning;Computational modeling;Density measurement;Geometry;Surface treatment;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461098&isnumber=8460178

R. Huang, D. Zou, R. Vaughan and P. Tan, "Active Image-Based Modeling with a Toy Drone," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6124-6131.
doi: 10.1109/ICRA.2018.8460673
Abstract: Image-based modeling techniques [1]-[3] can now generate photo-realistic 3D models from images. But it is up to users to provide high quality images with good coverage and view overlap, which makes the data capturing process tedious and time consuming. We seek to automate data capturing for image-based modeling. The core of our system is an iterative linear method to solve the multi-view stereo (MVS) problem quickly and plan the Next-Best-View (NBV) effectively. Our fast MVS algorithm enables online model reconstruction and quality assessment to determine the NBVs on the fly. We test our system with a toy unmanned aerial vehicle (UAV) in simulated, indoor and outdoor experiments. Results show that our system improves the efficiency of data acquisition and ensures the completeness of the final model.
keywords: {Three-dimensional displays;Image reconstruction;Solid modeling;Unmanned aerial vehicles;Planning;Pipelines;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460673&isnumber=8460178

H. Cheng et al., "Fusing Object Context to Detect Functional Area for Cognitive Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6132-6139.
doi: 10.1109/ICRA.2018.8460590
Abstract: A cognitive robot usually needs to perform multiple tasks in practice and needs to locate the desired area for each task. Since deep learning has achieved substantial progress in image recognition, to solve this area detection problem, it is straightforward to label a functional area (affordance) image dataset and apply a well-trained deep-model-based classifier on all the potential image regions. However, annotating the functional area is time consuming and the requirement of large amount of training data limits the application scope. We observe that the functional area are usually related to the surrounding object context. In this work, we propose to use the existing object detection dataset and employ the object context as effective prior to improve the performance without additional annotated data. In particular, we formulate a two-stream network that fuses the object-related and functionality-related feature for functional area detection. The whole system is formulated in an end-to-end manner and easy to implement with current object detection framework. Experiments demonstrate that the proposed network outperforms current method by almost 20% in terms of precision and recall.
keywords: {Feature extraction;Object detection;Robots;Task analysis;Machine learning;Proposals;Image recognition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460590&isnumber=8460178

M. Bui, S. Zakharov, S. Albarqouni, S. Ilic and N. Navab, "When Regression Meets Manifold Learning for Object Recognition and Pose Estimation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6140-6146.
doi: 10.1109/ICRA.2018.8460654
Abstract: In this work, we propose a method for object recognition and pose estimation from depth images using convolutional neural networks. Previous methods addressing this problem rely on manifold learning to learn low dimensional viewpoint descriptors and employ them in a nearest neighbor search on an estimated descriptor space. In comparison we create an efficient multi-task learning framework combining manifold descriptor learning and pose regression. By combining the strengths of manifold learning using triplet loss and pose regression, we could either estimate the pose directly reducing the complexity compared to NN search, or use the learned descriptor for the NN descriptor matching. By in depth experimental evaluation of the novel loss function we observed that the view descriptors learned by the network are much more discriminative resulting in almost 30% increase regarding relative pose accuracy compared to related works. On the other hand, regarding directly regressed poses we obtained important improvement compared to simple pose regression. By leveraging the advantages of both manifold learning and regression tasks, we are able to improve the current state-of-the-art for object recognition and pose retrieval.
keywords: {Pose estimation;Manifolds;Task analysis;Training;Robustness;Object recognition;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460654&isnumber=8460178

N. Chiba and K. Hashimoto, "Ultra-Fast Multi-Scale Shape Estimation of Light Transport Matrix for Complex Light Reflection Objects," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6147-6152.
doi: 10.1109/ICRA.2018.8460892
Abstract: 3D measurement of target objects characterized by specular reflection or subsurface scatterings cannot be measured by traditional 3D measurement methods because these targets have multiple light paths that make it difficult to determine the unique surface. We define these objects as complex light reflection objects. In this case, 3D measurement methods based on Light Transport (LT) Matrix estimation may be a solution to measure these complex light reflection objects, because LT Matrix captures every light path, and we can identify all 3D points on the target shape by using LT Matrix. However, these methods either provide low resolution results, or they are too slow for use in robot vision in practice. In this paper, we suppress the computational cost of LT Matrix estimation by dividing LT Matrix estimation into multi-scale. The proposed method reduces the number of candidate combinations between camera pixels and projector pixels greatly by using the information given by low resolution observations. The proposed algorithm allows high resolution measurement of the LT Matrix very efficiently. Furthermore, careful implementation of our method by using a sparse matrix representation achieves memory efficiency. We evaluated our method by measuring 3D points for a 256 × 256 resolution projector and camera system, which is an LT matrix 4096 times larger than that developed in our previous study [1] and 100 times faster than our naïve implementation of [2].
keywords: {Cameras;Three-dimensional displays;Estimation;Sparse matrices;Shape;Shape measurement;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460892&isnumber=8460178

T. Parhar, H. Baweja, M. Jenkins and G. Kantor, "A Deep Learning-Based Stalk Grasping Pipeline," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6161-6167.
doi: 10.1109/ICRA.2018.8460597
Abstract: The need for fast and precise measurements of plant attributes makes robotic solutions an ideal replacement for labor-intensive phenotyping processes. In this work we present a deep learning-based high throughput, online pipeline for in-situ sorghum stalk detection and grasping. We use a variation of Generative Adversarial Network (GAN) for stalk segmentation trained on a relatively small number of images followed by a grasp point generation pipeline. The presented pipeline is robust to field challenges such as occlusions, high stalk density and lighting variation, and was deployed on a custom-built ground robot. We tested our end-to-end system in a field of Sorghum bicolor in South Carolina, USA, achieving an average grasping accuracy of 74.13% and a stalk detection F1 score of 0.90. Grasp point detection for plant manipulation takes an average of 0.98 seconds, and pixel-wise stalk detection takes 0.2 seconds per image.
keywords: {Robots;Pipelines;Image segmentation;Generators;Three-dimensional displays;Gallium nitride;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460597&isnumber=8460178

V. Dietrich et al., "Configuration of Perception Systems via Planning Over Factor Graphs," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6168-6174.
doi: 10.1109/ICRA.2018.8460955
Abstract: Sensor guided, automated systems require the composition of various sensors and data processing algorithms to obtain relevant information for performing their task. Many applications have additional requirements such as a certain accuracy, which has to be achieved despite sensor noise and calibration errors. In this paper we model the configuration of perception systems as a planning problem over probabilistic graphical models. We work on a subset of the full configuration space of perceptions systems, specifically the used sensors, data processing algorithms and view poses. Based on a semantic description of the goal, available sensors and data processing algorithms, our system plans perception steps and sensor data fusion autonomously. The planner operates by constructing a factor graph until the accuracy requirements of tasks are fulfilled or unobtainable with the available action set. We validate our approach in an industrial assembly scenario.
keywords: {Task analysis;Planning;Robot sensing systems;Uncertainty;Semantics;Cameras;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460955&isnumber=8460178

J. Rutledge et al., "Intelligent Shipwreck Search Using Autonomous Underwater Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6175-6182.
doi: 10.1109/ICRA.2018.8460548
Abstract: This paper presents an autonomous robot system that is designed to autonomously search for and geo-localize potential underwater archaeological sites. The system, based on Autonomous Underwater Vehicles, invokes a multi-step pipeline. First, the AUV constructs a high altitude scan over a large area to collect low-resolution side scan sonar data. Second, image processing software is employed to automatically detect and identify potential sites of interest. Third, a ranking algorithm assigns importance scores to each site. Fourth, an AUV path planner is used to plan a time-limited path that visits sites with a high importance at a low altitude to acquire high-resolution sonar data. Last, the AUV is deployed to follow this path. This system was implemented and evaluated during an archaeological survey located along the coast of Malta. These experiments demonstrated that the system is able to identify valuable archaeological sites accurately and efficiently in a large previously unsurveyed area. Also, the planned missions led to the discovery of a historical plane wreck whose location was previously unknown.
keywords: {Sonar;Proposals;Clustering algorithms;Pipelines;Feature extraction;Software},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460548&isnumber=8460178

S. Heshmati-alamdari, G. C. Karras, P. Marantos and K. J. Kyriakopoulos, "A Robust Model Predictive Control Approach for Autonomous Underwater Vehicles Operating in a Constrained Workspace," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6183-6188.
doi: 10.1109/ICRA.2018.8460918
Abstract: This paper presents a novel Nonlinear Model Predictive Control (NMPC) scheme for underwater robotic vehicles operating in a constrained workspace including static obstacles. The purpose of the controller is to guide the vehicle towards specific way points. Various limitations such as: obstacles, workspace boundary, thruster saturation and predefined desired upper bound of the vehicle velocity are captured as state and input constraints and are guaranteed during the control design. The proposed scheme incorporates the full dynamics of the vehicle in which the ocean currents are also involved. Hence, the control inputs calculated by the proposed scheme are formulated in a way that the vehicle will exploit the ocean currents, when these are in favor of the way-point tracking mission which results in reduced energy consumption by the thrusters. The performance of the proposed control strategy is experimentally verified using a 4 Degrees of Freedom (DoF) underwater robotic vehicle inside a constrained test tank with obstacles.
keywords: {Oceans;Robots;Underwater vehicles;Mathematical model;Vehicle dynamics;Energy consumption;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460918&isnumber=8460178

W. Wang et al., "Design, Modeling, and Nonlinear Model Predictive Tracking Control of a Novel Autonomous Surface Vehicle," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6189-6196.
doi: 10.1109/ICRA.2018.8460632
Abstract: In this paper, we present the design, modeling, and real-time nonlinear model predictive control (NMPC) of an autonomous robotic boat. The robot is easy to manufacture, highly maneuverable, and capable of accurate trajectory tracking in both indoor and outdoor environments. In particular, a cross type four-thruster configuration is proposed for the robotic boat to produce efficient holonomic motions. The robot prototype is rapidly 3D-printed and then sealed by adhering several layers of fiberglass. To achieve accurate tracking control, we formulate an NMPC strategy for the four-control-input boat with control input constraints, where the nonlinear dynamic model includes a Coriolis and centripetal matrix, the hydrodynamic added mass, and damping. By integrating &#x201C;GPS&#x201D; modules and an inertial measurement unit (IMU) into the robot, we demonstrate accurate trajectory tracking of the robotic boat along preplanned paths in both a swimming pool and a natural river. Furthermore, the code generation strategy employed in our paper yields a two order of magnitude improvement in the run time of the NMPC algorithm compared to similar systems. The robot is designed to form the basis for surface swarm robotics testbeds, on which collective algorithms for surface transportation and self-assembly of dynamic floating infrastructures can be assessed.
keywords: {Boats;Vehicle dynamics;Symmetric matrices;Global Positioning System;Heuristic algorithms;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460632&isnumber=8460178

G. Brinkmann, W. M. Bessa, D. -A. Duecker, E. Kreuzer and E. Solowjow, "Reinforcement Learning of Depth Stabilization with a Micro Diving Agent," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6197-6203.
doi: 10.1109/ICRA.2018.8461137
Abstract: Reinforcement learning (RL) allows robots to solve control tasks through interaction with their environment. In this paper we study a model-based value-function RL approach, which is suitable for computationally limited robots and light embedded systems. We develop a diving agent, which uses the RL algorithm for underwater depth stabilization. Simulations and experiments with the micro diving agent demonstrate its ability to learn the depth stabilization task.
keywords: {Computational modeling;Learning (artificial intelligence);Task analysis;Robot kinematics;Heuristic algorithms;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461137&isnumber=8460178

R. DeBortoli, A. Nicolai, F. Li and G. A. Hollinger, "Real-Time Underwater 3D Reconstruction Using Global Context and Active Labeling," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6204-6211.
doi: 10.1109/ICRA.2018.8461148
Abstract: In this work we develop a novel framework that enables the real-time 3D reconstruction of underwater environments using features from 2D sonar images. Due to noisy and low-resolution imagery as compared with standard cameras, automatic feature extractors for sonar images are not reliable in many scenarios. Thus, a human often needs to hand-select features in sonar imagery for environment reconstructions. Given the high data capture rates of standard imaging sonars (on the order of 20Hz), hand-annotating the features in every frame cannot be done in real-time. To address this we use a Convolutional Neural Network (CNN) that analyzes incoming imagery in real-time and proposes only a small subset of high-quality frames to the user for feature annotation. We demonstrate that our approach provides real-time reconstruction capability without loss in classification performance on datasets captured onboard our underwater vehicle while operating in a variety of environments.
keywords: {Image reconstruction;Feature extraction;Real-time systems;Three-dimensional displays;Imaging;Sonar measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461148&isnumber=8460178

M. J. Islam, M. Ho and J. Sattar, "Dynamic Reconfiguration of Mission Parameters in Underwater Human-Robot Collaboration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6212-6219.
doi: 10.1109/ICRA.2018.8461197
Abstract: This paper presents a real-time programming and parameter reconfiguration method for autonomous underwater robots in human-robot collaborative tasks. Using a set of intuitive and meaningful hand gestures, we develop a syntactically simple framework that is computationally more efficient than a complex, grammar-based approach. In the proposed framework, a convolutional neural network is trained to provide accurate hand gesture recognition; subsequently, a finite-state machine- based deterministic model performs efficient gesture-to-instruction mapping and further improves robustness of the interaction scheme. The key aspect of this framework is that it can be easily adopted by divers for communicating simple instructions to underwater robots without using artificial tags such as fiducial markers or requiring memorization of a potentially complex set of language rules. Extensive experiments are performed both on field-trial data and through simulation, which demonstrate the robustness, efficiency, and portability of this framework in a number of different scenarios. Finally, a user interaction study is presented that illustrates the gain in the ease of use of our proposed interaction framework compared to the existing methods for the underwater domain.
keywords: {Robustness;Task analysis;Visualization;Robot sensing systems;Unmanned underwater vehicles;Gesture recognition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461197&isnumber=8460178

Y. T. Tan, A. Kunapareddy and M. Kobilarov, "Gaussian Process Adaptive Sampling Using the Cross-Entropy Method for Environmental Sensing and Monitoring," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6220-6227.
doi: 10.1109/ICRA.2018.8460821
Abstract: In this paper, we focus on adaptive sampling on a Gaussian Processes (GP) using the receding-horizon Cross-Entropy (CE) trajectory optimization. Specifically, we employ the GP upper confidence bound (GP-UCB) as the optimization criteria to adaptively plan sampling paths that balance the exploitation-exploration trade-off. Path planning at the initial stage focuses on exploring and learning a model of the environment, and later, on exploiting the learned model to focus sampling around regions that exhibit extreme sensory measurements and much higher spatial variability, denoted as the Region of Interest (ROI). The integration of the CE trajectory optimization allows the sampling density to be dynamically adjusted based on the latest sensory measurements, thus providing an efficient sampling strategy for sensing and localizing the ROI. We demonstrate the effectiveness of the proposed method in exploring simulated scalar fields with single or multiple ROIs. Field experiments with an Unmanned Surface Vehicle (USV) in a coastal bathymetry mapping mission validate the approach's capability in quickly exploring and mapping the given area, and then focusing and increasing the sampling density around the deepest region, as a surrogate for e.g. the extremal concentration of a pollutant in the environment.
keywords: {Robot sensing systems;Adaptation models;Optimization;Predictive models;Trajectory;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460821&isnumber=8460178

T. -H. Pham, G. De Magistris and R. Tachibana, "OptLayer - Practical Constrained Optimization for Deep Reinforcement Learning in the Real World," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6236-6243.
doi: 10.1109/ICRA.2018.8460547
Abstract: While deep reinforcement learning techniques have recently produced considerable achievements on many decision-making problems, their use in robotics has largely been limited to simulated worlds or restricted motions, since unconstrained trial-and-error interactions in the real world can have undesirable consequences for the robot or its environment. To overcome such limitations, we propose a novel reinforcement learning architecture, OptLayer, that takes as inputs possibly unsafe actions predicted by a neural network and outputs the closest actions that satisfy chosen constraints. While learning control policies often requires carefully crafted rewards and penalties while exploring the range of possible actions, OptLayer ensures that only safe actions are actually executed and unsafe predictions are penalized during training. We demonstrate the effectiveness of our approach on robot reaching tasks, both simulated and in the real world.
keywords: {Robot kinematics;Neural networks;Task analysis;Optimization;Learning (artificial intelligence);Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460547&isnumber=8460178

T. Haarnoja, V. Pong, A. Zhou, M. Dalal, P. Abbeel and S. Levine, "Composable Deep Reinforcement Learning for Robotic Manipulation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6244-6251.
doi: 10.1109/ICRA.2018.8460756
Abstract: Model-free deep reinforcement learning has been shown to exhibit good performance in domains ranging from video games to simulated robotic manipulation and locomotion. However, model-free methods are known to perform poorly when the interaction time with the environment is limited, as is the case for most real-world robotic tasks. In this paper, we study how maximum entropy policies trained using soft Q-learning can be applied to real-world robotic manipulation. The application of this method to real-world manipulation is facilitated by two important features of soft Q-learning. First, soft Q-learning can learn multimodal exploration strategies by learning policies represented by expressive energy-based models. Second, we show that policies learned with soft Q-learning can be composed to create new policies, and that the optimality of the resulting policy can be bounded in terms of the divergence between the composed policies. This compositionality provides an especially valuable tool for real-world manipulation, where constructing new policies by composing existing skills can provide a large gain in efficiency over training from scratch. Our experimental evaluation demonstrates that soft Q-learning is substantially more sample efficient than prior model-free deep reinforcement learning methods, and that compositionality can be performed for both simulated and real-world tasks.
keywords: {Entropy;Robots;Learning (artificial intelligence);Neural networks;Machine learning;Task analysis;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460756&isnumber=8460178

P. Long, T. Fan, X. Liao, W. Liu, H. Zhang and J. Pan, "Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6252-6259.
doi: 10.1109/ICRA.2018.8461113
Abstract: Developing a safe and efficient collision avoidance policy for multiple robots is challenging in the decentralized scenarios where each robot generates its paths without observing other robots' states and intents. While other distributed multi-robot collision avoidance systems exist, they often require extracting agent-level features to plan a local collision-free action, which can be computationally prohibitive and not robust. More importantly, in practice the performance of these methods are much lower than their centralized counterparts. We present a decentralized sensor-level collision avoidance policy for multi-robot systems, which directly maps raw sensor measurements to an agent's steering commands in terms of movement velocity. As a first step toward reducing the performance gap between decentralized and centralized methods, we present a multi-scenario multi-stage training framework to learn an optimal policy. The policy is trained over a large number of robots on rich, complex environments simultaneously using a policy gradient based reinforcement learning algorithm. We validate the learned sensor-level collision avoidance policy in a variety of simulated scenarios with thorough performance evaluations and show that the final learned policy is able to find time efficient, collision-free paths for a large-scale robot system. We also demonstrate that the learned policy can be well generalized to new scenarios that do not appear in the entire training period, including navigating a heterogeneous group of robots and a large-scale scenario with 100 robots. Videos are available at https://sites.google.com/view/drlmaca.
keywords: {Collision avoidance;Robot sensing systems;Robot kinematics;Navigation;Robustness;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461113&isnumber=8460178

J. Luo, R. Edmunds, F. Rice and A. M. Agogino, "Tensegrity Robot Locomotion Under Limited Sensory Inputs via Deep Reinforcement Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6260-6267.
doi: 10.1109/ICRA.2018.8463144
Abstract: Tensegrity robots are composed of rigid rods connected by elastic cables, and their unique light-weight yet compliant structure makes them an appealing choice for space exploration. However, locomotion control for these robotic systems remains difficult due to their nonlinear dynamics and high-dimensional state space. We demonstrate that in the domain of tensegrity robotics, it is possible to efficiently learn end-to-end locomotion policies using mirror descent guided policy search (MDGPS) even with limited sensory inputs. We compare learned neural network policies with other locomotion control policies in various testing environments; and results show that neural network policies consistently outperform others. We also shed light to the policy learning process by analyzing different choices of observation inputs to the robot. Moreover these findings motivate exploration of deep reinforcement learning algorithms in the domain of tensegrity robotics. We show preliminary results with one such locomotion example on discontinuous rough terrains.
keywords: {Robot sensing systems;Neural networks;Aerospace electronics;Hardware;NASA;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463144&isnumber=8460178

G. Ryou, Y. Sim, S. H. Yeon and S. Seok, "Applying Asynchronous Deep Classification Networks and Gaming Reinforcement Learning-Based Motion Planners to Mobile Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6268-6275.
doi: 10.1109/ICRA.2018.8460798
Abstract: In this paper, we propose a new methodology to embed deep learning-based algorithms in both visual recognition and motion planning for general mobile robotic platforms. A framework for an asynchronous deep classification network is introduced to integrate heavy deep classification networks into a mobile robot with no loss of system bandwidth. Moreover, a gaming reinforcement learning-based motion planner, a novel and convenient embodiment of reinforcement learning, is introduced for simple implementation and high applicability. The proposed approaches are implemented and evaluated on a developed robot, TT2-bot. The evaluation was based on a mission devised for a qualitative evaluation of the general purposes and performances of a mobile robotic platform. The robot was required to recognize targets with a deep classifier and plan the path effectively using a deep motion planner. As a result, the robot verified that the proposed approaches successfully integrate deep learning technologies on the stand-alone mobile robot. The embedded neural networks for recognition and path planning were critical components for the robot.
keywords: {Mobile robots;Learning (artificial intelligence);Machine learning;Neural networks;Sensors;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460798&isnumber=8460178

L. Xie, S. Wang, S. Rosa, A. Markham and N. Trigoni, "Learning with Training Wheels: Speeding up Training with a Simple Controller for Deep Reinforcement Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6276-6283.
doi: 10.1109/ICRA.2018.8461203
Abstract: Deep Reinforcement Learning (DRL) has been applied successfully to many robotic applications. However, the large number of trials needed for training is a key issue. Most of existing techniques developed to improve training efficiency (e.g. imitation) target on general tasks rather than being tailored for robot applications, which have their specific context to benefit from. We propose a novel framework, Assisted Reinforcement Learning, where a classical controller (e.g. a PID controller) is used as an alternative, switchable policy to speed up training of DRL for local planning and navigation problems. The core idea is that the simple control law allows the robot to rapidly learn sensible primitives, like driving in a straight line, instead of random exploration. As the actor network becomes more advanced, it can then take over to perform more complex actions, like obstacle avoidance. Eventually, the simple controller can be discarded entirely. We show that not only does this technique train faster, it also is less sensitive to the structure of the DRL network and consistently outperforms a standard Deep Deterministic Policy Gradient network. We demonstrate the results in both simulation and real-world experiments.
keywords: {Training;Navigation;Acceleration;Robot kinematics;Machine learning;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461203&isnumber=8460178

D. Quillen, E. Jang, O. Nachum, C. Finn, J. Ibarz and S. Levine, "Deep Reinforcement Learning for Vision-Based Robotic Grasping: A Simulated Comparative Evaluation of Off-Policy Methods," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6284-6291.
doi: 10.1109/ICRA.2018.8461039
Abstract: In this paper, we explore deep reinforcement learning algorithms for vision-based robotic grasping. Model-free deep reinforcement learning (RL) has been successfully applied to a range of challenging environments, but the proliferation of algorithms makes it difficult to discern which particular approach would be best suited for a rich, diverse task like grasping. To answer this question, we propose a simulated benchmark for robotic grasping that emphasizes off-policy learning and generalization to unseen objects. Off-policy learning enables utilization of grasping data over a wide variety of objects, and diversity is important to enable the method to generalize to new objects that were not seen during training. We evaluate the benchmark tasks against a variety of Q-function estimation methods, a method previously proposed for robotic grasping with deep neural network models, and a novel approach based on a combination of Monte Carlo return estimation and an off-policy correction. Our results indicate that several simple methods provide a surprisingly strong competitor to popular algorithms such as double Q-learning, and our analysis of stability sheds light on the relative tradeoffs between the algorithms1.
keywords: {Grasping;Robots;Task analysis;Benchmark testing;Monte Carlo methods;Machine learning;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461039&isnumber=8460178

A. Nair, B. McGrew, M. Andrychowicz, W. Zaremba and P. Abbeel, "Overcoming Exploration in Reinforcement Learning with Demonstrations," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6292-6299.
doi: 10.1109/ICRA.2018.8463162
Abstract: Exploration in environments with sparse rewards has been a persistent problem in reinforcement learning (RL). Many tasks are natural to specify with a sparse reward, and manually shaping a reward function can result in suboptimal performance. However, finding a non-zero reward is exponentially more difficult with increasing task horizon or action dimensionality. This puts many real-world tasks out of practical reach of RL methods. In this work, we use demonstrations to overcome the exploration problem and successfully learn to perform long-horizon, multi-step robotics tasks with continuous control such as stacking blocks with a robot arm. Our method, which builds on top of Deep Deterministic Policy Gradients and Hindsight Experience Replay, provides an order of magnitude of speedup over RL on simulated robotics tasks. It is simple to implement and makes only the additional assumption that we can collect a small set of demonstrations. Furthermore, our method is able to solve tasks not solvable by either RL or behavior cloning alone, and often ends up outperforming the demonstrator policy.
keywords: {Task analysis;Robots;Learning (artificial intelligence);Stacking;Training;Mathematical model;Games},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463162&isnumber=8460178

E. Palazzolo and C. Stachniss, "Fast Image-Based Geometric Change Detection Given a 3D Model," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6308-6315.
doi: 10.1109/ICRA.2018.8461019
Abstract: 3D models of the environment are used in numerous robotic applications and should reflect the current state of the world. In this paper, we address the problem of quickly finding structural changes between the current state of the world and a given 3D model using a small number of images. Our approach finds inconsistencies between pairs of images by re-projecting an image onto another one by passing through the given 3D model. This process leads to ambiguities, which we resolve by combining multiple images such that the 3D location of the change can be estimated. A focus of our approach is that it can be executed fast enough to allow the operation on a mobile system. We implemented our approach in C++ and released it as open source software. We tested it on existing datasets as well as on self-recorded image sequences and 3D models, which we publicly share. Our experiments show that our method quickly finds changes in the geometry of a scene.
keywords: {Three-dimensional displays;Solid modeling;Computational modeling;Cameras;Robots;Two dimensional displays;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461019&isnumber=8460178

N. Crombez, R. Seulin, O. Morel, D. Fofi and C. Demonceaux, "Multimodal 2D Image to 3D Model Registration via a Mutual Alignment of Sparse and Dense Visual Features," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6316-6322.
doi: 10.1109/ICRA.2018.8461092
Abstract: Many fields of application could benefit from an accurate registration of measurements of different modalities over a known 3D model. However, aligning a 2D image to a 3D model is a challenging task and is even more complex when the two have a different modality. Most of the 2D/3D registration methods are based on either geometric or dense visual features. Both have their own advantages and their own drawbacks. We propose, in this paper, to mutually exploit the advantages of one feature type to reduce the drawbacks of the other one. For this, an hybrid registration framework has been designed to mutually align geometrical and dense visual features in order to obtain an accurate final 2D/3D alignment. We evaluate and compare the proposed registration method on real data acquired by a robot equipped with several visual sensors. The results highlights the robustness of the method and its ability to produce wide convergence domain and a high registration accuracy.
keywords: {Three-dimensional displays;Cameras;Solid modeling;Visualization;Feature extraction;Two dimensional displays;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461092&isnumber=8460178

W. Dong, J. Shi, W. Tang, X. Wang and H. Zha, "An Efficient Volumetric Mesh Representation for Real-Time Scene Reconstruction Using Spatial Hashing," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6323-6330.
doi: 10.1109/ICRA.2018.8463157
Abstract: Mesh plays an indispensable role in dense realtime reconstruction essential in robotics. Efforts have been made to maintain flexible data structures for 3D data fusion, yet an efficient incremental framework specifically designed for online mesh storage and manipulation is missing. We propose a novel framework to compactly generate, update, and refine mesh for scene reconstruction upon a volumetric representation. Maintaining a spatial-hashed field of cubes, we distribute vertices with continuous value on discrete edges that support O(1) vertex accessing and forbid memory redundancy. By introducing Hamming distance in mesh refinement, we further improve the mesh quality regarding the triangle type consistency with a low cost. Lock-based and lock-free operations were applied to avoid thread conflicts in GPU parallel computation. Experiments demonstrate that the mesh memory consumption is significantly reduced while the running speed is kept in the online reconstruction process.
keywords: {Three-dimensional displays;Real-time systems;Data integration;Mesh generation;Rendering (computer graphics);Data structures;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463157&isnumber=8460178

P. Ruchti and W. Burgard, "Mapping with Dynamic-Object Probabilities Calculated from Single 3D Range Scans," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6331-6336.
doi: 10.1109/ICRA.2018.8463149
Abstract: Various autonomous robotic systems require maps for robust and safe navigation. Particularly when robots are employed in dynamic environments, accurate knowledge about which components of the robot perceptions belong to dynamic and static aspects in the environment can greatly improve navigation functions. In this paper we propose a novel method for building 3D grid maps using laser range data in dynamic environments. Our approach uses a neural network to estimate the pointwise probability of a point belonging to a dynamic object. The output from our network is fed to the mapping module for building a 3D grid map containing only static parts of the environment. We present experimental results obtained by training our neural network using the KITTI dataset and evaluating it in a mapping process using our own dataset. In extensive experiments, we show that maps generated using the proposed probability about dynamic objects increases the accuracy of the resulting maps.
keywords: {Three-dimensional displays;Cameras;Neural networks;Measurement by laser beam;Lasers;Laser beams;Image segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463149&isnumber=8460178

D. R. Canelhas, T. Stoyanov and A. J. Lilienthal, "A Survey of Voxel Interpolation Methods and an Evaluation of Their Impact on Volumetric Map-Based Visual Odometry," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 3637-3643.
doi: 10.1109/ICRA.2018.8461227
Abstract: Voxel volumes are simple to implement and lend themselves to many of the tools and algorithms available for 2D images. However, the additional dimension of voxels may be costly to manage in memory when mapping large spaces at high resolutions. While lowering the resolution and using interpolation is common work-around, in the literature we often find that authors either use trilinear interpolation or nearest neighbors and rarely any of the intermediate options. This paper presents a survey of geometric interpolation methods for voxel-based map representations. In particular we study the truncated signed distance field (TSDF) and the impact of using fewer than 8 samples to perform interpolation within a depth-camera pose tracking and mapping scenario. We find that lowering the number of samples fetched to perform the interpolation results in performance similar to the commonly used trilinear interpolation method, but leads to higher frame-rates. We also report that lower bit-depth generally leads to performance degradation, though not as much as may be expected, with voxels containing as few as 3 bits sometimes resulting in adequate estimation of camera trajectories.
keywords: {Interpolation;Memory management;Three-dimensional displays;Pose estimation;Extrapolation;Two dimensional displays;Image resolution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461227&isnumber=8460178

J. Jeong, Y. Cho, Y. Shin, H. Roh and A. Kim, "Complex Urban LiDAR Data Set," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6344-6351.
doi: 10.1109/ICRA.2018.8460834
Abstract: This paper presents a Light Detection and Ranging (LiDAR) data set that targets complex urban environments. Urban environments with high-rise buildings and congested traffic pose a significant challenge for many robotics applications. The presented data set is unique in the sense it is able to capture the genuine features of an urban environment (e.g. metropolitan areas, large building complexes and underground parking lots). Data of two-dimensional (2D) and three-dimensional (3D) LiDAR, which are typical types of LiDAR sensors, are provided in the data set. The two 16-ray 3D LiDARs are tilted on both sides for maximal coverage. One 2D LiDAR faces backward while the other faces forwards to collect data of roads and buildings, respectively. Raw sensor data from Fiber Optic Gyro (FOG), Inertial Measurement Unit (IMU), and the Global Positioning System (GPS) are presented in a file format for vehicle pose estimation. The pose information of the vehicle estimated at 100 Hz is also presented after applying the graph simultaneous localization and mapping (SLAM) algorithm. For the convenience of development, the file player and data viewer in Robot Operating System (ROS) environment were also released via the web page. The full data sets are available at: http://irap.kaist.ac.kr/dataset. In this website, 3D preview of each data set is provided using WebGL.
keywords: {Laser radar;Three-dimensional displays;Global Positioning System;Two dimensional displays;Sensor systems;Urban areas},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460834&isnumber=8460178

N. Olivier et al., "Live Structural Modeling Using RGB-D SLAM," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6352-6358.
doi: 10.1109/ICRA.2018.8460973
Abstract: This paper presents a method for localizing primitive shapes in a dense point cloud computed by the RGB-D SLAM system. To stably generate a shape map containing only primitive shapes, the primitive shape is incrementally modeled by fusing the shapes estimated at previous frames in the SLAM, so that an accurate shape can be finally generated. Specifically, the history of the fusing process is used to avoid the influence of error accumulation in the SLAM. The point cloud of the shape is then updated by fusing the points in all the previous frames into a single point cloud. In the experimental results, we show that metric primitive modeling in texture-less and unprepared environments can be achieved online.
keywords: {Shape;Three-dimensional displays;Simultaneous localization and mapping;Cameras;Computational modeling;History;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460973&isnumber=8460178

W. Luo and K. Sycara, "Adaptive Sampling and Online Learning in Multi-Robot Sensor Coverage with Mixture of Gaussian Processes," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6359-6364.
doi: 10.1109/ICRA.2018.8460473
Abstract: We consider the problem of online environmental sampling and modeling for multi-robot sensor coverage, where a team of robots spread out over the workspace in order to optimize the overall sensing performance. In contrast to most existing works on multi-robot coverage control that assume prior knowledge of the distribution of environmental phenomenon, also known as density function, we relax this assumption and enable the robot team to efficiently learn the model of the unknown density function Online using adaptive sampling and non-parametric inference such as Gaussian Process (GP). To capture significantly different components of the environmental phenomenon, we propose a new approach with mixture of locally learned Gaussian Processes for collective model learning and an information-theoretic criterion for simultaneous adaptive sampling in multi-robot coverage. Our approach demonstrates a better generalization of the environment modeling and thus the improved performance of coverage without assuming the density function is known a priori. We demonstrate the effectiveness of our algorithm via simulations of information gathering from indoor static sensors.
keywords: {Robot sensing systems;Adaptation models;Density functional theory;Temperature distribution;Data models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460473&isnumber=8460178

B. Balázs and G. Vásárhelyi, "Coordinated Dense Aerial Traffic with Self-Driving Drones," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6365-6372.
doi: 10.1109/ICRA.2018.8461073
Abstract: In this paper we present a general, decentralized air traffic control solution using autonomous drones. We challenge some of the most difficult dense traffic situations, namely, crosswalk and package-delivery scenarios, where intelligent collective collision avoidance and motion planning is essential for a jam-free optimal traffic flow. We build up a force-based distributed multi-robot control model using a tunable selection of interaction terms: anisotropic repulsion, behaviour-driven velocity alignment, self-organized queueing and conflict-avoiding self-driving. We optimize the model with evolution in a realistic simulation framework and demonstrate its applicability with 30 autonomous drones in a coordinated outdoor flight within a densely packed virtual arena.
keywords: {Drones;Mathematical model;Atmospheric modeling;Oscillators;Acceleration;Task analysis;Roads},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461073&isnumber=8460178

T. N. Hoang, Y. Xiao, K. Sivakumar, C. Amato and J. P. Howl, "Near-Optimal Adversarial Policy Switching for Decentralized Asynchronous Multi-Agent Systems," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6373-6380.
doi: 10.1109/ICRA.2018.8460485
Abstract: A key challenge in multi-robot and multi-agent systems is generating solutions that are robust to other self-interested or even adversarial parties who actively try to prevent the agents from achieving their goals. The practicality of existing works addressing this challenge is limited to only small-scale synchronous decision-making scenarios or a single agent planning its best response against a single adversary with fixed, procedurally characterized strategies. In contrast this paper considers a more realistic class of problems where a team of asynchronous agents with limited observation and communication capabilities need to compete against multiple strategic adversaries with changing strategies. This problem necessitates agents that can coordinate to detect changes in adversary strategies and plan the best response accordingly. Our approach first optimizes a set of stratagems that represent these best responses. These optimized stratagems are then integrated into a unified policy that can detect and respond when the adversaries change their strategies. The near-optimality of the proposed framework is established theoretically as well as demonstrated empirically in simulation and hardware.
keywords: {Switches;Planning;Task analysis;Robot kinematics;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460485&isnumber=8460178

R. Hunjet et al., "Data Ferrying with Swarming UAS in Tactical Defence Networks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6381-6388.
doi: 10.1109/ICRA.2018.8463151
Abstract: In this paper we categorise swarming into four classes, depending on the manner in which swarm members communicate. We identify two of these classes as ready candidates for the provision of communications within tactical defence networks in which radio-frequency communications are highly contested or denied. We demonstrate the feasibility of a swarm-robotics approach to data ferrying from both of these classes using simulation, emulation, and physical swarm robotic platforms within indoor flight facilities. The results show strong alignment between data dissemination capabilities of the simulated and physical systems; we envisage these techniques providing communications between not only troops, but also other swarm robotic platforms, thereby enabling swarm robotics applications and human-swarm interaction within harsh communications environments.
keywords: {Emulation;Convergence;Australia;Radio frequency;Data models;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463151&isnumber=8460178

B. Broecker, K. Tuyls and J. Butterworth, "Distance-Based Multi-Robot Coordination on Pocket Drones," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6389-6394.
doi: 10.1109/ICRA.2018.8461176
Abstract: We present a fully realised system illustrating decentralised coordination on Micro Aerial Vehicles (MAV) or pocket drones, based on distance information. This entails the development of an ultra light hardware solution to determine the distances between the drones and also the development of a model to learn good control policies. The model we present is a combination of a recurrent neural network and a Deep Q-Learning Network (DQN). The recurrent network provides bearing information to the DQN. The DQN itself is responsible for choosing movement actions to avoid collisions and to reach a desired position. Overall we are able provide a complete system which is capable of letting multiple drones navigate in a confined space only based on UWB-distance information and velocity input. We tackle the problem of neural networks and real world sensor noise, by combining the network with a particle filter and show that the combination outperforms the traditional particle filter in terms of converge speed and robustness. A video is available at: https://youtu.be/yj6QqhOzpok.
keywords: {Drones;Robot kinematics;Recurrent neural networks;Hardware;Robot sensing systems;Distance measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461176&isnumber=8460178

M. Guo, S. Andersson and D. V. Dimarogonas, "Human-in-the-Loop Mixed-Initiative Control Under Temporal Tasks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6395-6400.
doi: 10.1109/ICRA.2018.8460793
Abstract: This paper considers the motion control and task planning problem of mobile robots under complex high-level tasks and human initiatives. The assigned task is specified as Linear Temporal Logic (LTL) formulas that consist of hard and soft constraints. The human initiative influences the robot autonomy in two explicit ways: with additive terms in the continuous controller and with contingent task assignments. We propose an online coordination scheme that encapsulates (i) a mixed-initiative continuous controller that ensures all-time safety despite of possible human errors, (ii) a plan adaptation scheme that accommodates new features discovered in the workspace and short-term tasks assigned by the operator during run time, and (iii) an iterative inverse reinforcement learning (IRL) algorithm that allows the robot to asymptotically learn the human preference on the parameters during the plan synthesis. The results are demonstrated by both realistic human-in-the-loop simulations and experiments.
keywords: {Task analysis;Safety;Robot kinematics;Automata;Planning;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460793&isnumber=8460178

P. M. Wensing and J. Slotine, "Cooperative Adaptive Control for Cloud-Based Robotics," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6401-6408.
doi: 10.1109/ICRA.2018.8460856
Abstract: This paper studies collaboration through the cloud in the context of cooperative adaptive control for robot manipulators. We first consider the case of multiple robots manipulating a common object through synchronous centralized update laws to identify unknown inertial parameters. Through this development, we introduce a notion of Collective Sufficient Richness, wherein parameter convergence can be enabled through teamwork in the group. The introduction of this property and the analysis of stable adaptive controllers that benefit from it constitute the main new contributions of this work. Building on this original example, we then consider decentralized update laws, time-varying network topologies, and the influence of communication delays on this process. Perhaps surprisingly, these nonidealized networked conditions inherit the same benefits of convergence being determined through collective effects for the group. Simple simulations of a planar manipulator identifying an unknown load are provided to illustrate the central idea and benefits of Collective Sufficient Richness.
keywords: {Adaptive control;Manipulators;Convergence;Robot sensing systems;Cloud computing;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460856&isnumber=8460178

E. Vidal, J. D. Hernández, K. Istenic and M. Carreras, "Optimized Environment Exploration for Autonomous Underwater Vehicles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6409-6416.
doi: 10.1109/ICRA.2018.8460919
Abstract: Achieving full autonomous robotic environment exploration in the underwater domain is very challenging, mainly due to noisy acoustic sensors, high localization error, control disturbances of the water and lack of accurate underwater maps. In this work we present a robotic exploration algorithm for underwater vehicles that does not rely on prior information about the environment. Our method has been greatly influenced by many robotic exploration, view planning and path planning algorithms. The proposed method constitutes a significant improvement over our previous work [1]: Firstly, we refine our exploration approach to improve robustness; Secondly, we propose an alternative map representation based on the quadtree data structure that allows different relevant queries to be performed efficiently, reducing the computational cost of the viewpoint generation process; Thirdly, we present an algorithm that is capable of generating consistent maps even when noisy sonar data is used. The aforementioned contributions have increased the reliability of the algorithm, allowing new real experiments performed in artificial structures but also in more challenging natural environments, from which we provide a 3D reconstruction to show that with this algorithm full optical coverage is obtained.
keywords: {Cameras;Sonar;Planning;Robot sensing systems;Inspection;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460919&isnumber=8460178

S. Kemna, O. Kroemer and G. S. Sukhatme, "Pilot Surveys for Adaptive Informative Sampling," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6417-6424.
doi: 10.1109/ICRA.2018.8460488
Abstract: Adaptive sampling has been shown to be an effective method for modeling environmental fields, such as algae concentrations in the ocean. In adaptive sampling, a robot adapts its sampling trajectory based on data that it is collecting. This data is often aggregated into models, using techniques such as Gaussian Process (G P) regression. The (hyper-)parameters for these models need to be manually set or, ideally, estimated from data. For GP regression, hyperparameters are typically estimated using prior data. This paper addresses the case where initial hyperparameters need to be estimated, but no prior data is available. Without prior data or accurately pre-defined hyperparameters, adaptive sampling techniques may fail, because there is no good model to base path planning decisions on. One method of gathering data is to perform a pilot survey. This survey needs to select informative samples for initiating the model, but without having a model to determine where best to sample. In this work, we evaluate four pilot surveys, which use a softmax function on the distance between waypoints and previously sampled data for waypoint selection. Simulation results show that pilot surveys that maximize waypoint spread over randomization lead to more stable estimation of GP hyperparameters, and create accurate models more quickly.
keywords: {Adaptation models;Data models;Kernel;Robots;Gaussian processes;Estimation;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460488&isnumber=8460178

G. Gras, C. A. Seneci, P. Giataganas and G. -Z. Yang, "Gaze-Assisted Adaptive Motion Scaling Optimization Using Graded and Preference Based Bayesian Approaches," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6425-6430.
doi: 10.1109/ICRA.2018.8460588
Abstract: A key component to the success of master-slave surgical systems is the quality of the master interface used to relay the surgeon's instructions to the slave robot. In previous work the authors developed a gaze-assisted intention recognition scheme, allowing the system to dynamically adapt the motion scaling based on where the user is trying to reach. This allowed users to perform tasks significantly more quickly and with less need for clutching. However, the system possessed a number of core parameters that were manually optimized, potentially providing a non-optimal solution depending on the user. This paper presents a Bayesian approach to the problem of optimizing a human-robot interface in a user-specific manner. Two Bayesian optimization methods are studied: one in which users are asked to grade robot behavior for a given set of parameters, and one where only preference relative to other parameter sets is expressed. The performance of these optimizations is evaluated in a blind comparison user study, demonstrating that the optimized parameters are preferred to the manually optimized ones in over 90 % of cases after only 12 test samples. These parameters are further shown to perform at least as well as the manually optimized ones in all cases, and showing statistically significant improvement in the case of the graded optimization.
keywords: {Robots;Bayes methods;Instruments;Linear programming;Optimization methods;Master-slave},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460588&isnumber=8460178

R. Oliveira, F. H. M. Rocha, L. Ott, V. Guizilini, F. Ramos and V. Grassi, "Learning to Race Through Coordinate Descent Bayesian Optimisation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6431-6438.
doi: 10.1109/ICRA.2018.8460735
Abstract: In the automation of many kinds of processes, the observable outcome can often be described as the combined effect of an entire sequence of actions, or controls, applied throughout the process execution. In these cases, strategies to optimise control policies for individual stages of the process are not applicable, and instead the whole policy needs to be optimised at once. On the other hand, the cost to evaluate the policy's performance might also be high, being desirable that a solution can be found with as few interactions as possible with the real system. We consider the problem of optimising control policies to allow a robot to complete a given race track within a minimum amount of time. We assume that the robot has no prior information about the track or its own dynamical model, just an initial valid driving example. Localisation is only applied to monitor the robot and to provide an indication of its position along the track's centre axis. With that in mind, we propose a method for finding a policy that minimises the time per lap while keeping the vehicle on the track using a Bayesian optimisation (BO) approach over a reproducing kernel Hilbert space. We apply an algorithm to search more efficiently over high-dimensional policy-parameter spaces with BO, by iterating over each dimension individually, in a sequential coordinate descent-like scheme. Experiments demonstrate the performance of the algorithm against other methods in a simulated car racing environment.
keywords: {Optimization;Robot kinematics;Bayes methods;Search problems;Kernel;Linear programming},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460735&isnumber=8460178

K. P. Tee, J. Li, L. T. Pang Chen, K. W. Wan and G. Ganesh, "Towards Emergence of Tool Use in Robots: Automatic Tool Recognition and Use Without Prior Tool Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6439-6446.
doi: 10.1109/ICRA.2018.8460987
Abstract: Humans are adept at tool use. We can intuitively and immediately improvise and use unknown objects in our environment as tools, to assist us in performing tasks. In this study, we provide similar cognition and capabilities to robots. Neuroscientific studies on tool use have suggested that human dexterity with tools is enabled by the embodiment of the tools, which in effect, allows humans to immediately transfer prior skills acquired without tools, onto tasks requiring tool use. Here, utilizing the theoretical results from our investigations on embodiment and tool use in humans over the last years, we propose a concept and algorithm to enable similar skill transfer by robots. Our algorithm enables a robot that has had no prior learning with tools, to automatically recognize an object (seen for the first time) in its environment as a potential tool for an otherwise unattainable task, and use the tool to perform the task thereafter.
keywords: {Tools;Task analysis;Kinematics;Automobiles;Robot sensing systems;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460987&isnumber=8460178

K. Kase, K. Suzuki, P. Yang, H. Mori and T. Ogata, "Put-in-Box Task Generated from Multiple Discrete Tasks by aHumanoid Robot Using Deep Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6447-6452.
doi: 10.1109/ICRA.2018.8460623
Abstract: For robots to have a wide range of applications, they must be able to execute numerous tasks. However, recent studies into robot manipulation using deep neural networks (DNN) have primarily focused on single tasks. Therefore, we investigate a robot manipulation model that uses DNNs and can execute long sequential dynamic tasks by performing multiple short sequential tasks at appropriate times. To generate compound tasks, we propose a model comprising two DNNs: a convolutional autoencoder that extracts image features and a multiple timescale recurrent neural network (MTRNN) to generate motion. The internal state of the MTRNN is constrained to have similar values at the initial and final motion steps; thus, motions can be differentiated based on the initial image input. As an example compound task, we demonstrate that the robot can generate a “Put-In-Box” task that is divided into three subtasks: open the box, grasp the object and put it into the box, and close the box. The subtasks were trained as discrete tasks, and the connections between each subtask were not trained. With the proposed model, the robot could perform the Put-In-Box task by switching among subtasks and could skip or repeat subtasks depending on the situation.
keywords: {Task analysis;Robots;Feature extraction;Switches;Neurons;Training;Convolution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460623&isnumber=8460178

A. Murali, L. Pinto, D. Gandhi and A. Gupta, "CASSL: Curriculum Accelerated Self-Supervised Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6453-6460.
doi: 10.1109/ICRA.2018.8463147
Abstract: Recent self-supervised learning approaches focus on using a few thousand data points to learn policies for high-level, low-dimensional action spaces. However, scaling this framework for higher-dimensional control requires either scaling up the data collection efforts or using a clever sampling strategy for training. We present a novel approach - Curriculum Accelerated Self-Supervised Learning (CASSL) - to train policies that map visual information to high-level, higher-dimensional action spaces. CASSL orders the sampling of training data based on control dimensions: the learning and sampling are focused on few control parameters before other parameters. The right curriculum for learning is suggested by variance-based global sensitivity analysis of the control space. We apply our CASSL framework to learning how to grasp using an adaptive, underactuated multi-fingered gripper, a challenging system to control. Our experimental results indicate that CASSL provides significant improvement and generalization compared to baseline methods such as staged curriculum learning (8% increase) and complete end-to-end learning with random exploration (14% improvement) tested on a set of novel objects.
keywords: {Aerospace electronics;Grasping;Training;Task analysis;Robots;Sensitivity analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463147&isnumber=8460178

D. Driess et al., "Learning to Control Redundant Musculoskeletal Systems with Neural Networks and SQP: Exploiting Muscle Properties," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6461-6468.
doi: 10.1109/ICRA.2018.8463160
Abstract: Modeling biomechanical musculoskeletal systems reveals that the mapping from muscle stimulations to movement dynamics is highly nonlinear and complex, which makes it difficult to control those systems with classical techniques. In this work, we not only investigate whether machine learning approaches are capable of learning a controller for such systems. We are especially interested in the question if the structure of the musculoskeletal apparatus exhibits properties that are favorable for the learning task. In particular, we consider learning a control policy from target positions to muscle stimulations. To account for the high actuator redundancy of biomechanical systems, our approach uses a learned forward model represented by a neural network and sequential quadratic programming to obtain the control policy, which also enables us to alternate the co-contraction level and hence allows to change the stiffness of the system and to include optimality criteria like small muscle stimulations. Experiments on both a simulated musculoskeletal model of a human arm and a real biomimetic muscle-driven robot show that our approach is able to learn an accurate controller despite high redundancy and nonlinearity, while retaining sample efficiency.
keywords: {Muscles;Joints;Robots;Biological system modeling;Torque;Biomechanics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463160&isnumber=8460178

F. Riccio, R. Capobianco and D. Nardi, "Q-CP: Learning Action Values for Cooperative Planning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6469-6475.
doi: 10.1109/ICRA.2018.8460180
Abstract: Research on multi-robot systems has demonstrated promising results in manifold applications and domains. Still, efficiently learning an effective robot behaviors is very difficult, due to unstructured scenarios, high uncertainties, and large state dimensionality (e.g, hyper-redundant and groups of robot). To alleviate this problem, we present Q-CP a cooperative model-based reinforcement learning algorithm, which exploits action values to both (1) guide the exploration of the state space and (2) generate effective policies. Specifically, we exploit Q-learning to attack the curse-of-dimensionality in the iterations of a Monte-Carlo Tree Search. We implement and evaluate Q-CP on different stochastic cooperative (general-sum) games: (1) a simple cooperative navigation problem among 3 robots, (2) a cooperation scenario between a pair of KUKA YouBots performing hand-overs, and (3) a coordination task between two mobile robots entering a door. The obtained results show the effectiveness of Q- CP in the chosen applications, where action values drive the exploration and reduce the computational demand of the planning process while achieving good performance.
keywords: {Robot kinematics;Games;Monte Carlo methods;Task analysis;Planning;Stochastic processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460180&isnumber=8460178

E. Stenborg, C. Toft and L. Hammarstrand, "Long-Term Visual Localization Using Semantically Segmented Images," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6484-6490.
doi: 10.1109/ICRA.2018.8463150
Abstract: Robust cross-seasonal localization is one of the major challenges in long-term visual navigation of autonomous vehicles. In this paper, we exploit recent advances in semantic segmentation of images, i.e., where each pixel is assigned a label related to the type of object it represents, to attack the problem of long-term visual localization. We show that semantically labeled 3D point maps of the environment, together with semantically segmented images, can be efficiently used for vehicle localization without the need for detailed feature descriptors (SIFT, SURF, etc.), Thus, instead of depending on hand-crafted feature descriptors, we rely on the training of an image segmenter. The resulting map takes up much less storage space compared to a traditional descriptor based map. A particle filter based semantic localization solution is compared to one based on SIFT-features, and even with large seasonal variations over the year we perform on par with the larger and more descriptive SIFT-features, and are able to localize with an error below 1 m most of the time.
keywords: {Semantics;Cameras;Roads;Image segmentation;Visualization;Robustness;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463150&isnumber=8460178

J. Kim and W. Chung, "Robust Localization of Mobile Robots Considering Reliability of LiDAR Measurements," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6491-6496.
doi: 10.1109/ICRA.2018.8460648
Abstract: In this study, we propose a novel Light Detection and Ranging (LiDAR) sensor-based localization method for localization of a mobile robot. In localization using the LiDAR sensor, localization errors occur when real range measurements differ from reference distances computed from a map. This study focuses on three factors that cause differences between real range measurements and reference distances. The first factor corresponds to optical characteristics of the LiDAR sensor for objects such as glass walls and mirrors. The second factor corresponds to occlusions by dynamic obstacles. The third factor corresponds to static changes in the environment. In practical applications, three factors often simultaneously occur. Although there have been many previous works, robust localization to overcome these three difficulties is still a challenging problem. This study proposes a novel robust localization scheme that exploits only reliable range measurements. A LiDAR sensor-based localization scheme can be successfully executed by utilizing only a few reliable range measurements. Therefore, the computation of reliability plays a significant role. The computation of reliability is divided into two steps. The first step considers characteristics of optical sensors. The second step mainly deals with the effects of obstacles. The observation likelihood model exploits computed reliability for pose estimation. The proposed scheme was successfully verified through various experiments under challenging situations.
keywords: {Reliability;Laser radar;Robot sensing systems;Optical sensors;Glass;Adaptive optics;Optical variables measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460648&isnumber=8460178

J. Dong, M. Mukadam, B. Boots and F. Dellaert, "Sparse Gaussian Processes on Matrix Lie Groups: A Unified Framework for Optimizing Continuous-Time Trajectories," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6497-6504.
doi: 10.1109/ICRA.2018.8461077
Abstract: Continuous-time trajectories are useful for reasoning about robot motion in a wide range of tasks. Sparse Gaussian processes (GPs) can be used as a non-parametric representation for trajectory distributions that enables fast trajectory optimization by sparse GP regression. However, most previous approaches that utilize sparse GPs for trajectory optimization are limited by the fact that the robot state is represented in vector space. In this paper, we first extend previous works to consider the state on general matrix Lie groups by applying a constant-velocity prior and defining locally linear GPs. Next, we discuss how sparse GPs on Lie groups provide a unified continuous-time framework for trajectory optimization for solving a number of robotics problems including state estimation and motion planning. Finally, we demonstrate and evaluate our approach on several different estimation and motion planning tasks with both synthetic and real-world experiments.
keywords: {Trajectory;Simultaneous localization and mapping;Estimation;Planning;Sparse matrices;Gaussian processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461077&isnumber=8460178

K. M. Frey, T. J. Steiner and J. P. How, "Complexity Analysis and Efficient Measurement Selection Primitives for High-Rate Graph SLAM," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6505-6512.
doi: 10.1109/ICRA.2018.8460708
Abstract: Sparsity has been widely recognized as crucial for efficient optimization in graph-based SLAM. Because the sparsity and structure of the SLAM graph reflect the set of incorporated measurements, many methods for sparsification have been proposed in hopes of reducing computation. These methods often focus narrowly on reducing edge count without regard for structure at a global level. Such structurally-naïve techniques can fail to produce significant computational savings, even after aggressive pruning. In contrast, simple heuristics such as measurement decimation and keyframing are known empirically to produce significant computation reductions. To demonstrate why, we propose a quantitative metric called elimination complexity (EC) that bridges the existing analytic gap between graph structure and computation. EC quantifies the complexity of the primary computational bottleneck: the factorization step of a Gauss-Newton iteration. Using this metric, we show rigorously that decimation and keyframing impose favorable global structures and therefore achieve computation reductions on the order of r2/9 and r3, respectively, where r is the pruning rate. We additionally present numerical results showing EC provides a good approximation of computation in both batch and incremental (iSAM2) optimization and demonstrate that pruning methods promoting globally-efficient structure outperform those that do not.
keywords: {Simultaneous localization and mapping;Complexity theory;Optimization;Sparse matrices;Extraterrestrial measurements;Linear algebra},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460708&isnumber=8460178

M. Hsiao, E. Westman and M. Kaess, "Dense Planar-Inertial SLAM with Structural Constraints," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6521-6528.
doi: 10.1109/ICRA.2018.8461094
Abstract: In this work, we develop a novel dense planar-inertial SLAM (DPI-SLAM) system to reconstruct dense 3D models of large indoor environments using a hand-held RGB-D sensor and an inertial measurement unit (IMU). The preinte-grated IMU measurements are loosely-coupled with the dense visual odometry (VO) estimation and tightly-coupled with the planar measurements in a full SLAM framework. The poses, velocities, and IMU biases are optimized together with the planar landmarks in a global factor graph using incremental smoothing and mapping with the Bayes Tree (iSAM2). With odometry estimation using both RGB-D and IMU data, our system can keep track of the poses of the sensors even without sufficient planes or visual information (e.g. textureless walls) temporarily. Modeling planes and IMU states in the fully probabilistic global optimization reduces the drift that distorts the reconstruction results of other SLAM algorithms. Moreover, structural constraints between nearby planes (e.g. right angles) are added into the DPI-SLAM system, which further recovers the drift and distortion. We test our DPI-SLAM on large indoor datasets and demonstrate its state-of-the-art performance as the first planar-inertial SLAM system.
keywords: {Simultaneous localization and mapping;Optimization;Three-dimensional displays;Real-time systems;Estimation;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461094&isnumber=8460178

F. Mascarich, T. Wilson, C. Papachristos and K. Alexis, "Radiation Source Localization in GPS-Denied Environments Using Aerial Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6537-6544.
doi: 10.1109/ICRA.2018.8460760
Abstract: This paper details the system and methods developed to enable autonomous nuclear radiation source localization and mapping using aerial robots in GPS-denied environments. A Thallium-doped Cesium Iodide (CsI(Tl)) scintillator and a Silicon Photomultiplier are combined with custom-built electronics for counting and spectroscopy, and the provided radiation measurements are pose-annotated using visual-inertial localization enabling autonomous operation in GPS-denied environments. Provided this capability, a strategy for radioactive source localization, as well as active source search path planning was developed. The proposed method is motivated and accounts for the limited endurance of the vehicle, which entails a very small amount of dwell points, and the fact that GPS-denied localization implies varying uncertainty of the robot's position estimate. The complete system is evaluated in multiple experimental studies using a small aerial robot and a Cesium-137 radiation source. As shown, accurate radioactive source localization is achieved, enabling efficient radiation mapping of indoor GPS-denied environments.
keywords: {Scintillators;Calibration;Robot sensing systems;Detectors;Unmanned aerial vehicles;Radiation detectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460760&isnumber=8460178

F. Mirallès et al., "LineDrone Technology: Landing an Unmanned Aerial Vehicle on a Power Line," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6545-6552.
doi: 10.1109/ICRA.2018.8461250
Abstract: This paper presents the design of a multirotor unmanned aerial vehicle (UAV) capable of landing semiautomatically on a power line while carrying a payload. The vehicle then rolls along the line to perform an inspection. Special attention is given to the vehicle's onboard vision system, which consists of a monocular camera and LiDAR used together to compute the pose of the vehicle relative to the power line. Landing assistance is provided to the pilot by a position-based visual controller that aligns and keeps the vehicle centered along the power line. The pilot remains in control of vertical and longitudinal movement during descent. The proposed approach was tested on a full-scale test line and shows promise for future applications of high value to the electric industry such as non-destructive testing of power transmission lines.
keywords: {Cameras;Payloads;Unmanned aerial vehicles;Inspection;Laser radar;Task analysis;Machine vision},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461250&isnumber=8460178

S. K. Hla Win et al., "Direction Controlled Descent of Samara Autorotating Wings (SAW) with N-Wings," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6553-6559.
doi: 10.1109/ICRA.2018.8463145
Abstract: The seeds of Maple trees (Samara) use autorotation as a unique mechanism to disperse their seeds. By exploiting gyroscopic stability of a spinning wing, the Samara is able to cover large horizontal distance despite having no form of propulsion. We applied and adapted this natural ability in our novel concept, the Samara Autorotating Wings (SAW), and extended its stability and direction controllability by generalizing the mechanism to incorporate designs with more than 1 wing. By conceiving cyclic control, the translational motion of autorotation is regulated. A nonlinear model of SAW with $n$ wings is derived and control schemes developed to control the translational position during autorotation. Numerical simulations were performed to investigate the performance of the multi-wing SAW prototypes to track a conical spiral autorotation trajectory. Direct experiments were conducted in a vertical wind-tunnel through a special ball joint that allows z-axis translation and all three rotational degrees of freedom. Finally, free-fall drop tests are used to verify the directional controllability and performance of SAW.
keywords: {Surface acoustic waves;Blades;Prototypes;Rotors;Mathematical model;Solid modeling;Stability analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463145&isnumber=8460178

L. Dressel and M. J. Kochenderfer, "Pseudo-bearing Measurements for Improved Localization of Radio Sources with Multirotor UAVs," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6560-6565.
doi: 10.1109/ICRA.2018.8460734
Abstract: Localizing radio frequency (RF) sources is an important application for unmanned aerial vehicles (UAVs), Localization is often carried out by estimating bearing to an RF source, which can be achieved by rotating a directional antenna in place. Multirotor UAVs are well-suited for this sensing modality because they can efficiently rotate in place. However, a full rotation from a single location is needed to account for scale factors affecting the directional antenna's measurements. Although easy to perform, these rotations tend to be slow and delay localization. In this paper, we equip a multirotor UAV with a directional antenna and an omnidirectional antenna. The omnidirectional antenna serves to normalize measurements made by the directional antenna, yielding “pseudo-bearing” measurements. These bearing-like measurements are less informative than bearing measurements but do not require a full rotation, leading to more measurements and faster localization. We validate the normalization with antenna theory and ground tests. Claims of improved localization are validated with simulations and flight tests on a multirotor UAV. Our setup significantly reduces localization time compared to a multirotor UAV equipped with only a directional antenna.
keywords: {Antenna measurements;Directional antennas;Gain;Radio frequency;Extraterrestrial measurements;Rotation measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460734&isnumber=8460178

P. Foehn and D. Scaramuzza, "Onboard State Dependent LQR for Agile Quadrotors," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6566-6572.
doi: 10.1109/ICRA.2018.8460885
Abstract: State-of-the-art approaches in quadrotor control split the problem into multiple cascaded subproblems, exploiting the different time scales of the rotational and translational dynamics. They calculate a desired acceleration as input for a cascaded attitude controller but omit the attitude dynamics. These approaches use limits on the desired acceleration to maintain feasibility and robustness through the control cascade. We propose an implementation of an LQR controller, which: (I) is linearized depending on the quadrotor's state; (II) unifies the control of rotational and translational states; (III) handles time-varying system dynamics and control parameters. Our implementation is efficient enough to compute the full linearization and solution of the LQR at a minimum of 10 Hz on the vehicle using a common ARM processor. We show four successful experiments: (I) controlling at hover state with large disturbances; (II) tracking along a trajectory; (III) tracking along an infeasible trajectory; (IV) tracking along a trajectory with disturbances. All the experiments were done using only onboard visual inertial state estimation and LQR computation. To the best of our knowledge, this is the first implementation and evaluation of a state-dependent LQR capable of onboard computation while providing this amount of versatility and performance.
keywords: {Vehicle dynamics;Acceleration;Trajectory;Quaternions;Attitude control;Visualization;Regulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460885&isnumber=8460178

E. Bulka and M. Nahon, "Autonomous Fixed-Wing Aerobatics: From Theory to Flight," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6573-6580.
doi: 10.1109/ICRA.2018.8460610
Abstract: Unmanned aerial vehicles (UAVs) are increasingly being proposed for a wide range of applications. A promising new class of these vehicles, known as agile fixed-wing UAV s, is intended to bridge the gap between conventional fixed-wing aircraft, which can cover long distances efficiently, and rotorcraft, which are typically very maneuverable. This paper addresses the implementation of a controller for agile UAVs, beginning with a hardware-in-the-loop (HIL) simulator, followed by testing on a real platform, both implemented on the Pixhawk microcontroller. We replace the Xplane physics engine used in the standard Pixhawk HIL with our own in-house Matlab/Simulink high-fidelity simulation of an agile UA V. The HIL simulator is found to provide substantial advantages in the transition from pure simulation to experimental testing. Once the controller is integrated into the flight platform, flight tests are conducted, and the results of those tests are compared to those from the HIL simulation and those obtained from the pure simulation environment, for maneuvers including hover, aggressive turnaround, knife-edge, and rolling Harrier. The desired position and orientation time histories were successfully tracked with the proposed implementation, demonstrating the impressive autonomous maneuverability that can be achieved by this type of aircraft.
keywords: {Aircraft;Aerodynamics;Atmospheric modeling;Control systems;Mathematical model;Aerospace control;Propellers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460610&isnumber=8460178

W. Wang, J. Zhu, M. Kuang and X. Zhu, "Adaptive Attitude Control for a Tail-Sitter UAV with Single Thrust-Vectored Propeller," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6581-6586.
doi: 10.1109/ICRA.2018.8463158
Abstract: Tail-sitter unmanned aerial vehicles (UAVs) have gained extensive popularity in recent years due to their inherent advantages of both fixed wing and rotary wing UAVs. However, these advantages are accompanied with control challenges because of two different flight regimes and drastically changing dynamics during transition flights. This paper focuses on the design of a unified controller free from cumbersome controller switchings and applicable in all attitude range for a tail-sitter with single thrust-vectored propeller. To achieve this, both thrust vectoring model and full-regime aerodynamics model are built first, after which a complete attitude dynamics model of the tail-sitter is established utilizing the quaternion attitude description to avoid the singularity problem. An adaptive controller is then derived based on a simplified model using the Lyapunov stability theory with unknown system parameters identified online by forgetting factor recursive least square (FF-RLS) method. Flight experiments are conducted to demonstrate the feasibility and effectiveness of the proposed control scheme.
keywords: {Propellers;Aerodynamics;Atmospheric modeling;Attitude control;Aircraft;Mathematical model;Quaternions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463158&isnumber=8460178

P. Vaiopoulos, G. Zogopoulos-Papaliakos and K. J. Kyriakopoulos, "Online Aerodynamic Model Identification on Small Fixed-Wing UAVs with Uncertain Flight Data," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6587-6592.
doi: 10.1109/ICRA.2018.8460585
Abstract: This paper focuses on real-time estimation of the aerodynamic model parameters of small-scale fixed wing Unmanned Aerial Vehicles (UAVs) without the aid of wind-tunnel experiments, using exclusively flight data. The key tool of the following analysis centers around the principles of Total Least Squares estimation. Contrary to Ordinary Least Squares, this method accounts for errors in both explanatory data and variables to-be-explained. This is a highly desirable property for UAVs equipped with low-cost sensor systems. The proposed implementation combines both batch and real-time schemes, while deals efficiently with the problem of Insufficient System Excitation. Online adaptation to model changes is performed by applying a Variable Forgetting Factor to the estimation data. Finally, a Monte Carlo approach is developed for uncertainty estimation regarding compound aerodynamic variables.
keywords: {Aerodynamics;Atmospheric modeling;Estimation;Uncertainty;Real-time systems;Aircraft;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460585&isnumber=8460178

L. Joseph, V. Padois and G. Morel, "Towards X-Ray Medical Imaging with Robots in the Open: Safety Without Compromising Performances," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6604-6610.
doi: 10.1109/ICRA.2018.8460794
Abstract: In this paper, a control solution featuring an energetic constraint is developed to improve the safety of a robotic manipulator sharing its workspace with humans. This general control structure, exploits a generic safe controller that ensures the respect of multiple constraints thanks to a Linear Quadratic Problem formulation. With a unified energetic formulation, the controller allows to explicitly limit both the kinetic energy when moving and the wrench applied to the environment in case of contact with an unexpected obstacle. This control approach is experimented on a redundant Kuka LWR4+ robot which end-effector shall precisely point toward a given location while following a trajectory.
keywords: {Robots;Task analysis;Torque;Safety;Collision avoidance;X-ray imaging;Aerospace electronics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460794&isnumber=8460178

H. Su, J. Sandoval, M. Makhdoomi, G. Ferrigno and E. De Momi, "Safety-Enhanced Human-Robot Interaction Control of Redundant Robot for Teleoperated Minimally Invasive Surgery," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6611-6616.
doi: 10.1109/ICRA.2018.8463148
Abstract: In this paper, a teleoperation control of a 7-DoF robot manipulator for Minimally Invasive Surgery (MIS), which guarantees a safety-enhanced compliant behavior in the null space, is described. The redundancy of the manipulator is exploited to provide a flexible workspace for nurses or other staff (assisting physicians, patient support). The issue with safety and accurate surgical task execution may arise in the presence of human-robot interaction. Based on the implemented impedance control of tele-operated MIS tasks, a safety enhanced constraint is applied on the compliant null space motion. At the same time, the control approach integrates an adaptive fuzzy compensator to guarantee the accuracy of the surgical tasks during the uncertain human-robot interaction. The performance of the proposed algorithm is verified with virtual surgical tasks. The results showed that the compliant null space motion is constrained in a safe area, and also that the accuracy of tool tip is improved, providing a flexible and safe collaborative behavior in the null space for human-robot interaction during surgical tasks.
keywords: {Task analysis;Null space;Manipulators;Human-robot interaction;Torque;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463148&isnumber=8460178

O. Özgüner, R. Hao, R. C. Jackson, T. Shkurti, W. Newman and M. C. Cavusoglu, "Three-Dimensional Surgical Needle Localization and Tracking Using Stereo Endoscopic Image Streams," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6617-6624.
doi: 10.1109/ICRA.2018.8460867
Abstract: This paper presents algorithms for three-dimensional tracking of surgical needles using the stereo endoscopic camera images obtained from the da Vinci® Surgical Robotic System. The proposed method employs Bayesian state estimation, computer vision techniques, and robot kinematics. A virtual needle rendering procedure is implemented to create simulated images of the surgical needle under the da Vinci ® robot endoscope, which makes it possible to measure the similarity between the rendered needle image and the real needle. A particle filter algorithm using the mentioned techniques is then used for tracking the surgical needle. The performance of the tracking is experimentally evaluated using an actual da Vinci® surgical robotic system and quantitatively validated in a ROS/Gazebo simulation thereof.
keywords: {Needles;Robots;Task analysis;Surgery;Image segmentation;Bayes methods;Atmospheric measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460867&isnumber=8460178

N. Enayati et al., "Robotic Assistance-as-Needed for Enhanced Visuomotor Learning in Surgical Robotics Training: An Experimental Study," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6631-6636.
doi: 10.1109/ICRA.2018.8463168
Abstract: Hands-on training is an indispensable part of surgical practice. As the tools used in the operating room become more intricate, the demand for efficient training methods increases. This work proposes a robotic assistance-as-needed method for training with surgical teleoperated robots. The method adapts the intensity of the assistance according to the trainee's current and past performance while gradually increasing the level of control of the trainee as the training progresses. The work includes an experiment comprising 160 acquisition sessions from 16 novice subjects performing a bimanual teleoperated exercise with a da Vinci Research Kit surgical console. Results capture the subtleties in the task's learning curve with and without robotic assistance and hint at the potential of robotic assistance for complex visuomotor training. Although robotic assistance for motor learning has received mixed results that range from beneficial to detrimental effects, this study shows such assistance may increase the rate of learning of certain skills in complex motor tasks.
keywords: {Task analysis;Training;Robot kinematics;Wires;Tools;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463168&isnumber=8460178

H. N. D. Le et al., "Semi-Autonomous Laparoscopic Robotic Electro-Surgery with a Novel 3D Endoscope," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6637-6644.
doi: 10.1109/ICRA.2018.8461060
Abstract: This paper reports a robotic laparoscopic surgery system performing electro-surgery on porcine cadaver kidney, and evaluates its accuracy in an open loop control scheme to conduct targeting and cutting tasks guided by a novel 3D endoscope. We describe the design and integration of the novel laparoscopic imaging system that is capable of reconstructing the surgical field using structured light. A targeting task is first performed to determine the average positioning error of the system as guided by the laparoscopic camera. The imaging system is then used to reconstruct the surface of a porcine cadaver kidney, and generate a cutting trajectory with consistent depth. The paper concludes by using the robotic system in open loop control to cut this trajectory using a multi degree of freedom electro-surgical tool. It is demonstrated that for a cutting depth of 3 mm, the robotic surgical system follows the trajectory with an average depth of 2.44 mm and standard deviation of 0.34 mm. The average positional accuracy of the system was 2.74±0.99 mm.
keywords: {Robots;Imaging;Surgery;Three-dimensional displays;Laparoscopes;Kidney;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461060&isnumber=8460178

A. Gordon, T. Looi, J. Drake and C. R. Forrest, "An Ultrasonic Bone Cutting Tool for the da Vinci Research Kit," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6645-6650.
doi: 10.1109/ICRA.2018.8460797
Abstract: This paper presents a minimally invasive ultrasonic bone cutting tool designed for the da Vinci® research kit (dVRK). An ultrasonic transducer is modelled using finite element software, and correlated with testing results using an impedance analyzer. A multi-objective genetic algorithm is then used to design and analyze the remaining components of the ultrasonic system, in order to maximize system performance. The system is fabricated and mounted to the da Vinci® research kit system and tested on a cutting phantom.
keywords: {Acoustics;Impedance;Finite element analysis;Transducers;Bones;Surgery;Cutting tools},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460797&isnumber=8460178

D. Seita, S. Krishnan, R. Fox, S. McKinley, J. Canny and K. Goldberg, "Fast and Reliable Autonomous Surgical Debridement with Cable-Driven Robots Using a Two-Phase Calibration Procedure," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6651-6658.
doi: 10.1109/ICRA.2018.8460583
Abstract: Automating precision subtasks such as debridement (removing dead or diseased tissue fragments) with Robotic Surgical Assistants (RSAs) such as the da Vinci Research Kit (dVRK) is challenging due to inherent nOnlinearities in cable-driven systems. We propose and evaluate a novel two-phase coarse-to-fine calibration method. In Phase I (coarse), we place a red calibration marker on the end effector and let it randomly move through a set of open-loop trajectories to obtain a large sample set of camera pixels and internal robot end-effector configurations. This coarse data is then used to train a Deep Neural Network (DNN) to learn the coarse transformation bias. In Phase II (fine), the bias from Phase I is applied to move the end -effector toward a small set of specific target points on a printed sheet. For each target, a human operator manually adjusts the end -effector position by direct contact (not through teleoperation) and the residual compensation bias is recorded. This fine data is then used to train a Random Forest (RF) to learn the fine transformation bias. Subsequent experiments suggest that without calibration, position errors average 4.55mm. Phase I can reduce average error to 2.14mm and the combination of Phase I and Phase II can reduces average error to 1.08mm. We apply these results to debridement of raisins and pumpkin seeds as fragment phantoms. Using an endoscopic stereo camera with standard edge detection, experiments with 120 trials achieved average success rates of 94.5 %, exceeding prior results with much larger fragments (89.4%) and achieving a speedup of 2.1x, decreasing time per fragment from 15.8 seconds to 7.3 seconds. Source code, data, and videos are available at https://sites.google.com/view/calib-icra/.
keywords: {Calibration;Cameras;Grippers;Robot kinematics;Robot vision systems;Tools},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460583&isnumber=8460178

M. Abdelkader, Y. Lu, H. Jaleel and J. S. Shamma, "Distributed Real Time Control of Multiple UAVs in Adversarial Environment: Algorithm and Flight Testing Results," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6659-6664.
doi: 10.1109/ICRA.2018.8460866
Abstract: We present a complete design and implementation of a system that consists of multiple quadrotors playing capture the flag game. Our main contributions in this work include a custom built quadrotor platform, an efficient implementation of a distributed trajectory planning algorithm, and a WiFi based communication infrastructure. In our design, we equip the quadrotors with autopilot modules for low level control. Moreover, we install low power computing modules for implementing the distributed trajectory planning algorithm online. Furthermore, we develop a communication infrastructure to enable coordination among the quadrotors, which is required for computing a suboptimal control action in real time. The interactions among all the hardware and software components are managed at a higher level by Robot Operating System (ROS). To test the performance of the system, we select a motivating setup of capture the flag game, which is an adversarial game played between two teams of agents called attack and defense. The system is initially simulated in the Gazebo robot simulator with software in the loop. Finally, the complete system is tested and the flight testing results are presented.
keywords: {Games;Software algorithms;Software;Hardware;Real-time systems;Testing;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460866&isnumber=8460178

M. Karrer, M. Agarwal, M. Kamel, R. Siegwart and M. Chli, "Collaborative 6DoF Relative Pose Estimation for Two UAVs with Overlapping Fields of View," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6688-6693.
doi: 10.1109/ICRA.2018.8461143
Abstract: Driven by the promise of leveraging the benefits of collaborative robot operation, this paper presents an approach to estimate the relative transformation between two small Unmanned Aerial Vehicles (UAVs), each equipped with a single camera and an inertial sensor, comprising the first step of any meaningful collaboration. Formation flying and collaborative object manipulation are some of the few tasks that the proposed work has direct applications on, while forming a variable-baseline stereo rig using two UAVs carrying a monocular camera each promises unprecedented effectiveness in collaborative scene estimation. Assuming an overlap in the UAVs' fields of view, in the proposed framework, each UAV runs monocular-inertial odometry onboard, while an Extended Kalman Filter fuses the UAVs' estimates and common image measurements to estimate the metrically scaled relative transformation between them, in realtime. Decoupling the direction of the baseline between the cameras of the two UAVs from its magnitude, this work enables consistent and robust estimation of the uncertainty of the relative pose estimation. Our evaluation on both on simulated data and benchmarking datasets consisting of real aerial data, reveals the power of the proposed methodology in a variety of scenarios. Video - https://youtu.be/AmkkaXa2601.
keywords: {Cameras;Simultaneous localization and mapping;Collaboration;Estimation;Unmanned aerial vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461143&isnumber=8460178

C. Hireche, C. Dezan, J. -P. Diguet and L. Mejias, "BFM: a Scalable and Resource-Aware Method for Adaptive Mission Planning of UAVs," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6702-6707.
doi: 10.1109/ICRA.2018.8460944
Abstract: UAVs must continuously adapt their mission to face unexpected internal or external hazards. This paper proposes a new BFM model (Bayesian Networks built from FMEA tables for MDP). This scalable model offers a modular and comprehensive method to incorporate different types of diagnosis modules based on BN (Bayesian Networks) and FMEA table (Failure Mode and Effects Analysis) to mission specifications expressed as a MDP (Markov Decision Processes). The BFM model implements the complete decision making process that covers both the application configurations at the embedded system level and the mission planning at the UAV level. These decisions are based on the QoS (Quality of Service) of applications, the resource use and the system and sensors health. We demonstrate on a case study for a target tracking mission that the BFM model can interface hazards and applications specifications and can improve the success and quality of the mission. To the best of our knowledge, this is the first proposal of a systematic method that integrates diagnosis modules to MDP model in order to take care of the implementation of embedded applications during a mission.
keywords: {Quality of service;Target tracking;Monitoring;Computational modeling;Sensor systems and applications;Context modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460944&isnumber=8460178

S. Agarwal and S. Akella, "Simultaneous Optimization of Assignments and Goal Formations for Multiple Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6708-6715.
doi: 10.1109/ICRA.2018.8460542
Abstract: This paper presents algorithms to simultaneously compute the optimal assignments and formation parameters for a team of robots from a given initial formation to a variable goal formation (where the shape of the goal formation is given, and its scale and location parameters must be optimized). We assume the n robots are identical spheres. We use the sum of squared travel distances as the objective function to be minimized, which also ensures that the trajectories are collision free. We show that this assignment with variable goal formation problem can be transformed to a linear sum assignment problem (LSAP) with pseudo costs that we establish are independent of the formation parameters. The transformed problem can then be solved using the Hungarian algorithm in O(n3) time. Thus the assignment problem with variable goal formations using this new approach has the same O(n3) time complexity as the standard assignment problem with fixed goal formations. Results from simulations on 200 and 600 robots are presented to show the algorithm is sufficiently fast for practical applications.
keywords: {Collision avoidance;Robot kinematics;Trajectory;Shape;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460542&isnumber=8460178

X. Xiao and S. Zarar, "Machine Learning for Placement-Insensitive Inertial Motion Capture," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6716-6721.
doi: 10.1109/ICRA.2018.8463176
Abstract: Although existing inertial motion-capture systems work reasonably well (≤10° error in Euler angles), their accuracy suffers when sensor positions change relative to the associated body segments (±60° mean error and 120° standard deviation). We attribute this performance degradation to undermined calibration values, sensor movement latency and displacement offsets. The latter specifically leads to incongruent rotation matrices in kinematic algorithms that rely on rotational transformations. To overcome these limitations, we propose to employ machine-learning techniques. In particular, we use multi-layer perceptrons to learn sensor-displacement patterns based on 3 hours of motion data collected from 12 test subjects in the lab over 215 trials. Furthermore, to compensate for calibration and latency errors, we directly process sensor data with deep neural networks and estimate the joint angles. Based on these approaches, we demonstrate up to 69% reduction in tracking errors.
keywords: {Tracking;Robot sensing systems;Motion segmentation;Machine learning;Calibration;Kinematics;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463176&isnumber=8460178

J. Hunt, P. Artemiadis and H. Lee, "Optimizing Stiffness of a Novel Parallel-Actuated Robotic Shoulder Exoskeleton for a Desired Task or Workspace," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6745-6751.
doi: 10.1109/ICRA.2018.8463159
Abstract: The purpose of this work is to optimize the stiffness of a novel parallel-actuated robotic exoskeleton designed to offer a large workspace. This is done in an effort to help provide a solution to the issue wearable parallel actuated robots face regarding a tradeoff between stiffness and workspace. Presented in the form of a shoulder exoskeleton, the device demonstrates a new parallel architecture that can be used for wearable hip, ankle and wrist robots as well. The stiffness of the architecture is dependent on the placement of its actuated substructures. Therefore, it is desirable to place these substructures effectively so as to maximize dynamic performance for any application. In this work, an analytical stiffness model of the device is created and validated experimentally. The model is then used, along with a method of bounded nonlinear multi-objective optimization to configure the parallel actuators so as to maximize stiffness for the entire workspace. Furthermore, it is shown how to use the same technique to optimize the device for a particular task, such as lifting in the sagittal plane.
keywords: {Shoulder;Actuators;Exoskeletons;Kinematics;End effectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463159&isnumber=8460178

K. Seo et al., "Adaptive Oscillator-Based Control for Active Lower-Limb Exoskeleton and its Metabolic Impact," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6752-6758.
doi: 10.1109/ICRA.2018.8460841
Abstract: We developed a robotic lower-limb exoskeleton for those who have weakened muscle due to aging and experience difficulty in walking or getting up without help. The exoskeleton covering both limbs from the feet to the waist has 6 electric actuators in the hip abduction/adduction, hip extension/flexion and knee extension/flexion joints. For users with volitional motion, delivering assistance power according to their intention is a challenging task. We propose an adaptive oscillator-based controller to assist users walk in the lower-limb exoskeleton. To adapt to changes in walking speed and environment, motion command from the controller is modulated by estimate walking speed and walking environment recognized as one of the following categories: level ground, stairs up/down and slope up/down. Experimental results demonstrate the feasibility of the proposed environment recognition method and the impact of assistance on the metabolic cost of walking on level and inclined treadmills.
keywords: {Foot;Legged locomotion;Exoskeletons;Hip;Torque;Knee;Oscillators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460841&isnumber=8460178

R. Mallat et al., "Human-Exoskeleton System Dynamics Identification Using Affordable Sensors," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6759-6765.
doi: 10.1109/ICRA.2018.8463178
Abstract: This paper presents a practical method to identify body segments inertial parameters of a human-exoskeleton system using affordable and easy-to-use sensors. First, the joints and the base kinematics are estimated based on the use of an extended Kalman filter and QR visual markers. Then, joints kinematics are used in a dynamic identification pipeline together with the ground reaction force and moments collected with an affordable Wii Balance Board. The identification process is done using an augmented regressor matrix to identify at once each segment mass, center of mass 3D position and inertia tensor elements of both human locomotor apparatus and exoskeleton. The proposed method is able to accurately estimate external force and moments, with less than 6 % of normalized RMS difference in average, and is experimentally validated with a subject wearing a full lower limb exoskeleton.
keywords: {Exoskeletons;Kinematics;Solid modeling;Dynamics;Three-dimensional displays;Calibration;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463178&isnumber=8460178

T. Yan, Y. Sun, T. Liu, C. -H. Cheung and M. Q. -H. Meng, "A Locomotion Recognition System Using Depth Images," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6766-6772.
doi: 10.1109/ICRA.2018.8460514
Abstract: Powered lower-limb orthoses and prostheses are attracting an increasing amount of attention in assisting daily living activities. To safely and naturally collaborate with human users, the key technology relies on an intelligent controller to accurately decode users' movement intention. In this work, we proposed an innovative locomotion recognition system based on depth images. Composed of a feature extraction subsystem and a finite-state-machine based recognition subsystem, the proposed approach is capable of capturing both the limb movements and the terrains right in front of the user. This makes it possible to anticipate the detection of locomotion modes, especially at transition states, thus enabling the associated wearable robot to deliver a smooth and seamless assistance. Validation experiments were implemented with nine subjects to trace a track that comprised of standing, walking, stair ascending, and stair descending, for three rounds each. The results showed that in steady state, the proposed system could recognize all four locomotion tasks with approximate 100% of accuracy. Out of 216 mode transitions, 82.4% of the intended locomotion tasks can be detected before the transition happened. Thanks to its high accuracy and promising prediction performance, the proposed locomotion recognition system is expected to significantly improve the safety as well as the effectiveness of a lower-limb assistive device.
keywords: {Cameras;Task analysis;Image edge detection;Feature extraction;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460514&isnumber=8460178

B. Temple, A. Simaite and M. Spenko, "The Effect of Bending Compliance on Adhesion Pressure of Hybrid Electrostatic/Gecko-Like Adhesives," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6773-6778.
doi: 10.1109/ICRA.2018.8460725
Abstract: One of the constraints in the design of dry switchable adhesives is the compliance trade-off: compliant structures conform better to surfaces but are limited in strength due to high stored strain energy. In this work we study the effects of bending compliance on the shear adhesion pressures of hybrid electrostatic/gecko-like adhesives of various areas. We reaffirm that normal electrostatic preload increases contact area and show that it is more effective on compliant adhesives. We also show that the gain in contact area can compensate for low shear stiffness and adhesives with high bending compliance outperform stiffer adhesives on substrates with large scale roughness.
keywords: {Electrodes;Adhesives;Substrates;Force;Rough surfaces;Surface roughness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460725&isnumber=8460178

T. D. Ta, T. Umedachi and Y. Kawahara, "Design of Frictional 2D-Anisotropy Surface for Wriggle Locomotion of Printable Soft-Bodied Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6779-6785.
doi: 10.1109/ICRA.2018.8463177
Abstract: Soft-bodied and continuum robots have shown great adaptability to the environment thanks to its flexibility of the body. They have great potential in environment exploring or rescuing mission. One of those robots is snake-like soft-bodied robots. A snake robot is often made by attaching passive wheels along a long body to achieve frictional anisotropy. This anisotropic structure helps to propel the body with serpentine locomotion and prevents it from sliding laterally. However, with a snake-like soft-bodied robot, attaching wheels is not only clumsy but also adding weight to the robot. In this paper, being inspired by the scales on the skin of a snake, we propose a designing scheme to achieve an all-printed wriggle soft-bodied robot by patterning high and low friction material to the ventral side of the robot. Compared to a totally flat ventral, we are able to speed-up the serpentine locomotion 2.8 times. Besides, by changing the configuration of high/low friction material, our wriggle soft-bodied robot can easily move forward or backward just by switching the controlling signal. The fabrication time is just less than 1 hour and the robot can achieve the speed of 26 mm/s.
keywords: {Friction;Tendons;Anisotropic magnetoresistance;DC motors;Mobile robots;Surface morphology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463177&isnumber=8460178

Y. Luo, N. Zhao, K. J. Kim, J. Yi and Y. Shen, "Inchworm Locomotion Mechanism Inspired Self-Deformable Capsule-Like Robot: Design, Modeling, and Experimental Validation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6800-6805.
doi: 10.1109/ICRA.2018.8460666
Abstract: Inspired by the inchworm locomotion mechanism, this paper presents our recently developed self-deformable capsule-like robot. The robot has the actuated deformation capability that relies on a novel rigid elements-based morphing structure (REMS) and its soft actuation mechanisms. When the robot deforms, it generates the crawling locomotion behavior and thus friction waves between the robot and contact surface to facilitate the inchworm-like crawling movement. The paper starts reviewing the deformable properties of natural biological entities like capsules, presents state of the art of the current capsule-like robots, and details the bio-inspired design of the self-deformable capsule-like robot by describing the model of robot kinematics and its locomotion mechanism. Both simulation and experimental results validate the excellent performance of this capsule-like robot. The developed self-deformable capsule-like robot has the advantage of crawling on varied surfaces and it also has the capabilities to crawl in a variety of narrow pipes based on the deformation elicited locomotion nature of the robot.
keywords: {Robots;Force;Strain;Friction;Kinetic theory;Biological system modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460666&isnumber=8460178

Z. Tu, F. Fei, Y. Yang, J. Zhang and X. Deng, "Realtime On-Board Attitude Estimation of High-Frequency Flapping Wing MAVs Under Large Instantaneous Oscillation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6806-6811.
doi: 10.1109/ICRA.2018.8461025
Abstract: Unlike conventional aerial vehicles of fixed or rotary wings, realtime on-board attitude estimation of insect or hummingbird scale Flapping Wing Micro Aerial Vehicles (FWMAVs) is very challenging due to the severe instantaneous oscillations (approximately ten times of gravity on our platform) induced by high-frequency wing flapping. In this work, we present a novel sensor fusion algorithm for realtime on-board attitude estimation of FWMAVs. The algorithm is proposed with adaptive model-based compensation for both sensing drift and aerodynamic forces induced by flapping wings. We validated our approach on a 12.5 grams hummingbird robot. The experimental results demonstrated the accuracy, convergence, and robustness of the proposed algorithm.
keywords: {Magnetometers;Robot sensing systems;Aerodynamics;Estimation;Accelerometers;Magnetic flux;Magnetomechanical effects},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461025&isnumber=8460178

P. Swissler and M. Rubenstein, "FireAnt: A Modular Robot with Full-Body Continuous Docks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6812-6817.
doi: 10.1109/ICRA.2018.8463146
Abstract: Nature offers many examples of organisms coming together to form self-assembling structures. The attachment methods these organisms employ allow them to grab onto others' bodies, often without need for specific alignment or orientation, an ability absent from most existing robotic self-assembling structures, which require complicated sensing and specific alignment. This paper presents FireAnt, a modular 2D robot that demonstrates full-body continuous docks, an attachment mechanism able to attach anywhere onto other robots at any orientation, eliminating the need for alignment mechanisms and complex sensors. Such docks allow FireAnt to climb over copies of itself, something critical to self-assembling structures. This paper first discusses the design of FireAnt before presenting test results that show the strength and reliability of the continuous docks and demonstrate FireAnt's ability to traverse an environment consisting of inert FireAnt robots. The work presented in this paper provides a docking mechanism that can minimize the mechanical complexity of modular robots and will allow the creation of swarms of rigid and adaptable self-assembling structures.
keywords: {Robot sensing systems;Plastics;Copper;Strips;Wires},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463146&isnumber=8460178

T. Tosun, J. Daudelin, G. Jing, H. Kress-Gazit, M. Campbell and M. Yim, "Perception-Informed Autonomous Environment Augmentation with Modular Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6818-6824.
doi: 10.1109/ICRA.2018.8463155
Abstract: We present a system enabling a modular robot to autonomously build structures in order to accomplish high-level tasks. Building structures allows the robot to surmount large obstacles, expanding the set of tasks it can perform. This addresses a common weakness of modular robot systems, which often struggle to traverse large obstacles. This paper presents the hardware, perception, and planning tools that comprise our system. An environment characterization algorithm identifies features in the environment that can be augmented to create a path between two disconnected regions of the environment. Specially-designed building blocks enable the robot to create structures that can augment the environment to make obstacles traversable. A high-level planner reasons about the task, robot locomotion capabilities, and environment to decide if and where to augment the environment in order to perform the desired task. We validate our system in hardware experiments.
keywords: {Task analysis;Hardware;Mobile robots;Bridges;Buildings;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463155&isnumber=8460178

Z. Yu, Q. Shi, H. Wang, T. Sun, Q. Huang and T. Fukuda, "Design and Online Calibration of a Highly Compact Microgripper," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6825-6830.
doi: 10.1109/ICRA.2018.8460683
Abstract: Microgrippers play a significant role in manipulation of micro-objects. To achieve dexterous and precise manipulation, a microgripper is required to be compactly designed and embedded with sensing feedback. Meanwhile, to convert the sensor position into displacement of the microgripper, the embedded sensors should be calibrated by additional equipment like laser sensor. However, a microgripper always needs to be calibrated during manipulation (online calibration), which is still a big challenge with current technology. In this paper, we proposed a highly compact microgripper integrated with position sensors, and a visual-based calibration method to handle such challenge. Moreover, to enhance grasping accuracy, flexure hinges are employed to achieve a low impedance grasping mechanism and to avoid the backlash in traditional bearing. Furthermore, kinematics analysis and Fine Element Analysis (FEA) are implemented to improve the design efficiency. Finally, fibrous micro-rings are successfully assembled, and the results reveal that the calibrated microgripper can be well employed to operate micro-objects.
keywords: {Grippers;Force;Fasteners;Calibration;Robot sensing systems;Strain measurement;Prototypes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460683&isnumber=8460178

P. Schmidt, N. Vahrenkamp, M. Wächter and T. Asfour, "Grasping of Unknown Objects Using Deep Convolutional Neural Networks Based on Depth Images," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6831-6838.
doi: 10.1109/ICRA.2018.8463204
Abstract: We present a data-driven, bottom-up, deep learning approach to robotic grasping of unknown objects using Deep Convolutional Neural Networks (DCNNs). The approach uses depth images of the scene as its sole input for synthesis of a single-grasp solution during execution, adequately portraying the robot's visual perception during exploration of a scene. The training input consists of precomputed high-quality grasps, generated by analytical grasp planners, accompanied with rendered depth images of the training objects. In contrast to previous work on applying deep learning techniques to robotic grasping, our approach is able to handle full end-effector poses and therefore approach directions other than the view direction of the camera. Furthermore, the approach is not limited to a certain grasping setup (e. g. parallel jaw gripper) by design. We evaluate the method regarding its force-closure performance in simulation using the KIT and YCB object model datasets as well as a big data grasping database. We demonstrate the performance of our approach in qualitative grasping experiments on the humanoid robot ARMAR-III.
keywords: {Grasping;Robots;Training;Data models;Databases;Feature extraction;Machine learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463204&isnumber=8460178

U. Tariq, R. Muthusamy and V. Kyrki, "Grasp Planning for Load Sharing in Collaborative Manipulation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6847-6854.
doi: 10.1109/ICRA.2018.8460579
Abstract: In near future, robots are envisioned to work alongside humans in unstructured professional and domestic environments. In such setups, collaborative manipulation is a fundamental skill that allows manipulation of heavy loads by load sharing between agents. Grasp planning plays a pivotal role for load sharing but it has not received attention in the literature. This work proposes a grasp analysis approach for collaborative manipulation that allows load sharing by minimizing exerted grasp wrenches in a task specific way. The manipulation task is defined as expected external wrenches acting on the target object. The analysis approach is demonstrated in a two-agent decentralized set-up with unknown objects. After the first agent has grasped the target, the second agent observes the first agent's grasp location and plans its own grasp according to optimal load sharing. The method was verified in a human robot collaborative lifting task. Experiments with multiple objects show that the proposed method results in optimal load sharing despite limited information and partial observability.
keywords: {Task analysis;Robot kinematics;Planning;Collaboration;Force;Quadratic programming},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460579&isnumber=8460178

T. D. Niehues and A. D. Deshpande, "Human-Inspired Object Manipulation Control with the Anatomically Correct Testbed Hand," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6861-6866.
doi: 10.1109/ICRA.2018.8463166
Abstract: Dexterous manipulation with robotic hands can be achieved using object-level impedance control strategies, which allow intuitive regulation of object position, external environmental interactions, and grasp forces. However, for grasp stability, object stiffness gains are limited by the inherent compliance of the robotic system, object size/shape, and applied grasp forces, which can lead to restricted manipulation capabilities. In this work, we first use analytical modeling techniques to explore the theoretical passivity bounds on object stiffness control gains to ensure grasp stability. Then, an object-space stiffness control algorithm is developed for the Anatomically Correct Testbed (ACT) hand, a robotic hand designed to replicate the complex tendon and joint structure of the human hand, and grasp stability bounds are experimentally tested for various task scenarios. Finally, inspired by the hierarchical structure of the human neuromuscular system, we develop a novel control strategy that implements low-level stiffness in muscle-space, while also emulating a separately defined object-space stiffness in quasi-static conditions. Experimental results demonstrate that this control strategy increases achievable object stiffness without sacrificing grasp stability, leading to significantly increased manipulation capabilities.
keywords: {Robots;Force;Tendons;Task analysis;Muscles;Frequency modulation;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463166&isnumber=8460178

G. Vezzani, U. Pattacini, G. Pasquale and L. Natale, "Improving Superquadric Modeling and Grasping with Prior on Object Shapes," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6875-6882.
doi: 10.1109/ICRA.2018.8463161
Abstract: This paper proposes an object modeling and grasping pipeline for humanoid robots. This work improves our previous approach based on superquadric functions. In particular, we speed up and refine the modeling process by using prior information on the object shape provided by an object classifier. We use our previous method for the computation of grasping pose to obtain pose candidates for both the robot hands and, then, we automatically choose the best candidate for grasping the object according to a given quality index. The performance of our pipeline has been assessed on a real robotic system, the iCub humanoid robot. The robot can grasp 18 objects of the YCB and iCub World datasets considerably different in terms of shape and dimensions with a high success rate.
keywords: {Grasping;Shape;Computational modeling;Robots;Three-dimensional displays;Pipelines;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463161&isnumber=8460178

Y. Cui and S. Niekum, "Active Reward Learning from Critiques," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6907-6914.
doi: 10.1109/ICRA.2018.8460854
Abstract: Learning from demonstration algorithms, such as Inverse Reinforcement Learning, aim to provide a natural mechanism for programming robots, but can often require a prohibitive number of demonstrations to capture important subtleties of a task. Rather than requesting additional demonstrations blindly, active learning methods leverage uncertainty to query the user for action labels at states with high expected information gain. However, this approach can still require a large number of labels to adequately reduce uncertainty and may also be unintuitive, as users are not accustomed to determining optimal actions in a single out-of-context state. To address these shortcomings, we propose a novel trajectory-based active Bayesian inverse reinforcement learning algorithm that (1) queries the user for critiques of automatically generated trajectories, rather than asking for demonstrations or action labels, (2) utilizes trajectory segmentation to expedite the critique / labeling process, and (3) predicts the user's critiques to generate the most highly informative trajectory queries. We evaluated our algorithm in simulated domains, finding it to compare favorably to prior work and a randomized baseline.
keywords: {Trajectory;Robots;Learning (artificial intelligence);Bayes methods;Entropy;Task analysis;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460854&isnumber=8460178

S. Choi, K. Lee, S. Lim and S. Oh, "Uncertainty-Aware Learning from Demonstration Using Mixture Density Networks with Sampling-Free Variance Modeling," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6915-6922.
doi: 10.1109/ICRA.2018.8462978
Abstract: In this paper, we propose an uncertainty-aware learning from demonstration method by presenting a novel uncertainty estimation method utilizing a mixture density network appropriate for modeling complex and noisy human behaviors. The proposed uncertainty acquisition can be done with a single forward path without Monte Carlo sampling and is suitable for real-time robotics applications. Then, we show that it can be decomposed into explained variance and unexplained variance where the connections between aleatoric and epistemic uncertainties are addressed. The properties of the proposed uncertainty measure are analyzed through three different synthetic examples, absence of data, heavy measurement noise, and composition of functions scenarios. We show that each case can be distinguished using the proposed uncertainty measure and presented an uncertainty-aware learning from demonstration method for autonomous driving using this property. The proposed uncertainty-aware learning from demonstration method outperforms other compared methods in terms of safety using a complex real-world driving dataset.
keywords: {Uncertainty;Predictive models;Noise measurement;Data models;Training;Estimation;Measurement uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462978&isnumber=8460178

K. Bullard, S. Chernova and A. L. Thomaz, "Human-Driven Feature Selection for a Robotic Agent Learning Classification Tasks from Demonstration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6923-6930.
doi: 10.1109/ICRA.2018.8461012
Abstract: The state features available to a robot define the variables on which the learning computation depends. However, little prior work considers feature selection in the context of deploying a general-purpose robot able to learn new tasks. In this work, we explore human-driven feature selection in which a robotic agent can identify useful features with the aid of a human user, by extracting information from users about which features are most informative for discriminating between classes of objects needed for a given task (e.g. sorting groceries). The research questions examine (a) whether a domain expert is able to identify a subset of informative task features, (b) whether human selected features will enable the agent to classify unseen examples as accurately as using computational feature selection, and (c) if the interaction strategy used to elicit the information from the user impacts the quality of resulting feature selection. Toward that end, we conducted a user study with 30 participants on campus, given a multi-class classification task and one of five different approaches for conveying information about informative features to a robot learner. Our findings show that when features are semantically interpretable, human feature selection is effective in LfD scenarios because it is able to outperform computational methods when there is limited training data, yet still remains on-par with computational methods as the training sample size increases.
keywords: {Task analysis;Feature extraction;Robots;Training;Training data;Object recognition;Support vector machines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461012&isnumber=8460178

E. H. Chen and D. Burschka, "Object-Centric Approach to Prediction and Labeling of Manipulation Tasks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6931-6938.
doi: 10.1109/ICRA.2018.8462973
Abstract: We propose an object-centric framework to label and predict human manipulation actions from observations of the object trajectories in 3D space. The goal is to lift the low-level sensor observation to a context specific human vocabulary. The low-level visual sensory input from a depth camera is processed into high-level descriptive action labels using a directed action graph representation. It is built based on the concepts of pre-computed Location Areas (LA), regions within a scene where an action typically occur, and Sector-Maps (SM), reference trajectories between the LAs. The framework consists of two stages, an offline teaching phase for graph generation, and an online action recognition phase that maps the current observations to the generated graph. This graph representation allows the framework to predict the most probable action from the observed motion in real-time and to adapt its structure whenever a new LA appears. Furthermore, the descriptive action labels enable not only a better exchange of information between a human and a robot but they allow also the robots to perform high-level reasoning. We present experimental results on real human manipulation actions using a system designed with this framework to show the performance of prediction and labeling that can be achieved.
keywords: {Service robots;Hidden Markov models;Vocabulary;Feature extraction;Knowledge based systems;Task analysis;Action Recognition;Motion analysis;Graph method;Location Area;Sector-Map;Knowledge representation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462973&isnumber=8460178

A. Valada, N. Radwan and W. Burgard, "Deep Auxiliary Learning for Visual Localization and Odometry," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6939-6946.
doi: 10.1109/ICRA.2018.8462979
Abstract: Localization is an indispensable component of a robot's autonomy stack that enables it to determine where it is in the environment, essentially making it a precursor for any action execution or planning. Although convolutional neural networks have shown promising results for visual localization, they are still grossly outperformed by state-of-the-art local feature-based techniques. In this work, we propose VLocNet, a new convolutional neural network architecture for 6-DoF global pose regression and odometry estimation from consecutive monocular images. Our multitask model incorporates hard parameter sharing, thus being compact and enabling real-time inference, in addition to being end-to-end trainable. We propose a novel loss function that utilizes auxiliary learning to leverage relative pose information during training, thereby constraining the search space to obtain consistent pose estimates. We evaluate our proposed VLocNet on indoor as well as outdoor datasets and show that even our single task model exceeds the performance of state-of-the-art deep architectures for global localization, while achieving competitive performance for visual odometry estimation. Furthermore, we present extensive experimental evaluations utilizing our proposed Geometric Consistency Loss that show the effectiveness of multitask learning and demonstrate that our model is the first deep learning technique to be on par with, and in some cases outperforms state-of-the-art SIFT-based approaches.
keywords: {Task analysis;Visual odometry;Estimation;Visualization;Training;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462979&isnumber=8460178

J. -. Merlet, "An Experimental Investigation of Extra Measurements for Solving the Direct Kinematics of Cable-Driven Parallel Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6947-6952.
doi: 10.1109/ICRA.2018.8460901
Abstract: Solving the direct kinematics (DK) of cable-driven parallel robots (CDPR) based only on the cable length measurements is a demanding problem that is still not well mastered, especially for robots having sagging cables. A model-based approach may be used to solve this problem but the model parameters and measurements are uncertain, thereby leading to positioning inaccuracy. A possible way to improve the accuracy and speed up the solving is to add extra measurements. For that purpose a preliminary step is to determine what type of measurements are possible and then to estimate how accurate they are. For that purpose we have used a CDPR with 4 cables that has been instrumented with various types of extra measurements: cable tensions and orientations, platform orientation. Ground truth has been established and we have compared the data provided by the extra sensors with their real values. This work shows that cable tensions sensors and platform orientation sensors are not good candidates to be used for the DK while cable orientations may be obtained with a good accuracy both in static poses or during a quasi-static motion.
keywords: {Measurement uncertainty;Mathematical model;Robot sensing systems;Kinematics;Instruments},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460901&isnumber=8460178

N. M. Bajaj and A. M. Dollar, "Kinematic Optimization of a Novel Partially Decoupled Three Degree of Freedom Hybrid Wrist Mechanism," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6953-6960.
doi: 10.1109/ICRA.2018.8460568
Abstract: This paper discusses the kinematic design and geometric optimization of a novel hybrid three degree-of-freedom (DOF) wrist mechanism. The architecture consists of a one prismatic-revolute-universal linkage and one prismatic-spherical-spherical linkage in parallel with a revolute-universal linkage. This architecture is capable of spherical motion identical to that of a pitch-yaw-roll wrist. Moreover, this mechanism is considered to be partially decoupled, as not all actuators contribute to motion in an arbitrary direction. The forward and inverse kinematics of the parallel 2-DOF mechanism are presented. The 2-DOF mechanism is geometrically optimized over its design parameters to maximize a global transmission index, which measures the motion and torque transmissibility of particular wrist configuration over its workspace. The decoupled nature of the mechanism allows the pitch and yaw mechanism to be optimized separately, greatly reducing the parameter search space and allowing a much larger number of mechanism configurations to be simulated. We leverage this increase in simulated configurations to examine the effect of size constraints on the resulting mechanisms as well.
keywords: {Kinematics;Wrist;Couplings;Actuators;Optimization;Computer architecture;End effectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460568&isnumber=8460178

W. Ding, T. Detert, J. De La Cruz and B. Corves, "Reconfiguration Analysis and Motion Planning of a Novel Reconfigurable Mobile Manipulator Torso," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6961-6966.
doi: 10.1109/ICRA.2018.8460214
Abstract: A novel 2-RER reconfigurable parallel mechanism (ReConBot) considered as the flexible torso of the mobile manipulator is proposed. This paper deals with the analysis of reconfiguration, kinematics, and motion planning. The ReConBot is composed of straight bar-shape base and moving platforms and two metamorphic kinematic chains (MKC) consisted of a revolute (R) joint, a planar (E) joint, and an R joint in sequence. Firstly, mobility and reconfiguration analysis discuss the conditions and mutual mode transition rules of 12 possible configuration states. And then, the kinematics model covers all states with Cartesian coordinate and axis/angle representations. What's more, the motion planning following the rules of the mode transition is explained and illustrated together with a case study. Furthermore, the method of handling the transition at singularity position is discussed. Finally, the robotic system and its experiments verify the correctness of the theoretical analysis and the validation of reconfiguration rules.
keywords: {Kinematics;Torso;Mathematical model;Robot kinematics;Planning;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460214&isnumber=8460178

R. Wakatabe, K. Morita, G. Cheng and Y. Kuniyoshi, "Efficient Event-Driven Forward Kinematics of Open Kinematic Chains with O(Log n) Complexity," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6975-6982.
doi: 10.1109/ICRA.2018.8461211
Abstract: This paper presents novel event-driven forward kinematics algorithms for open kinematic chains with O(log n) complexity. This event-driven algorithm can efficiently update forward kinematics only when new sensory data comes. This will also contribute to localization of computational resources at sensitive joints to the position of the endpoint (e.g. a fingertip), like a root joint. We constructed 3 event-driven FK algorithms. We proved that the algorithms have the complexity of O(logn) for updating 1 joint angle, and O(logn) for obtaining a homogeneous transformation matrix between links. We compared the 3 algorithms with a conventional forward kinematics algorithm in the viewpoint of complexity, computation time, time-variance and algebraic structures. The results showed that the computation time is well adequate for real-time computation. Computation time is less than 2 us per 1 query, for 40,000 kinematic chains.
keywords: {Kinematics;Robot sensing systems;Heuristic algorithms;Robot kinematics;Complexity theory;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461211&isnumber=8460178

A. Ataka, H. Lam and K. Althoefer, "Reactive Magnetic-Field-Inspired Navigation for Non-Holonomic Mobile Robots in Unknown Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6983-6988.
doi: 10.1109/ICRA.2018.8463203
Abstract: In this paper, we present a reactive robot navigation method for a non-holonomic mobile robot taking inspiration from the phenomena observed in magnetic fields. The algorithm is shown to be able to guide mobile robots in arbitrary-shaped convex environment without being trapped in local minima by exploiting the local sensory information without priori knowledge about the environment. A preliminary validation study involving simulation of and experiments with a TurtleBot mobile robot platform show the advantage of the proposed method over existing ones.
keywords: {Robot sensing systems;Collision avoidance;Navigation;Mobile robots;Force;Wires},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463203&isnumber=8460178

T. Anzai, M. Zhao, S. Nozawa, F. Shi, K. Okada and M. Inaba, "Aerial Grasping Based on Shape Adaptive Transformation by HALO: Horizontal Plane Transformable Aerial Robot with Closed-Loop Multilinks Structure," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6990-6996.
doi: 10.1109/ICRA.2018.8460928
Abstract: In this paper, we present the achievement of aerial grasping by shape adaptive transformation to the object shape, using a novel transformable aerial robot called HALO: Horizontal Plane Transformable Aerial Robot with Closed-loop Multilinks Structure. Aerial manipulation is an active research area and using multiple aerial robots is an effective solution for the large size object. However the cooperation is considered that there are some difficulties such as the synchronized flight control and collision with each other. Then, we focus on the transformable aerial robot with two-dimensional multilinks proposed in our previous works, which can transform to the suitable form for the target object and grasp it. However the transformable aerial robot with the serial-link structure could not achieve stable flight in terms of horizontal position and yaw control due to the low rigidity and large inertia in the case of more than 4 links. Thus, first we construct a novel type of multilinks with closed-loop structure to avoid the deformation and a new link module with a tilted propeller for fully-actuated control. Second, we describe transformation method with closed-loop multilinks. Third, we present the optimization planning method for the multilinks form to be adaptive to the two-dimensional shape of the target object. Finally, we present experimental results to demonstrate the feasibility of closed-loop aerial transformation and aerial grasping for the large size object.
keywords: {Unmanned aerial vehicles;Propellers;Shape;Grasping;Servomotors;Force;End effectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460928&isnumber=8460178

N. Staub, D. Bicego, Q. Sablé, V. Arellano, S. Mishra and A. Franchi, "Towards a Flying Assistant Paradigm: the OTHex," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 6997-7002.
doi: 10.1109/ICRA.2018.8460877
Abstract: This paper presents the OTHex platform for aerial manipulation developed at LAAS-CNRS. The OTHex is probably the first multi-directional thrust platform designed to act as Flying Assistant which can aid human operators and/or Ground Manipulators to move long bars for assembly and maintenance tasks. The work emphasis is on task-driven custom design and experimental validations. The proposed control framework is built around a low-level geometric controller, and includes an external wrench estimator, an admittance filter, and a trajectory generator. This tool gives the system the necessary compliance to resist external force disturbances arising from contact with the surrounding environment or to parameter uncertainties in the load. A set of experiments validates the real-world applicability and robustness of the overall system.
keywords: {Propellers;Bars;Trajectory;Robots;Task analysis;Admittance;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460877&isnumber=8460178

J. Paulos, B. Caraher and M. Yim, "Emulating a Fully Actuated Aerial Vehicle Using Two Actuators," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7011-7016.
doi: 10.1109/ICRA.2018.8462975
Abstract: Micro air vehicles exemplified by quadrotors generate downward thrust in their body fixed frame and may only maneuver spatially by changing their orientation. As a result of this underactuation they are fundamentally incapable of simultaneously regulating orientation and position. Furthermore, their feasible maneuvers are limited to spatial trajectories with continuously differentiable acceleration. We present a coaxial helicopter which emulates full actuation over forces and torques (six degrees of freedom) using only two actuators. The orientation of the thrust vector from each rotor is governed by the drive motor by exciting a cyclic flapping response in special articulated blades. The useful separation of orientation and translation dynamics is demonstrated in flight experiments by tracking spatial trajectories while maintaining flat body attitude as well as tracking desired orientations near hover while station keeping.
keywords: {Rotors;Blades;Aircraft;Force;Fasteners;Actuators;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462975&isnumber=8460178

H. Yang, S. Park, J. Lee, J. Ahn, D. Son and D. Lee, "LASDRA: Large-Size Aerial Skeleton System with Distributed Rotor Actuation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7017-7023.
doi: 10.1109/ICRA.2018.8460713
Abstract: Electrical motor and hydraulic actuation widely-used in robotics are “internal actuation” with their actuators sitting at the joint between two links. This internal actuation is fundamentally limiting to construct a large-size dexterously-articulated robot, since any external force (and its own link weight) is to be accumulated to the base multiplied by the moment arm length, requiring extremely strong/sturdy base actuator/structure as the system size increases. In this paper, we propose a novel robotic system, LASDRA (large-size aerial skeleton with distributed rotor actuation), which, by utilizing distributed rotors as “external actuation”, can overcome this limitation of internal actuation and enables us to realize large-size dexterously-articulated robots. We present its design and modeling, joint locking strategy to increase its loading capability, and also a novel decentralized control scheme to allow for compliant operation with scalability against the number of links. Trajectory tracking and valve turning experiments are also performed to validate the theory.
keywords: {Rotors;Robots;Force;Loading;Torque;Hydraulic systems;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460713&isnumber=8460178

B. Gabrich, D. Saldaña, V. Kumar and M. Yim, "A Flying Gripper Based on Cuboid Modular Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7024-7030.
doi: 10.1109/ICRA.2018.8460682
Abstract: We present a novel flying modular platform capable of grasping and transporting objects. It is composed of four cooperative identical modules where each is based on a quadrotor within a cuboid frame with a docking mechanism. Pairs of modules are able to fly independently and physically connect by matching their vertical edges forming a hinge. Four one degree of freedom (DOF) connections results in a one DOF four-bar linkage that can be used to grasp external objects. In this paper, we propose a decentralized method that allows the Flying Gripper to control its position, attitude and aperture angle. In our experiments, we tested the hovering performance for different aperture angles and with a grasped object. The performance for a closing and opening motion was also verified.
keywords: {Grippers;Apertures;Robots;Rotors;Grasping;Propellers;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460682&isnumber=8460178

C. Huang et al., "ACT: An Autonomous Drone Cinematography System for Action Scenes," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7039-7046.
doi: 10.1109/ICRA.2018.8460703
Abstract: Drones are enabling new forms of cinematography. Aerial filming via drones in action scenes is difficult because it requires users to understand the dynamic scenarios and operate the drone and camera simultaneously. Existing systems allow the user to manually specify the shots and guide the drone to capture footage, while none of them employ aesthetic objectives to automate aerial filming in action scenes. Meanwhile, these drone cinematography systems depend on the external motion capture systems to perceive the human action, which is limited to the indoor environment. In this paper, we propose an Autonomous CinemaTography system “ACT” on the drone platform to address the above the challenges. To our knowledge, this is the first drone camera system which can autonomously capture cinematic shots of action scenes based on limb movements in both indoor and outdoor environments. Our system includes the following novelties. First, we propose an efficient method to extract 3D skeleton points via a stereo camera. Second, we design a real-time dynamical camera planning strategy that fulfills the aesthetic objectives for filming and respects the physical limits of a drone. At the system level, we integrate cameras and GPUs into the limited space of a drone and demonstrate the feasibility of running the entire cinematography system onboard in real-time. Experimental results in both simulation and real-world scenarios demonstrate that our cinematography system “ACT” can capture more expressive video footage of human action than that of a state-of-the-art drone camera system.
keywords: {Cameras;Drones;Three-dimensional displays;Skeleton;Planning;Robot vision systems;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460703&isnumber=8460178

D. Strawser and B. Williams, "Approximate Branch and Bound for Fast, Risk-Bound Stochastic Path Planning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7047-7054.
doi: 10.1109/ICRA.2018.8461070
Abstract: Path planning under uncertainty is a difficult and often intractable problem. Autonomous agents must model and reason about complex stochastic processes to quickly derive high quality plans. Most approaches separate the model of uncertainty from the planning; a model is selected and then a controller derived. This work proposes an approach for fast path planning under uncertainty that scales the model of uncertainty such that good policies receive the most effort. To do this, we use an innovative form of the problem's chance constraint to formulate a convex, stochastic path planning problem from the non-convex problem. Next, a bound on the path's expected cost is developed that allows a trade-off between speed of computation and accuracy. The bound is trivially parallelized on a GPU. Finally, a modified branch and bound algorithm is introduced that scales computational effort for more promising solutions. The method is benchmarked against existing approaches including those using Boole's inequality, a MILP approach, and a parallelized sampling-based approach. It outperforms other approaches based on speed and the ability to meet the chance constraint while not being overly conservative.
keywords: {Computational modeling;Stochastic processes;Trajectory;Uncertainty;Planning;Aerospace electronics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461070&isnumber=8460178

A. Tahirovic and M. Ferizbegovic, "Rapidly-Exploring Random Vines (RRV) for Motion Planning in Configuration Spaces with Narrow Passages," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7055-7062.
doi: 10.1109/ICRA.2018.8460186
Abstract: Classical RRT algorithm is blind to efficiently explore configuration space for expanding the tree through a narrow passage when solving a motion planning (MP) problem. Although there have been several attempts to deal with narrow passages which are based on a wide spectrum of assumptions and configuration setups, we solve this problem in rather general way. We use dominant eigenvectors of the configuration sets formed by properly sampling the space around the nearest node, to efficiently expand the tree around the obstacles and through narrow passages. Unlike classical RRT, our algorithm is aware of having the tree nodes in front of a narrow passage and in a narrow passage, which enables a proper tree expansion in a vine-like manner. A thorough comparison with RRT, RRT-connect, and DDRRT algorithm is provided by solving three different difficult MP problems. The results suggest a significant superiority the proposed Rapidly-exploring Random Vines (RRV) algorithm might have in configuration spaces with narrow passages.
keywords: {Space exploration;Planning;Terminology;Principal component analysis;Probabilistic logic;Robots;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460186&isnumber=8460178

D. Yi, R. Thakker, C. Gulino, O. Salzman and S. Srinivasa, "Generalizing Informed Sampling for Asymptotically-Optimal Sampling-Based Kinodynamic Planning via Markov Chain Monte Carlo," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7063-7070.
doi: 10.1109/ICRA.2018.8460188
Abstract: Asymptotically-optimal motion planners such as RRT* have been shown to incrementally approximate the shortest path between start and goal states. Once an initial solution is found, their performance can be dramatically improved by restricting subsequent samples to regions of the state space that can potentially improve the current solution. When the motion-planning problem lies in a Euclidean space, this region Xinf, called the informed set, can be sampled directly. However, when planning with differential constraints in non-Euclidean state spaces, no analytic solutions exists to sampling Xinf directly. State-of-the-art approaches to sampling Xinf in such domains such as Hierarchical Rejection Sampling (HRS) may still be slow in high -dimensional state space. This may cause the planning algorithm to spend most of its time trying to produces samples in Xinf rather than explore it. In this paper, we suggest an alternative approach to produce samples in the informed set Xinf for a wide range of settings. Our main insight is to recast this problem as one of sampling uniformly within the sub-level-set of an implicit non-convex function. This recasting enables us to apply Monte Carlo sampling methods, used very effectively in the Machine Learning and Optimization communities, to solve our problem. We show for a wide range of scenarios that using our sampler can accelerate the convergence rate to high-quality solutions in high-dimensional problems.
keywords: {Trajectory;Planning;Monte Carlo methods;Markov processes;Cost function;Heuristic algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460188&isnumber=8460178

D. Kim, Y. Kwon and S. -E. Yoon, "Dancing PRM: Simultaneous Planning of Sampling and Optimization with Configuration Free Space Approximation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7071-7078.
doi: 10.1109/ICRA.2018.8463181
Abstract: A recent trend in optimal motion planning has broadened the research area toward the hybridization of sampling, optimization and grid-based approaches. We can expect that synergy from such integrations leads to overall performance improvement, but seamless integration and generalization is still an open problem. In this paper, we suggest a hybrid motion planning algorithm utilizing a sampling-based and optimization-based planner while simultaneously approximating a configuration free space. Unlike conventional optimization-based approaches, the proposed algorithm does not depend on a priori information or resolution-complete factors, e.g., a distance field. Ours instead learns spatial information on the fly by exploiting empirical information during the execution, and decentralizes the information over the constructed graph for efficient access. With the help of the learned information, our optimization-based local planner exploits the local area to identify the connectivity of configuration free space without depending on the precomputed domain knowledge. To show the novelty of proposed algorithm, we evaluate it against other asymptotic optimal planners in both synthetic and complex benchmarks with varying degrees of freedom. We also discuss the performance improvement, properties and limitations we have observed.
keywords: {Planning;Approximation algorithms;Trajectory;Optimization;Robots;Probabilistic logic;Linear programming},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463181&isnumber=8460178

R. Bordalba, L. Ros and J. M. Porta, "Randomized Kinodynamic Planning for Constrained Systems," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7079-7086.
doi: 10.1109/ICRA.2018.8460753
Abstract: Kinodynamic RRT planners are considered to be general tools for effectively finding feasible trajectories for high-dimensional dynamical systems. However, they struggle when holonomic constraints are present in the system, such as those arising in parallel manipulators, in robots that cooperate to fulfill a given task, or in situations involving contacts with the environment. In such cases, the state space becomes an implicitly-defined manifold, which makes the diffusion heuristic inefficient and leads to inaccurate dynamical simulations. To address these issues, this paper presents an extension of the kinodynamic RRT planner that constructs an atlas of the state-space manifold incrementally, and uses this atlas both to generate random states and to dynamically steer the system towards such states. To the best of our knowledge, this is the first randomized kinodynamic planner that explicitly takes holonomic constraints into account. We validate the approach in significantly-complex systems.
keywords: {Mathematical model;Robot kinematics;Planning;Trajectory;Manifolds;Standards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460753&isnumber=8460178

B. Ichter, J. Harrison and M. Pavone, "Learning Sampling Distributions for Robot Motion Planning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7087-7094.
doi: 10.1109/ICRA.2018.8460730
Abstract: A defining feature of sampling-based motion planning is the reliance on an implicit representation of the state space, which is enabled by a set of probing samples. Traditionally, these samples are drawn either probabilistically or deterministically to uniformly cover the state space. Yet, the motion of many robotic systems is often restricted to “small” regions of the state space, due to e.g. differential constraints or collision-avoidance constraints. To accelerate the planning process, it is thus desirable to devise non-uniform sampling strategies that favor sampling in those regions where an optimal solution might lie. This paper proposes a methodology for nonuniform sampling, whereby a sampling distribution is learned from demonstrations, and then used to bias sampling. The sampling distribution is computed through a conditional variational autoencoder, allowing sample generation from the latent space conditioned on the specific planning problem. This methodology is general, can be used in combination with any sampling-based planner, and can effectively exploit the underlying structure of a planning problem while maintaining the theoretical guarantees of sampling-based approaches. Specifically, on several planning problems, the proposed methodology is shown to effectively learn representations for the relevant regions of the state space, resulting in an order of magnitude improvement in terms of success rate and convergence to the optimal cost.
keywords: {Planning;Robots;Probabilistic logic;Manifolds;Collision avoidance;Feature extraction;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460730&isnumber=8460178

C. Devin, P. Abbeel, T. Darrell and S. Levine, "Deep Object-Centric Representations for Generalizable Robot Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7111-7118.
doi: 10.1109/ICRA.2018.8461196
Abstract: Robotic manipulation in complex open-world scenarios requires both reliable physical manipulation skills and effective and generalizable perception. In this paper, we propose using an object-centric prior and a semantic feature space for the perception system of a learned policy. We devise an object-level attentional mechanism that can be used to determine relevant objects from a few trajectories or demonstrations, and then immediately incorporate those objects into a learned policy. A task-independent attention locates possible objects in the scene, and a task-specific attention identifies which objects are predictive of the trajectories. The scope of the task-specific attention is easily adjusted by showing demonstrations with distractor objects or with diverse relevant objects. Our results indicate that this approach exhibits good generalization across object instances using very few samples, and can be used to learn a variety of manipulation tasks using reinforcement learning.
keywords: {Task analysis;Visualization;Semantics;Trajectory;Computer vision;Standards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461196&isnumber=8460178

D. Geisler, D. Fox and E. Kasneci, "Real-time 3D Glint Detection in Remote Eye Tracking Based on Bayesian Inference," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7119-7126.
doi: 10.1109/ICRA.2018.8460800
Abstract: As human gaze provides information on our cognitive states, actions, and intentions, gaze-based interaction has the potential to enable a fluent and natural human-robot collaboration. In this work, we focus on reliable gaze estimation in remote eye tracking based on calibration-free methods. Although these methods work well in controlled settings, they fail when illumination conditions change or other objects induce noise. We propose a novel, adaptive method based on a probabilistic model, which reliably detects glints from stereo images and evaluate our method using a data set that contains different challenges with regarding to light and reflections.
keywords: {Cameras;Gaze tracking;Feature extraction;Three-dimensional displays;Probabilistic logic;Solid modeling;Calibration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460800&isnumber=8460178

S. M. Grigorescu, "Generative One-Shot Learning (GOL): A Semi-Parametric Approach to One-Shot Learning in Autonomous Vision," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7127-7134.
doi: 10.1109/ICRA.2018.8461174
Abstract: Highly Autonomous Driving (HAD) systems rely on deep neural networks for the visual perception of the driving environment. Such networks are train on large manually annotated databases. In this work, a semi-parametric approach to one-shot learning is proposed, with the aim of bypassing the manual annotation step required for training perceptions systems used in autonomous driving. The proposed generative framework, coined Generative One-Shot Learning (GOL), takes as input single one-shot objects, or generic patterns, and a small set of so-called regularization samples used to drive the generative process. New synthetic data is generated as Pareto optimal solutions from one-shot objects using a set of generalization functions built into a generalization generator. GOL has been evaluated on environment perception challenges encountered in autonomous vision.
keywords: {Pareto optimization;Training;Autonomous vehicles;Generators;Linear programming;Probability density function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461174&isnumber=8460178

G. Angeletti, B. Caputo and T. Tommasi, "Adaptive Deep Learning Through Visual Domain Localization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7135-7142.
doi: 10.1109/ICRA.2018.8460650
Abstract: A commercial robot, trained by its manufacturer to recognize a predefined number and type of objects, might be used in many settings, that will in general differ in their illumination conditions, background, type and degree of clutter, and so on. Recent computer vision works tackle this generalization issue through domain adaptation methods, assuming as source the visual domain where the system is trained and as target the domain of deployment. All approaches assume to have access to images from all classes of the target during training, an unrealistic condition in robotics applications. We address this issue proposing an algorithm that takes into account the specific needs of robot vision. Our intuition is that the nature of the domain shift experienced mostly in robotics is local. We exploit this through the learning of maps that spatially ground the domain and quantify the degree of shift, embedded into an end-to-end deep domain adaptation architecture. By explicitly localizing the roots of the domain shift we significantly reduce the number of parameters of the architecture to tune, we gain the flexibility necessary to deal with subset of categories in the target domain at training time, and we provide a clear feedback on the rationale behind any classification decision, which can be exploited in human-robot interactions. Experiments on two different settings of the iCub World database confirm the suitability of our method for robot vision.
keywords: {Visualization;Training;Adaptive systems;Adaptation models;Machine learning;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460650&isnumber=8460178

A. Aly and T. Taniguchi, "Towards Understanding Object-Directed Actions: A Generative Model for Grounding Syntactic Categories of Speech Through Visual Perception," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7143-7150.
doi: 10.1109/ICRA.2018.8461231
Abstract: Creating successful human-robot collaboration requires robots to have high-level cognitive functions that could allow them to understand human language and actions in space. To meet this target, an elusive challenge that we address in this paper is to understand object-directed actions through grounding language based on visual cues representing the dynamics of human actions on objects, object characteristics (color and geometry), and spatial relationships between objects in a tabletop scene. The proposed probabilistic framework investigates unsupervised Part-of-Speech (POS) tagging to determine syntactic categories of words so as to infer grammatical structure of language. The dynamics of object-directed actions are characterized through the locations of the human arm joints - modeled on a Hidden Markov Model (HMM) - while manipulating objects, in addition to those of objects represented in 3D point clouds. These corresponding point clouds to segmented objects encode geometric features and spatial semantics of referents and landmarks in the environment. The proposed Bayesian learning model is successfully evaluated through interaction experiments between a human user and Toyota HSR robot in space.
keywords: {Hidden Markov models;Grounding;Tagging;Three-dimensional displays;Robots;Computational modeling;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461231&isnumber=8460178

G. J. Stein and N. Roy, "GeneSIS-Rt: Generating Synthetic Images for Training Secondary Real-World Tasks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7151-7158.
doi: 10.1109/ICRA.2018.8462971
Abstract: We propose a novel approach for generating high-quality, synthetic data for domain-specific learning tasks, for which training data may not be readily available. We leverage recent progress in image-to-image translation to bridge the gap between simulated and real images, allowing us to generate realistic training data for real-world tasks using only unlabeled real-world images and a simulation. GeneSIS-Rtameliorates the burden of having to collect labeled real-world images and is a promising candidate for generating high-quality, domain-specific, synthetic data. To show the effectiveness of using GeneSIS-Rtto create training data, we study two tasks: semantic segmentation and reactive obstacle avoidance. We demonstrate that learning algorithms trained using data generated by GeneSIS-RT make high-accuracy predictions and outperform systems trained on raw simulated data alone, and as well or better than those trained on real data. Finally, we use our data to train a quadcopter to fly 60 meters at speeds up to 3.4 m/s through a cluttered environment, demonstrating that our GeneSIS-RT images can be used to learn to perform mission-critical tasks.
keywords: {Training;Task analysis;Semantics;Image segmentation;Collision avoidance;Gallium nitride;Training data},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462971&isnumber=8460178

C. Fabbri, M. J. Islam and J. Sattar, "Enhancing Underwater Imagery Using Generative Adversarial Networks," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7159-7165.
doi: 10.1109/ICRA.2018.8460552
Abstract: Autonomous underwater vehicles (AUVs) rely on a variety of sensors - acoustic, inertial and visual - for intelligent decision making. Due to its non-intrusive, passive nature and high information content, vision is an attractive sensing modality, particularly at shallower depths. However, factors such as light refraction and absorption, suspended particles in the water, and color distortion affect the quality of visual data, resulting in noisy and distorted images. AUVs that rely on visual sensing thus face difficult challenges and consequently exhibit poor performance on vision-driven tasks. This paper proposes a method to improve the quality of visual underwater scenes using Generative Adversarial Networks (GANs), with the goal of improving input to vision-driven behaviors further down the autonomy pipeline. Furthermore, we show how recently proposed methods are able to generate a dataset for the purpose of such underwater image restoration. For any visually-guided underwater robots, this improvement can result in increased safety and reliability through robust visual perception. To that effect, we present quantitative and qualitative data which demonstrates that images corrected through the proposed approach generate more visually appealing images, and also provide increased accuracy for a diver tracking algorithm.
keywords: {Nonlinear distortion;Gallium nitride;Generators;Image color analysis;Visualization;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460552&isnumber=8460178

X. Mai, H. Zhang and M. Q. . -H. Meng, "Faster R-CNN with Classifier Fusion for Small Fruit Detection," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7166-7172.
doi: 10.1109/ICRA.2018.8461130
Abstract: The-state-of-the-art of fruit detection with Faster R-CNN shows lack of detection advantage on small fruits. One of reasons is only single level features is used for localization of proposal candidates. In this paper, we propose to incorporate a multiple classifier fusion strategy into a Faster R-CNN network for small fruit detection. We utilize features from three different levels to learn three classifiers for objectness classification in the stage of proposal localization. Probabilities from classifiers are combined by a simple convolutional layer to generate final objectness classification for proposal candidates. In order to keep diversity of multiple classifiers, a novel loss term of classifier correlation is introduced into original loss function. Experimental results show that our model is feasible for detecting small fruits.
keywords: {Proposals;Correlation;Feature extraction;Image segmentation;Machine learning;Robots;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461130&isnumber=8460178

F. Wang, G. Chen and K. Hauser, "Robot Button Pressing in Human Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7173-7180.
doi: 10.1109/ICRA.2018.8463180
Abstract: In order to conduct many desirable functions, service robots will need to actuate buttons and switches that are designed for humans. This paper presents the design of a robot named SwitchIt that is small, relatively inexpensive, easily mounted on a mobile robot, and actuates buttons reliably. Its operating characteristics were developed after conducting a systematic study of buttons and switches in human environments. From this study, we develop a categorization of buttons based on a set of physical properties relevant for robots to operate them. After a human calibrates and annotates buttons in the robot's environment using a hand-held tablet, the system automatically recognizes, pushes, and detects the state of a variety of buttons. Empirical tests demonstrate that the system succeeds in operating 95.7% of 234 total buttons/switches in an office building and a household environment.
keywords: {Force;Robot sensing systems;Switches;Reliability;Pressing;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463180&isnumber=8460178

M. M. S. N. Edirisinghe, M. A. V. J. Muthugala, H. P. C. Sirithunge, A. G. Buddhika and P. Jayasekara, "Enhancing Overall Object Placement by Understanding Uncertain Spatial and Qualitative Distance Information in User Commands," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7181-7188.
doi: 10.1109/ICRA.2018.8460624
Abstract: Humans prefer to use voice commands to guide their peer companions in daily assistive tasks. In human perspective, they expect same behavior from assistive robot companions as well. The paper presents an approach towards using such voice instructions based on uncertain and qualitative information to describe object placements. Consider a case in which a set of objects has to be arranged on a table in a particular spatial area. In such a situation, humans will prefer to use a single command regarding overall arrangement rather than repeating the same command for each and every object placement. In such scenarios, people will be comfortable with commands which are simple and with non-technical words. Most of such commands include uncertain spatial terms such as “Left”, “Middle”, “Right” and uncertain qualitative terms such as “Together”, “Little separately”, “Separately” to describe the arrangement. For example “Keep all objects together in the middle of the table” and “Keep objects separately on the right side of the table” can be considered. But in some situations, these commands will not give a direct idea about the placement location of the objects. For instance, “Keep the middle of the table free” can be cited. Therefore, the robot must be able to understand precisely such information in commands before executing them. The experiments are conducted in a simulated domestic environment. Results of the experiment are presented and discussed.
keywords: {Task analysis;Navigation;Visualization;Robot kinematics;Service robots;Manipulators;human-robot interactions;human friendly robotics;service robotics;object manipulation;spatial infor-mation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460624&isnumber=8460178

B. Lee, J. Choi, C. Baek and B. Zhang, "Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7189-7195.
doi: 10.1109/ICRA.2018.8462969
Abstract: The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.
keywords: {Robot kinematics;Trajectory;Collision avoidance;Robustness;Robot sensing systems;Bayes methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462969&isnumber=8460178

V. Magnago, M. Andreetto, S. Divan, D. Fontanelli and L. Palopoli, "Ruling the Control Authority of a Service Robot Based on Information Precision," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7204-7210.
doi: 10.1109/ICRA.2018.8460714
Abstract: We consider the problem of guiding a senior user along a path using a robotic walking assistant. This is a particular type of path following problem, for which most of the solutions available in the literature require an exact localisation of the robot in the environment. An accurate localisation is obtained either with a heavy infrastructure (e.g., an active sensing system deployed in the environment or deploying landmarks in known positions) or using SLAM approaches with a massive data collection. Our key observation is that the intervention of the system (and a good level of accuracy) is only required in proximity of difficult decision points, while we can rely on the user in an environment where the only possibility is just to maintain a course (e.g., a corridor). The direct implication is that we can instrument the environment with a heavy infrastructure only in certain areas. This design strategy has to be complemented by an adequate control law that shifts the authority (i.e., the control of the actuators) between the robot and the user according to the accuracy of the information available to the robot. Such a control law is exactly the contribution of this paper.
keywords: {Robot sensing systems;Estimation error;Uncertainty;Probabilistic logic;Service robots;Automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460714&isnumber=8460178

S. Choi, K. Lee, H. A. Park and S. Oh, "A Nonparametric Motion Flow Model for Human Robot Cooperation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7211-7218.
doi: 10.1109/ICRA.2018.8463201
Abstract: In this paper, we present a novel nonparametric motion flow model that effectively describes a motion trajectory of a human and its application to human robot cooperation. To this end, motion flow similarity measure which considers both spatial and temporal properties of a trajectory is proposed by utilizing the mean and variance functions of a Gaussian process. We also present a human robot cooperation method using the proposed motion flow model. Given a set of interacting trajectories of two workers, the underlying reward function of cooperating behaviors is optimized by using the learned motion description as an input to the reward function where a stochastic trajectory optimization method is used to control a robot. The presented human robot cooperation method is compared with the state-of-the-art algorithm, which utilizes a mixture of interaction primitives (MIP), in terms of the RMS error between generated and target trajectories. While the proposed method shows comparable performance with the MIP when the full observation of human demonstrations is given, it shows superior performance when partial trajectory information is given.
keywords: {Trajectory;Motion measurement;Kernel;Computational modeling;Robot sensing systems;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463201&isnumber=8460178

B. Nemec, K. Yasuda, N. Mullennix, N. Likar and A. Ude, "Learning by Demonstration and Adaptation of Finishing Operations Using Virtual Mechanism Approach," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7219-7225.
doi: 10.1109/ICRA.2018.8460603
Abstract: In this paper we propose a new approach for efficient programming of grinding and polishing operation. In the proposed system, the initial policy is performed by a skilled operator and recorded with a passive digitizer. The demonstrated policy comprises both position and force data. The optimal robot execution of the task is provided by applying a virtual mechanism approach, which models the polishing/grinding tool as a serial kinematic chain. By joining the robot and the virtual mechanism in an augmented system, additional degrees of freedom are obtained and redundancy resolution can be applied to optimize the demonstrated motion. Another benefit of the proposed approach is that the same policy can be transferred to different combination of robots and grinding/polishing tools without any modification of the captured motion. The proposed approach requires known contact point between the treated object and the polishing/grinding tool. We propose a novel approach for accurate estimation of this point using data obtained from the force-torque sensor. Finally, the demonstrated path is refined to compensate for inaccurate calibration and different dynamics of a robot and the human demonstrator using iterative learning controller. The proposed method was verified in a real industrial environment.
keywords: {Robot kinematics;Task analysis;Tools;Service robots;Trajectory;Quaternions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460603&isnumber=8460178

Y. Huang, J. Silvério, L. Rozo and D. G. Caldwell, "Hybrid Probabilistic Trajectory Optimization Using Null-Space Exploration," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7226-7232.
doi: 10.1109/ICRA.2018.8460550
Abstract: In the context of learning from demonstration, human examples are usually imitated in either Cartesian or joint space. However, this treatment might result in undesired movement trajectories in either space. This is particularly important for motion skills such as striking, which typically imposes motion constraints in both spaces. In order to address this issue, we consider a probabilistic formulation of dynamic movement primitives, and apply it to adapt trajectories in Cartesian and joint spaces simultaneously. The probabilistic treatment allows the robot to capture the variability of multiple demonstrations and facilitates the mixture of trajectory constraints from both spaces. In addition to this proposed hybrid space learning, the robot often needs to consider additional constraints such as motion smoothness and joint limits. On the basis of Jacobian-based inverse kinematics, we propose to exploit robot null-space so as to unify trajectory constraints from Cartesian and joint spaces while satisfying additional constraints. Evaluations of hand-shaking and striking tasks carried out with a humanoid robot demonstrate the applicability of our approach.
keywords: {Probabilistic logic;Task analysis;Robot kinematics;Acceleration;Trajectory optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460550&isnumber=8460178

X. Deng, Z. Zhang, A. Sintov, J. Huang and T. Bretl, "Feature-constrained Active Visual SLAM for Mobile Robot Navigation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7233-7238.
doi: 10.1109/ICRA.2018.8460721
Abstract: This paper focuses on tracking failure avoidance during vision-based navigation to a desired goal in unknown environments. While using feature-based Visual Simultaneous Localization and Mapping (VSLAM), continuous identification and association of map points are required during motion. Thus, we discuss a motion planning framework that takes into account sensory constraints for a reliable navigation. We use information available in the SLAM and propose a data-driven approach to predict the number of map points associated in a given pose. Then, a distance-optimal path planner utilizes the model to constrain paths such that the number of associated map points in each pose is above a threshold. We also include an online mapping of the environment for collision avoidance. Overall, we propose an iterative motion planning framework that enables real-time replanning after the acquisition of more information. Experiments in two environments demonstrate the performance of the proposed framework.
keywords: {Cameras;Navigation;Collision avoidance;Simultaneous localization and mapping;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460721&isnumber=8460178

M. Warren, A. P. Schoellig and T. D. Barfoot, "Level-Headed: Evaluating Gimbal-Stabilised Visual Teach and Repeat for Improved Localisation Performance," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7239-7246.
doi: 10.1109/ICRA.2018.8460961
Abstract: Operating in rough, unstructured terrain is an essential requirement for any truly field-deployable ground robot. Search-and-rescue, border patrol and agricultural work all require operation in environments with little established infrastructure for easy navigation. This presents challenges for sensor-based navigation such as vision, where erratic motion and feature-poor environments test feature tracking and hinder the performance of repeat matching of point features. For vision-based route-following methods such as Visual Teach and Repeat (VT&R), maintaining similar visual perspective of salient point features is critical for reliable odometry and accurate localisation over long periods. In this paper, we investigate a potential solution to these challenges by integrating a gimbaled camera with VT&R on a Grizzly Robotic Utility Vehicle (RUV) for testing at high speeds and in visually challenging environments. We examine the benefits and drawbacks of using an actively gimbaled camera to attenuate image motion and control viewpoint. We compare the use of a gimbaled camera to our traditional fixed stereo configuration and demonstrate cases of improved performance in Visual Odometry (VO), localisation and path following in several sets of outdoor experiments.
keywords: {Transforms;Cameras;Visualization;Robot sensing systems;Robustness;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460961&isnumber=8460178

P. Kim, B. Coltin and H. J. Kim, "Low-Drift Visual Odometry in Structured Environments by Decoupling Rotational and Translational Motion," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7247-7253.
doi: 10.1109/ICRA.2018.8463207
Abstract: We present a low-drift visual odometry algorithm that separately estimates rotational and translational motion from lines, planes, and points found in RGB-D images. Previous methods estimate drift-free rotational motion from structural regularities to reduce drift in the rotation estimate, which is the primary source of positioning inaccuracy in visual odometry. However, multiple orthogonal planes are required to be visible throughout the entire motion estimation process; otherwise, these VO approaches fail. We propose a new approach to estimate drift-free rotational motion jointly from both lines and planes by exploiting environmental regularities. We track the spatial regularities with an efficient SO(3)-manifold constrained mean shift algorithm. Once the drift-free rotation is found, we recover the translational motion from all tracked points with and without depth by minimizing the de-rotated reprojection error. We compare the proposed algorithm to other state-of-the-art visual odometry methods on a variety of RGB-D datasets (including especially challenging pure rotations) and demonstrate improved accuracy and lower drift error.
keywords: {Cameras;Tracking;Three-dimensional displays;Estimation;Visual odometry;Feature extraction;Image segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463207&isnumber=8460178

J. Ma et al., "Visual Homing via Guided Locality Preserving Matching," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7254-7261.
doi: 10.1109/ICRA.2018.8460935
Abstract: This study proposes a simple yet surprisingly effective feature matching approach, termed as guided locality preserving matching (GLPM), for visual homing of panoramic images. The key idea of our approach is merely to preserve the neighborhood structures of potential true matches between two panoramic images. We formulate it into a mathematical model, and derive a simple closed-form solution with linearithmic time and linear space complexities. This enables our method to accomplish the mismatch removal from hundreds of putative correspondences in only a few milliseconds. To handle extremely large proportions of outliers, we further design a guided matching strategy based on the proposed method, using the matching result on a small putative set with a high inlier ratio to guide the matching on a large putative set. This strategy can also significantly boost true matches without sacrifice in accuracy. To apply our GLPM to the visual homing problem, we develop a method for dense motion flow estimation from sparse feature matches based on Tikhonov regularization. Moreover, the focus-of-contraction/focus-of-expansion is derived to determine homing directions. The effectiveness of our method is demonstrated on a panoramic database in both feature matching and visual homing.
keywords: {Visualization;Feature extraction;Electronic mail;Cost function;Measurement;Closed-form solutions;Intelligent robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460935&isnumber=8460178

S. Lowry and H. Andreasson, "LOGOS: Local Geometric Support for High-Outlier Spatial Verification," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7262-7269.
doi: 10.1109/ICRA.2018.8460988
Abstract: This paper presents LOGOS, a method of spatial verification for visual localization that is robust in the presence of a high proportion of outliers. LOGOS uses scale and orientation information from local neighbourhoods of features to determine which points are likely to be inliers. The inlier points can be used for secondary localization verification and pose estimation. LOGOS is demonstrated on a number of benchmark localization datasets and outperforms RANSAC as a method of outlier removal and localization verification in scenarios that require robustness to many outliers.
keywords: {Visualization;Feature extraction;Robustness;Urban areas;Transforms;Pose estimation;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460988&isnumber=8460178

D. Van Opdenbosch, M. Oelsch, A. Garcea, T. Aykut and E. Steinbach, "Selection and Compression of Local Binary Features for Remote Visual SLAM," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7270-7277.
doi: 10.1109/ICRA.2018.8463202
Abstract: In the field of autonomous robotics, Simultaneous Localization and Mapping (SLAM) is still a challenging problem. With cheap visual sensors attracting more and more attention, various solutions to the SLAM problem using visual cues have been proposed. However, current visual SLAM systems are still computationally demanding, especially on embedded devices. In addition, collaborative SLAM approaches emerge using visual information acquired from multiple robots simultaneously to build a joint map. In order to address both challenges, we present an approach for remote visual SLAM where local binary features are extracted at the robot, compressed and sent over a network to a centralized powerful processing node running the visual SLAM algorithm. To this end, we propose a new feature coding scheme including a feature selection stage which ensures that only relevant information is transmitted. We demonstrate the effectiveness of our approach on well-known datasets. With the proposed approach, it is possible to build an accurate map while limiting the data rate to 75 kbits/frame.
keywords: {Visualization;Encoding;Simultaneous localization and mapping;Feature extraction;Task analysis;Image coding},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463202&isnumber=8460178

R. Li, S. Wang, Z. Long and D. Gu, "UnDeepVO: Monocular Visual Odometry Through Unsupervised Deep Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7286-7291.
doi: 10.1109/ICRA.2018.8461251
Abstract: We propose a novel monocular visual odometry (VO) system called UnDeepVO in this paper. UnDeepVO is able to estimate the 6-DoF pose of a monocular camera and the depth of its view by using deep neural networks. There are two salient features of the proposed UnDeepVo:one is the unsupervised deep learning scheme, and the other is the absolute scale recovery. Specifically, we train UnDeepVoby using stereo image pairs to recover the scale but test it by using consecutive monocular images. Thus, UnDeepVO is a monocular system. The loss function defined for training the networks is based on spatial and temporal dense information. A system overview is shown in Fig. 1. The experiments on KITTI dataset show our UnDeepVO achieves good performance in terms of pose accuracy.
keywords: {Training;Cameras;Machine learning;Three-dimensional displays;Estimation;Image sequences;Visual odometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461251&isnumber=8460178

L. Feng, M. Ghasemi, K. -W. Chang and U. Topcu, "Counterexamples for Robotic Planning Explained in Structured Language," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7292-7297.
doi: 10.1109/ICRA.2018.8460945
Abstract: Automated techniques such as model checking have been used to verify models of robotic mission plans based on Markov decision processes (MDPs) and generate counterexamples that may help diagnose requirement violations. However, such artifacts may be too complex for humans to understand, because existing representations of counterexamples typically include a large number of paths or a complex automaton. To help improve the interpretability of counterexamples, we define a notion of explainable counterexample, which includes a set of structured natural language sentences to describe the robotic behavior that lead to a requirement violation in an MDP model of robotic mission plan. We propose an approach based on mixed-integer linear programming for generating explainable counterexamples that are minimal, sound and complete. We demonstrate the usefulness of the proposed approach via a case study of warehouse robots planning.
keywords: {Robots;Natural languages;Planning;Computational modeling;Charging stations;Model checking;Markov processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460945&isnumber=8460178

J. Karlsson, C. Vasile, J. Tumova, S. Karaman and D. Rus, "Multi-Vehicle Motion Planning for Social Optimal Mobility-on-Demand," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7298-7305.
doi: 10.1109/ICRA.2018.8462968
Abstract: In this paper we consider a fleet of self-driving cars operating in a road network governed by rules of the road, such as the Vienna Convention on Road Traffic, providing rides to customers to serve their demands with desired deadlines. We focus on the associated motion planning problem that trades-off the demands' delays and level of violation of the rules of the road to achieve social optimum among the vehicles. Due to operating in the same environment, the interaction between the cars must be taken into account, and can induce further delays. We propose an integrated route and motion planning approach that achieves scalability with respect to the number of cars by resolving potential collision situations locally within so-called bubble spaces enclosing the conflict. The algorithms leverage the road geometries, and perform joint planning only for lead vehicles in the conflict and use queue scheduling for the remaining cars. Furthermore, a framework for storing previously resolved conflict situations is proposed, which can be use for quick querying of joint motion plans. We show the mobility-on-demand setup and effectiveness of the proposed approach in simulated case studies involving up to 10 self-driving vehicles.
keywords: {Roads;Planning;Delays;Task analysis;Sensors;Trajectory;Automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462968&isnumber=8460178

S. Ghosh, F. Berkenkamp, G. Ranade, S. Qadeer and A. Kapoor, "Verifying Controllers Against Adversarial Examples with Bayesian Optimization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7306-7313.
doi: 10.1109/ICRA.2018.8460635
Abstract: Recent successes in reinforcement learning have lead to the development of complex controllers for realworld robots. As these robots are deployed in safety-critical applications and interact with humans, it becomes critical to ensure safety in order to avoid causing harm. A first step in this direction is to test the controllers in simulation. To be able to do this, we need to capture what we mean by safety and then efficiently search the space of all behaviors to see if they are safe. In this paper, we present an active-testing framework based on Bayesian Optimization. We specify safety constraints using logic and exploit structure in the problem in order to test the system for adversarial counter examples that violate the safety specifications. These specifications are defined as complex boolean combinations of smooth functions on the trajectories and, unlike reward functions in reinforcement learning, are expressive and impose hard constraints on the system. In our framework, we exploit regularity assumptions on individual functions in form of a Gaussian Process (GP) prior. We combine these into a coherent optimization framework using problem structure. The resulting algorithm is able to provably verify complex safety specifications or alternatively find counter examples. Experimental results show that the proposed method is able to find adversarial examples quickly.
keywords: {Safety;Uncertainty;Robots;Testing;Trajectory;Optimization;Bayes methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460635&isnumber=8460178

H. Rahmani and J. M. O'Kane, "On the Relationship Between Bisimulation and Combinatorial Filter Reduction," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7314-7321.
doi: 10.1109/ICRA.2018.8460507
Abstract: Combinatorial filters are discrete structures for modeling and reasoning about robotic systems. Such filters are of interest not only because of the potential for reduction of the computational power needed to execute the filter, but also for the insight they can sometimes provide into the information requirements of certain robotic tasks. It is known that the filter minimization problem -that is, for a given filter, to find a combinatorial filter with the minimal number of states among all filters with equivalent behavior-is NP-hard. Intuition might suggest that the well-known notion of bisimulation might be of direct use for this minimization problem. Indeed, the bisimilarity relation -the union of all bisimulation relations over the state space of the original filter-is an equivalence relation, and one might attempt to reduce a filter by merging states that are equivalent under this relation. This paper studies this relationship between bisimulation and combinatorial filter reduction. Specifically, we show that every filter minimization problem can be solved by computing a quotient of the input filter with some relation, but that for some filters, the bisimilarity relation is not the correct relation for this purpose. We also characterize the result of the bisimulation quotient operation as the solution to a different, stricter filter minimization problem, and identify several classes of filters for which a variant of bisimulation, called compatibility, can be used to minimize filters in polynomial time.
keywords: {Minimization;Robots;Task analysis;Color;Computational modeling;Cognition;Partitioning algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460507&isnumber=8460178

K. Cho and S. Oh, "Learning-Based Model Predictive Control Under Signal Temporal Logic Specifications," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7322-7329.
doi: 10.1109/ICRA.2018.8460811
Abstract: This paper presents a control strategy synthesis method for dynamical systems with differential constraints while satisfying a set of given rules in consideration of their importances. A special attention is given to situations where all rules cannot be met in order to fulfill a given task. Such dilemmas compel us to make a decision on the degree of satisfaction of each rule including which rule should be maintained or not. In this work, we propose a learning-based model predictive control method in order to solve this problem, where a key insight is to combine a learning method and traditional control scheme so that the designed controller behaves close to human experts. A rule is represented as a signal temporal logic (STL) formula. A robustness slackness, a margin to the satisfaction of the rule, is learned from expert's demonstrations using Gaussian process regression. The learned margin is used in a model predictive control procedure, which helps to decide how much to obey each rule, even ignoring specific rules. In track driving simulation, we show that the proposed method generates human-like behavior and efficiently handles dilemmas as human teachers do.
keywords: {Predictive control;Robustness;Collision avoidance;Task analysis;Gaussian processes;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460811&isnumber=8460178

P. Schillinger, M. Bürger and D. V. Dimarogonas, "Auctioning over Probabilistic Options for Temporal Logic-Based Multi-Robot Cooperation Under Uncertainty," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7330-7337.
doi: 10.1109/ICRA.2018.8462967
Abstract: Coordinating a team of robots to fulfill a common task is still a demanding problem. This is even more the case when considering uncertainty in the environment, as well as temporal dependencies within the task specification. A multi-robot cooperation from a single goal specification requires mechanisms for decomposing the goal as well as an efficient planning for the team. However, planning action sequences offline is insufficient in real world applications. Rather, due to uncertainties, the robots also need to closely coordinate during execution and adjust their policies when additional observations are made. The framework presented in this paper enables the robot team to cooperatively fulfill tasks given as temporal logic specifications while explicitly considering uncertainty and incorporating observations during execution. We present the effectiveness of our ROS implementation of this approach in a case study scenario.
keywords: {Robot kinematics;Task analysis;Uncertainty;Planning;Resource management;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462967&isnumber=8460178

J. F. Carvalho, M. Vejdemo-Johansson, D. Kragic and F. T. Pokorny, "Path Clustering with Homology Area," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7346-7353.
doi: 10.1109/ICRA.2018.8460939
Abstract: Path clustering has found many applications in recent years. Common approaches to this problem use aggregates of the distances between points to provide a measure of dissimilarity between paths which do not satisfy the triangle inequality. Furthermore, they do not take into account the topology of the space where the paths are embedded. To tackle this, we extend previous work in path clustering with relative homology, by employing minimum homology area as a measure of distance between homologous paths in a triangulated mesh. Further, we show that the resulting distance satisfies the triangle inequality, and how we can exploit the properties of homology to reduce the amount of pairwise distance calculations necessary to cluster a set of paths. We further compare the output of our algorithm with that of DTW on a toy dataset of paths, as well as on a dataset of real-world paths.
keywords: {Clustering methods;Topology;Clustering algorithms;Toy manufacturing industry;Robots;Programming;Support vector machines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460939&isnumber=8460178

N. Govindan, S. S. V. Kovvali, K. Chandrasekaran and A. Thondiyath, "GraspMan - A Novel Robotic Platform with Grasping, Manipulation, and Multimodal Locomotion Capability," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7354-7359.
doi: 10.1109/ICRA.2018.8462970
Abstract: In this paper, we present the design of a novel, hybrid multipurpose robotic platform equipped with a pair of graspers to synergize grasping, manipulation, and locomotion. The multipurpose grasper consists of two underactuated fingers with an active gripping surface, which passively conforms to an object while grasping. Each finger has a spring loaded synchronous belt drive which functions as the active gripping surface. The grasper is capable of handling a range of objects with irregular geometry and size. Two such underactuated graspers are connected through a serial kinematic chain and this provides the platform both manipulation and locomotion capability. Graspers act as “legs” or “wheels” of the robot during locomotion and can easily adapt to terrain variations. Fewer number of actuators, simple and scalable kinematic structure, and computationally efficient control are some of the main features of the design. Design details and kinematic analysis are presented. Experiments were conducted on a prototype robot to demonstrate multiple modes of operation.
keywords: {Grasping;Belts;Actuators;Task analysis;Grippers;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462970&isnumber=8460178

Y. Xiong, P. J. From and V. Isler, "Design and Evaluation of a Novel Cable-Driven Gripper with Perception Capabilities for Strawberry Picking Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7384-7391.
doi: 10.1109/ICRA.2018.8460705
Abstract: This paper presents a novel cable-driven gripper with perception capabilities for autonomous harvesting of strawberries. Experiments show that the gripper allows for more accurate and faster picking of strawberries compared to existing systems. The gripper consists of four functional parts for sensing, picking, transmission, and storing. It has six fingers that open to form a closed space to swallow a target strawberry and push other surrounding berries away from the target. Equipped with three IR sensors, the gripper controls a manipulator arm to correct for positional error, and can thus pick strawberries that are not exactly localized by the vision algorithm, improving the robustness. Experiments show that the gripper is gentle on the berries as it merely cuts the stem and there is no physical interaction with the berries during the cutting process. We show that the gripper has close-to-perfect successful picking rate when addressing isolated strawberries. By including internal perception, we get high positional error tolerance, and avoid using slow, high-level closed-loop control. Moreover, the gripper can store several berries, which reduces the overall travel distance for the manipulator, and decreases the time needed to pick a single strawberry substantially. The experiments show that the gripper design decreased picking execution time noticeably compared to results found in literature.
keywords: {Grippers;Servomotors;Containers;Sensors;Robots;Mechanical cables;Pulleys},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460705&isnumber=8460178

T. Chen, M. Haas-Heger and M. Ciocarlie, "Underactuated Hand Design Using Mechanically Realizable Manifolds," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7392-7398.
doi: 10.1109/ICRA.2018.8462972
Abstract: Hand synergies, or joint coordination patterns, have become an effective tool for achieving versatile robotic grasping with simple hands or planning algorithms. Here we propose a method to determine the hand synergies such that they can be physically implemented in an underactuated fashion. Given a kinematic hand model and a set of desired grasps, our algorithm optimizes a Mechanically Realizable Manifold designed to be achievable by a physical underactuation mechanism, enabling the resulting hand to achieve the desired grasps with few actuators. Furthermore, in contrast to existing methods for determining synergies which are only concerned with hand posture, our method explicitly optimizes the stability of the target grasps. We implement this method in the design of a three-finger single-actuator hand as an example, and evaluate its effectiveness numerically and experimentally.
keywords: {Tendons;Force;Optimization;Springs;Manifolds;Kinematics;Grasping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462972&isnumber=8460178

R. Maderna, A. Casalino, A. M. Zanchettin and P. Rocco, "Robotic Handling of Liquids with Spilling Avoidance: A Constraint-Based Control Approach," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7414-7420.
doi: 10.1109/ICRA.2018.8460927
Abstract: Handling liquids with spilling avoidance is a topic of interest for a broad range of fields, both in industry and in service robotic applications. In this paper we present a new control architecture for motion planning of industrial robots, able to tackle the problem of liquid transfer with sloshing control. We do not focus on a complete sloshing suppression, but we show how to enforce an anti spilling constraint. This less conservative approach allows to impose higher accelerations, reducing motion time. A constraint-based approach, amenable to an Online implementation, has been developed. The proposed controller generates trajectories in real time, in order to follow a reference path, while being compliant to the spilling avoidance constraint. The approach has been validated on a 6 degree of freedom industrial ABB robot.
keywords: {Liquids;Robots;Trajectory;Containers;Task analysis;Acceleration;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460927&isnumber=8460178

A. Causo et al., "A Robust Robot Design for Item Picking," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7421-7426.
doi: 10.1109/ICRA.2018.8461057
Abstract: In order to build a stable and reliable system for the Amazon Robotics Challenge we went through a detailed study of the performance and system requirements based on the rules and our past experience of the challenge. The challenge was to build a robot that integrates grasping, vision, motion planning, among others, to be able to pick items from a shelf to specific order boxes. This paper presents the development process including component selection, module designs, and deployment. The resulting robot system has dual 6 degrees of freedom industrial arms mounted on fixed bases, which in turn are mounted on a calibrated table. The robot works with a custom-designed top-open extendable shelf. The vision system uses multiple stereo cameras mounted on a fixed calibrated frame. Feature-based comparison and machine-learning based matching are used to identify and determine item pose. The gripper system uses suction cup and the grasping strategy is pick from the top. Error recovery strategies were also implemented to ensure robust performance. During the competition, the robot was able to pick all target items with the shortest amount of time.
keywords: {Cameras;Manipulators;Task analysis;Planning;Service robots;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461057&isnumber=8460178

C. Eppner, R. Martín-Martín and O. Brock, "Physics-Based Selection of Informative Actions for Interactive Perception," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7427-7432.
doi: 10.1109/ICRA.2018.8460596
Abstract: Interactive perception exploits the correlation between forceful interactions and changes in the observed signals to extract task-relevant information from the sensor stream. Finding the most informative interactions to perceive complex objects, like articulated mechanisms, is challenging because the outcome of the interaction is difficult to predict. We propose a method to select the most informative action while deriving a model of articulated mechanisms that includes kinematic, geometric, and dynamic properties. Our method addresses the complexity of the action selection task based on two insights. First, we show that for a class of interactive perception methods, information gain can be approximated by the amount of motion induced in the mechanism. Second, we resort to physics simulations grounded in the real-world through interactive perception to predict possible action outcomes. Our method enables the robot to autonomously select actions for interactive perception that reveal most information, given the current knowledge of the world. This leads to improved perception and more accurate world models, finally enabling robust manipulation.
keywords: {Kinematics;Task analysis;Dynamics;Robot sensing systems;Shape;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460596&isnumber=8460178

M. Gualtieri, A. t. Pas and R. Platt, "Pick and Place Without Geometric Object Models," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7433-7440.
doi: 10.1109/ICRA.2018.8460553
Abstract: We propose a novel formulation of robotic pick and place as a deep reinforcement learning (RL) problem. Whereas most deep RL approaches to robotic manipulation frame the problem in terms of low level states and actions, we propose a more abstract formulation. In this formulation, actions are target reach poses for the hand and states are a history of such reaches. We show this approach can solve a challenging class of pick-place and regrasping problems where the exact geometry of the objects to be handled is unknown. The only information our method requires is: 1) the sensor perception available to the robot at test time; 2) prior knowledge of the general class of objects for which the system was trained. We evaluate our method using objects belonging to two different categories, mugs and bottles, both in simulation and on real hardware. Results show a major improvement relative to a shape primitives baseline.
keywords: {Shape;History;Task analysis;Robot sensing systems;Three-dimensional displays;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460553&isnumber=8460178

V. Petrík, J. Cmíral, V. Smutný, P. Krsek and V. Hlaváč, "Automatic Material Properties Estimation for the Physics-Based Robotic Garment Folding," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7449-7454.
doi: 10.1109/ICRA.2018.8461016
Abstract: The estimation of the fabric material property during the folding is presented. The available techniques for the accurate garment folding rely on known material properties. Currently, the properties are estimated by an operator in advance of folding. We propose an iterative strategy, which updates the property while the garment is folded. The estimation is formulated as an optimisation task. It is based on measurements from a laser range finder. The proposed algorithm improves the estimation iteratively and prevents the garment from slipping at the same time. We demonstrate the estimation procedure for 10 fabric strips of different materials.
keywords: {Fabrics;Estimation;Robots;Grippers;Material properties;Clothing;Measurement by laser beam},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461016&isnumber=8460178

M. Costanzo, G. De Maria and C. Natale, "Slipping Control Algorithms for Object Manipulation with Sensorized Parallel Grippers," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7455-7461.
doi: 10.1109/ICRA.2018.8460883
Abstract: Parallel jaw grippers have a limited dexterity, however they can still be used for in-hand manipulation tasks, such as pivoting or other controlled sliding motions of the grasped object. A rotational sliding maneuver is challenging since the grasped object can easily slip if the grip force is not properly adjusted to allow rotational sliding while avoiding translational sliding at the same time. This paper has a twofold aim. First, it intends to refine control algorithms to avoid both rotational and linear slippage, already presented by the authors, by proposing a novel sliding motion model that leads to a grip force as small as possible to avoid slippage, so as to enlarge the set of fragile and deformable objects that can be safely grasped with this approach. Second, the paper exploits the motion model to set up a new algorithm for controlled rotational sliding, thus enabling challenging in-hand manipulation actions. All control algorithms are sensor-based, exploiting a sensorized gripper equipped with a six-axis force/tactile sensor, which provides contact force and torque measurements as well as orientation of the object with respect to the gripper. A set of experiments are executed on a Kuka iiwa showing how the proposed control algorithms are effective to both avoid slippage and allow a controlled sliding motion.
keywords: {Force;Robot sensing systems;Grippers;Friction;Task analysis;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460883&isnumber=8460178

Z. Zeng, Z. Zhou, Z. Sui and O. C. Jenkins, "Semantic Robot Programming for Goal-Directed Manipulation in Cluttered Scenes," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7462-7469.
doi: 10.1109/ICRA.2018.8460538
Abstract: We present the Semantic Robot Programming (SRP) paradigm as a convergence of robot programming by demonstration and semantic mapping. In SRP, a user can directly program a robot manipulator by demonstrating a snapshot of their intended goal scene in workspace. The robot then parses this goal as a scene graph comprised of object poses and inter-object relations, assuming known object geometries. Task and motion planning is then used to realize the user's goal from an arbitrary initial scene configuration. Even when faced with different initial scene configurations, SRP enables the robot to seamlessly adapt to reach the user's demonstrated goal. For scene perception, we propose the Discriminatively-Informed Generative Estimation of Scenes and Transforms (DIGEST) method to infer the initial and goal states of the world from RGBD images. The efficacy of SRP with DIGEST perception is demonstrated for the task of tray-setting with a Michigan Progress Fetch robot. Scene perception and task execution are evaluated with a public household occlusion dataset and our cluttered scene dataset.
keywords: {Task analysis;Semantics;Robot programming;Estimation;Planning;Detectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460538&isnumber=8460178

A. Tallavajhula, Ç. Meriçli and A. Kelly, "Off-Road Lidar Simulation with Data-Driven Terrain Primitives," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7470-7477.
doi: 10.1109/ICRA.2018.8461198
Abstract: Developing software for large scale off-road robot applications is challenging and tedious due to cost, logistics, and rigor of field testing. High-fidelity sensor-realistic simulation can speed up the development process for perception and state estimation algorithms. We focus on Lidar simulation for robots operating in off-road environments. Lidars are integral sensors for robots, and Lidar simulation for off-road environments is particularly challenging due to the way Lidar rays interact with natural terrain such as vegetation. A hybrid geometric terrain representation has been shown to model Lidar observations well [1]. However, previous work has only been able to simulate a single, fixed scene, and the entire scene had to be precisely surveyed. In this work, we add semantic information to the hybrid geometric model. This allows us to extract terrain primitives, such as trees and shrubs, from data logs. Our approach uses these primitives to compose arbitrary scenes for Lidar simulation. We evaluate our simulator on a real-world environment of interest, and show that primitives derived using our approach generalize to new scenes.
keywords: {Laser radar;Software;Three-dimensional displays;Robot sensing systems;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461198&isnumber=8460178

W. C. Tan, C. -Y. Weng, Y. Zhou, K. H. Chua and I. . -M. Chen, "Historical Data is Useful for Navigation Planning: Data Driven Route Generation for Autonomous Ship," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7478-7483.
doi: 10.1109/ICRA.2018.8460880
Abstract: This work presents a method for automated generation of navigation plan for autonomous or robotic surface vessel. Historical Automatic Identification System (AIS) data is of significant value to this problem. The method joins AIS locations of a same vessel at different time and locations in a region into a route. Next, it automatically computes navigation plans using nearest neighbour based path retrieval relying on two representations, Ship Feature and Navigation Feature. Before starting service, existing AIS records in the form of ship properties and corresponding route are preprocessed and stored in the form of Ship and Navigation Feature. During online retrieval, given input constraints in vector form, nearest neighbour of this query vector in the same space is found and corresponding path of the neighbour is returned as recommended path. Analysis was done in four and two dimensional spaces for Ship and Navigation Feature respectively. Application of the method is demonstrated in two regions of Australian, covering Bass Strait and Great Australian Bight.
keywords: {Marine vehicles;Navigation;Artificial intelligence;Noise measurement;Planning;Path planning;Databases},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460880&isnumber=8460178

L. D. L. Barker and L. L. Whitcomb, "A Preliminary Study of Ice-Relative Underwater Vehicle Navigation Beneath Moving Sea Ice," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7484-7491.
doi: 10.1109/ICRA.2018.8461166
Abstract: This paper addresses the problem of underwater robotic vehicle navigation relative to moving or stationary sea ice. A brief review of previously-reported under-ice navigation methods is given, as well as a brief motivation for the use of under-ice robotic vehicles with precision navigation capabilities. We then describe our proposed approach, which employs two or more satellite navigation beacons atop the sea ice along with other precision vehicle and ship mounted navigation sensors to estimate vehicle, ice, and ship states by means of an Extended Kalman Filter. Navigation results for a simulated 7.6 km under ice survey are presented for varying satellite beacon separation. Preliminary analysis suggests that for the simulated sensors, vehicle trajectory, and ice velocities, the proposed method can accurately estimate vehicle position up to 1.2 km from the deployment ship given sufficient satellite beacon separation. Decreased beacon separation results in divergence of the vehicle's position estimate at large standoff distances from the ship. We conclude with suggestions for future improvements.
keywords: {Satellite navigation systems;Marine vehicles;Sea ice;Sonar navigation;Acoustics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461166&isnumber=8460178

S. Mintchev, D. Zappetti, J. Willemin and D. Floreano, "A Soft Robot for Random Exploration of Terrestrial Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7492-7497.
doi: 10.1109/ICRA.2018.8460667
Abstract: A swarm of randomly moving miniature robots is an effective solution for the exploration of unknown terrains. However, the deployment of a swarm of miniature robots poses two challenges: finding an adequate locomotion strategy for fast exploration and obstacles negotiation; and implementing simple design and control solutions suited for mass manufacturing. Here, we tackle these challenges by developing a new soft robot with a minimalistic design and a simple control strategy that can randomly propel itself above obstacles and roll on the ground upon landing. The robot is equipped with two propellers that are periodically activated to jump, a soft cage that protects the robot from impacts and allows to passively roll on the ground, and a passive self-righting mechanism for repetitive jumps. The minimalistic control and design reduce the complexity of the mechanics and electronics and are instrumental to the production of a large number of robots. In the paper, the key design aspects of the robot are discussed, the locomotion of a single prototype is experimentally characterized, and improvements of the system for future swarm operations are discussed.
keywords: {Robots;Propellers;Aerodynamics;Shock absorbers;Batteries},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460667&isnumber=8460178

D. A. Duecker, A. Hackbarth, T. Johannink, E. Kreuzer and E. Solowjow, "Micro Underwater Vehicle Hydrobatics: A Submerged Furuta Pendulum," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7498-7503.
doi: 10.1109/ICRA.2018.8461091
Abstract: We present the new HippoCampus micro underwater vehicle, first introduced in [1]. It is designed for monitoring confined fluid volumes. These tightly constrained settings demand agile vehicle dynamics. Moreover, we adapt a robust attitude control scheme for aerial drones to the underwater domain. We demonstrate the performance of the controller with a challenging maneuver. A submerged Furuta pendulum is stabilized by HippoCampus after a swing-up. The experimental results reveal the robustness of the control method, as the system quickly recovers from strong physical disturbances, which are applied to the system.
keywords: {Vehicle dynamics;Hippocampus;Attitude control;Hydrodynamics;Force;Monitoring;Drones},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461091&isnumber=8460178

P. Di Lillo, D. Di Vito, E. Simetti, G. Casalino and G. Antonelli, "Satellite-Based Tele-Operation of an Underwater Vehicle-Manipulator System. Preliminary Experimental Results," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7504-7509.
doi: 10.1109/ICRA.2018.8462976
Abstract: Within the European project DexROV the topic of underwater intervention is addressed. In particular, a remote control room is connected through a satellite communication link to surface vessel, which is in turn connected to an UVMS (Underwater Vehicle-Manipulator System) with an umbilical cable. The operator may interact with the system using a joystick or exoskeleton. Since a direct teleoperation is not feasible, a cognitive engine is in charge of handling communication latency or interruptions caused by the satellite link, and the UVMS should have sufficient autonomy in dealing with low level constraints or secondary objectives. To this purpose, a task-priority-based inverse kinematics algorithm has been developed in order to allow the operator to control only the end effector, while the algorithm is in charge of handling both operative and joint-space constraints. This paper describes some preliminary experimental results achieved during the DexROV campaign of July 2017 in Marseilles (France), where most of the components have been successfully integrated and the inverse kinematics nicely run.
keywords: {Task analysis;Trajectory;Kinematics;Satellite communication;Exoskeletons;Engines;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462976&isnumber=8460178

I. A. Barsan, P. Liu, M. Pollefeys and A. Geiger, "Robust Dense Mapping for Large-Scale Dynamic Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7510-7517.
doi: 10.1109/ICRA.2018.8462974
Abstract: We present a stereo-based dense mapping algorithm for large-scale dynamic urban environments. In contrast to other existing methods, we simultaneously reconstruct the static background, the moving objects, and the potentially moving but currently stationary objects separately, which is desirable for high-level mobile robotic tasks such as path planning in crowded environments. We use both instance-aware semantic segmentation and sparse scene flow to classify objects as either background, moving, or potentially moving, thereby ensuring that the system is able to model objects with the potential to transition from static to dynamic, such as parked cars. Given camera poses estimated from visual odometry, both the background and the (potentially) moving objects are reconstructed separately by fusing the depth maps computed from the stereo input. In addition to visual odometry, sparse scene flow is also used to estimate the 3D motions of the detected moving objects, in order to reconstruct them accurately. A map pruning technique is further developed to improve reconstruction accuracy and reduce memory consumption, leading to increased scalability. We evaluate our system thoroughly on the well-known KITTI dataset. Our system is capable of running on a PC at approximately 2.5Hz, with the primary bottleneck being the instance-aware semantic segmentation, which is a limitation we hope to address in future work. The source code is available from the project Websitea.
keywords: {Three-dimensional displays;Cameras;Semantics;Vehicle dynamics;Dynamics;Real-time systems;Heuristic algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462974&isnumber=8460178

E. Yel, T. X. Lin and N. Bezzo, "Self-triggered Adaptive Planning and Scheduling of UAV Operations," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7518-7524.
doi: 10.1109/ICRA.2018.8463205
Abstract: Modern unmanned aerial vehicles (UAVs) rely on constant periodic sensor measurements to detect and avoid obstacles. However, constant checking and replanning are time and energy consuming and are often not necessary especially in situations in which the UAV can safely fly in uncluttered environments without entering unsafe states. Thus, in this paper, we propose a self-triggered framework that leverages reachability analysis to schedule the next time to check sensor measurements and perform replanning while guaranteeing safety under noise and disturbance effects. Further, we relax sensor checking and motion replanning operations by leveraging a risk-based analysis that determines the likelihood to reach undesired states over a certain time horizon. We also propose an online speed adaptation policy based on the planned trajectory curvature to minimize drift from the desired path due to the system dynamics. Finally, we validate the proposed approach with simulations and experiments for a quadrotor UAV motion planning case study in a cluttered environment.
keywords: {Trajectory;Robot sensing systems;Safety;Unmanned aerial vehicles;Reachability analysis;Schedules},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463205&isnumber=8460178

G. Joshi and G. Chowdhary, "Cross-Domain Transfer in Reinforcement Learning Using Target Apprentice," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7525-7532.
doi: 10.1109/ICRA.2018.8462977
Abstract: In this paper, we present a new approach to transfer in Reinforcement Learning (RL) for cross-domain tasks. Unlike, available transfer approaches, where target task learning is accelerated through initialized learning from source, we propose to adapt and reuse the optimal source policy directly in the related domains. We show the optimal policy from a related source task can be near optimal in target domain provided an adaptive policy accounts for the model error between target and the projected source. A significant advantage of the proposed policy augmentation is in generalizing the policies across related domains without having to re-Iearn the new tasks. We demonstrate that, this architecture leads to better sample efficiency in the transfer, reducing sample complexity of target task learning to target apprentice learning.
keywords: {Task analysis;Adaptation models;Automobiles;Manifolds;Bicycles;Learning (artificial intelligence);Complexity theory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8462977&isnumber=8460178

S. Qi and S. -C. Zhu, "Intent-Aware Multi-Agent Reinforcement Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7533-7540.
doi: 10.1109/ICRA.2018.8463211
Abstract: This paper proposes an intent-aware multi-agent planning framework as well as a learning algorithm. Under this framework, an agent plans in the goal space to maximize the expected utility. The planning process takes the belief of other agents' intents into consideration. Instead of formulating the learning problem as a partially observable Markov decision process (POMDP), we propose a simple but effective linear function approximation of the utility function. It is based on the observation that for humans, other people's intents will pose an influence on our utility for a goal. The proposed framework has several major advantages: i) it is computationally feasible and guaranteed to converge. ii) It can easily integrate existing intent prediction and low-level planning algorithms. iii) It does not suffer from sparse feedbacks in the action space. We experiment our algorithm in a real-world problem that is non-episodic, and the number of agents and goals can vary over time. Our algorithm is trained in a scene in which aerial robots and humans interact, and tested in a novel scene with a different environment. Experimental results show that our algorithm achieves the best performance and human-like behaviors emerge during the dynamic process.
keywords: {Planning;Prediction algorithms;Automata;Vehicles;History;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463211&isnumber=8460178

V. C. V. Kumar, S. Ha and K. Yamane, "Improving Model-Based Balance Controllers Using Reinforcement Learning and Adaptive Sampling," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7541-7547.
doi: 10.1109/ICRA.2018.8463209
Abstract: Balance control to recover from a wide range of disturbances is an important skill for humanoid robots. Traditionally, researchers have often designed a balance controller by applying optimal control theory on a simplified model that abstracts the full-body dynamics. However, the resulting controller may not be able to recover from unexpected scenarios such as non-planar pushes, or fail to exploit full-body actions such as balancing with arm movements. This paper presents a learning framework for enhancing the performance of a model-based optimal controller by expanding the region of attraction (RoA). We train a control policy that generates additional control signals on top of the model-based controller using deep reinforcement learning techniques. Instead of relying on standard reinforcement learning formulations, we explicitly model the region of attraction and continuously adjust it during the training. By drawing the training disturbances at the boundary of the RoA, we can effectively expand the RoA while avoiding local minima. We test our learning framework for in-place balancing as well as balancing with stepping on a humanoid model in simulation.
keywords: {Perturbation methods;Hip;Adaptation models;Robots;Training;Lips;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463209&isnumber=8460178

D. Zhu, T. Li, D. Ho, C. Wang and M. Q. . -H. Meng, "Deep Reinforcement Learning Supervised Autonomous Exploration in Office Environments," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7548-7555.
doi: 10.1109/ICRA.2018.8463213
Abstract: Exploration region selection is an essential decision making process in autonomous robot exploration task. While a majority of greedy methods are proposed to deal with this problem, few efforts are made to investigate the importance of predicting long-term planning. In this paper, we present an algorithm that utilizes deep reinforcement learning (DRL) to learn exploration knowledge over office blueprints, which enables the agent to predict a long-term visiting order for unexplored subregions. On the basis of this algorithm, we propose an exploration architecture that integrates a DRL model, a next-best-view (NBV) selection approach and a structural integrity measurement to further improve the exploration performance. At the end of this paper, we evaluate the proposed architecture against other methods on several new office maps, showing that the agent can efficiently explore uncertain regions with a shorter path and smarter behaviors.
keywords: {Planning;Optimization;Prediction algorithms;Task analysis;Predictive models;Computer architecture;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463213&isnumber=8460178

R. Pautrat, K. Chatzilygeroudis and J. Mouret, "Bayesian Optimization with Automatic Prior Selection for Data-Efficient Direct Policy Search," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7571-7578.
doi: 10.1109/ICRA.2018.8463197
Abstract: One of the most interesting features of Bayesian optimization for direct policy search is that it can leverage priors (e.g., from simulation or from previous tasks) to accelerate learning on a robot. In this paper, we are interested in situations for which several priors exist but we do not know in advance which one fits best the current situation. We tackle this problem by introducing a novel acquisition function, called Most Likely Expected Improvement (MLEI), that combines the likelihood of the priors and the expected improvement. We evaluate this new acquisition function on a transfer learning task for a 5-DOF planar arm and on a possibly damaged, 6-legged robot that has to learn to walk on flat ground and on stairs, with priors corresponding to different stairs and different kinds of damages. Our results show that MLEI effectively identifies and exploits the priors, even when there is no obvious match between the current situations and the priors.
keywords: {Optimization;Bayes methods;Legged locomotion;Task analysis;Predictive models;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463197&isnumber=8460178

A. Nagabandi, G. Kahn, R. S. Fearing and S. Levine, "Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7559-7566.
doi: 10.1109/ICRA.2018.8463189
Abstract: Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of 3-5× on swimmer, cheetah, hopper, and ant agents. Videos can be found at https://sites.google.com/view/mbmf.
keywords: {Task analysis;Predictive models;Neural networks;Data models;Heuristic algorithms;Machine learning;Complexity theory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463189&isnumber=8460178

J. S. Laursen, L. C. Sorensen, U. P. Schultz, L. Ellekilde and D. Kraft, "Adapting Parameterized Motions Using Iterative Learning and Online Collision Detection," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7587-7594.
doi: 10.1109/ICRA.2018.8463208
Abstract: Achieving both the flexibility and robustness required to advance the use of robotics in small and medium-sized productions is an essential but difficult task. A fundamental problem is making the robot run blindly without additional sensors while still being robust to uncertainties and variations in the assembly processes. In this paper, we address the use of parameterized motions suitable for blind execution and robust to uncertainties in the assembly process. Collisions and incorrect assemblies are detected based on robot motor currents while motion parameters are updated based on Bayesian Optimization utilizing Gaussian Process learning. This allows for motion parameters to be optimized using real world trials which incorporate all uncertainties inherent in the assembly process without requiring advanced robot and sensor setups. The result is a simple and straightforward system which helps the user automatically find robust and uncertainty-tolerant motions. We present experiments for an assembly case showing both detection and learning in the real world and how these combine to a robust robot system.
keywords: {Collision avoidance;Robot sensing systems;Robustness;Robotic assembly;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463208&isnumber=8460178

W. Ding, W. Gao, K. Wang and S. Shen, "Trajectory Replanning for Quadrotors Using Kinodynamic Search and Elastic Optimization," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7595-7602.
doi: 10.1109/ICRA.2018.8463188
Abstract: We focus on a replanning scenario for quadrotors where considering time efficiency, non-static initial state and dynamical feasibility is of great significance. We propose a real-time B-spline based kinodynamic (RBK) search algorithm, which transforms a position-only shortest path search (such as A * and Dijkstra) into an efficient kinodynamic search, by exploring the properties of B-spline parameterization. The RBK search is greedy and produces a dynamically feasible time-parameterized trajectory efficiently, which facilitates non-static initial state of the quadrotor. To cope with the limitation of the greedy search and the discretization induced by a grid structure, we adopt an elastic optimization (EO) approach as a post-optimization process, to refine the control point placement provided by the RBK search. The EO approach finds the optimal control point placement inside an expanded elastic tube which represents the free space, by solving a Quadratically Constrained Quadratic Programming (QCQP) problem. We design a receding horizon replanner based on the local control property of B-spline. A systematic comparison of our method against two state-of-the-art methods is provided. We integrate our replanning system with a monocular vision-based quadrotor and validate our performance onboard.
keywords: {Splines (mathematics);Trajectory;Optimization;Real-time systems;Process control;Planning;Complexity theory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463188&isnumber=8460178

S. Tarbouriech and W. Suleiman, "On Bisection Continuous Collision Checking Method: Spherical Joints and Minimum Distance to Obstacles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7613-7619.
doi: 10.1109/ICRA.2018.8463199
Abstract: In this paper, we adapt the Continuous Collision Detection (CCD) method proposed in [1] to efficiently handle the case of spherical and two revolute joints, this kind of joints is very common in modern robotic systems. The new formulations provide more tight motion bounds, thus increase the success rate of checking collision-free paths. We also propose an extension to get the minimum distance to obstacles along a path, this information is primordial as it allows sampling-based motion planning techniques to sort collision-free paths according to their minimum clearance. We have integrated our implementation into a sampling-based motion planning technique and validated it through simulation and on the real Baxter research robot. The experiments revealed that the method not only does not miss any collision between the robot and the obstacles, but also the minimum distance extension provides the path with the maximum clearance at no additional computational cost.
keywords: {Collision avoidance;Charge coupled devices;Planning;Computational modeling;Manipulators;Motion segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463199&isnumber=8460178

I. B. Hagen, D. K. M. Kufoalor, E. F. Brekke and T. A. Johansen, "MPC-based Collision Avoidance Strategy for Existing Marine Vessel Guidance Systems," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7618-7623.
doi: 10.1109/ICRA.2018.8463182
Abstract: This paper presents a viable approach for incorporating collision avoidance strategies into existing guidance and control systems on marine vessels. We propose a method that facilitates the use of simulation-based Model Predictive Control (MPC) for collision avoidance (COLAV) on marine vessels. Any COLAV strategy to be applied in real traffic must adhere to the international regulations for preventing collisions at sea (COLREGS). The proposed MPC COLAV method does not rely on an accurate model of the guidance system to achieve vessel behaviors that are compliant with the COLREGS. Rather, it depends on transitional costs in the MPC objective for collision avoidance maneuvers that are being executed by the marine vessel. Hence, it is straightforward to implement the MPC COLAV on different vessels without specific knowledge of the vessel's guidance strategy. Moreover, it offers the possibility to switch between different (possibly application specific) guidance strategies on the same vessel while running the same MPC COLAV algorithm. We present results from full scale experiments that show the viability of our method in different collision avoidance scenarios.
keywords: {Collision avoidance;Computational modeling;Trajectory;Cost function;Mathematical model;Vehicle dynamics;Propulsion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463182&isnumber=8460178

Z. Liu, Z. Jiang, T. Xu, H. Cheng, Z. Xie and L. Lin, "Avoidance of High-Speed Obstacles Based on Velocity Obstacles," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7624-7630.
doi: 10.1109/ICRA.2018.8463200
Abstract: For obstacles moving with high speeds, existing motion planning methods can rarely guarantee collision avoidance. This paper proposes a viable two-period velocity obstacle algorithm where one period predicts potential collisions within a limited time horizon, and the second period foresees collisions beyond that horizon. The second period is activated only when the obstacle's moving speed is larger than the maximum speed of the robot. The applicability of the new algorithm and the related computation issues are discussed. Both computer simulations and laboratory experiments illustrated the effectiveness of the proposed obstacle avoidance algorithm.
keywords: {Collision avoidance;Robot kinematics;Prediction algorithms;Heuristic algorithms;Robot sensing systems;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463200&isnumber=8460178

P. R. Florence, J. Carter, J. Ware and R. Tedrake, "NanoMap: Fast, Uncertainty-Aware Proximity Queries with Lazy Search Over Local 3D Data," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7631-7638.
doi: 10.1109/ICRA.2018.8463195
Abstract: We would like robots to be able to safely navigate at high speed, efficiently use local 3D information, and robustly plan motions that consider pose uncertainty of measurements in a local map structure. This is hard to do with previously existing mapping approaches, like occupancy grids, that are focused on incrementally fusing 3D data into a common world frame. In particular, both their fragile sensitivity to state estimation errors and computational cost can be limiting. We develop an alternative framework, NanoMap, which alleviates the need for global map fusion and enables a motion planner to efficiently query pose-uncertainty-aware local 3D geometric information. The key idea of NanoMap is to store a history of noisy relative pose transforms and search over a corresponding set of depth sensor measurements for the minimum-uncertainty view of a queried point in space. This approach affords a variety of capabilities not offered by traditional mapping techniques: (a) the pose uncertainty associated with 3D data can be incorporated in motion planning, (b) poses can be updated (i.e., from loop closures) with minimal computational effort, and (c) 3D data can be fused lazily for the purpose of planning. We provide an open-source implementation of NanoMap, and analyze its capabilities and computational efficiency in simulation experiments. Finally, we demonstrate in hardware its effectiveness for fast 3D obstacle avoidance onboard a quadrotor flying up to 10 m/s.
keywords: {Uncertainty;Robot sensing systems;Planning;Three-dimensional displays;Collision avoidance;History;Current measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463195&isnumber=8460178

Z. Qiu and R. Ozawa, "A Sensorless Collision Detection Approach Based on Virtual Contact Points," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7639-7645.
doi: 10.1109/ICRA.2018.8460219
Abstract: This paper presents a force-sensorless collision detection approach based on virtual contacts. A series of indices based on virtual instantaneous powers are introduced associating to several virtual contacts defined on corresponding links of a manipulator. A possible contact link can be determined by comparing the introduced indices without any force or tactile sensors. Simulation results of 2D collision detection tasks by using a three DOF (Degree of Freedom) planar manipulator and 3D collision detection tasks by using a six DOF spatial manipulator validate the effectiveness of the proposed collision detection approach.
keywords: {Collision avoidance;Task analysis;Manipulators;Force;Two dimensional displays;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460219&isnumber=8460178

R. Wehbe and R. K. Williams, "Probabilistic Graph Security for Networked Multi-Robot Systems," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7646-7653.
doi: 10.1109/ICRA.2018.8460752
Abstract: In this paper, we develop a method for determining the probability of a multi-robot system (MRS) being secure when robot interactions are modeled as a probabilistic graph. To define the security of an MRS, we apply an existing control-theoretic notion of network attacks based on the left invertibility of a dynamical system. We then extend previous work by assuming probabilistic robot communication and sensing, modeling the effects of noise, failure, or adversarial influence on interactions in the network. The probabilistic graph security problem can then be seen as a variant of problems solved in the field of system reliability. This interpretation motivates the application of an efficient graphical representation of boolean functions known as binary decision diagrams (BDDs). Specifically, we use the canonical properties of a special type of BDD, the Reduced Order BDD, to generate a tree that can be efficiently traversed to compute the probability that a networked MRS is left invertible, and thus, secure. We then show how our adopted approach can be applied to systems that have interactions that change over time, e.g., for mobile multi-robot teams. Finally, we demonstrate the validity of our method by simulating a mobile MRS performing a rendezvous objective, while tracking its probability of security over time.
keywords: {Robot sensing systems;Probabilistic logic;Observers;Security;Boolean functions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460752&isnumber=8460178

L. Sabattini, C. Secchi and C. Fantuzzi, "Controlling the Interaction of a Multi-Robot System with External Entities," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7654-7659.
doi: 10.1109/ICRA.2018.8463198
Abstract: In this paper we consider a multi-robot system that shares the environment with external entities, and we propose a methodology for controlling the interaction with them. In particular, we consider the problem of achieving a desired dynamic interaction model, in such a way that the multi-robot system exchanges desired forces with external entities. This is obtained by introducing local deformations of the coupling actions among the robots. The proposed method ensures preservation of the passivity property, which provides safety guarantees in the interaction with the (possibly poorly known) external entities.
keywords: {Robots;Couplings;Multi-robot systems;Dynamics;Force;Damping;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463198&isnumber=8460178

B. L. Mendívez Vásquez and J. c. Barca, "Network Topology Inference in Swarm Robotics," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7660-7666.
doi: 10.1109/ICRA.2018.8463190
Abstract: Swarm robotics refers to the implementation of swarm intelligence features like autonomy and self-organization to a collective of robots. This study focuses on the construction of a topological graph that represents both the magnitude and orientation of swarm interactions. Such structure is used for identifying global parameters like leadership and to derive a relationship between the distribution of interaction magnitudes and swarm parameters. Interaction magnitudes were derived from the trajectory distance between nearest neighbors and it was found that the distribution is able to differentiate between only a small subset of controllers, communication ranges and swarm sizes. Leader detection was based on the analysis of position vectors orientation in local neighborhoods. The method was successful at a 100% rate for 10 and 30 robots, while for 60 a minimum rate of 67% was obtained. Additionally, processing times never exceeded a simulation duration for swarms up to 30 robots, with the potential to parallelize for larger sizes.
keywords: {Trajectory;Robots;Network topology;Acceleration;Australia;Mathematical model;Atmospheric measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463190&isnumber=8460178

G. Espinosa and M. Rubenstein, "Using Hardware Specialization and Hierarchy to Simplify Robotic Swarms," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7667-7673.
doi: 10.1109/ICRA.2018.8463206
Abstract: Specialization has always been a tool for work distribution and simplification in nature and in distributed robotics. We present a novel approach to use hardware specialization hierarchically to enhance the capabilities of a swarm without increasing complexity, allowing a numerous group of robots to benefit from the extended features of a few to complete a task that was impossible for them before. We tested the concept under a simulated environment with a classical distributed robotics problem, shape formation, and validated the simulated results against a real experiment.
keywords: {Shape;Task analysis;Hardware;Robot sensing systems;Legged locomotion;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463206&isnumber=8460178

J. Panerati, L. Gianoli, C. Pinciroli, A. Shabah, G. Nicolescu and G. Beltrame, "From Swarms to Stars: Task Coverage in Robot Swarms with Connectivity Constraints," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7674-7681.
doi: 10.1109/ICRA.2018.8463193
Abstract: Swarm robotics carries the potential of solving complex tasks using simple devices. To do so, however, one must define distributed control algorithms capable of producing globally coordinated behaviours. We propose a methodology to address the problem of the spatial coverage of multiple tasks with a swarm of robots that must not lose global connectivity. Our methodology comprises two layers: (i) a distributed Robot Navigation Controller (RNC) is responsible for simultaneously guaranteeing connectivity and pursuit of multiple tasks; and (ii) a global Task Scheduling Controller approximates the optimal strategy for the RNC with minimal computational load. Our contributions include: (i) a qualitative analysis of the literature on connectivity assessment, (ii) our proposed methodology, (iii) simulations in a multi-physics environment, (iv) real-life robot experiments, and (v) the experimental validation of connectivity, coverage optimality, and fault-tolerance.
keywords: {Task analysis;Robot kinematics;Navigation;Eigenvalues and eigenfunctions;Computational modeling;Multi-robot systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463193&isnumber=8460178

G. Arpino, K. Morris, S. Nagavalli and K. Sycara, "Using Information Invariants to Compare Swarm Algorithms and General Multi-Robot Algorithms," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7682-7687.
doi: 10.1109/ICRA.2018.8463210
Abstract: Robotic swarms are decentralized multi-robot systems whose members use local information from proximal neighbors to execute simple reactive control laws that result in emergent collective behaviors. In contrast, members of a general multi-robot system may have access to global information, all-to-all communication or sophisticated deliberative collaboration. Some algorithms in the literature are applicable to robotic swarms. Others require the extra complexity of general multi-robot systems. Given an application domain, a system designer or supervisory operator must choose an appropriate system or algorithm respectively that will enable them to achieve their goals while satisfying mission constraints (e.g, bandwidth, energy, time limits). In this paper, we compare representative swarm and general multi-robot algorithms in two application domains - navigation and dynamic area coverage - with respect to several metrics (e.g, completion time, distance travelled). Our objective is to characterize each class of algorithms to inform offline system design decisions by engineers or online algorithm selection decisions by supervisory operators. Our contributions are (a) an empirical performance comparison of representative swarm and general multi-robot algorithms in two application domains, (b) a comparative analysis of the algorithms based on the theory of information invariants, which provides a theoretical characterization supported by our emnirical results.
keywords: {Heuristic algorithms;Robot kinematics;Robot sensing systems;Collision avoidance;Multi-robot systems;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463210&isnumber=8460178

G. H. W. Gebhardt, K. Daun, M. Schnaubelt and G. Neumann, "Learning Robust Policies for Object Manipulation with Robot Swarms," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7688-7695.
doi: 10.1109/ICRA.2018.8463215
Abstract: Swarm robotics investigates how a large population of robots with simple actuation and limited sensors can collectively solve complex tasks. One particular interesting application with robot swarms is autonomous object assembly. Such tasks have been solved successfully with robot swarms that are controlled by a human operator using a light source. In this paper, we present a method to solve such assembly tasks autonomously based on policy search methods. We split the assembly process in two subtasks: generating a high-level assembly plan and learning a low-level object movement policy. The assembly policy plans the trajectories for each object and the object movement policy controls the trajectory execution. Learning the object movement policy is challenging as it depends on the complex state of the swarm which consists of an individual state for each agent. To approach this problem, we introduce a representation of the swarm which is based on Hilbert space embeddings of distributions. This representation is invariant to the number of agents in the swarm as well as to the allocation of an agent to its position in the swarm. These invariances make the learned policy robust to changes in the swarm and also reduce the search space for the policy search method significantly. We show that the resulting system is able to solve assembly tasks with varying object shapes in multiple simulation scenarios and evaluate the robustness of our representation to changes in the swarm size. Furthermore, we demonstrate that the policies learned in simulation are robust enough to be transferred to real robots.
keywords: {Robot sensing systems;Task analysis;Light sources;Robustness;Kernel;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463215&isnumber=8460178

J. C. Cambera, J. A. Chocoteco and V. Feliu-Batlle, "Modeling and Identification of a Single Link Flexible Arm with a Passive Gravity Compensation Mechanism," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7704-7710.
doi: 10.1109/ICRA.2018.8461097
Abstract: In this paper, we present an experimental study concerning the gravity compensation of flexible link arms based on linear springs. In the field of flexible link robotics, the gravity compensation based on counterweights has been successfully applied in the past, but little effort has been made to examine the potential benefits and difficulties of using spring-based compensation mechanisms. This paper focuses on the modeling and identification of a single link flexible arm compensated with a spring based mechanism. As modeling approach, we followed the lumped-mass methodology to develop a model capable of reproducing the first vibrational frequency of the flexible link arm. Keeping in mind the forces that interact with the flexible link, a combination of sensors is suggested in order to measure and estimate the most important variables of the system. Subsequently, a very simple and reliable identification method based on the time and frequency response of the system is proposed. Finally, the results of the modeling and identification are validated on our experimental platform.
keywords: {Gravity;Springs;Torque;DC motors;Wires;Robots;Payloads},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461097&isnumber=8460178

C. G. Frazelle, A. D. Kapadia and I. D. Walker, "A Nonlinear Control Strategy for Extensible Continuum Robots," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7727-7734.
doi: 10.1109/ICRA.2018.8463187
Abstract: In this paper, we describe a novel nonlinear control strategy for the closed-loop control of extensible continuum robots. Previous attempts at controlling continuum robots have proved difficult due to the complexity of their system dynamics. Taking advantage of a previously developed dynamic model for a three-section, planar, continuum manipulator, we develop an adaptation-based control law. We present simulation results of a set-point tracking between a rigid-link control device and an extensible continuum manipulator. Experimental results of the controller implemented on a six degree-of-freedom continuum robot are also presented.
keywords: {Manipulator dynamics;Mathematical model;Convergence;Kinematics;Jacobian matrices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463187&isnumber=8460178

J. Malzahn, V. D. Amara and N. Tsagarakis, "Continuously Controllable Series Clutches for Efficient Robot Actuation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7735-7741.
doi: 10.1109/ICRA.2018.8463192
Abstract: This paper investigates the energy efficiency potential of continuously controllable clutches between the motors and links of robot joints. Inspired by biological muscles, the clutch enables free, purely gravity driven robot link motion phases gradually disengaged from gear friction, not requiring motor effort. The concept combines the energetic benefits of direct drives during unforced motion phases with the high torque density of conventional and mature geared robotic drive technology during forced motion phases. The paper specifies the general functional principle of the clutch for energy saving independent of any particular clutch implementation. The feasible energy saving of up to 60 % is investigated for harmonic link motions with varying frequencies and with respect to different ratios of link weight to friction torque. The outcomes of the theoretical investigations are supported by first experimental results.
keywords: {Friction;Torque;Robots;Actuators;Tendons;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463192&isnumber=8460178

H. F. Lau, A. Sutrisno, T. H. Chong and D. J. Braun, "Stiffness Modulator: A Novel Actuator for Human Augmentation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7742-7748.
doi: 10.1109/ICRA.2018.8463186
Abstract: Stiffness modulators are devices that promote a novel means of actuation; they provide stiffness modulation without deliberately doing mechanical work. These type of compliant actuators may be used for human augmentation to complement co-contracted antagonistic muscles and as such reduce muscle activity and metabolic energy cost. Despite the theoretical appeal of this concept, its implementation remains elusive in practical applications. This is particularly true for human augmentation which requires a portable stiffness modulator. In this paper, we present a compact, lightweight, and self-contained stiffness modulator. Using this device, we demonstrate stiffness augmentation of the human knee joint in a sit to stand task. The experimental results indicate that the proposed device is able to assist a human by reducing muscle activity while drawing minimal battery power.
keywords: {Modulation;Springs;Actuators;Force;Muscles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463186&isnumber=8460178

D. Morrison et al., "Cartman: The Low-Cost Cartesian Manipulator that Won the Amazon Robotics Challenge," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7757-7764.
doi: 10.1109/ICRA.2018.8463191
Abstract: The Amazon Robotics Challenge enlisted sixteen teams to each design a pick-and-place robot for autonomous warehousing, addressing development in robotic vision and manipulation. This paper presents the design of our custom-built, cost-effective, Cartesian robot system Cartman, which won first place in the competition finals by stowing 14 (out of 16) and picking all 9 items in 27 minutes, scoring a total of 272 points. We highlight our experience-centred design methodology and key aspects of our system that contributed to our competitiveness. We believe these aspects are crucial to building robust and effective robotic systems.
keywords: {Task analysis;Manipulators;Tools;Grippers;Planning;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463191&isnumber=8460178

J. Li, S. Dong and E. Adelson, "Slip Detection with Combined Tactile and Visual Information," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7772-7777.
doi: 10.1109/ICRA.2018.8460495
Abstract: Slip detection plays a vital role in robotic manipulation and it has long been a challenging problem in the robotic community. In this paper, we propose a new method based on deep neural network (DNN) to detect slip. The training data is acquired by a GelSight tactile sensor and a camera mounted on a gripper when we use a robot arm to grasp and lift 94 daily objects with different grasping forces and grasping positions. The DNN is trained to classify whether a slip occurred or not. To evaluate the performance of the DNN, we test 10 unseen objects in 152 grasps. A detection accuracy as high as 88.03 % is achieved. It is anticipated that the accuracy can be further improved with a larger dataset. This method is beneficial for robots to make stable grasps, which can be widely applied to automatic force control, grasping strategy selection and fine manipulation.
keywords: {Grippers;Grasping;Cameras;Tactile sensors;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8460495&isnumber=8460178

K. Yu and A. Rodriguez, "Realtime State Estimation with Tactile and Visual Sensing. Application to Planar Manipulation," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7778-7785.
doi: 10.1109/ICRA.2018.8463183
Abstract: Accurate and robust object state estimation enables successful object manipulation. Visual sensing is widely used to estimate object poses. However, in a cluttered scene or in a tight workspace, the robot's end-effector often occludes the object from the visual sensor. The robot then loses visual feedback and must fall back on open-loop execution. In this paper, we integrate both tactile and visual input using a framework for solving the SLAM problem, incremental smoothing and mapping (iSAM), to provide a fast and flexible solution. Visual sensing provides global pose information but is noisy in general, whereas contact sensing is local, but its measurements are more accurate relative to the end-effector. By combining them, we aim to exploit their advantages and overcome their limitations. We explore the technique in the context of a pusher-slider system. We adapt iSAM's measurement cost and motion cost to the pushing scenario, and use an instrumented setup to evaluate the estimation quality with different object shapes, on different surface materials, and under different contact modes.
keywords: {Robot sensing systems;Visualization;Cost function;State estimation;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463183&isnumber=8460178

M. Bianchi et al., "Touch-Based Grasp Primitives for Soft Hands: Applications to Human-to-Robot Handover Tasks and Beyond," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7794-7801.
doi: 10.1109/ICRA.2018.8463212
Abstract: Recently, the avenue of adaptable, soft robotic hands has opened simplified opportunities to grasp different items; however, the potential of soft end effectors (SEEs) is still largely unexplored, especially in human-robot interaction. In this paper, we propose, for the first time, a simple touch-based approach to endow a SEE with autonomous grasp sensory-motor primitives, in response to an item passed to the robot by a human (human-to-robot handover). We capitalize on human inspiration and minimalistic sensing, while hand adaptability is exploited to generalize grasp response to different objects. We consider the Pisa/IIT SoftHand (SH), an under-actuated soft anthropomorphic robotic hand, which is mounted on a robotic arm and equipped with Inertial Measurement Units (IMUs) on the fingertips. These sensors detect the accelerations arisen from contact with external items. In response to a contact, the hand pose and closure are planned for grasping, by executing arm motions with hand closure commands. We generate these motions from human wrist poses acquired from a human maneuvering the SH to grasp an object from a table. We obtained 86% of successful grasps, considering many objects passed to the SH in different manners. We also tested our techniques in preliminary experiments, where the robot moved to autonomously grasp objects from a surface. Results are positive and open interesting perspectives for soft robotic manipulation.
keywords: {Robot sensing systems;Robot kinematics;Acceleration;Wrist;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463212&isnumber=8460178

F. Shkurti, N. Kakodkar and G. Dudek, "Model-Based Probabilistic Pursuit via Inverse Reinforcement Learning," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7804-7811.
doi: 10.1109/ICRA.2018.8463196
Abstract: We address the integrated prediction, planning, and control problem that enables a single follower robot (the photographer) to quickly re-establish visual contact with a moving target (the subject) that has escaped the follower's field of view. We deal with this scenario, which reactive controllers are typically ill-equipped to handle, by making plausible predictions about the long- and short-term behavior of the target, and planning pursuit paths that will maximize the chance of seeing the target again. At the core of our pursuit method is the use of predictive models of target behavior, which help narrow down the set of possible future locations of the target to a few discrete hypotheses, as well as the use of combinatorial search in physical space to check those hypotheses efficiently. We model target behavior in terms of a learned navigation reward function, using Inverse Reinforcement Learning, based on semantic terrain features of satellite maps. Our pursuit algorithm continuously predicts the latent destination of the target and its position in the future, and relies on efficient graph representation and search methods in order to navigate to locations at which the target is most likely to be seen at an anticipated time. We perform extensive evaluation of our predictive pursuit algorithm over multiple satellite maps, thousands of simulation scenarios, against state-of-the art MDP and POMDP solvers. We show that our method significantly outperforms them by exploiting domain-specific knowledge, while being able to run in real-time.
keywords: {Navigation;Planning;Trajectory;Visualization;Entropy;Predictive models;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463196&isnumber=8460178

A. Nguyen, D. Krupke, M. Burbage, S. Bhatnagar, S. P. Fekete and A. T. Becker, "Using a UAV for Destructive Surveys of Mosquito Population," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7812-7819.
doi: 10.1109/ICRA.2018.8463184
Abstract: This paper introduces techniques for mosquito population surveys in the field using electrified screens (bug zappers) mounted to a UAV. Instrumentation on the UAV logs the UAV path and the GPS location, altitude, and time of each mosquito elimination. Hardware experiments with a UAV equipped with an electrified screen provide real-time measurements of (former) mosquito locations and mosquito-free volumes. Planning a trajectory for the UAV that maximizes the number of mosquito kills is related to the Traveling Salesman Problem, the Lawn Mower Problem and, most closely, Milling with Turn Cost. We reduce this problem to considering variants of covering a grid graph with minimum turn cost, corresponding to optimized energy consumption. We describe an exact method based on Integer Programming that is able to compute provably optimal instances with over 1,500 pixels. These solutions are then implemented on the UAV.
keywords: {Unmanned aerial vehicles;Sociology;Statistics;Global Positioning System;Robots;Monitoring;Wind tunnels},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463184&isnumber=8460178

F. S. Delgado, M. A. Jucà, A. L. M. Marcato and A. B. Dos Santos, "Optical Fiber-Based Sensor for Assessing Electric Current in Unmanned Aerial Vehicles with ROS Interface," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7820-7825.
doi: 10.1109/ICRA.2018.8461144
Abstract: In this work, we propose and experimentally validate a novel optical fiber-based sensor for monitoring and assessing electric current in unmanned aerial vehicles electric motors. The proposed sensing technology combines a Long-Period Fiber Grating sensor and a permanent Neodymium magnet, providing a small and flexible sensing scheme deployed inside the arm of the drone. The experimental results show that good accuracy and linear electric current sensitivity of 0.21 A and 2.08 A/nm, respectively, were achieved with electric current measurements at a 100 Hz sampling rate. The values of hysteresis and repeatability achieved were 0.08 A and 0.22 A, respectively. Finally, a Robot Operating System package for interfacing with the sensing system was developed and tested, which greatly simplifies the deployment of the sensor in robotics applications.
keywords: {Robot sensing systems;Current;Optical fiber sensors;Optical fibers;Current measurement;Fiber gratings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461144&isnumber=8460178

S. D. Gollob, Y. Manian, R. St. Pierre, A. S. Chen and S. Bergbreiter, "A Lightweight, Compliant, Contact-Resistance-Based Airflow Sensor for Quadcopter Ground Effect Sensing," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7826-7831.
doi: 10.1109/ICRA.2018.8461229
Abstract: Sensors to measure quadcopter ground effect are often relatively large, heavy, and require significant power, which restricts their applicability when it comes to small quadcopters and other aircraft that require lightweight and non-obstructive solutions. This paper presents the design of an elastomeric contact-resistance-based airflow sensor to measure ground effect with a mass of approximately 0.04 g and a power draw of 42 μW when in operation. It uses a rigid flap attached to the top of a flexible conductive pillar (CNT/PDMS), which deflects with varying winds speeds. A simple model is presented to describe expected trends between air flow speeds and sensor deflection and is compared with a wind tunnel characterization of the sensor for varying airflows. The sensor is characterized in a wind tunnel to identify a minimum airflow necessary for sensor functionality. Finally, sensors are attached to a Crazyflie 2.0 (Bitcraze) quadcopter and tested for performance in detecting ground effect, where there is a clear trend between sensor output and the intensity of the turbulent flow, related to proximity to ground and thrust level.
keywords: {Wind speed;Robot sensing systems;Wind tunnels;Fabrication;Market research;Hair},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8461229&isnumber=8460178

K. Mohta et al., "Experiments in Fast, Autonomous, GPS-Denied Quadrotor Flight," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7832-7839.
doi: 10.1109/ICRA.2018.8463214
Abstract: High speed navigation through unknown environments is a challenging problem in robotics. It requires fast computation and tight integration of all the subsystems on the robot such that the latency in the perception-action loop is as small as possible. Aerial robots add a limitation of payload capacity, which restricts the amount of computation that can be carried onboard. This requires efficient algorithms for each component in the navigation system. In this paper, we describe our quadrotor system which is able to smoothly navigate through mixed indoor and outdoor environments and is able to fly at speeds of more than 18 m/s. We provide an overview of our system and details about the specific component technologies that enable the high speed navigation capability of our platform. We demonstrate the robustness of our system through high speed autonomous flights and navigation through a variety of obstacle rich environments.
keywords: {Cameras;Navigation;Robot vision systems;Laser radar;Payloads},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463214&isnumber=8460178

M. Odelga, P. Stegagno, N. Kochanek and H. H. Bülthoff, "A Self-contained Teleoperated Quadrotor: On-Board State-Estimation and Indoor Obstacle Avoidance," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7840-7847.
doi: 10.1109/ICRA.2018.8463185
Abstract: Indoor operation of unmanned aerial vehicles (UAV s) poses many challenges due to the lack of GPS signal and cramped spaces. The presence of obstacles in an unfamiliar environment requires reliable state estimation and active algorithms to prevent collisions. In this paper, we present a teleoperated quadrotor UAV platform equipped with an onboard miniature computer and a minimal set of sensors for this task. The platform is capable of highly accurate state-estimation, tracking of desired velocity commanded by the user and ensuring collision-free navigation. The robot estimates its linear velocity through a Kalman filter integration of inertial and optical flow (OF) readings with corresponding distance measurements. An RGB-D camera serves the purpose of providing visual feedback to the operator and depth measurements to build a probabilistic, robo-centric obstacle model, allowing the robot to avoid collisions. The platform is thoroughly validated in experiments in an obstacle rich environment.
keywords: {Collision avoidance;Robot sensing systems;Estimation;Cameras;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463185&isnumber=8460178

B. Xu and K. Sreenath, "Safe Teleoperation of Dynamic UAVs Through Control Barrier Functions," 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 7848-7855.
doi: 10.1109/ICRA.2018.8463194
Abstract: This paper presents a method for assisting human operators to teleoperate highly dynamic systems such as quadrotors inside a constrained environment with safety guarantees. Our method enables human operators to focus on manually operating and flying quadrotor systems without the need to focus on avoiding potential obstacles. This is achieved with the presented supervisory controller overriding human input to enforce safety constraints when necessary. This method can be used as an assistive training solution for novice pilots to begin flying quadrotors without crashing them. Our supervisory controller uses an Exponential control barrier function based quadratic program to achieve safe human teleoperated flight. We demonstrate and validate our control approach through several experiments with multiple users with varying skill levels for three different scenarios of a quadrotor flying in a motion capture environment with virtual and physical constraints.
keywords: {Safety;Trajectory;Collision avoidance;Vehicle dynamics;Dynamics;Robots;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463194&isnumber=8460178