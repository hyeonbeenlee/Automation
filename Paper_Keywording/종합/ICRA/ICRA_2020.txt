"Index of papers presented at ICRA 2020 and published in the IEEE Robotics and Automation Letters," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. i-lvi.
doi: 10.1109/ICRA40945.2020.9196768
Abstract: Presents the table of contents/splash page of the proceedings record.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196768&isnumber=9196508

W. N. Greene and N. Roy, "Metrically-Scaled Monocular SLAM using Learned Scale Factors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 43-50.
doi: 10.1109/ICRA40945.2020.9196900
Abstract: We propose an efficient method for monocular simultaneous localization and mapping (SLAM) that is capable of estimating metrically-scaled motion without additional sensors or hardware acceleration by integrating metric depth predictions from a neural network into a geometric SLAM factor graph. Unlike learned end-to-end SLAM systems, ours does not ignore the relative geometry directly observable in the images. Unlike existing learned depth estimation approaches, ours leverages the insight that when used to estimate scale, learned depth predictions need only be coarse in image space. This allows us to shrink our network to the point that performing inference on a standard CPU becomes computationally tractable.We make several improvements to our network architecture and training procedure to address the lack of depth observability when using coarse images, which allows us to estimate spatially coarse, but depth-accurate predictions in only 30 ms per frame without GPU acceleration. At runtime we incorporate the learned metric data as unary scale factors in a Sim(3) pose graph. Our method is able to generate accurate, scaled poses without additional sensors, hardware accelerators, or special maneuvers and does not ignore or corrupt the observable epipolar geometry. We show compelling results on the KITTI benchmark dataset in addition to real-world experiments with a handheld camera.
keywords: {Simultaneous localization and mapping;Feature extraction;Cameras;Loss measurement;Neural networks;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196900&isnumber=9196508

C. Campos, J. M. M. Montiel and J. D. Tard√≥s, "Inertial-Only Optimization for Visual-Inertial Initialization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 51-57.
doi: 10.1109/ICRA40945.2020.9197334
Abstract: We formulate for the first time visual-inertial initialization as an optimal estimation problem, in the sense of maximum-a-posteriori (MAP) estimation. This allows us to properly take into account IMU measurement uncertainty, which was neglected in previous methods that either solved sets of algebraic equations, or minimized ad-hoc cost functions using least squares. Our exhaustive initialization tests on EuRoC dataset show that our proposal largely outperforms the best methods in the literature, being able to initialize in less than 4 seconds in almost any point of the trajectory, with a scale error of 5.3% on average. This initialization has been integrated into ORB-SLAM Visual-Inertial boosting its robustness and efficiency while maintaining its excellent accuracy.
keywords: {Estimation;Trajectory;Simultaneous localization and mapping;Gravity;Visualization;Optimization;Accelerometers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197334&isnumber=9196508

H. Xie, W. Chen, J. Wang and H. Wang, "Hierarchical Quadtree Feature Optical Flow Tracking Based Sparse Pose-Graph Visual-Inertial SLAM," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 58-64.
doi: 10.1109/ICRA40945.2020.9197278
Abstract: Accurate, robust and real-time localization under constrained-resources is a critical problem to be solved. In this paper, we present a new sparse pose-graph visual-inertial SLAM (SPVIS). Unlike the existing methods that are costly to deal with a large number of redundant features and 3D map points, which are inefficient for improving positioning accuracy, we focus on the concise visual cues for high-precision pose estimating. We propose a novel hierarchical quadtree based optical flow tracking algorithm, it achieves high accuracy and robustness within very few concise features, which is only about one fifth features of the state-of-the-art visual-inertial SLAM algorithms. Benefiting from the efficient optical flow tracking, our sparse pose-graph optimization time cost achieves bounded complexity. By selecting and optimizing the informative features in sliding window and local VIO, the computational complexity is bounded, it achieves low time cost in long-term operation. We compare with the state-of-the-art VIO/VI-SLAM systems on the challenging public datasets by the embedded platform without GPUs, the results effectively verify that the proposed method has better real-time performance and localization accuracy.
keywords: {Optical flow;Optimization;Simultaneous localization and mapping;Robustness;Tracking;Feature extraction;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197278&isnumber=9196508

Z. Dai et al., "Keypoint Description by Descriptor Fusion Using Autoencoders," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 65-71.
doi: 10.1109/ICRA40945.2020.9197205
Abstract: Keypoint matching is an important operation in computer vision and its applications such as visual simultaneous localization and mapping (SLAM) in robotics. This matching operation heavily depends on the descriptors of the keypoints, and it must be performed reliably when images undergo conditional changes such as those in illumination and viewpoint. In this paper, a descriptor fusion model (DFM) is proposed to create a robust keypoint descriptor by fusing CNN-based descriptors using autoencoders. Our DFM architecture can be adapted to either trained or pre-trained CNN models. Based on the performance of existing CNN descriptors, we choose HardNet and DenseNet169 as representatives of trained and pre-trained descriptors. Our proposed DFM is evaluated on the latest benchmark datasets in computer vision with challenging conditional changes. The experimental results show that DFM is able to achieve state-of-the-art performance, with the mean mAP that is 6.45% and 6.53% higher than HardNet and DenseNet169, respectively.
keywords: {Fuses;Lighting;Robustness;Computer vision;Simultaneous localization and mapping;Image coding},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197205&isnumber=9196508

A. Thyagharajan, O. J. Omer, D. Mandal and S. Subramoney, "Towards Noise Resilient SLAM," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 72-79.
doi: 10.1109/ICRA40945.2020.9196745
Abstract: Sparse-indirect SLAM systems have been dominantly popular due to their computational efficiency and photometric invariance properties. Depth sensors are critical to SLAM frameworks for providing scale information to the 3D world, yet known to be plagued by a wide variety of noise sources, possessing lateral and axial components. In this work, we demonstrate the detrimental impact of these depth noise components on the performance of the state-of-the-art sparse-indirect SLAM system (ORB-SLAM2). We propose (i) Map-Point Consensus based Outlier Rejection (MC-OR) to counter lateral noise, and (ii) Adaptive Virtual Camera (AVC) to combat axial noise accurately. MC-OR utilizes consensus information between multiple sightings of the same landmark to disambiguate noisy depth and filter it out before pose optimization. In AVC, we introduce an error vector as an accurate representation of the axial depth error. We additionally propose an adaptive algorithm to find the virtual camera location for projecting the error used in the objective function of the pose optimization. Our techniques work equally well for stereo image pairs and RGB-D input directly used by sparse-indirect SLAM systems. Our methods were tested on the TUM (RGB-D) and EuRoC (stereo) datasets and we show that they outperform existing state-of-the-art ORB-SLAM2 by 2-3x, especially in sequences critically affected by depth noise.
keywords: {Cameras;Simultaneous localization and mapping;Three-dimensional displays;Measurement;Feature extraction;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196745&isnumber=9196508

K. Ebadi et al., "LAMP: Large-Scale Autonomous Mapping and Positioning for Exploration of Perceptually-Degraded Subterranean Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 80-86.
doi: 10.1109/ICRA40945.2020.9197082
Abstract: Simultaneous Localization and Mapping (SLAM) in large-scale, unknown, and complex subterranean environments is a challenging problem. Sensors must operate in off-nominal conditions; uneven and slippery terrains make wheel odometry inaccurate, while long corridors without salient features make exteroceptive sensing ambiguous and prone to drift; finally, spurious loop closures that are frequent in environments with repetitive appearance, such as tunnels and mines, could result in a significant distortion of the entire map. These challenges are in stark contrast with the need to build highly-accurate 3D maps to support a wide variety of applications, ranging from disaster response to the exploration of underground extraterrestrial worlds. This paper reports on the implementation and testing of a lidar-based multi-robot SLAM system developed in the context of the DARPA Subterranean Challenge. We present a system architecture to enhance subterranean operation, including an accurate lidar-based front-end, and a flexible and robust back-end that automatically rejects outlying loop closures. We present an extensive evaluation in large-scale, challenging subterranean environments, including the results obtained in the Tunnel Circuit of the DARPA Subterranean Challenge. Finally, we discuss potential improvements, limitations of the state of the art, and future research directions.
keywords: {Simultaneous localization and mapping;Laser radar;Three-dimensional displays;Base stations;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197082&isnumber=9196508

A. Harakeh, M. Smart and S. L. Waslander, "BayesOD: A Bayesian Approach for Uncertainty Estimation in Deep Object Detectors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 87-93.
doi: 10.1109/ICRA40945.2020.9196544
Abstract: When incorporating deep neural networks into robotic systems, a major challenge is the lack of uncertainty measures associated with their output predictions. Methods for uncertainty estimation in the output of deep object detectors (DNNs) have been proposed in recent works, but have had limited success due to 1) information loss at the detectors nonmaximum suppression (NMS) stage, and 2) failure to take into account the multitask, many-to-one nature of anchor-based object detection. To that end, we introduce BayesOD, an uncertainty estimation approach that reformulates the standard object detector inference and Non-Maximum suppression components from a Bayesian perspective. Experiments performed on four common object detection datasets show that BayesOD provides uncertainty estimates that are better correlated with the accuracy of detections, manifesting as a significant reduction of 9.77%-13.13% on the minimum Gaussian uncertainty error metric and a reduction of 1.63%-5.23% on the minimum Categorical uncertainty error metric. Code will be released at https://github.com/asharakeh/bayes-od-rc.
keywords: {Uncertainty;Detectors;Neural networks;Bayes methods;Estimation;Object detection;Measurement uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196544&isnumber=9196508

O. Mees, A. Emek, J. Vertens and W. Burgard, "Learning Object Placements For Relational Instructions by Hallucinating Scene Representations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 94-100.
doi: 10.1109/ICRA40945.2020.9197472
Abstract: Robots coexisting with humans in their environment and performing services for them need the ability to interact with them. One particular requirement for such robots is that they are able to understand spatial relations and can place objects in accordance with the spatial relations expressed by their user. In this work, we present a convolutional neural network for estimating pixelwise object placement probabilities for a set of spatial relations from a single input image. During training, our network receives the learning signal by classifying hallucinated high-level scene representations as an auxiliary task. Unlike previous approaches, our method does not require ground truth data for the pixelwise relational probabilities or 3D models of the objects, which significantly expands the applicability in practical applications. Our results obtained using real-world data and human-robot experiments demonstrate the effectiveness of our method in reasoning about the best way to place objects to reproduce a spatial relation. Videos of our experiments can be found at https://youtu.be/zaZkHTWFMKM.
keywords: {Robots;Training;Three-dimensional displays;Natural languages;Graphical models;Distribution functions;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197472&isnumber=9196508

Q. Wang, S. Shi, S. Zheng, K. Zhao and X. Chu, "FADNet: A Fast and Accurate Network for Disparity Estimation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 101-107.
doi: 10.1109/ICRA40945.2020.9197031
Abstract: Deep neural networks (DNNs) have achieved great success in the area of computer vision. The disparity estimation problem tends to be addressed by DNNs which achieve much better prediction accuracy in stereo matching than traditional hand-crafted feature based methods. On one hand, however, the designed DNNs require significant memory and computation resources to accurately predict the disparity, especially for those 3D convolution based networks, which makes it difficult for deployment in real-time applications. On the other hand, existing computation-efficient networks lack expression capability in large-scale datasets so that they cannot make an accurate prediction in many scenarios. To this end, we propose an efficient and accurate deep network for disparity estimation named FADNet with three main features: 1) It exploits efficient 2D based correlation layers with stacked blocks to preserve fast computation; 2) It combines the residual structures to make the deeper model easier to learn; 3) It contains multi-scale predictions so as to exploit a multi-scale weight scheduling training technique to improve the accuracy. We conduct experiments to demonstrate the effectiveness of FADNet on two popular datasets, Scene Flow and KITTI 2015. Experimental results show that FADNet achieves state-of-the-art prediction accuracy, and runs at a significant order of magnitude faster speed than existing 3D models. The codes of FADNet are available at https://github.com/HKBU-HPML/FADNet.
keywords: {Estimation;Convolution;Correlation;Three-dimensional displays;Training;Feature extraction;Computer architecture},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197031&isnumber=9196508

S. Kuutti, S. Fallah and R. Bowden, "Training Adversarial Agents to Exploit Weaknesses in Deep Control Policies," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 108-114.
doi: 10.1109/ICRA40945.2020.9197351
Abstract: Deep learning has become an increasingly common technique for various control problems, such as robotic arm manipulation, robot navigation, and autonomous vehicles. However, the downside of using deep neural networks to learn control policies is their opaque nature and the difficulties of validating their safety. As the networks used to obtain state-of-the-art results become increasingly deep and complex, the rules they have learned and how they operate become more challenging to understand. This presents an issue, since in safety-critical applications the safety of the control policy must be ensured to a high confidence level. In this paper, we propose an automated black box testing framework based on adversarial reinforcement learning. The technique uses an adversarial agent, whose goal is to degrade the performance of the target model under test. We test the approach on an autonomous vehicle problem, by training an adversarial reinforcement learning agent, which aims to cause a deep neural network-driven autonomous vehicle to collide. Two neural networks trained for autonomous driving are compared, and the results from the testing are used to compare the robustness of their learned control policies. We show that the proposed framework is able to find weaknesses in both control policies that were not evident during online testing and therefore, demonstrate a significant benefit over manual testing methods.
keywords: {Testing;Autonomous vehicles;Training;Learning (artificial intelligence);Machine learning;Robots;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197351&isnumber=9196508

S. Nair, M. Babaeizadeh, C. Finn, S. Levine and V. Kumar, "TRASS: Time Reversal as Self-Supervision," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 115-121.
doi: 10.1109/ICRA40945.2020.9196862
Abstract: A longstanding challenge in robot learning for manipulation tasks has been the ability to generalize to varying initial conditions, diverse objects, and changing objectives. Learning based approaches have shown promise in producing robust policies, but require heavy supervision and large number of environment interactions, especially from visual inputs. We propose a novel self-supervision technique that uses time-reversal to provide high level supervision to reach goals. In particular, we introduce the time-reversal model (TRM), a self-supervised model which explores outward from a set of goal states and learns to predict these trajectories in reverse. This provides a high level plan towards goals, allowing us to learn complex manipulation tasks with no demonstrations or exploration at test time. We test our method on the domain of assembly, specifically the mating of tetris-style block pairs. Using our method operating atop visual model predictive control, we are able to assemble tetris blocks on a KuKa IIWA-7 using only uncalibrated RGB camera input, and generalize to unseen block pairs. Project's-page: https://sites.google.com/view/time-reversal.
keywords: {Task analysis;Trajectory;Robots;Transmission line measurements;Visualization;Predictive models;Grippers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196862&isnumber=9196508

M. P. Strub and J. D. Gammell, "Advanced BIT (ABIT): Sampling-Based Planning with Advanced Graph-Search Techniques," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 130-136.
doi: 10.1109/ICRA40945.2020.9196580
Abstract: Path planning is an active area of research essential for many applications in robotics. Popular techniques include graph-based searches and sampling-based planners. These approaches are powerful but have limitations.This paper continues work to combine their strengths and mitigate their limitations using a unified planning paradigm. It does this by viewing the path planning problem as the two subproblems of search and approximation and using advanced graph-search techniques on a sampling-based approximation.This perspective leads to Advanced BIT*. ABIT* combines truncated anytime graph-based searches, such as ATD*, with anytime almost-surely asymptotically optimal sampling-based planners, such as RRT*. This allows it to quickly find initial solutions and then converge towards the optimum in an anytime manner. ABIT* outperforms existing single-query, sampling- based planners on the tested problems in ‚Ñù4 and ‚Ñù8, and was demonstrated on real-world problems with NASA/JPL-Caltech.
keywords: {Planning;Approximation algorithms;Search problems;Path planning;Robots;Acceleration;Conferences},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196580&isnumber=9196508

S. Dorn, N. Wolpert and E. Sch√∂mer, "Voxel-based General Voronoi Diagram for Complex Data with Application on Motion Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 137-143.
doi: 10.1109/ICRA40945.2020.9196775
Abstract: One major challenge in Assembly Sequence Planning (ASP) for complex real-world CAD-scenarios is to find appropriate disassembly paths for all assembled parts. Such a path places demands on its length and clearance. In the past, it became apparent that planning the disassembly path based on the (approximate) General Voronoi Diagram (GVD) is a good approach to achieve these requirements. But for complex real-world data, every known solution for computing the GVD is either too slow or very memory consuming, even if only approximating the GVD.We present a new approach for computing the approximate GVD and demonstrate its practicability using a representative vehicle data set. We can calculate an approximation of the GVD within minutes and meet the accuracy requirement of some few millimeters for the subsequent path planning. This is achieved by voxelizing the surface with a common error-bounded GPU render approach. We then use an error-bounded wavefront propagation technique and combine it with a novel hash table-based data structure, the so-called Voronoi Voxel History (VVH). On top of the GVD, we present a novel approach for the creation of a General Voronoi Diagram Graph (GVDG) that leads to an extensive roadmap. For the later motion planning task this roadmap can be used to suggest appropriate disassembly paths.
keywords: {Octrees;Planning;Three-dimensional displays;Approximation algorithms;Task analysis;Runtime},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196775&isnumber=9196508

L. Koutras and Z. Doulgeri, "Dynamic Movement Primitives for moving goals with temporal scaling adaptation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 144-150.
doi: 10.1109/ICRA40945.2020.9196765
Abstract: In this work, we propose an augmentation to the Dynamic Movement Primitives (DMP) framework which allows the system to generalize to moving goals without the use of any known or approximation model for estimating the goal's motion. We aim to maintain the demonstrated velocity levels during the execution to the moving goal, generating motion profiles appropriate for human robot collaboration. The proposed method employs a modified version of a DMP, learned by a demonstration to a static goal, with adaptive temporal scaling in order to achieve reaching of the moving goal with the learned kinematic pattern. Only the current position and velocity of the goal are required. The goal's reaching error and its derivative is proved to converge to zero via contraction analysis. The theoretical results are verified by simulations and experiments on a KUKA LWR4+ robot.
keywords: {Trajectory;Robots;Dynamics;Encoding;Collaboration;Adaptation models;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196765&isnumber=9196508

C. Huang et al., "Navigating Discrete Difference Equation Governed WMR by Virtual Linear Leader Guided HMPC," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 151-157.
doi: 10.1109/ICRA40945.2020.9197375
Abstract: In this paper, we revisit model predictive control (MPC) for the classical wheeled mobile robot (WMR) navigation problem. We prove that the reachable set based hierarchical MPC (HMPC), a state-of-the-art MPC, cannot handle WMR navigation in theory due to the non-existence of non-trivial linear system with an under-approximate reachable set of WMR. Nevertheless, we propose a virtual linear leader guided MPC (VLL-MPC) to enable HMPC structure. Different from current HMPCs, we use a virtual linear system with an under-approximate path set rather than the traditional trace set to guide the WMR. We provide a valid construction of the virtual linear leader. We prove the stability of VLL-MPC, and discuss its complexity. In the experiment, we demonstrate the advantage of VLL-MPC empirically by comparing it with NMPC, LMPC and anytime RRT* in several scenarios.
keywords: {Navigation;Linear systems;Stability analysis;Planning;Robots;Mathematical model;Nonlinear dynamical systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197375&isnumber=9196508

R. A. Moan, V. M. Baez, A. T. Becker and J. M. O‚ÄôKane, "Aggregation and localization of simple robots in curved environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 165-171.
doi: 10.1109/ICRA40945.2020.9197198
Abstract: This paper is about the closely-related problems of localization and aggregation for extremely simple robots, for which the only available action is to move in a given direction as far as the geometry of the environment allows. Such problems may arise, for example, in biomedical applications, wherein a large group of tiny robots moves in response to a shared external stimulus. Specifically, we extend the prior work on these kinds of problems presenting two algorithms for localization in environments with curved (rather than polygonal) boundaries and under low-friction models of interaction with the environment boundaries. We present both simulations and physical demonstrations to validate the approach.
keywords: {Robot sensing systems;Collision avoidance;Computational modeling;Biological system modeling;Propulsion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197198&isnumber=9196508

T. Nishio et al., "Stable Control in Climbing and Descending Flight under Upper Walls using Ceiling Effect Model based on Aerodynamics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 172-178.
doi: 10.1109/ICRA40945.2020.9197137
Abstract: Stable flight control under ceilings is difficult for multirotor Unmanned Aerial Vehicles (UAVs). The wake interaction between rotors and upper walls, called the "ceiling effect", causes an increase of rotor thrust. As a result of the thrust increase, multi-rotors are drawn upward abruptly and collide with ceilings. In previous work, several thrust models of the ceiling effect have been proposed for stable flight under ceilings, assuming that the airflow around rotors is in steady states. However, the airflow around rotors in vertical flight is not in steady states and each thrust model in previous work is skillfully determined based on large amounts of precise experimental data. In this paper, we introduce an aerodynamics-based thrust model and a stable control method under ceilings. This model is derived from the momentum theory and the relationship between vertical climbing/descending rates of rotors and an induced velocity. To confirm our proposed model, we collect thrust data at various vertical rates in flight. In addition, we use only onboard sensors to estimate selfstate for structural inspections. Consequently, we reveal that the proposed model is consistent with the experimental results. Based on an aerodynamic model, we need not collect large amounts of precise experimental data to realize stable flight. Furthermore, the vertical flight tests under ceilings demonstrate that our in-unsteady-state-model-based controller outperforms the conventional steady-state ones.
keywords: {Rotors;Data models;Adaptation models;Aerodynamics;Steady-state;Atmospheric modeling;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197137&isnumber=9196508

M. Dharmadhikari et al., "Motion Primitives-based Path Planning for Fast and Agile Exploration using Aerial Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 179-185.
doi: 10.1109/ICRA40945.2020.9196964
Abstract: This paper presents a novel path planning strategy for fast and agile exploration using aerial robots. Tailored to the combined need for large-scale exploration of challenging and confined environments, despite the limited endurance of micro aerial vehicles, the proposed planner employs motion primitives to identify admissible paths that search the configuration space, while exploiting the dynamic flight properties of small aerial robots. Utilizing a computationally efficient volumetric representation of the environment, the planner provides fast collision-free and future-safe paths that maximize the expected exploration gain and ensure continuous fast navigation through the unknown environment. The new method is field-verified in a set of deployments relating to subterranean exploration and specifically, in both modern and abandoned underground mines in Northern Nevada utilizing a 0.55m-wide collision-tolerant flying robot exploring with a speed of up to 2m/s and navigating sections with width as small as 0.8m.
keywords: {Vehicle dynamics;Collision avoidance;Path planning;Unmanned aerial vehicles;Educational robots;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196964&isnumber=9196508

V. Sindhwani, H. Sidahmed, K. Choromanski and B. Jones, "Unsupervised Anomaly Detection for Self-flying Delivery Drones," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 186-192.
doi: 10.1109/ICRA40945.2020.9197074
Abstract: We propose a novel anomaly detection framework for a fleet of hybrid aerial vehicles executing high-speed package pickup and delivery missions. The detection is based on machine learning models of normal flight profiles, trained on millions of flight log measurements of control inputs and sensor readings. We develop a new scalable algorithm for robust regression which can simultaneously fit predictive flight dynamics models while identifying and discarding abnormal flight missions from the training set. The resulting unsupervised estimator has a very high breakdown point and can withstand massive contamination of training data to uncover what normal flight patterns look like, without requiring any form of prior knowledge of aircraft aerodynamics or manual labeling of anomalies upfront. Across many different anomaly types, spanning simple 3sigma statistical thresholds to turbulence and other equipment anomalies, our models achieve high detection rates across the board. Our method consistently outperforms alternative robust detection methods on synthetic benchmark problems. To the best of our knowledge, dynamics modeling of hybrid delivery drones for anomaly detection at the scale of 100 million measurements from 5000 real flight missions in variable flight conditions is unprecedented.
keywords: {Aerodynamics;Smoothing methods;Robustness;Training;Anomaly detection;Optimization;Aircraft},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197074&isnumber=9196508

Y. Li, C. Fu, Z. Huang, Y. Zhang and J. Pan, "Keyfilter-Aware Real-Time UAV Object Tracking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 193-199.
doi: 10.1109/ICRA40945.2020.9196943
Abstract: Correlation filter-based tracking has been widely applied in unmanned aerial vehicle (UAV) with high efficiency. However, it has two imperfections, i.e., boundary effect and filter corruption. Several methods enlarging the search area can mitigate boundary effect, yet introducing undesired background distraction. Existing frame-by-frame context learning strategies for repressing background distraction nevertheless lower the tracking speed. Inspired by keyframe-based simultaneous localization and mapping, keyfilter is proposed in visual tracking for the first time, in order to handle the above issues efficiently and effectively. Keyfilters generated by periodically selected keyframes learn the context intermittently and are used to restrain the learning of filters, so that 1) context awareness can be transmitted to all the filters via keyfilter restriction, and 2) filter corruption can be repressed. Compared to the state-of-the-art results, our tracker performs better on two challenging benchmarks, with enough speed for UAV real-time applications.
keywords: {Unmanned aerial vehicles;Correlation;Visualization;Object tracking;Frequency-domain analysis;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196943&isnumber=9196508

F. Shi, M. Zhao, M. Murooka, K. Okada and M. Inaba, "Aerial Regrasping: Pivoting with Transformable Multilink Aerial Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 200-207.
doi: 10.1109/ICRA40945.2020.9196576
Abstract: Regrasping is one of the most common and important manipulation skills used in our daily life. However, aerial regrasping has not been seriously investigated yet, since most of the aerial manipulator lacks dexterous manipulation abilities except for the basic pick-and-place. In this paper, we focus on pivoting a long box, which is one of the most classical problems among regrasping researches, using a transformable multilink aerial robot. First, we improve our previous controller by compensating for the external wrench. Second, we optimize the joints configuration of our transformable multilink drone for stable grasping form under the constraints of thrust force and joints effort. Third, we sequentially optimize the grasping force in the pivoting process. The optimization goal is to generate continous grasping force whilst maximizing the friction force in case of the downwash, which would influence the grasped object and is difficult to model. Fourth, we develop the impedance controller in joint space and admittance controller in task space. As far as we know, it is the first research to achieve extrinsic contact-aware regrasping task on aerial robots.
keywords: {Task analysis;Force;Grasping;Unmanned aerial vehicles;Rotors;End effectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196576&isnumber=9196508

M. Berg, D. Bayazit, R. Mathew, A. Rotter-Aboyoun, E. Pavlick and S. Tellex, "Grounding Language to Landmarks in Arbitrary Outdoor Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 208-215.
doi: 10.1109/ICRA40945.2020.9197068
Abstract: Robots operating in outdoor, urban environments need the ability to follow complex natural language commands which refer to never-before-seen landmarks. Existing approaches to this problem are limited because they require training a language model for the landmarks of a particular environment before a robot can understand commands referring to those landmarks. To generalize to new environments outside of the training set, we present a framework that parses references to landmarks, then assesses semantic similarities between the referring expression and landmarks in a predefined semantic map of the world, and ultimately translates natural language commands to motion plans for a drone. This framework allows the robot to ground natural language phrases to landmarks in a map when both the referring expressions to landmarks and the landmarks themselves have not been seen during training. We test our framework with a 14-person user evaluation demonstrating an end-to-end accuracy of 76.19% in an unseen environment. Subjective measures show that users find our system to have high performance and low workload. These results demonstrate our approach enables untrained users to control a robot in large unseen outdoor environments with unconstrained natural language.
keywords: {Natural languages;Semantics;Robots;Grounding;Training;Planning;Databases},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197068&isnumber=9196508

I. Nishitani, H. Yang, R. Guo, S. Keshavamurthy and K. Oguchi, "Deep Merging: Vehicle Merging Controller Based on Deep Reinforcement Learning with Embedding Network," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 216-221.
doi: 10.1109/ICRA40945.2020.9197559
Abstract: Vehicles at highway merging sections must make lane changes to join the highway. This lane change can generate congestion. To reduce congestion, vehicles should merge so as not to affect traffic flow as much as possible. In our study, we propose a vehicle controller called Deep Merging that uses deep reinforcement learning to improve the merging efficiency of vehicles while considering the impact on traffic flow. The system uses the images of a merging section as input to output the target vehicle speed. Moreover, an embedding network for estimating the controlled vehicle speed is introduced to the deep reinforcement learning network architecture to improve the learning efficiency. In order to show the effectiveness of the proposed method, the merging behavior and traffic conditions in several situations are verified by experiments using a traffic simulator. Through these experiments, it is confirmed that the proposed method enables controlled vehicles to effectively merge without adversely affecting to the traffic flow.
keywords: {Merging;Machine learning;Feature extraction;Acceleration;Road transportation;Vehicle dynamics;Network architecture},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197559&isnumber=9196508

S. Chadwick and P. Newman, "Radar as a Teacher: Weakly Supervised Vehicle Detection using Radar Labels," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 222-228.
doi: 10.1109/ICRA40945.2020.9196855
Abstract: It has been demonstrated that the performance of an object detector degrades when it is used outside the domain of the data used to train it. However, obtaining training data for a new domain can be time consuming and expensive. In this work we demonstrate how a radar can be used to generate plentiful (but noisy) training data for image-based vehicle detection. We then show that the performance of a detector trained using the noisy labels can be considerably improved through a combination of noise-aware training techniques and relabelling of the training data using a second viewpoint. In our experiments, using our proposed process improves average precision by more than 17 percentage points when training from scratch and 10 percentage points when fine-tuning a pre-trained model.
keywords: {Training;Noise measurement;Training data;Radar imaging;Labeling;Lenses},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196855&isnumber=9196508

K. Brandes, A. Wang and R. Shah, "Robust Lane Detection with Binary Integer Optimization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 229-235.
doi: 10.1109/ICRA40945.2020.9197098
Abstract: Formula Student Driverless (FSD) is a competition where student teams compete to build an autonomous racecar. The main dynamic event in FSD is trackdrive, where the racecar traverses an unknown track with lanes demarcated by cones. One major challenge of the event is to determine the boundaries of the lane from cones perceived online despite false positive cone detections and sharp turns. We present a binary integer optimization to address this problem by leveraging a priori knowledge from competition rules on parameters such as average cone spacings and minimum track width. In this paper, we describe our approach, and analyze its latency, accuracy, and robustness to false positive cone detections. This approach is used on-board to solve the lane detection problem during the competition in real-time.
keywords: {Automobiles;Optimization;Robustness;Meters;Roads;Real-time systems;Pipelines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197098&isnumber=9196508

Z. Liu et al., "A Synchronization Approach for Achieving Cooperative Adaptive Cruise Control Based Non-Stop Intersection Passing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 236-242.
doi: 10.1109/ICRA40945.2020.9196991
Abstract: Cooperative adaptive cruise control (CACC) of intelligent vehicles contributes to improving cruise control performance, reducing traffic congestion, saving energy and increasing traffic flow capacity. In this paper, we resolve the CACC problem from the viewpoint of synchronization control, our main idea is to introduce the spatial-temporal synchronization mechanism into vehicle platoon control to achieve the robust CACC and to further realize the non-stop intersection control. Firstly, by introducing the cross-coupling based space synchronization mechanism, a distributed control algorithm is presented to achieve the single-lane CACC in the presence of vehicle-to-vehicle (V2V) communications, which enables autonomous vehicles to track the desired platoon trajectory while synchronizing their longitudinal velocities to keeping the expected inter-vehicle distance. Secondly, by designing the enter-time scheduling mechanism (temporal synchronization), a high-level intersection control strategy is proposed to command vehicles to form a virtual platoon to pass through the intersection without stopping. Thirdly, a Lyapunov-based time-domain stability analysis approach is presented. Compared with the traditional string stability based approach, the proposed approach guarantees the global asymptotical convergence of the proposed CACC system. Experiments in the small-scale simulated system demonstrate the effectiveness of the proposed approach.
keywords: {Synchronization;Stability analysis;Cruise control;Robustness;Autonomous vehicles;Motion control;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196991&isnumber=9196508

J. Hawke et al., "Urban Driving with Conditional Imitation Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 251-257.
doi: 10.1109/ICRA40945.2020.9197408
Abstract: Hand-crafting generalised decision-making rules for real-world urban autonomous driving is hard. Alternatively, learning behaviour from easy-to-collect human driving demonstrations is appealing. Prior work has studied imitation learning (IL) for autonomous driving with a number of limitations. Examples include only performing lane-following rather than following a user-defined route, only using a single camera view or heavily cropped frames lacking state observability, only lateral (steering) control, but not longitudinal (speed) control and a lack of interaction with traffic. Importantly, the majority of such systems have been primarily evaluated in simulation - a simple domain, which lacks real-world complexities. Motivated by these challenges, we focus on learning representations of semantics, geometry and motion with computer vision for IL from human driving demonstrations. As our main contribution, we present an end-to-end conditional imitation learning approach, combining both lateral and longitudinal control on a real vehicle for following urban routes with simple traffic. We address inherent dataset bias by data balancing, training our final policy on approximately 30 hours of demonstrations gathered over six months. We evaluate our method on an autonomous vehicle by driving 35km of novel routes in European urban streets.
keywords: {Cameras;Sensor fusion;Autonomous vehicles;Roads;Computational modeling;Aerospace electronics;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197408&isnumber=9196508

R. Asghar, M. Garz√≥n, J. Lussereau and C. Laugier, "Vehicle Localization Based on Visual Lane Marking and Topological Map Matching," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 258-264.
doi: 10.1109/ICRA40945.2020.9197543
Abstract: Accurate and reliable localization is crucial to autonomous vehicle navigation and driver assistance systems. This paper presents a novel approach for online vehicle localization in a digital map. Two distinct map matching algorithms are proposed: i) Iterative Closest Point (ICP) based lane level map matching is performed with visual lane tracker and grid map ii) decision-rule based approach is used to perform topological map matching. Results of both the map matching algorithms are fused together with GPS and dead reckoning using Extended Kalman Filter to estimate vehicle's pose relative to the map. The proposed approach has been validated on real life conditions on an equipped vehicle. Detailed analysis of the experimental results show improved localization using the two aforementioned map matching algorithms.
keywords: {Roads;Iterative closest point algorithm;Global Positioning System;Dead reckoning;Sensors;Visualization;Cameras;Map Relative Localization;Topological Map Matching;Lane Level Matching;Autonomous Vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197543&isnumber=9196508

C. S√°nchez-Belenguer, E. Wolfart and V. Sequeira, "RISE: A Novel Indoor Visual Place Recogniser," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 265-271.
doi: 10.1109/ICRA40945.2020.9196871
Abstract: This paper presents a new technique to solve the Indoor Visual Place Recognition problem from the Deep Learning perspective. It consists on an image retrieval approach supported by a novel image similarity metric. Our work uses a 3D laser sensor mounted on a backpack with a calibrated spherical camera i) to generate the data for training the deep neural network and ii) to build a database of geo-referenced images for an environment. The data collection stage is fully automatic and requires no user intervention for labelling. Thanks to the 3D laser measurements and the spherical panoramas, we can efficiently survey large indoor areas in a very short time. The underlying 3D data associated to the map allows us to define the similarity between two training images as the geometric overlap between the observed pixels. We exploit this similarity metric to effectively train a CNN that maps images into compact embeddings. The goal of the training is to ensure that the L2 distance between the embeddings associated to two images is small when they are observing the same place and large when they are observing different places. After the training, similarities between a query image and the geo-referenced images in the database are efficiently retrieved by performing a nearest neighbour search in the embeddings space.
keywords: {Training;Deep learning;Visualization;Three-dimensional displays;Databases;Neural networks;Lasers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196871&isnumber=9196508

J. Quenzel, R. A. Rosu, T. L√§be, C. Stachniss and S. Behnke, "Beyond Photometric Consistency: Gradient-based Dissimilarity for Improving Visual Odometry and Stereo Matching," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 272-278.
doi: 10.1109/ICRA40945.2020.9197483
Abstract: Pose estimation and map building are central ingredients of autonomous robots and typically rely on the registration of sensor data. In this paper, we investigate a new metric for registering images that builds upon on the idea of the photometric error. Our approach combines a gradient orientation-based metric with a magnitude-dependent scaling term. We integrate both into stereo estimation as well as visual odometry systems and show clear benefits for typical disparity and direct image registration tasks when using our proposed metric. Our experimental evaluation indicate that our metric leads to more robust and more accurate estimates of the scene depth as well as camera trajectory. Thus, the metric improves camera pose estimation and in turn the mapping capabilities of mobile robots. We believe that a series of existing visual odometry and visual SLAM systems can benefit from the findings reported in this paper.
keywords: {Measurement;Robustness;Cameras;Estimation;Visual odometry;Simultaneous localization and mapping;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197483&isnumber=9196508

P. Sodhi, S. Choudhury, J. G. Mangelson and M. Kaess, "ICS: Incremental Constrained Smoothing for State Estimation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 279-285.
doi: 10.1109/ICRA40945.2020.9196649
Abstract: A robot operating in the world constantly receives information about its environment in the form of new measurements at every time step. Smoothing-based estimation methods seek to optimize for the most likely robot state estimate using all measurements up till the current time step. Existing methods solve for this smoothing objective efficiently by framing the problem as that of incremental unconstrained optimization. However, in many cases observed measurements and knowledge of the environment is better modeled as hard constraints derived from real-world physics or dynamics. A key challenge is that the new optimality conditions introduced by the hard constraints break the matrix structure needed for incremental factorization in these incremental optimization methods. Our key insight is that if we leverage primal-dual methods, we can recover a matrix structure amenable to incremental factorization. We propose a framework ICS that combines a primal-dual method like the Augmented Lagrangian with an incremental Gauss Newton approach that reuses previously computed matrix factorizations. We evaluate ICS on a set of simulated and real-world problems involving equality constraints like object contact and inequality constraints like collision avoidance.
keywords: {Optimization;Smoothing methods;Time measurement;Integrated circuits;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196649&isnumber=9196508

V. Delafontaine, F. Schiano, G. Cocco, A. Rusu and D. Floreano, "Drone-aided Localization in LoRa IoT Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 286-292.
doi: 10.1109/ICRA40945.2020.9196869
Abstract: Besides being part of the Internet of Things (IoT), drones can play a relevant role in it as enablers. The 3D mobility of UAVs can be exploited to improve node localization in IoT networks for, e.g., search and rescue or goods localization and tracking. One of the widespread IoT communication technologies is Long Range Wide Area Network (LoRaWAN), which allows achieving long communication distances with low power. In this work, we present a drone-aided localization system for LoRa networks in which a UAV is used to improve the estimation of a node's location initially provided by the network. We characterize the relevant parameters of the communication system and use them to develop and test a search algorithm in a realistic simulated scenario. We then move to the full implementation of a real system in which a drone is seamlessly integrated into Swisscom's LoRa network. The drone coordinates with the network with a two-way exchange of information which results in an accurate and fully autonomous localization system. The results obtained in our field tests show a ten-fold improvement in localization precision with respect to the estimation provided by the fixed network. Up to our knowledge, this is the first time a UAV is successfully integrated in a LoRa network to improve its localization accuracy.
keywords: {Logic gates;Drones;Estimation;Receivers;Servers;Internet of Things;Global navigation satellite system},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196869&isnumber=9196508

J. Wietrzykowski and P. Skrzypczy≈Ñski, "A fast and practical method of indoor localization for resource-constrained devices with limited sensing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 293-299.
doi: 10.1109/ICRA40945.2020.9197215
Abstract: We describe and experimentally demonstrate a practical method for indoor localization using measurements obtained from resource-constrained devices with limited sensing capabilities. We focus on handheld/mobile devices but the method can be useful for a variety of wearable devices. Our system works with sparse WiFi or image-based measurements, avoiding laborious site surveying for dense signal maps and runs in real-time. It uses Conditional Random Fields to infer the most probable sequence of agent positions from a known floor plan, dead reckoning and sparse absolute position estimates. Our solution leverages known topology of the environment by pre-computing allowed motion sequences of an agent, which are then used to constraint the motion inferred from the sensory data. The system is evaluated in a typical office building, demonstrating good accuracy and robustness to sparse, low-quality measurements.
keywords: {Wireless fidelity;Position measurement;Computational modeling;Dead reckoning;Robot sensing systems;Buildings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197215&isnumber=9196508

L. Nardi and C. Stachniss, "Long-Term Robot Navigation in Indoor Environments Estimating Patterns in Traversability Changes," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 300-306.
doi: 10.1109/ICRA40945.2020.9197078
Abstract: Nowadays, mobile robots are deployed in many indoor environments such as offices or hospitals. These environments are subject to changes in the traversability that often happen following patterns. In this paper, we investigate the problem of navigating in such environments over extended periods of time by capturing and exploiting these patterns to make informed decisions for navigation. Our approach uses a probabilistic graphical model to incrementally estimate a model of the traversability changes from the robot's observations and to make predictions at currently unobserved locations. In the belief space defined by the predictions, we plan paths that trade off the risk to encounter obstacles and the information gain of visiting unknown locations. We implemented our approach and tested it in different indoor environments. The experiments suggest that, in the long run, our approach leads robots to navigate along shorter paths compared to following a greedy shortest path policy.
keywords: {Robots;Navigation;Predictive models;Correlation;Probabilistic logic;Planning;Indoor environments},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197078&isnumber=9196508

C. -Y. Kuo, Y. Cui and T. Matsubara, "Sample-and-computation-efficient Probabilistic Model Predictive Control with Random Features," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 307-313.
doi: 10.1109/ICRA40945.2020.9197449
Abstract: Gaussian processes (GPs) based Reinforcement Learning (RL) methods with Model Predictive Control (MPC) have demonstrated their excellent sample efficiency. However, since the computational cost of GPs largely depends on the training sample size, learning an accurate dynamics using GPs result in low control frequency in MPC. To alleviate this trade-off and achieve a sample-and-computation-efficient nature, we propose a novel model-based RL method with MPC. Our approach employs a linear Gaussian model with randomized features using the Fastfood as an approximated GP dynamics. Then, we derive an analytic moment-matching scheme in state prediction with the model and uncertain inputs. As a result, the computational cost of the MPC in our RL method does not depend on the training sample size and can improve the control frequency over previous methods. Through experiments with simulated and real robot control tasks, the sample efficiency, as well as the computation efficiency of our model-based RL method, are demonstrated.
keywords: {Training;Predictive models;Kernel;Probabilistic logic;Computational modeling;Computational efficiency;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197449&isnumber=9196508

J. A. Delgado-Guerrero, A. Colom√© and C. Torras, "Sample-Efficient Robot Motion Learning using Gaussian Process Latent Variable Models," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 314-320.
doi: 10.1109/ICRA40945.2020.9196658
Abstract: Robotic manipulators are reaching a state where we could see them in household environments in the following decade. Nevertheless, such robots need to be easy to instruct by lay people. This is why kinesthetic teaching has become very popular in recent years, in which the robot is taught a motion that is encoded as a parametric function - usually a Movement Primitive (MP)-. This approach produces trajectories that are usually suboptimal, and the robot needs to be able to improve them through trial-and-error. Such optimization is often done with Policy Search (PS) reinforcement learning, using a given reward function. PS algorithms can be classified as model-free, where neither the environment nor the reward function are modelled, or model-based, which can use a surrogate model of the reward function and/or a model for the dynamics of the task. However, MPs can become very high-dimensional in terms of parameters, which constitute the search space, so their optimization often requires too many samples. In this paper, we assume we have a robot motion task characterized with an MP of which we cannot model the dynamics. We build a surrogate model for the reward function, that maps an MP parameter latent space (obtained through a Mutual-information-weighted Gaussian Process Latent Variable Model) into a reward. While we do not model the task dynamics, using mutual information to shrink the task space makes it more consistent with the reward and so the policy improvement is faster in terms of sample efficiency.
keywords: {Gaussian processes;Optimization;Trajectory;Task analysis;Robots;Mutual information;Kernel},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196658&isnumber=9196508

N. Raj, A. Simha, M. Kothari, Abhishek and R. N. Banavar, "Iterative Learning based feedforward control for Transition of a Biplane-Quadrotor Tailsitter UAS," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 321-327.
doi: 10.1109/ICRA40945.2020.9196671
Abstract: This paper provides a real time on-board algorithm for a biplane-quadrotor to iteratively learn a forward transition maneuver via repeated flight trials. The maneuver is controlled by regulating the pitch angle and propeller thrust according to feedforward control laws that are parameterized by polynomials. Based on a nominal model with simplified aerodynamics, the optimal coefficients of the polynomials are chosen through simulation such that the maneuver is completed with specified terminal conditions on altitude and air speed. In order to compensate for modeling errors, repeated flight trials are performed by updating the feedforward control parameters according to an iterative learning algorithm until the maneuver is perfected. A geometric attitude controller, valid for all flight modes is employed in order to track the pitch angle according to the feedforward law. Further, a high-fidelity thrust model of the propeller for varying advance-ratio and orientation angle is obtained from wind tunnel data which is captured using a neural network model. This facilitates accurate application of feedforward thrust for varying flow conditions during transition. Experimental flight trials are performed to demonstrate the robustness and rapid convergence of the proposed learning algorithm.
keywords: {Aerodynamics;Propellers;Wind tunnels;Atmospheric modeling;Feedforward systems;Data models;Trajectory;VTOL UAS;transition maneuver;iterative learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196671&isnumber=9196508

J. -R. Betterton, D. Ratner, S. Webb and M. Kochenderfer, "Reinforcement Learning for Adaptive Illumination with X-rays," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 328-334.
doi: 10.1109/ICRA40945.2020.9196614
Abstract: We propose a learning algorithm for automating image sampling in scientific applications. We consider settings where images are sampled by controlling a probe beam's scanning trajectory over the image surface. We explore alternatives to obtaining images by the standard rastering method. We formulate the scanner control problem as a reinforcement learning (RL) problem and train a policy to adaptively sample only the highest value regions of the image, choosing the acquisition time and resolution for each sample position based on an observation of previous readings. We use convolutional neural network (CNN) policies to control the scanner as a way to generalize our approach to larger samples. We show simulation results for a simple policy on both synthetic data and real world data from an archaeological application.
keywords: {Apertures;Trajectory;Learning (artificial intelligence);Time measurement;Imaging;Image reconstruction;X-rays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196614&isnumber=9196508

K. M. Brian Lee, W. Martens, J. Khatkar, R. Fitch and R. Mettu, "Efficient Updates for Data Association with Mixtures of Gaussian Processes," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 335-341.
doi: 10.1109/ICRA40945.2020.9196734
Abstract: Gaussian processes (GPs) enable a probabilistic approach to important estimation and classification tasks that arise in robotics applications. Meanwhile, most GP-based methods are often prohibitively slow, thereby posing a substantial barrier to practical applications. Existing "sparse" methods to speed up GPs seek to either make the model more sparse, or find ways to more efficiently manage a large covariance matrix. In this paper, we present an orthogonal approach that memoises (i.e. reuses) previous computations in GP inference. We demonstrate that a substantial speedup can be achieved by incorporating memoisation into applications in which GPs must be updated frequently. Moreover, we derive a novel online update scheme for sparse GPs that can be used in conjunction with our memoisation approach for a synergistic improvement in performance. Across three robotic vision applications, we demonstrate between 40-100% speed-up over the standard method for inference in GP mixtures.
keywords: {Covariance matrices;Robots;Gaussian processes;Mixture models;Sparse representation;Inference algorithms;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196734&isnumber=9196508

H. Peng, X. Yang, Y. -H. Su and B. Hannaford, "Real-time Data Driven Precision Estimator for RAVEN-II Surgical Robot End Effector Position," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 350-356.
doi: 10.1109/ICRA40945.2020.9196915
Abstract: Surgical robots have been introduced to operating rooms over the past few decades due to their high sensitivity, small size, and remote controllability. The cable-driven nature of many surgical robots allows the systems to be dexterous and lightweight, with diameters as low as 5mm. However, due to the slack and stretch of the cables and the backlash of the gears, inevitable uncertainties are brought into the kinematics calcu-lation [1]. Since the reported end effector position of surgical robots like RAVEN-II [2] is directly calculated using the motor encoder measurements and forward kinematics, it may contain relatively large error up to 10mm, whereas semi-autonomous functions being introduced into abdominal surgeries require position inaccuracy of at most 1mm. To resolve the problem, a cost-effective, real-time and data-driven pipeline for robot end effector position precision estimation is proposed and tested on RAVEN-II. Analysis shows an improved end effector position error of around 1mm RMS traversing through the entire robot workspace without high-resolution motion tracker. The open source code, data sets, videos, and user guide can be found at //github.com/HaonanPeng/RAVEN Neural Network Estimator.
keywords: {End effectors;Cameras;Medical robotics;Robot sensing systems;Image edge detection;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196915&isnumber=9196508

Y. Qin et al., "Temporal Segmentation of Surgical Sub-tasks through Deep Learning with Multiple Data Sources," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 371-377.
doi: 10.1109/ICRA40945.2020.9196560
Abstract: Many tasks in robot-assisted surgeries (RAS) can be represented by finite-state machines (FSMs), where each state represents either an action (such as picking up a needle) or an observation (such as bleeding). A crucial step towards the automation of such surgical tasks is the temporal perception of the current surgical scene, which requires a real-time estimation of the states in the FSMs. The objective of this work is to estimate the current state of the surgical task based on the actions performed or events occurred as the task progresses. We propose Fusion-KVE, a unified surgical state estimation model that incorporates multiple data sources including the Kinematics, Vision, and system Events. Additionally, we examine the strengths and weaknesses of different state estimation models in segmenting states with different representative features or levels of granularity. We evaluate our model on the JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS), as well as a more complex dataset involving robotic intra-operative ultrasound (RIOUS) imaging, created using the da Vinci¬Æ Xi surgical system. Our model achieves a superior frame-wise state estimation accuracy up to 89.4%, which improves the state-of-the-art surgical state estimation models in both JIGSAWS suturing dataset and our RIOUS dataset.
keywords: {State estimation;Data models;Task analysis;Feature extraction;Hidden Markov models;Robots;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196560&isnumber=9196508

D. P. Losey, K. Srinivasan, A. Mandlekar, A. Garg and D. Sadigh, "Controlling Assistive Robots with Learned Latent Actions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 378-384.
doi: 10.1109/ICRA40945.2020.9197197
Abstract: Assistive robotic arms enable users with physical disabilities to perform everyday tasks without relying on a caregiver. Unfortunately, the very dexterity that makes these arms useful also makes them challenging to teleoperate: the robot has more degrees-of-freedom than the human can directly coordinate with a handheld joystick. Our insight is that we can make assistive robots easier for humans to control by leveraging latent actions. Latent actions provide a lowdimensional embedding of high-dimensional robot behavior: for example, one latent dimension might guide the assistive arm along a pouring motion. In this paper, we design a teleoperation algorithm for assistive robots that learns latent actions from task demonstrations. We formulate the controllability, consistency, and scaling properties that user-friendly latent actions should have, and evaluate how different lowdimensional embeddings capture these properties. Finally, we conduct two user studies on a robotic arm to compare our latent action approach to both state-of-the-art shared autonomy baselines and a teleoperation strategy currently used by assistive arms. Participants completed assistive eating and cooking tasks more efficiently when leveraging our latent actions, and also subjectively reported that latent actions made the task easier to perform. The video accompanying this paper can be found at: https://youtu.be/wjnhrzugBj4.
keywords: {Robot kinematics;Task analysis;Manipulators;Aerospace electronics;Robot sensing systems;Glass;Physically assistive devices;cognitive humanrobot interaction;human-centered robotics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197197&isnumber=9196508

V. D. Amara, J. Malzahn, Z. Ren, W. Roozing and N. Tsagarakis, "On the efficient control of series-parallel compliant articulated robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 385-391.
doi: 10.1109/ICRA40945.2020.9196786
Abstract: Torque distribution in redundant robots that combine the potential of asymmetric series-parallel actuated branches and multi-articulation pose a non-trivial challenge. To address the problem, this work proposes a novel optimization based controller that can accommodate various quadratic criteria to perform the torque distribution among dissimilar series and parallel actuators in order to maximize the motion efficiency. Three candidate criteria are composed and their performances are compared during periodic squat motions with a 3 degree of freedom series-parallel compliant articulated leg prototype. It is first shown that by minimizing a criterion that takes into account the actuator hardware specifications such as torque constant and transmission ratio, the gravity-driven phases can be lengthened. Thereby, this particular criterion results in slightly better performance than when adopting a strategy that maximizes the torque allocation to the higher efficiency actuators. Furthermore, valuable insights such as that the efficacy of maximum utilization of the highly-efficient parallel actuation branches decreases progressively at high frequencies were observed.
keywords: {Torque;Actuators;Joints;Tendons;Legged locomotion;Topology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196786&isnumber=9196508

D. Wisth, M. Camurri and M. Fallon, "Preintegrated Velocity Bias Estimation to Overcome Contact Nonlinearities in Legged Robot Odometry," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 392-398.
doi: 10.1109/ICRA40945.2020.9197214
Abstract: In this paper, we present a novel factor graph formulation to estimate the pose and velocity of a quadruped robot on slippery and deformable terrain. The factor graph introduces a preintegrated velocity factor that incorporates velocity inputs from leg odometry and also estimates related biases. From our experimentation we have seen that it is difficult to model uncertainties at the contact point such as slip or deforming terrain, as well as leg flexibility. To accommodate for these effects and to minimize leg odometry drift, we extend the robot's state vector with a bias term for this preintegrated velocity factor. The bias term can be accurately estimated thanks to the tight fusion of the preintegrated velocity factor with stereo vision and IMU factors, without which it would be unobservable. The system has been validated on several scenarios that involve dynamic motions of the ANYmal robot on loose rocks, slopes and muddy ground. We demonstrate a 26% improvement of relative pose error compared to our previous work and 52% compared to a state-of-the-art proprioceptive state estimator.
keywords: {Legged locomotion;Robot sensing systems;Velocity measurement;Estimation;Kinematics;Foot},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197214&isnumber=9196508

L. Chen, S. Ye, C. Sun, A. Zhang, G. Deng and T. Liao, "Optimized Foothold Planning and Posture Searching for Energy-Efficient Quadruped Locomotion over Challenging Terrains," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 399-405.
doi: 10.1109/ICRA40945.2020.9197135
Abstract: Energy-efficient locomotion is of primary importance for legged robot to extend operation time in practical applications. This paper presents an approach to achieve energy-efficient locomotion for a quadrupedal robot walking over challenging terrains. Firstly, we optimize the nominal stance parameters based on the analysis of leg torque distribution. Secondly, we proposed the foothold planner and the center of gravity (COG) trajectory planner working together to guide the robot to place its standing legs in an energy-saving stance posture. We have validated the effectiveness of our method on a real quadrupedal robot in experiments including autonomously walking on plain ground and climbing stairs.
keywords: {Legged locomotion;Torque;Thigh;Hip;Knee;Energy efficiency},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197135&isnumber=9196508

G. Bledt and S. Kim, "Extracting Legged Locomotion Heuristics with Regularized Predictive Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 406-412.
doi: 10.1109/ICRA40945.2020.9197488
Abstract: Optimization based predictive control is a powerful tool that has improved the ability of legged robots to execute dynamic maneuvers and traverse increasingly difficult terrains. However, it is often challenging and unintuitive to design meaningful cost functions and build high-fidelity models while adhering to timing restrictions. A novel framework to extract and design principled regularization heuristics for legged locomotion optimization control is presented. By allowing a simulation to fully explore the cost space offline, certain states and actions can be constrained or isolated. Data is fit with simple models relating the desired commands, optimal control actions, and robot states to identify new heuristic candidates. Basic parameter learning and adaptation laws are then applied to the models online. This method extracts simple, but powerful heuristics that can approximate complex dynamics and account for errors stemming from model simplifications and parameter uncertainty without the loss of physical intuition while generalizing the parameter tuning process. Results on the Mini Cheetah robot verify the increased capabilities due to the newly extracted heuristics without any modification to the controller structure or gains.
keywords: {Cost function;Legged locomotion;Data models;Tuning;Predictive control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197488&isnumber=9196508

T. Li, N. Lambert, R. Calandra, F. Meier and A. Rai, "Learning Generalizable Locomotion Skills with Hierarchical Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 413-419.
doi: 10.1109/ICRA40945.2020.9196642
Abstract: Learning to locomote to arbitrary goals on hardware remains a challenging problem for reinforcement learning. In this paper, we present a hierarchical framework that improves sample-efficiency and generalizability of learned locomotion skills on real-world robots. Our approach divides the problem of goal-oriented locomotion into two sub-problems: learning diverse primitives skills, and using model-based planning to sequence these skills. We parametrize our primitives as cyclic movements, improving sample-efficiency of learning from scratch on a 18 degrees of freedom robot. Then, we learn coarse dynamics models over primitive cycles and use them in a model predictive control framework. This allows us to learn to walk to arbitrary goals up to 12m away, after about two hours of training from scratch on hardware. Our results on a Daisy hexapod hardware and simulation demonstrate the efficacy of our approach at reaching distant targets, in different environments, and with sensory noise.
keywords: {Hardware;Legged locomotion;Training;Task analysis;Planning;Heuristic algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196642&isnumber=9196508

Z. Liu, Z. Lu and K. Karydis, "SoRX: A Soft Pneumatic Hexapedal Robot to Traverse Rough, Steep, and Unstable Terrain," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 420-426.
doi: 10.1109/ICRA40945.2020.9196731
Abstract: Soft robotics technology creates new ways for legged robots to interact with and adapt to their environment. In this paper we develop i) a new 2-degree-of-freedom soft pneumatic actuator, and ii) a novel soft robotic hexapedal robot called SoRX that leverages the new actuators. Simulation and physical testing confirm that the proposed actuator can generate cyclic foot trajectories that are appropriate for legged locomotion. Consistent with other hexapedal robots (and animals), SoRX employs an alternating tripod gait to propel itself forward. Experiments reveal that SoRX can reach forward speeds of up to 0.44 body lengths per second, or equivalently 101 mm/s. With a size of 230 mm length, 140 mm width and 100 mm height, and weight of 650 grams, SoRX is among the fastest tethered soft pneumatically-actuated legged robots to date. The motion capabilities of SoRX are evaluated through five experiments: running, step climbing, and traversing rough terrain, steep terrain, and unstable terrain. Experimental results show that SoRX is able to operate over challenging terrains in open-loop control and by following the same alternating tripod gait across all experimental cases.
keywords: {Legged locomotion;Pneumatic systems;Soft robotics;Pneumatic actuators;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196731&isnumber=9196508

M. Won, "UBAT: On Jointly Optimizing UAV Trajectories and Placement of Battery Swap Stations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 427-433.
doi: 10.1109/ICRA40945.2020.9197227
Abstract: Unmanned aerial vehicles (UAVs) have been widely used in many applications. The limited flight time of UAVs, however, still remains as a major challenge. Although numerous approaches have been developed to recharge the battery of UAVs effectively, little is known about optimal methodologies to deploy charging stations. In this paper, we address the charging station deployment problem with an aim to find the optimal number and locations of charging stations such that the system performance is maximized. We show that the problem is NP-Hard and propose UBAT, a heuristic framework based on the ant colony optimization (ACO) to solve the problem. Additionally, a suite of algorithms are designed to enhance the execution time and the quality of the solutions for UBAT. Through extensive simulations, we demonstrate that UBAT effectively performs multi-objective optimization of generation of UAV trajectories and placement of charging stations that are within 8.3% and 7.3% of the true optimal solutions, respectively.
keywords: {Charging stations;Batteries;Trajectory;Optimization;Sensors;Unmanned aerial vehicles;Euclidean distance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197227&isnumber=9196508

J. Park, J. Kim, I. Jang and H. J. Kim, "Efficient Multi-Agent Trajectory Planning with Feasibility Guarantee using Relative Bernstein Polynomial," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 434-440.
doi: 10.1109/ICRA40945.2020.9197162
Abstract: This paper presents a new efficient algorithm which guarantees a solution for a class of multi-agent trajectory planning problems in obstacle-dense environments. Our algorithm combines the advantages of both grid-based and optimization-based approaches, and generates safe, dynamically feasible trajectories without suffering from an erroneous optimization setup such as imposing infeasible collision constraints. We adopt a sequential optimization method with dummy agents to improve the scalability of the algorithm, and utilize the convex hull property of Bernstein and relative Bernstein polynomial to replace non-convex collision avoidance constraints to convex ones. The proposed method can compute the trajectory for 64 agents on average 6.36 seconds with Intel Core i7-7700 @ 3.60GHz CPU and 16G RAM, and it reduces more than 50% of the objective cost compared to our previous work. We validate the proposed algorithm through simulation and flight tests.
keywords: {Trajectory;Planning;Heuristic algorithms;Collision avoidance;Optimization;System recovery;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197162&isnumber=9196508

K. Brown, O. Peltzer, M. A. Sehr, M. Schwager and M. J. Kochenderfer, "Optimal Sequential Task Assignment and Path Finding for Multi-Agent Robotic Assembly Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 441-447.
doi: 10.1109/ICRA40945.2020.9197527
Abstract: We study the problem of sequential task assignment and collision-free routing for large teams of robots in applications with inter-task precedence constraints (e.g., task A and task B must both be completed before task C may begin). Such problems commonly occur in assembly planning for robotic manufacturing applications, in which sub-assemblies must be completed before they can be combined to form the final product. We propose a hierarchical algorithm for computing makespan-optimal solutions to the problem. The algorithm is evaluated on a set of randomly generated problem instances where robots must transport objects between stations in a "factory" grid world environment. In addition, we demonstrate in high-fidelity simulation that the output of our algorithm can be used to generate collision-free trajectories for non-holonomic differential-drive robots.
keywords: {Robots;Task analysis;Schedules;Manufacturing;Collision avoidance;Routing;Production facilities},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197527&isnumber=9196508

R. Han, S. Chen and Q. Hao, "Cooperative Multi-Robot Navigation in Dynamic Environment with Deep Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 448-454.
doi: 10.1109/ICRA40945.2020.9197209
Abstract: The challenges of multi-robot navigation in dynamic environments lie in uncertainties in obstacle complexities, partially observation of robots, and policy implementation from simulations to the real world. This paper presents a cooperative approach to address the multi-robot navigation problem (MRNP) under dynamic environments using a deep reinforcement learning (DRL) framework, which can help multiple robots jointly achieve optimal paths despite a certain degree of obstacle complexities. The novelty of this work includes threefold: (1) developing a cooperative architecture that robots can exchange information with each other to select the optimal target locations; (2) developing a DRL based framework which can learn a navigation policy to generate the optimal paths for multiple robots; (3) developing a training mechanism based on dynamics randomization which can make the policy generalized and achieve the maximum performance in the real world. The method is tested with Gazebo simulations and 4 differential drive robots. Both simulation and experiment results validate the superior performance of the proposed method in terms of success rate and travel time when compared with the other state-of-art technologies.
keywords: {Collision avoidance;Navigation;Robot sensing systems;Robot kinematics;Training;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197209&isnumber=9196508

M. R. Nimmagadda, S. Dattawadkar, S. Muthukumar and V. Honkote, "Adaptive Directional Path Planner for Real-Time, Energy-Efficient, Robust Navigation of Mobile Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 455-461.
doi: 10.1109/ICRA40945.2020.9197417
Abstract: Autonomous navigation through unknown and complex environments is a fundamental capability that is essential in almost all robotic applications. Optimal robot path planning is critical to enable efficient navigation. Path planning is a complex, compute and memory intensive task. Traditional methods employ either graph based search methods or sample based methods to implement path planning, which are sub-optimal and compute/memory-intensive. To this end, an Adaptive Directional Planner (ADP) algorithm is devised to achieve real-time, energy-efficient, memory-optimized, robust local path planning for enabling efficient autonomous navigation of mobile robots. The ADP algorithm ensures that the paths are optimal and kinematically-feasible. Further, the proposed algorithm is tested with different challenging scenarios verifying the functionality and robustness. The ADP algorithm implementation results demonstrate 40- 60X less number of nodes and 40 - 50X less execution time compared to the standard TP-RRT schemes, without compromising on accuracy. Finally, the algorithm has also been implemented as an accelerator for non-holonomic, multi-shape, small form factor mobile robots to provide a silicon solution with high performance and low memory footprint (28KB).
keywords: {Mobile robots;Trajectory;Real-time systems;Navigation;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197417&isnumber=9196508

D. Cardona-Ortiz, A. Paz and G. Arechavaleta, "Exploiting sparsity in robot trajectory optimization with direct collocation and geometric algorithms," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 469-475.
doi: 10.1109/ICRA40945.2020.9196668
Abstract: This paper presents a robot trajectory optimization formulation that builds upon numerical optimal control and Lie group methods. In particular, the inherent sparsity of direct collocation is carefully analyzed to dramatically reduce the number of floating-point operations to get first-order information of the problem. We describe how sparsity exploitation is employed with both numerical and analytical differentiation. Furthermore, the use of geometric algorithms based on Lie groups and their associated Lie algebras allow to analytically evaluate the state equations and their derivatives with efficient recursive algorithms. We demonstrate the scalability of the proposed formulation with three different articulated robots, such as a finger, a mobile manipulator and a humanoid composed of five, eight and more than twenty degrees of freedom, respectively. The performance of our implementation in C++ is also validated and compared against a state-of-the-art general purpose numerical optimal control solver.
keywords: {Robots;Heuristic algorithms;Jacobian matrices;Optimal control;System dynamics;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196668&isnumber=9196508

A. K. Singh, R. Ram Theerthala, M. Babu, U. K. R. Nair and K. Madhava Krishna, "Bi-Convex Approximation of Non-Holonomic Trajectory Optimization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 476-482.
doi: 10.1109/ICRA40945.2020.9197092
Abstract: Autonomous cars and fixed-wing aerial vehicles have the so-called non-holonomic kinematics which non-linearly maps control input to states. As a result, trajectory optimization with such a motion model becomes highly non-linear and non-convex. In this paper, we improve the computational tractability of non-holonomic trajectory optimization by reformulating it in terms of a set of bi-convex cost and constraint functions along with a non-linear penalty. The bi-convex part acts as a relaxation for the non-holonomic trajectory optimization while the residual of the penalty dictates how well its output obeys the non-holonomic behavior. We adopt an alternating minimization approach for solving the reformulated problem and show that it naturally leads to the replacement of the challenging non-linear penalty with a globally valid convex surrogate. Along with the common cost functions modeling goal-reaching, trajectory smoothness, etc., the proposed optimizer can also accommodate a class of non-linear costs for modeling goal-sets, while retaining the bi-convex structure. We benchmark the proposed optimizer against off-the-shelf solvers implementing sequential quadratic programming and interior-point methods and show that it produces solutions with similar or better cost as the former while significantly outperforming the latter. Furthermore, as compared to both off-the-shelf solvers, the proposed optimizer achieves more than 20x reduction in computation time.
keywords: {Trajectory optimization;Minimization;Computational modeling;Collision avoidance;Robots;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197092&isnumber=9196508

W. Gao, C. Young, J. Nicholson, C. Hubicki and J. Clark, "Fast, Versatile, and Open-loop Stable Running Behaviors with Proprioceptive-only Sensing using Model-based Optimization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 483-489.
doi: 10.1109/ICRA40945.2020.9196542
Abstract: As we build our legged robots smaller and cheaper, stable and agile control without expensive inertial sensors becomes increasingly important. We seek to enable versatile dynamic behaviors on robots with limited modes of state feedback, specifically proprioceptive-only sensing. This work uses model-based trajectory optimization methods to design open-loop stable motion primitives. We specifically design running gaits for a single-legged planar robot, and can generate motion primitives in under 3 seconds, approaching online-capable speeds. A direct-collocation-formulated optimization generated axial force profiles for the direct-drive robot to achieve desired running speed and apex height. When implemented in hardware, these trajectories produced open-loop stable running. Further, the measured running achieved the desired speed within 10% of the speed specified for the optimization in spite of having no control loop actively measuring or controlling running speed. Additionally, we examine the shape of the optimized force profile and observe features that may be applicable to open-loop stable running in general.
keywords: {Legged locomotion;Force;Optimization;Springs;Modulation;Hip},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196542&isnumber=9196508

A. Hakobyan and I. Yang, "Wasserstein Distributionally Robust Motion Planning and Control with Safety Constraints Using Conditional Value-at-Risk," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 490-496.
doi: 10.1109/ICRA40945.2020.9196857
Abstract: In this paper, we propose an optimization-based decision-making tool for safe motion planning and control in an environment with randomly moving obstacles. The unique feature of the proposed method is that it limits the risk of unsafety by a pre-specified threshold even when the true probability distribution of the obstacles' movements deviates, within a Wasserstein ball, from an available empirical distribution. Another advantage is that it provides a probabilistic out-of-sample performance guarantee of the risk constraint. To develop a computationally tractable method for solving the distributionally robust model predictive control problem, we propose a set of reformulation procedures using (i) the Kantorovich duality principle, (ii) the extremal representation of conditional value-at-risk, and (iii) a geometric expression of the distance to the union of halfspaces. The performance and utility of this distributionally robust method are demonstrated through simulations using a 12D quadrotor model in a 3D environment.
keywords: {Robustness;Safety;Planning;Robots;Trajectory;Probability distribution;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196857&isnumber=9196508

Z. Pan, X. Gao and D. Manocha, "Grasping Fragile Objects Using A Stress-Minimization Metric," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 517-523.
doi: 10.1109/ICRA40945.2020.9196938
Abstract: We present a new method to generate optimal grasps for brittle and fragile objects using a novel stress- minimization (SM) metric. Our approach is designed for objects that are composed of homogeneous isotopic materials. Our SM metric measures the maximal resistible external wrenches that would not result in fractures in the target objects. In this paper, we propose methods to compute our new metric. We also use our SM metric to design optimal grasp planning algorithms. Finally, we compare the performance of our metric and conventional grasp metrics, including Q1,Q‚àû,QG11,QMSV,QVEW. Our experiments show that our SM metric takes into account the material characteristics and object shapes to indicate the fragile regions, where prior methods may not work well. We also show that the computational cost of our SM metric is on par with prior methods. Finally, we show that grasp planners guided by our metric can lower the probability of breaking target objects.
keywords: {Measurement;Planning;Force;Tensile stress;Grasping;Resilience},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196938&isnumber=9196508

M. Costanzo, G. De Maria, G. Lettera and C. Natale, "Grasp Control for Enhancing Dexterity of Parallel Grippers," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 524-530.
doi: 10.1109/ICRA40945.2020.9196873
Abstract: A robust grasp controller for both slipping avoidance and controlled sliding is proposed based on force/tactile feedback only. The model-based algorithm exploits a modified LuGre friction model to consider rotational frictional sliding motions. The modification relies on the Limit Surface concept where a novel computationally efficient method is introduced to compute in real-time the minimum grasping force to balance tangential and torsional loads. The two control modalities are considered by the robot motion planning algorithm that automatically generates robot motions and gripper commands to solve complex manipulation tasks in a material handling application.
keywords: {Force;Grippers;Friction;Dynamics;Mathematical model;Computational modeling;Grasping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196873&isnumber=9196508

T. Narita, S. Nagakari, W. Conus, T. Tsuboi and K. Nagasaka, "Theoretical Derivation and Realization of Adaptive Grasping Based on Rotational Incipient Slip Detection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 531-537.
doi: 10.1109/ICRA40945.2020.9196615
Abstract: Manipulating objects whose physical properties are unknown remains one of the greatest challenges in robotics. Controlling grasp force is an essential aspect of handling unknown objects without slipping or crushing them. Although extensive research has been carried out on grasp force control, unknown object manipulation is still difficult because conventional approaches assume that object properties (mass, center of gravity, friction coefficient, etc.) are known for grasp force control. One of the approaches to address this issue is incipient slip detection. However, there has been few detailed investigations of robust detection and control of incipient slip on rotational case. This study makes contributions on deriving the theoretical model of incipient slip and proposes a new algorithm to detect incipient slip. Additionally, a novel sensor configuration and a grasp force control algorithm based on the derived theoretical model are proposed. Finally, the proposed algorithm is evaluated by grasping objects with different weights and moments including a fragile pastry (√©clair).
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196615&isnumber=9196508

S. Cui, R. Wang, J. Wei, F. Li and S. Wang, "Grasp State Assessment of Deformable Objects Using Visual-Tactile Fusion Perception," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 538-544.
doi: 10.1109/ICRA40945.2020.9196787
Abstract: Humans can quickly determine the force required to grasp a deformable object to prevent its sliding or excessive deformation through vision and touch, which is still a challenging task for robots. To address this issue, we propose a novel 3D convolution-based visual-tactile fusion deep neural network (C3D-VTFN) to evaluate the grasp state of various deformable objects in this paper. Specifically, we divide the grasp states of deformable objects into three categories of sliding, appropriate and excessive. Also, a dataset for training and testing the proposed network is built by extensive grasping and lifting experiments with different widths and forces on 16 various deformable objects with a robotic arm equipped with a wrist camera and a tactile sensor. As a result, a classification accuracy as high as 99.97% is achieved. Furthermore, some delicate grasp experiments based on the proposed network are implemented in this paper. The experimental results demonstrate that the C3D-VTFN is accurate and efficient enough for grasp state assessment, which can be widely applied to automatic force control, adaptive grasping, and other visual-tactile spatiotemporal sequence learning problems.
keywords: {Visualization;Grasping;Feature extraction;Task analysis;Tactile sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196787&isnumber=9196508

J. Lundell, F. Verdoja and V. Kyrki, "Beyond Top-Grasps Through Scene Completion," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 545-551.
doi: 10.1109/ICRA40945.2020.9197320
Abstract: Current end-to-end grasp planning methods propose grasps in the order of seconds that attain high grasp success rates on a diverse set of objects, but often by constraining the workspace to top-grasps. In this work, we present a method that allows end-to-end top-grasp planning methods to generate full six-degree-of-freedom grasps using a single RGBD view as input. This is achieved by estimating the complete shape of the object to be grasped, then simulating different viewpoints of the object, passing the simulated viewpoints to an end-to-end grasp generation method, and finally executing the overall best grasp. The method was experimentally validated on a Franka Emika Panda by comparing 429 grasps generated by the state-of-the-art Fully Convolutional Grasp Quality CNN, both on simulated and real camera images. The results show statistically significant improvements in terms of grasp success rate when using simulated images over real camera images, especially when the real camera viewpoint is angled. Code and video are available at https://irobotics.aalto.fi/beyond-topgrasps-through-scene-completion/.
keywords: {Shape;Cameras;Grasping;Planning;Robot vision systems;Pipelines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197320&isnumber=9196508

H. Zhang, J. Ichnowski, Y. Avigal, J. Gonzales, I. Stoica and K. Goldberg, "Dex-Net AR: Distributed Deep Grasp Planning Using a Commodity Cellphone and Augmented Reality App," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 552-558.
doi: 10.1109/ICRA40945.2020.9197247
Abstract: Consumer demand for augmented reality (AR) in mobile phone applications, such as the Apple ARKit. Such applications have potential to expand access to robot grasp planning systems such as Dex-Net. AR apps use structure from motion methods to compute a point cloud from a sequence of RGB images taken by the camera as it is moved around an object. However, the resulting point clouds are often noisy due to estimation errors. We present a distributed pipeline, Dex-Net AR, that allows point clouds to be uploaded to a server in our lab, cleaned, and evaluated by Dex-Net grasp planner to generate a grasp axis that is returned and displayed as an overlay on the object. We implement Dex-Net AR using the iPhone and ARKit and compare results with those generated with high-performance depth sensors. The success rates with AR on harder adversarial objects are higher than traditional depth images. The server URL is https://sites.google.com/berkeley.edu/dex-net-ar/home.
keywords: {Three-dimensional displays;Cameras;Planning;Sensors;Smart phones;Feature extraction;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197247&isnumber=9196508

C. Won, H. Seok, Z. Cui, M. Pollefeys and J. Lim, "OmniSLAM: Omnidirectional Localization and Dense Mapping for Wide-baseline Multi-camera Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 559-566.
doi: 10.1109/ICRA40945.2020.9196695
Abstract: In this paper, we present an omnidirectional localization and dense mapping system for a wide-baseline multiview stereo setup with ultra-wide field-of-view (FOV) fisheye cameras, which has a 360¬∞ coverage of stereo observations of the environment. For more practical and accurate reconstruction, we first introduce improved and light-weighted deep neural networks for the omnidirectional depth estimation, which are faster and more accurate than the existing networks. Second, we integrate our omnidirectional depth estimates into the visual odometry (VO) and add a loop closing module for global consistency. Using the estimated depth map, we reproject keypoints onto each other view, which leads to a better and more efficient feature matching process. Finally, we fuse the omnidirectional depth maps and the estimated rig poses into the truncated signed distance function (TSDF) volume to acquire a 3D map. We evaluate our method on synthetic datasets with ground-truth and real-world sequences of challenging environments, and the extensive experiments show that the proposed system generates excellent reconstruction results in both synthetic and real-world environments.
keywords: {Cameras;Three-dimensional displays;Estimation;Feature extraction;Visual odometry;Sensors;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196695&isnumber=9196508

J. Guerrero-Viu, C. Fernandez-Labrador, C. Demonceaux and J. J. Guerrero, "What‚Äôs in my Room? Object Recognition on Indoor Panoramic Images," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 567-573.
doi: 10.1109/ICRA40945.2020.9197335
Abstract: In the last few years, there has been a growing interest in taking advantage of the 360¬∞ panoramic images potential, while managing the new challenges they imply. While several tasks have been improved thanks to the contextual information these images offer, object recognition in indoor scenes still remains a challenging problem that has not been deeply investigated. This paper provides an object recognition system that performs object detection and semantic segmentation tasks by using a deep learning model adapted to match the nature of equirectangular images. From these results, instance segmentation masks are recovered, refined and transformed into 3D bounding boxes that are placed into the 3D model of the room. Quantitative and qualitative results support that our method outperforms the state of the art by a large margin and show a complete understanding of the main objects in indoor scenes.
keywords: {Image segmentation;Object recognition;Three-dimensional displays;Semantics;Task analysis;Layout;Distortion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197335&isnumber=9196508

V. R. Kumar et al., "FisheyeDistanceNet: Self-Supervised Scale-Aware Distance Estimation using Monocular Fisheye Camera for Autonomous Driving," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 574-581.
doi: 10.1109/ICRA40945.2020.9197319
Abstract: Fisheye cameras are commonly used in applications like autonomous driving and surveillance to provide a large field of view (> 180o). However, they come at the cost of strong non-linear distortions which require more complex algorithms. In this paper, we explore Euclidean distance estimation on fisheye cameras for automotive scenes. Obtaining accurate and dense depth supervision is difficult in practice, but self-supervised learning approaches show promising results and could potentially overcome the problem. We present a novel self-supervised scale-aware framework for learning Euclidean distance and ego-motion from raw monocular fisheye videos without applying rectification. While it is possible to perform piece-wise linear approximation of fisheye projection surface and apply standard rectilinear models, it has its own set of issues like re-sampling distortion and discontinuities in transition regions. To encourage further research in this area, we will release our dataset as part of the WoodScape project [1]. We further evaluated the proposed algorithm on the KITTI dataset and obtained state-of-the-art results comparable to other self-supervised monocular methods. Qualitative results on an unseen fisheye video demonstrate impressive performance1.
keywords: {Cameras;Estimation;Training;Euclidean distance;Image reconstruction;Three-dimensional displays;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197319&isnumber=9196508

N. -H. Wang, B. Solarte, Y. -H. Tsai, W. -C. Chiu and M. Sun, "360SD-Net: 360¬∞ Stereo Depth Estimation with Learnable Cost Volume," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 582-588.
doi: 10.1109/ICRA40945.2020.9196975
Abstract: Recently, end-to-end trainable deep neural networks have significantly improved stereo depth estimation for perspective images. However, 360¬∞ images captured under equirectangular projection cannot benefit from directly adopting existing methods due to distortion introduced (i.e., lines in 3D are not projected onto lines in 2D). To tackle this issue, we present a novel architecture specifically designed for spherical disparity using the setting of top-bottom 360¬∞ camera pairs. Moreover, we propose to mitigate the distortion issue by (1) an additional input branch capturing the position and relation of each pixel in the spherical coordinate, and (2) a cost volume built upon a learnable shifting filter. Due to the lack of 360¬∞ stereo data, we collect two 360¬∞ stereo datasets from Matterport3D and Stanford3D for training and evaluation. Extensive experiments and ablation study are provided to validate our method against existing algorithms. Finally, we show promising results on real-world environments capturing images with two consumer-level cameras. Our project page is at https://albert100121.github.io/360SD-Net-Project-Page.
keywords: {Cameras;Estimation;Three-dimensional displays;Distortion;Feature extraction;Convolution;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196975&isnumber=9196508

X. Cheng, P. Wang, Y. Zhou, C. Guan and R. Yang, "Omnidirectional Depth Extension Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 589-595.
doi: 10.1109/ICRA40945.2020.9197123
Abstract: Omnidirectional 360&#x00B0; camera proliferates rapidly for autonomous robots since it significantly enhances the perception ability by widening the field of view (FoV). However, corresponding 360&#x00B0; depth sensors, which are also critical for the perception system, are still difficult or expensive to have. In this paper, we propose a low-cost 3D sensing system that combines an omnidirectional camera with a calibrated projective depth camera, where the depth from the limited FoV can be automatically extended to the rest of recorded omnidirectional image. To accurately recover the missing depths, we design an omnidirectional depth extension convolutional neural network (ODE-CNN), in which a spherical feature transform layer (SFTL) is embedded at the end of feature encoding layers, and a deformable convolutional spatial propagation network (D-CSPN) is appended at the end of feature decoding layers. The former re-samples the neighborhood of each pixel in the omnidirectional coordination to the projective coordination, which reduce the difficulty of feature learning, and the later automatically finds a proper context to well align the structures in the estimated depths via CNN w.r.t. the reference image, which significantly improves the visual quality. Finally, we demonstrate the effectiveness of proposed ODE-CNN over the popular 360D dataset, and show that ODE-CNN significantly outperforms (relatively 33% reduction in depth error) other state-of-the-art (SoTA) methods.
keywords: {Convolution;Estimation;Sensors;Cameras;Transforms;Kernel;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197123&isnumber=9196508

Y. Shi, X. Tong, J. Wen, H. Zhao, X. Ying and H. Zha, "3D Orientation Estimation and Vanishing Point Extraction from Single Panoramas Using Convolutional Neural Network," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 596-602.
doi: 10.1109/ICRA40945.2020.9196966
Abstract: 3D orientation estimation is a key component of many important computer vision tasks such as autonomous navigation and 3D scene understanding. This paper presents a new CNN architecture to estimate the 3D orientation of an omnidirectional camera with respect to the world coordinate system from a single spherical panorama. To train the proposed architecture, we leverage a dataset of panoramas named VOP60K from Google Street View with labeled 3D orientation, including 50 thousand panoramas for training and 10 thousand panoramas for testing. Previous approaches usually estimate 3D orientation under pinhole cameras. However, for a panorama, due to its larger field of view, previous approaches cannot be suitable. In this paper, we propose an edge extractor layer to utilize the low-level and geometric information of panorama, an attention module to fuse different features generated by previous layers. A regression loss for two column vectors of the rotation matrix and classification loss for the position of vanishing points are added to optimize our network simultaneously. The proposed algorithm is validated on our benchmark, and experimental results clearly demonstrate that it outperforms previous methods.
keywords: {Cameras;Three-dimensional displays;Feature extraction;Google;Estimation;Data mining;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196966&isnumber=9196508

X. Lin, L. Willemet, A. Bailleul and M. Wiertlewski, "Curvature sensing with a spherical tactile sensor using the color-interference of a marker array," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 603-609.
doi: 10.1109/ICRA40945.2020.9197050
Abstract: The only way to perceive a small object held between our fingers is to trust our sense of touch. Touch provides cues about the state of the contact even if its view is occluded by the finger. The interaction between the soft fingers and the surface reveals crucial information, such as the local shape of the object, that plays a central role in fine manipulation. In this work, we present a new spherical sensor that endows robots with a fine distributed sense of touch. This sensor is an evolution of our distributed tactile sensor that measures the dense 3-dimensional displacement field of an elastic membrane, using the subtractive color-mixing principle. We leverage a planar manufacturing process that enables the design and manufacturing of the functional features on a flat surface. The flat functional panels are then folded to create a spherical shape able to sense a wide variety of objects.The resulting 40mm-diameter spherical sensor has 77 measurement points, each of which gives an estimation of the local 3d displacement, normal and tangential to the surface. Each marker is built around 2 sets of colored patches placed at different depths. The relative motion and resulting hue of each marker, easily captured by an embedded RGB camera, provides a measurement of their 3d motion. To benchmark the sensor, we compared the measurements obtained while pressing the sensor on a curved surface with Hertz contact theory, a hallmark of contact mechanics. While the mechanics did strictly follow Hertz contact theory, using the shear and normal sensing, ChromaTouch can estimate the curvature of an object after a millimeter-size indentation of the sensor.
keywords: {Shape;Cameras;Tactile sensors;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197050&isnumber=9196508

Q. Feng, Z. Chen, J. Deng, C. Gao, J. Zhang and A. Knoll, "Center-of-Mass-based Robust Grasp Planning for Unknown Objects Using Tactile-Visual Sensors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 610-617.
doi: 10.1109/ICRA40945.2020.9196815
Abstract: An unstable grasp pose can lead to slip, thus an unstable grasp pose can be predicted by slip detection. A regrasp is required afterwards to correct the grasp pose in order to finish the task. In this work, we propose a novel regrasp planner with multi-sensor modules to plan grasp adjustments with the feedback from a slip detector. Then a regrasp planner is trained to estimate the location of center of mass, which helps robots find an optimal grasp pose. The dataset in this work consists of 1 025 slip experiments and 1 347 regrasps collected by one pair of tactile sensors, an RGB-D camera and one Franka Emika robot arm equipped with joint force/torque sensors. We show that our algorithm can successfully detect and classify the slip for 5 unknown test objects with an accuracy of 76.88% and a regrasp planner increases the grasp success rate by 31.0% compared to the state-of-the-art vision-based grasping algorithm.
keywords: {Grasping;Tactile sensors;Force;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196815&isnumber=9196508

A. Padmanabha, F. Ebert, S. Tian, R. Calandra, C. Finn and S. Levine, "OmniTact: A Multi-Directional High-Resolution Touch Sensor," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 618-624.
doi: 10.1109/ICRA40945.2020.9196712
Abstract: Incorporating touch as a sensing modality for robots can enable finer and more robust manipulation skills. Existing tactile sensors are either flat, have small sensitive fields or only provide low-resolution signals. In this paper, we introduce OmniTact, a multi-directional high-resolution tactile sensor. OmniTact is designed to be used as a fingertip for robotic manipulation with robotic hands, and uses multiple micro-cameras to detect multi-directional deformations of a gel-based skin. This provides a rich signal from which a variety of different contact state variables can be inferred using modern image processing and computer vision methods. We evaluate the capabilities of OmniTact on a challenging robotic control task that requires inserting an electrical connector into an outlet, as well as a state estimation problem that is representative of those typically encountered in dexterous robotic manipulation, where the goal is to infer the angle of contact of a curved finger pressing against an object. Both tasks are performed using only touch sensing and deep convolutional neural networks to process images from the sensor's cameras. We compare with a state-of-the-art tactile sensor that is only sensitive on one side, as well as a state-of-the-art multi-directional tactile sensor, and find that OmniTact's combination of high-resolution and multi-directional sensing is crucial for reliably inserting the electrical connector and allows for higher accuracy in the state estimation task. Videos and supplementary material can be found here4.
keywords: {Cameras;Tactile sensors;Sensitivity;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196712&isnumber=9196508

P. Ribeiro, S. Cardoso, A. Bernardino and L. Jamone, "Highly sensitive bio-inspired sensor for fine surface exploration and characterization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 625-631.
doi: 10.1109/ICRA40945.2020.9197305
Abstract: Texture sensing is one of the types of information sensed by humans through touch, and is thus of interest to robotics that this type of information can be acquired and processed. In this work we present a texture topography sensor based on a ciliary structure, a biological structure found in many organisms. The device consists of up to 9 elastic cilia with permanent magnetization assembled on top of a highly sensitive tunneling magnetoresistance (TMR) sensor, within a compact footprint of 6√ó6 mm2. When these cilia brush against some textured surface, their movement and vibrations give rise to a signal that can be correlated to the characteristics of the texture being measured. We also present an electronic signal acquisition board, used in this work. Various configurations of cilia sizes are tested, with the most precise being capable of differentiating different types of sandpaper from 9.2 Œºm to 213 Œºm average surface roughness with a 7 Œºm resolution. As a topography scanner the sensor was able to scan a 20 Œºm high step in a flat surface.
keywords: {Robot sensing systems;Tunneling magnetoresistance;Magnetic separation;Substrates;Bridge circuits;Magnetic tunneling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197305&isnumber=9196508

F. Palermo, J. Konstantinova, K. Althoefer, S. Poslad and I. Farkhatdinov, "Implementing Tactile and Proximity Sensing for Crack Detection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 632-637.
doi: 10.1109/ICRA40945.2020.9196936
Abstract: Remote characterisation of the environment during physical robot-environment interaction is an important task commonly accomplished in telerobotics. This paper demonstrates how tactile and proximity sensing can be efficiently used to perform automatic crack detection. A custom-designed integrated tactile and proximity sensor is implemented. It measures the deformation of its body when interacting with the physical environment and distance to the environment's objects with the help of fibre optics. This sensor was used to slide across different surfaces and the data recorded during the experiments was used to detect and classify cracks, bumps and undulations. The proposed method uses machine learning techniques (mean absolute value as feature and random forest as classifier) to detect cracks and determine their width. An average crack detection accuracy of 86.46% and width classification accuracy of 57.30% is achieved. Kruskal-Wallis results (p<; 0.001) indicate statistically significant differences among results obtained when analysing only force data, only proximity data and both force and proximity data. In contrast to previous techniques, which mainly rely on visual modality, the proposed approach based on optical fibres is suitable for operation in extreme environments, such as nuclear facilities in which nuclear radiation may damage the electronic components of video cameras.
keywords: {Robot sensing systems;Force;Surface cracks;Optics;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196936&isnumber=9196508

S. Doi, H. Koga, T. Seki and Y. Okuno, "Novel Proximity Sensor for Realizing Tactile Sense in Suction Cups," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 638-643.
doi: 10.1109/ICRA40945.2020.9196726
Abstract: We propose a new capacitive proximity sensor that detects deformations of a suction cup as a tactile sense. We confirmed that one sensor module provides three applications for reliable picking and a simplified setup. The first application is the picking height decision. The second one is the placing height decision for detecting whether the grasped object is placed on the placement surface. These two applications are achieved by detecting the push-in stroke of the suction cup. The final application is detection of whether the suction cup is in partial contact or full contact with the object. This function can correct the picking posture as well as detect whether picking is possible before the pull-up motion. We also demonstrate that the partial contact position can be estimated in real time.
keywords: {Robot sensing systems;Capacitance;Electrodes;Capacitance measurement;Sensitivity;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196726&isnumber=9196508

J. H. Jung and C. Gook Park, "Constrained Filtering-based Fusion of Images, Events, and Inertial Measurements for Pose Estimation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 644-650.
doi: 10.1109/ICRA40945.2020.9197248
Abstract: In this paper, we propose a novel filtering-based method that fuses events from a dynamic vision sensor (DVS), images, and inertial measurements to estimate camera poses. A DVS is a bio-inspired sensor that generates events triggered by brightness changes. It can cover the drawbacks of a conventional camera by virtual of its independent pixels and high dynamic range. Specifically, we focus on optical flow obtained from both a stream of events and intensity images in which the former is much like a differential quantity, whereas the latter is a pixel difference in a much longer time interval than events. This nature characteristic motivates us to model optical flow estimated from events directly, but feature tracks for images in the filter design. An inequality constraint is considered in our method since the inverse scene-depth is larger than zero by its definition. Furthermore, we evaluate our proposed method in the benchmark DVS dataset and a dataset collected by the authors. The results reveal that the presented algorithm has reduced the position error by 49.9% on average and comparable accuracy only using events when compared to the state-of-the-art filtering-based estimator.
keywords: {Optical imaging;Optical filters;Optical sensors;Integrated optics;Optical variables measurement;Adaptive optics;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197248&isnumber=9196508

K. Eckenhoff, P. Geneva, N. Merrill and G. Huang, "Schmidt-EKF-based Visual-Inertial Moving Object Tracking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 651-657.
doi: 10.1109/ICRA40945.2020.9197352
Abstract: In this paper we investigate the effect of tightly-coupled estimation on the performance of visual-inertial localization and dynamic object pose tracking. In particular, we show that while a joint estimation system outperforms its decoupled counterpart when given a "proper" model for the target's motion, inconsistent modeling, such as choosing improper levels for the target's propagation noises, can actually lead to a degradation in ego-motion accuracy. To address the realistic scenario where a good prior knowledge of the target's motion model is not available, we design a new system based on the Schmidt-Kalman Filter (SKF), in which target measurements do not update the navigation states, however all correlations are still properly tracked. This allows for both consistent modeling of the target errors and the ability to update target estimates whenever the tracking sensor receives non-target data such as bearing measurements to static, 3D environmental features. We show in extensive simulation that this system, along with a robot-centric representation of the target, leads to robust estimation performance even in the presence of an inconsistent target motion model. Finally, the system is validated in a real-world experiment, and is shown to offer accurate localization and object pose tracking performance.
keywords: {Target tracking;Robot sensing systems;Estimation;Three-dimensional displays;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197352&isnumber=9196508

Y. Li and J. Ko≈°ecka, "Learning View and Target Invariant Visual Servoing for Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 658-664.
doi: 10.1109/ICRA40945.2020.9197136
Abstract: The advances in deep reinforcement learning recently revived interest in data-driven learning based approaches to navigation. In this paper we propose to learn viewpoint invariant and target invariant visual servoing for local mobile robot navigation; given an initial view and the goal view or an image of a target, we train deep convolutional network controller to reach the desired goal. We present a new architecture for this task which rests on the ability of establishing correspondences between the initial and goal view and novel reward structure motivated by the traditional feedback control error. The advantage of the proposed model is that it does not require calibration and depth information and achieves robust visual servoing in a variety of environments and targets without any parameter fine tuning. We present comprehensive evaluation of the approach and comparison with other deep learning architectures as well as classical visual servoing methods in visually realistic simulation environment [1]. The presented model overcomes the brittleness of classical visual servoing based methods and achieves significantly higher generalization capability compared to the previous learning approaches.
keywords: {Visual servoing;Navigation;Visualization;Feature extraction;Task analysis;Semantics;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197136&isnumber=9196508

T. H. Nguyen, T. -M. Nguyen and L. Xie, "Tightly-Coupled Single-Anchor Ultra-wideband-Aided Monocular Visual Odometry System," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 665-671.
doi: 10.1109/ICRA40945.2020.9196794
Abstract: In this work, we propose a tightly-coupled odometry framework, which combines monocular visual feature observations with distance measurements provided by a single ultra-wideband (UWB) anchor with an initial guess for its location. Firstly, the scale factor and the anchor position in the vision frame will be simultaneously estimated using a variant of Levenberg-Marquardt non-linear least squares optimization scheme. Once the scale factor is obtained, the map of visual features is updated with the new scale. Subsequent ranging errors in a sliding window are continuously monitored and the estimation procedure will be reinitialized to refine the estimates. Lastly, range measurements and anchor position estimates are fused when needed into a pose-graph optimization scheme to minimize both the landmark reprojection errors and ranging errors, thus reducing the visual drift and improving the system robustness. The proposed method is implemented in Robot Operating System (ROS) and can function in real-time. The performance is validated on both public datasets and real-life experiments and compared with state-of-the-art methods.
keywords: {Cameras;Distance measurement;Robot sensing systems;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196794&isnumber=9196508

X. Meng, N. Ratliff, Y. Xiang and D. Fox, "Scaling Local Control to Large-Scale Topological Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 672-678.
doi: 10.1109/ICRA40945.2020.9196644
Abstract: Visual topological navigation has been revitalized recently thanks to the advancement of deep learning that substantially improves robot perception. However, the scalability and reliability issue remain challenging due to the complexity and ambiguity of real world images and mechanical constraints of real robots. We present an intuitive approach to show that by accurately measuring the capability of a local controller, large-scale visual topological navigation can be achieved while being scalable and robust. Our approach achieves state-of-the-art results in trajectory following and planning in large-scale environments. It also generalizes well to real robots and new environments without retraining or finetuning.
keywords: {Navigation;Trajectory;Robustness;Robot kinematics;Planning;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196644&isnumber=9196508

X. Pan, T. Zhang, B. Ichter, A. Faust, J. Tan and S. Ha, "Zero-shot Imitation Learning from Demonstrations for Legged Robot Visual Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 679-685.
doi: 10.1109/ICRA40945.2020.9196602
Abstract: Imitation learning is a popular approach for training effective visual navigation policies. However, collecting expert demonstrations for legged robots is challenging as these robots can be hard to control, move slowly, and cannot operate continuously for long periods of time. In this work, we propose a zero-shot imitation learning framework for training a goal-driven visual navigation policy on a legged robot from human demonstrations (third-person perspective), allowing for high-quality navigation and cost-effective data collection. However, imitation learning from third-person demonstrations raises unique challenges. First, these demonstrations are captured from different camera perspectives, which we address via a feature disentanglement network (FDN) that extracts perspective-invariant state features. Second, as transition dynamics vary between systems, we reconstruct missing action labels by either building an inverse model of the robot's dynamics in the feature space and applying it to the human demonstrations or developing a Graphic User Interface (GUI) to label human demonstrations. To train a navigation policy we use a model-based imitation learning approach with FDN and action-labeled human demonstrations. We show that our framework can learn an effective policy for a legged robot, Laikago, from human demonstrations in both simulated and real-world environments. Our approach is zero-shot as the robot never navigates the same paths during training as those at testing time. We justify our framework by performing a comparative study.
keywords: {Feature extraction;Navigation;Legged locomotion;Visualization;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196602&isnumber=9196508

C. Sozer, L. Patern√≤, G. Tortora and A. Menciassi, "Pressure-Driven Manipulator with Variable Stiffness Structure," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 696-702.
doi: 10.1109/ICRA40945.2020.9197401
Abstract: The high deformability and compliance of soft robots allow safer interaction with the environment. On the other hand, these advantages bring along controllability and predictability challenges which result in loss of force and stiffness output. Such challenges should be addressed in order to improve the overall functional performance and to meet the requirements of real-scenario applications. In this paper, we present a bidirectional in-plane manipulator which consists of two unidirectional fiber-reinforced actuators (FRAs) and a hybrid soft-rigid stiffness control structure (SCS), all of them controlled by air pressure. Both controllability and predictability of the manipulator are enhanced by the hybrid soft-rigid structure. While the FRAs provide positioning and position dependent stiffness, the SCS increases the stiffness of the manipulator without position dependency. The SCS is able to increase the manipulator stiffness by 35%, 30%, and 18%, when one FRA is pressurized at 150 kPa, 75 kPa, and 0 kPa, respectively. Experiments are carried out to present the feasibility of the proposed manipulator.
keywords: {Manipulators;Actuators;Encapsulation;Fabrication;Force;Controllability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197401&isnumber=9196508

F. Stroppa, M. Luo, K. Yoshida, M. M. Coad, L. H. Blumenschein and A. M. Okamura, "Human Interface for Teleoperated Object Manipulation with a Soft Growing Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 726-732.
doi: 10.1109/ICRA40945.2020.9197094
Abstract: Soft growing robots are proposed for use in applications such as complex manipulation tasks or navigation in disaster scenarios. Safe interaction and ease of production promote the usage of this technology, but soft robots can be challenging to teleoperate due to their unique degrees of freedom. In this paper, we propose a human-centered interface that allows users to teleoperate a soft growing robot for manipulation tasks using arm movements. A study was conducted to assess the intuitiveness of the interface and the performance of our soft robot, involving a pick-and-place manipulation task. The results show that users were able to complete the task 97% of the time and achieve placement errors below 2 cm on average. These results demonstrate that our body-movement-based interface is an effective method for control of a soft growing robot manipulator.
keywords: {Robot kinematics;Task analysis;Manipulators;Soft robotics;Tracking;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197094&isnumber=9196508

J. Lee, H. R. Warren, V. Agarwal, M. E. Huber and N. Hogan, "Modulating hip stiffness with a robotic exoskeleton immediately changes gait," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 733-739.
doi: 10.1109/ICRA40945.2020.9197054
Abstract: Restoring healthy kinematics is a critical component of assisting and rehabilitating impaired locomotion. Here we tested whether spatiotemporal gait patterns can be modulated by applying mechanical impedance to hip joints. Using the Samsung GEMS-H exoskeleton, we emulated a virtual spring (positive and negative) between the user's legs. We found that applying positive stiffness with the exoskeleton decreased stride time and hip range of motion for healthy subjects during treadmill walking. Conversely, the application of negative stiffness increased stride time and hip range of motion. These effects did not vary over long nor short repeated exposures to applied stiffness. In addition, minimal transient behavior was observed in spatiotemporal measures of gait when the stiffness controller transitioned between on and off states. These results suggest that changes in gait behavior induced by applying hip stiffness were purely a mechanical effect. Together, our findings indicate that applying mechanical impedance using lower-limb assistive devices may be an effective, minimally-encumbering intervention to restore healthy gait patterns.
keywords: {Hip;Exoskeletons;Legged locomotion;Read only memory;Kinematics;Springs;Time measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197054&isnumber=9196508

J. T. Lee and M. Goldfarb, "Swing-Assist for Enhancing Stair Ambulation in a Primarily-Passive Knee Prosthesis," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 740-746.
doi: 10.1109/ICRA40945.2020.9196974
Abstract: This paper presents the design and implementation of a controller for stair ascent and descent in a primarily-passive stance-controlled swing-assist (SCSA) prosthesis. The prosthesis and controller enable users to perform both step-over and step-to stair ascent and descent. The efficacy of the controller and SCSA prosthesis prototype in providing improved stair ambulation was tested on a unilateral transfemoral amputee in experiments that employed motion capture apparatus to compare joint kinematics with the SCSA prosthesis, relative to performing the same activity with a microprocessor-controlled daily-use passive prosthesis. Results suggest that the SCSA knee significantly decreases compensatory motion during stair activity when compared to the passive prosthesis.
keywords: {Knee;Prosthetics;Valves;Hip;Torque;Actuators;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196974&isnumber=9196508

S. J. Kim, J. Park, W. Shin, D. Y. Lee and J. Kim, "Proof-of-concept of a Pneumatic Ankle Foot Orthosis Powered by a Custom Compressor for Drop Foot Correction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 747-753.
doi: 10.1109/ICRA40945.2020.9196817
Abstract: Pneumatic transmission has several advantages in developing powered ankle foot orthosis (AFO) systems, such as the flexibility in placing pneumatic components for mass distribution and providing high back-drivability via simple valve control. However, pneumatic systems are generally tethered to large stationary air compressors that restrict them for being used as daily assistive devices. In this study, we improved a previously developed wearable (untethered) custom compressor that can be worn (1.5 kg) at the waist of the body and can generate adequate amount of pressurized air (maximum pressure of 1050 kPa and a flow rate of 15.1 mL/sec at 550 kPa) to power a unilateral active AFO used to assist the dorsiflexion (DF) motion of drop-foot patients. The finalized system can provide a maximum assistive torque of 10 Nm and induces an average 0.03¬±0.06 Nm resistive torque when free movement is provided. The system was tested for two unilateral drop-foot patients. The proposed system showed an average improvement of 13.6¬∞ of peak dorsiflexion angle during the swing phase of the gait cycle.
keywords: {Foot;Torque;DC motors;Valves;Optical sensors;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196817&isnumber=9196508

X. Gao, J. Si, Y. Wen, M. Li and H. H. Huang, "Knowledge-Guided Reinforcement Learning Control for Robotic Lower Limb Prosthesis," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 754-760.
doi: 10.1109/ICRA40945.2020.9196749
Abstract: Robotic prostheses provide new opportunities to better restore lost functions than passive prostheses for trans-femoral amputees. But controlling a prosthesis device automatically for individual users in different task environments is an unsolved problem. Reinforcement learning (RL) is a naturally promising tool. For prosthesis control with a user in the loop, it is desirable that the controlled prosthesis can adapt to different task environments as quickly and smoothly as possible. However, most RL agents learn or relearn from scratch when the environment changes. To address this issue, we propose the knowledge-guided Q-learning (KG-QL) control method as a principled way for the problem. In this report, we collected and used data from two able-bodied (AB) subjects wearing a RL controlled robotic prosthetic limb walking on level ground. Our ultimate goal is to build an efficient RL controller with reduced time and data requirements and transfer knowledge from AB subjects to amputee subjects. Toward this goal, we demonstrate its feasibility by employing OpenSim, a well-established human locomotion simulator. Our results show the OpenSim simulated amputee subject improved control tuning performance over learning from scratch by utilizing knowledge transfer from AB subjects. Also in this paper, we will explore the possibility of information transfer from AB subjects to help tuning for the amputee subjects.
keywords: {Prosthetics;Task analysis;Impedance;Knee;Legged locomotion;Tuning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196749&isnumber=9196508

H. -S. Seong, D. -H. Kim, I. Gaponov and J. -H. Ryu, "Development of a Twisted String Actuator-based Exoskeleton for Hip Joint Assistance in Lifting Tasks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 761-767.
doi: 10.1109/ICRA40945.2020.9197359
Abstract: This paper presents a study on a compliant cable-driven exoskeleton for hip assistance in lifting tasks that is aimed at preventing low-back pain and injuries in the vocational setting. In the proposed concept, we used twisted string actuator (TSA) to design a light-weight and powerful exoskeleton that benefits from inherent TSA advantages. We have noted that nonlinear nature of twisted strings&#x2019; transmission ratio (decreasing with twisting) closely matched typical torque-speed requirements for hip assistance during lifting tasks and tried to use this fact in the exoskeleton design and motor selection. Hip-joint torque and speed required to lift a 10-kg load from stoop to stand were calculated, which gave us a baseline that we used to design and manufacture a practical exoskeleton prototype. Preliminary experimental trials demonstrated that the proposed device was capable of generating required torque and speed at the hip joint while weighing under 6 kg, including battery.
keywords: {Hip;Exoskeletons;Torque;Pulleys;Actuators;Kinematics;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197359&isnumber=9196508

L. Zhou, W. Chen, W. Chen, S. Bai and J. Wang, "A Novel Portable Lower Limb Exoskeleton for Gravity Compensation during Walking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 768-773.
doi: 10.1109/ICRA40945.2020.9197422
Abstract: This paper presents a novel portable passive lower limb exoskeleton for walking assistance. The exoskeleton is designed with built-in spring mechanisms at the hip and knee joints to realize gravity balancing of the human leg. A pair of mating gears is used to convert the tension force from the built-in springs into balancing torques at hip and knee joints for overcoming the influence of gravity. Such a design makes the exoskeleton has a compact layout with small protrusion, which improves its safety and user acceptance. In this paper, the design principle of gravity balancing is described. Simulation results show a significant reduction of driving torques at the limb joints. A prototype of single leg exoskeleton has been constructed and preliminary test results show the effectiveness of the exoskeleton.
keywords: {Springs;Exoskeletons;Gravity;Legged locomotion;Gears;Potential energy;Hip},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197422&isnumber=9196508

M. Barenboim and A. Degani, "Steerable Burrowing Robot: Design, Modeling and Experiments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 829-835.
doi: 10.1109/ICRA40945.2020.9196648
Abstract: This paper investigates a burrowing robot that can maneuver and steer while being submerged in a granular medium. The robot locomotes using an internal vibro-impact mechanism and steers using a rotating bevel-tip head. We formulate and investigate a non-holonomic model for the steering mechanism and a hybrid dynamics model for the thrusting mechanism. We perform a numerical analysis of the dynamics of the robot's thrusting mechanism using a simplified, orientation and depth dependent model for the drag forces acting on the robot. We first show, in simulation, that by carefully tuning various control input parameters, the thrusting mechanism can drive the robot both forward and backward. We present several experiments designed to evaluate and verify the simulative results using a proof-of-concept robot. We show that different input amplitudes indeed affect the direction of motion, as suggested by the simulation. We further demonstrate the ability of the robot to perform a simple S-shaped trajectory. These experiments demonstrate the feasibility of the robot's design and fidelity of the model.
keywords: {Robot kinematics;Needles;Numerical models;Solid modeling;Trajectory;Springs},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196648&isnumber=9196508

E. Lee, Z. Goddard, J. Ngotiaoco, N. Monterrosa and A. Mazumdar, "High Force Density Gripping with UV Activation and Sacrificial Adhesion," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 836-842.
doi: 10.1109/ICRA40945.2020.9197246
Abstract: This paper presents a novel physical gripping framework intended for controlled, high force density attachment on a range of surfaces. Our framework utilizes a light-activated chemical adhesive to attach to surfaces. The cured adhesive is part of a "sacrificial layer," which is shed when the gripper separates from the surface. In order to control adhesive behavior we utilize ultraviolet (UV) light sensitive acrylics which are capable of rapid curing when activated with 380nm light. Once cured, zero input power is needed to hold load. Thin plastic parts can be used as the sacrificial layers, and these can be released using an electric motor. This new gripping framework including the curing load capacity, adhesive deposition, and sacrificial methods are described in detail. Two proof-of concept prototypes are designed, built, and tested. The experimental results illustrate the response time (15-75s depending on load), high holding force-to-weight ratio (10-30), and robustness to material type. Additionally, two drawbacks of this design are discussed: corruption of the gripped surface and a limited number of layers.
keywords: {Grippers;Force;Curing;Adhesives;Chemicals;Mobile robots;Mechanism Design;Manipulation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197246&isnumber=9196508

D. Gueners, H. Chanal and B. C. Bouzgarrou, "Stiffness optimization of a cable driven parallel robot for additive manufacturing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 843-849.
doi: 10.1109/ICRA40945.2020.9197368
Abstract: In this paper, the optimization of the anchor points of a cable driven parallel robot (CDPR) for 3D printing is proposed in order to maximize the rigidity. Indeed, in the context of 3D printing, robot stiffness should guarantee a high level of tool path following accuracy. The optimized platform showed a rigidity improvement in simulation, but also experimentally with a first study of vibration modes. In the same time, this study illustrates the influence of preload in cables on the platform rigidity.
keywords: {Vibrations;Parallel robots;Automation;Simulation;Robot kinematics;Conferences;Three-dimensional printing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197368&isnumber=9196508

D. Mannhart, F. Dubois, K. Bodie, V. Klemm, A. Morra and M. Hutter, "CAMI - Analysis, Design and Realization of a Force-Compliant Variable Cam System," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 850-856.
doi: 10.1109/ICRA40945.2020.9197019
Abstract: This work presents a novel design concept that achieves multi-legged locomotion using a three-dimensional cam system. A computational framework has been developed to analyze and dimension this cam apparatus, that can perform arbitrary end effector motions within its design constraints. The mechanism enables continuous gait transition and inherent force compliance. With only two motors, any trajectory of a continuous set of gaits can be followed. One motor is used to actuate the system and a second one to morph its movement. To illustrate a possible application of this system, a working prototype of a bipedal robot is developed and validated in hardware. It showcases a smooth velocity change by transitioning through different gaits from standing still to walking fast at 124mm/s within 2.0s, while following the given end effector trajectory with an error of only 2.47mm.
keywords: {Legged locomotion;Trajectory;End effectors;Couplings;Shape;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197019&isnumber=9196508

R. Kim, A. Debate, S. Balakirsky and A. Mazumdar, "Using Manipulation to Enable Adaptive Ground Mobility," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 857-863.
doi: 10.1109/ICRA40945.2020.9197061
Abstract: In order to accomplish various missions, autonomous ground vehicles must operate on a wide range of terrain. While many systems such as wheels and whegs can navigate some types of terrain, none are optimal across all. This creates a need for physical adaptation. This paper presents a broad new approach to physical adaptation that relies on manipulation. Specifically, we explore how multipurpose manipulators can enable ground vehicles to dramatically modify their propulsion system in order to optimize performance across various terrain. While this approach is general and widely applicable, this work focuses on physically switching between wheels and legs. We outline the design of "swappable propulsors" that combine the powerful adhesion forces of permanent magnets with geometric features for easy detachment. We provide analysis on how the swappable propulsors can be manipulated, and use these results to create a functional prototype robot. This robot can use its manipulator to change between wheeled and legged locomotion. Our experimental results illustrate how this approach can enhance energy efficiency and versatility.
keywords: {Legged locomotion;Wheels;Manipulators;Steel;Force;Mechanism design;mobile manipulation;wheeled robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197061&isnumber=9196508

T. Yang, Y. Zhang, P. Li, Y. Shen, Y. Liu and H. Chen, "SNIAE-SSE Deformation Mechanism Enabled Scalable Multicopter: Design, Modeling and Flight Performance Validation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 864-870.
doi: 10.1109/ICRA40945.2020.9197025
Abstract: This paper focuses on designing, modeling and validating a novel scalable multicopter whose deformation mechanism, called SNIAE-SSE, relies on a combination of simple non-intersecting angulated elements (SNIAEs) and straight scissor-like elements (SSEs). The proposed SNIAE-SSE mechanism has the advantages of single degree-of-freedom, fast actuation capability and large deformation ratio. In this work, enabled by the SNIAE-SSE mechanism, a quadcopter prototype with symmetrical and synchronous deformation is firstly developed, which facilitates a novel and controllably scalable multicopter system for us to analyze its modeling, as well as to validate its flight performance and dynamics during the deformation in several flight missions including hover, throwing, and morphing flying through a narrow window. Experimental results demonstrate that the developed scalable multicopter can maintain its stable flight behavior even both the folding and unfolding body deformations are fast performed, which indicates an excellent capability of the scalable multicopter to rapidly adapt to complex and dynamically changed environments.
keywords: {Strain;Rotors;Servomotors;Prototypes;Deformable models;Task analysis;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197025&isnumber=9196508

G. Ferri, P. Stinco, G. De Magistris, A. Tesei and K. D. LePage, "Cooperative Autonomy and Data Fusion for Underwater Surveillance With Networked AUVs," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 871-877.
doi: 10.1109/ICRA40945.2020.9197367
Abstract: Cooperative autonomy and data sharing can largely improve the mission performance of robotic networks in underwater surveillance applications. In this paper, we describe the cooperative autonomy used to control the Autonomous Underwater Vehicles (AUVs) acting as sonar receiver nodes in the CMRE Anti-Submarine Warfare (ASW) network. The paper focuses on a track management module that was integrated in the robot autonomy software for enabling the share of information. Track to track (T2T) associations are used for improving track classification and for creating a common tactical picture, necessary for AUV cooperative strategies. We also present a new cooperative data-driven AUV behaviour that exploits the spatial diversity of multiple robots for improving target tracking and for facilitating T2T associations. We report results with real data collected at sea that validate the approach. The reported results are one of the first examples that show the potential of cooperative autonomy and data fusion in realistic underwater surveillance scenarios characterised by limited communications.
keywords: {Target tracking;Robot kinematics;Sonar;Receivers;Signal processing algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197367&isnumber=9196508

T. W. Secord and T. R. Louwagie, "Bidirectional Resonant Propulsion and Localization for AUVs," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 878-884.
doi: 10.1109/ICRA40945.2020.9197363
Abstract: Battery life, reliability, and localization are prominent challenges in the design of autonomous underwater vehicles (AUVs). This work aims to address facets of these challenges using a single system. We describe the design of a bidirectional resonant pump that uses a single electromagnetic voice coil motor (VCM) capable of rotation around a central two degree-of-freedom flexure stage axis. This actuator design produces highly efficient resonant motion that drives two orthogonally oriented diaphragms simultaneously. The operation of this diaphragm pump mechanism produces both adjustable thrust vectors at the aft surface of the AUV and a monotonic relationship between thrust vectors and operating frequency. We propose using the unique frequency to thrust relationship to enhance AUV localization capabilities. We construct a prototype and use it to experimentally demonstrate the feasibility of the directionally-tunable resonance concept.
keywords: {Propulsion;Resonant frequency;Strain;Standards;Damping;Reliability engineering},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197363&isnumber=9196508

J. J. Heon Lee, C. Yoo, S. Anstee and R. Fitch, "Hierarchical Planning in Time-Dependent Flow Fields for Marine Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 885-891.
doi: 10.1109/ICRA40945.2020.9197513
Abstract: We present an efficient approach for finding shortest paths in flow fields that vary as a sequence of flow predictions over time. This approach is applicable to motion planning for slow marine robots that are subject to dynamic ocean currents. Although the problem is NP-hard in general form, we incorporate recent results from the theory of finding shortest paths in time-dependent graphs to construct a polynomial-time algorithm that finds continuous trajectories in time-dependent flow fields. The algorithm has a hierarchical structure where a graph is constructed with time-varying edge costs that are derived from sets of continuous trajectories in the underlying flow field. We show that the continuous algorithm retains the time complexity and path quality properties of the discrete graph solution, and demonstrate its application to surface and underwater vehicles including a traversal along the East Australian Current with an autonomous marine vehicle. Results show that the algorithm performs efficiently in practice and can find paths that adapt to changing ocean currents. These results are significant to marine robotics because they allow for efficient use of time-varying ocean predictions for motion planning.
keywords: {Planning;Robots;Vehicle dynamics;Oceans;Heuristic algorithms;Prediction algorithms;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197513&isnumber=9196508

M. Xanthidis et al., "Navigation in the Presence of Obstacles for an Agile Autonomous Underwater Vehicle," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 892-899.
doi: 10.1109/ICRA40945.2020.9197558
Abstract: Navigation underwater traditionally is done by keeping a safe distance from obstacles, resulting in "fly-overs" of the area of interest. Movement of an autonomous underwater vehicle (AUV) through a cluttered space, such as a shipwreck or a decorated cave, is an extremely challenging problem that has not been addressed in the past. This paper proposes a novel navigation framework utilizing an enhanced version of Trajopt for fast 3D path-optimization planning for AUVs. A sampling-based correction procedure ensures that the planning is not constrained by local minima, enabling navigation through narrow spaces. Two different modalities are proposed: planning with a known map results in efficient trajectories through cluttered spaces; operating in an unknown environment utilizes the point cloud from the visual features detected to navigate efficiently while avoiding the detected obstacles. The proposed approach is rigorously tested, both on simulation and in-pool experiments, proven to be fast enough to enable safe real-time 3D autonomous navigation for an AUV.
keywords: {Planning;Three-dimensional displays;Navigation;Optimization;Robots;Trajectory;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197558&isnumber=9196508

M. J. Islam, S. Sakib Enan, P. Luo and J. Sattar, "Underwater Image Super-Resolution using Deep Residual Multipliers," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 900-906.
doi: 10.1109/ICRA40945.2020.9197213
Abstract: We present a deep residual network-based generative model for single image super-resolution (SISR) of underwater imagery for use by autonomous underwater robots. We also provide an adversarial training pipeline for learning SISR from paired data. In order to supervise the training, we formulate an objective function that evaluates the perceptual quality of an image based on its global content, color, and local style information. Additionally, we present USR-248, a large-scale dataset of three sets of underwater images of `high' (640√ó480) and `low' (80 √ó 60, 160 √ó 120, and 320√ó240) resolution. USR-248 contains paired instances for supervised training of 2√ó, 4√ó, or 8√ó SISR models. Furthermore, we validate the effectiveness of our proposed model through qualitative and quantitative experiments and compare the results with several state-of-the-art models' performances. We also analyze its practical feasibility for applications such as scene understanding and attention modeling in noisy visual conditions.
keywords: {Training;Image resolution;Robots;Data models;Cameras;Pipelines;Generators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197213&isnumber=9196508

C. Wei, H. G. Tanner and M. Ani Hsieh, "Nonlinear Synchronization Control for Short-Range Mobile Sensors Drifting in Geophysical Flows," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 907-913.
doi: 10.1109/ICRA40945.2020.9196701
Abstract: This paper presents a synchronization controller for mobile sensors that are minimally actuated and can only communicate with each other over a very short range. This work is motivated by ocean monitoring applications where large-scale sensor networks consisting of drifters with minimal actuation capabilities, i.e., active drifters, are employed. We assume drifters are tasked to monitor regions consisting of gyre flows where their trajectories are periodic. As drifters in neighboring regions move into each other's proximity, it presents an opportunity for data exchange and synchronization to ensure future rendezvous. We present a nonlinear synchronization control strategy to ensure that drifters will periodically rendezvous and maximize the time they are in their rendezvous regions. Numerical simulations and small-scale experiments validate the efficacy of the control strategy and hint at extensions to large-scale mobile sensor networks.
keywords: {Synchronization;Sensors;Vehicle dynamics;Orbits;Robots;Oscillators;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196701&isnumber=9196508

W. Roozing, S. S. Groothuis and S. Stramigioli, "Energy-based Safety in Series Elastic Actuation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 914-920.
doi: 10.1109/ICRA40945.2020.9197448
Abstract: This work presents the concept of energy-based safety for series-elastic actuation. Generic actuation passivity and safety is treated, defining several energy storage and power flow properties related to passivity. Safe behaviour is not guaranteed by passivity, but can be guaranteed by energy and power limits that adapt the nominal behaviour of an impedance controller. A discussion on power flows in series-elastic actuation is presented and an appropriate controller is developed. Experimental results validate the effectiveness of the energy-based safety in elastic actuation.
keywords: {Safety;Robots;Energy storage;Actuators;Impedance;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197448&isnumber=9196508

K. Haninger, A. Asignacion and S. Oh, "Safe high impedance control of a series-elastic actuator with a disturbance observer," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 921-927.
doi: 10.1109/ICRA40945.2020.9197402
Abstract: In many series-elastic actuator applications, the ability to safely render a wide range of impedance is important. Advanced torque control techniques such as the disturbance observer (DOB) can improve torque tracking performance, but their impact on safe impedance range is not established. Here, safety is defined with load port passivity, and passivity conditions are developed for two variants of DOB torque control. These conditions are used to determine the maximum safe stiffness and Z-region of the DOB controllers, which are analyzed and compared with the no DOB case. A feedforward controller is proposed which increases the maximum safe stiffness of the DOB approaches. The results are experimentally validated by manual excitation and in a high-stiffness environment.
keywords: {Impedance;Torque;Torque control;Springs;Stability analysis;Safety;Measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197402&isnumber=9196508

S. Y. Kim, T. Zhang and D. J. Braun, "Variable Stiffness Springs for Energy Storage Applications," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 928-933.
doi: 10.1109/ICRA40945.2020.9197245
Abstract: Theory suggests an inverse relation between the stiffness and the energy storage capacity for linear helical springs: reducing the active length of the spring by 50% increases its stiffness by 100%, but reduces its energy storage capacity by 50%. State-of-the-art variable stiffness actuators used to drive robots are characterized by a similar inverse relation, implying reduced energy storage capacity for increased spring stiffness. This relation limits the potential of the variable stiffness actuation technology when it comes to human performance augmentation in natural tasks, e.g., jumping, weight-bearing and running, which may necessitate a spring exoskeleton with large stiffness range and high energy storage capacity. In this paper, we theoretically show that the trade-off between stiffness range and energy storage capacity is not fundamental; it is possible to develop variable stiffness springs with simultaneously increasing stiffness and energy storage capacity. Consistent with the theory, we experimentally show that a controllable volume air spring, has a direct relation between its stiffness range and energy storage capacity. The mathematical conditions presented in this paper may be used to develop actuators that could bypass the limited energy storage capacity of current variable stiffness spring technology.
keywords: {Springs;Energy storage;Actuators;Potential energy;Strain;Force;Valves},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197245&isnumber=9196508

S. Liu, H. Wu, Y. Yang and M. Y. Wang, "Parallel-motion Thick Origami Structure for Robotic Design," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 934-939.
doi: 10.1109/ICRA40945.2020.9197339
Abstract: Structures with origami design enable objects to transform into various three-dimensional shapes. Traditionally origami structures are designed with zero-thickness flat paper sheets. However, the thickness and intersection of origami facets are non-negligible in most cases, uniquely when integrating origami design with robotic design because of the more efficient force transfer between thick plates compared with zero-thickness paper-sheets. Meanwhile, the single-layer-paper oriented initial design limited the shape transformation potential as multiple layer origami structures could conduct more variety of deformation. In this article, we are proposing a general design method of parallel-motion thick origami structures that could apply in robotic design like a parallel-motion gripper.
keywords: {Fasteners;Grippers;Robots;Shape;Actuators;Force;Electronic mail},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197339&isnumber=9196508

Y. Okada, S. Kojima, K. Ohno and S. Tadokoro, "Real-time Simulation of Non-Deformable Continuous Tracks with Explicit Consideration of Friction and Grouser Geometry," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 948-954.
doi: 10.1109/ICRA40945.2020.9196776
Abstract: In this study, we developed a real-time simulation method for non-deformable continuous tracks having grousers for rough terrain by explicitly considering the collision and friction between the tracks and the ground. In the proposed simulation method, an arbitrary trajectory of a track is represented with multiple linear and circular segments, each of which is a link connected to a robot body. The proposed method sets velocity constraints between each segment link and the robot body, to simulate the track rotation around the body. To maintain the shape of a track, it also restores the positions of the segment links when required. Experimental comparisons with other existing real-time simulation methods demonstrated that while the proposed method considered the grousers and the friction with the ground, it was comparable to them in terms of the computational speed. Experimental comparison of the simulations based on the proposed method and a physical robot exhibited that the former was comparable to the precise motion of the robot on rough or uneven terrain.
keywords: {Robots;Trajectory;Tracking;Friction;Collision avoidance;Real-time systems;Wheels},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196776&isnumber=9196508

J. G. Rogers, J. M. Gregory, J. Fink and E. Stump, "Test Your SLAM! The SubT-Tunnel dataset and metric for mapping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 955-961.
doi: 10.1109/ICRA40945.2020.9197156
Abstract: This paper presents an approach and introduces new open-source tools that can be used to evaluate robotic mapping algorithms. Also described is an extensive subterranean mine rescue dataset based upon the DARPA Subterranean (SubT) challenge including professionally surveyed ground truth. Finally, some commonly available approaches are evaluated using this metric.
keywords: {Simultaneous localization and mapping;Cameras;Measurement;Laser radar;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197156&isnumber=9196508

S. Dutta, B. Rekabdar and C. Ekenna, "Uncertainty Measured Markov Decision Process in Dynamic Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 962-968.
doi: 10.1109/ICRA40945.2020.9197064
Abstract: Successful robot path planning is challenging in the presence of visual occlusions and moving targets. Classical methods to solve this problem have used visioning and perception algorithms in addition to partially observable markov decision processes to aid in path planning for pursuit-evasion and robot tracking. We present a predictive path planning process that measures and utilizes the uncertainty present during robot motion planning. We develop a variant of subjective logic in combination with the Markov decision process (MDP) and provide a measure for belief, disbelief, and uncertainty in relation to feasible trajectories being generated. We then model the MDP to identify the best path planning method from a list of possible choices. Our results show a high percentage accuracy based on the closest acquired proximity between a target and a tracking robot and a simplified pursuer trajectory in comparison with related work.
keywords: {Uncertainty;Planning;Robots;Markov processes;Target tracking;Probabilistic logic;Measurement uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197064&isnumber=9196508

S. Hu, Y. Hu, J. Li, X. Long, M. Chen and Q. Gu, "Natural Scene Facial Expression Recognition with Dimension Reduction Network," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 987-992.
doi: 10.1109/ICRA40945.2020.9197547
Abstract: As an external manifestation of human emotions, expression recognition plays an important role in human-computer interaction. Although existing expression recognition methods performs perfectly on constrained frontal faces, there are still many challenges in expression recognition in natural scenes due to different unrestricted conditions. Expression classification belongs to a pattern recognition problem where intra-class distance is greater than the inter-class distance, which leads to severe over-fitting when using neural networks for expression recognition. This paper proposes a novel net-work structure called Dimension Reduction Network which can effectively reduce generalization error. By adding a data dimension reduction module before the general classification network, a lot of redundant information is filtered, and only useful information is left. This can reduce the interference by irrelevant information when performing classification tasks and reduce generalization error. The proposed method does not require any modification to the classification network, only a small dimension reduction module needs to be added in front of the classification network. However, it can effectively reduce generalization error. We designed big and tiny versions of Dimension Reduction Network, both exceeds our baseline on AffectNet data set. The big version of our proposed method surpassed the state-of-the-art methods by more than 1.2% on AffectNet data set. Our code will open source3 when the paper is accepted.
keywords: {Feature extraction;Faces;Face recognition;Neural networks;Training;Dimensionality reduction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197547&isnumber=9196508

S. Li, H. Wang and D. Lee, "Hand Pose Estimation for Hand-Object Interaction Cases using Augmented Autoencoder," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 993-999.
doi: 10.1109/ICRA40945.2020.9197299
Abstract: Hand pose estimation with objects is challenging due to object occlusion and the lack of large annotated datasets. To tackle these issues, we propose an Augmented Autoencoder based deep learning method using augmented clean hand data. Our method takes 3D point cloud of a hand with an augmented object as input and encodes the input to latent representation of the hand. From the latent representation, our method decodes 3D hand pose and we propose to use an auxiliary point cloud decoder to assist the formation of the latent space. Through quantitative and qualitative evaluation on both synthetic dataset and real captured data containing objects, we demonstrate state-of-the-art performance for hand pose estimation with objects, even using only a small number of annotated hand-object samples.
keywords: {Three-dimensional displays;Pose estimation;Decoding;Image reconstruction;Task analysis;Shape;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197299&isnumber=9196508

T. Linder, K. Y. Pfeiffer, N. Vaskevicius, R. Schirmer and K. O. Arras, "Accurate detection and 3D localization of humans using a novel YOLO-based RGB-D fusion approach and synthetic training data," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1000-1006.
doi: 10.1109/ICRA40945.2020.9196899
Abstract: While 2D object detection has made significant progress, robustly localizing objects in 3D space under presence of occlusion is still an unresolved issue. Our focus in this work is on real-time detection of human 3D centroids in RGB-D data. We propose an image-based detection approach which extends the YOLO v3 architecture with a 3D centroid loss and mid-level feature fusion to exploit complementary information from both modalities. We employ a transfer learning scheme which can benefit from existing large-scale 2D object detection datasets, while at the same time learning end-to-end 3D localization from our highly randomized, diverse synthetic RGB-D dataset with precise 3D groundtruth. We further propose a geometrically more accurate depth-aware crop augmentation for training on RGB-D data, which helps to improve 3D localization accuracy. In experiments on our challenging intralogistics dataset, we achieve state-of-the-art performance even when learning 3D localization just from synthetic data.
keywords: {Three-dimensional displays;Two dimensional displays;Training;Detectors;Feature extraction;Robustness;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196899&isnumber=9196508

Y. Murozaki and F. Arai, "Wide-range Load Sensor Using Vacuum Sealed Quartz Crystal Resonator for Simultaneous Biosignals Measurement on Bed," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1015-1020.
doi: 10.1109/ICRA40945.2020.9196533
Abstract: Monitoring of biosignals on a daily basis plays important roles for the health management of elderly. The monitoring system for the daily life, the system should not require the subjects to take special effort like wearing a sensor. We propose biosignals measurement using wide-range load sensor on the bed. The sensing system can detect the body weight, heartbeat and respiration simultaneously by just lying on the bed. We have developed load sensor using quartz crystal resonator (QCR load sensor) as wide-range load sensor. However, the measurement range was not sufficient for the simultaneous measurement of biosgnals on bed. To realize such sensing system, we propose a QCR load sensor utilizing vacuum sealing technology for expanding the measurement range. We improved the oscillation characteristics of the QCR by the vacuum sealing to stabilize the sensor output. Accordingly, the resolution of the sensor was improved. Moreover, the load capacity of the sensor was increased by improving the bonding strength of sensor structure. The fabricated sensor had a measurement range of 0.27 mN - 1180 N (4.4 √ó 106). This wide enough compared with the conventional force sensor (103 - 104).Also, we developed mechanically robust jig of QCR load sensor for practical use of QCR load sensor. We succeed in simultaneous measurement of weight, heart rate, and respiration rate using fabricated QCR load sensing system. The accuracy of heart rate and respiration rate measurement are 0.4 bpm (0.6 %) and 1.1 brpm (6.1 %), respectively, in standard deviation of error compared with ECG signal.
keywords: {Bonding;Weight measurement;Robot sensing systems;Force;Heart beat;Resists;Stress},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196533&isnumber=9196508

H. Kataoka, T. Suzuki, K. Nakashima, Y. Satoh and Y. Aoki, "Joint Pedestrian Detection and Risk-level Prediction with Motion-Representation-by-Detection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1021-1027.
doi: 10.1109/ICRA40945.2020.9197399
Abstract: The paper presents a pedestrian near-miss detector with temporal analysis that provides both pedestrian detection and risk-level predictions which are demonstrated on a self-collected database. Our work makes three primary contributions: (i) The framework of pedestrian near-miss detection is proposed by providing both a pedestrian detection and risk-level assignment. Specifically, we have created a Pedestrian Near-Miss (PNM) dataset that categorizes traffic near-miss incidents based on their risk levels (high-, low-, and no-risk). Unlike existing databases, our dataset also includes manually localized pedestrian labels as well as a large number of incident-related videos. (ii) Single-Shot MultiBox Detector with Motion Representation (SSD-MR) is implemented to effectively extract motion-based features in a detected pedestrian. (iii) Using the self-collected PNM dataset and SSD-MR, our proposed method achieved +19.38% (on risk-level prediction) and +13.00% (on joint pedestrian detection and risk-level prediction) higher scores than that of the baseline SSD and LSTM. Additionally, the running time of our system is over 50 fps on a graphics processing unit (GPU).
keywords: {Videos;Databases;Detectors;Feature extraction;Object detection;Accidents;Autonomous automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197399&isnumber=9196508

P. Gao and H. Zhang, "Long-term Place Recognition through Worst-case Graph Matching to Integrate Landmark Appearances and Spatial Relationships," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1070-1076.
doi: 10.1109/ICRA40945.2020.9196906
Abstract: Place recognition is an important component for simultaneously localization and mapping in a variety of robotics applications. Recently, several approaches using landmark information to represent a place showed promising performance to address long-term environment changes. However, previous approaches do not explicitly consider changes of the landmarks, i,e., old landmarks may disappear and new ones often appear over time. In addition, representations used in these approaches to represent landmarks are limited, based upon visual or spatial cues only. In this paper, we introduce a novel worst-case graph matching approach that integrates spatial relationships of landmarks with their appearances for long-term place recognition. Our method designs a graph representation to encode distance and angular spatial relationships as well as visual appearances of landmarks in order to represent a place. Then, we formulate place recognition as a graph matching problem under the worst-case scenario. Our approach matches places by computing the similarities of distance and angular spatial relationships of the landmarks that have the least similar appearances (i.e., worst-case). If the worst appearance similarity of landmarks is small, two places are identified to be not the same, even though their graph representations have high spatial relationship similarities. We evaluate our approach over two public benchmark datasets for long-term place recognition, including St. Lucia and CMU-VL. The experimental results have validated that our approach obtains the state-of-the-art place recognition performance, with a changing number of landmarks.
keywords: {Visualization;Simultaneous localization and mapping;Robustness;Strain;Image recognition;Tensile stress},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196906&isnumber=9196508

K. Joo, T. -H. Oh, F. Rameau, J. -C. Bazin and I. S. Kweon, "Linear RGB-D SLAM for Atlanta World," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1077-1083.
doi: 10.1109/ICRA40945.2020.9196561
Abstract: We present a new linear method for RGB-D based simultaneous localization and mapping (SLAM). Compared to existing techniques relying on the Manhattan world assumption defined by three orthogonal directions, our approach is designed for the more general scenario of the Atlanta world. It consists of a vertical direction and a set of horizontal directions orthogonal to the vertical direction and thus can represent a wider range of scenes. Our approach leverages the structural regularity of the Atlanta world to decouple the non-linearity of camera pose estimations. This allows us separately to estimate the camera rotation and then the translation, which bypasses the inherent non-linearity of traditional SLAM techniques. To this end, we introduce a novel tracking-by-detection scheme to estimate the underlying scene structure by Atlanta representation. Thereby, we propose an Atlanta frame-aware linear SLAM framework which jointly estimates the camera motion and a planar map supporting the Atlanta structure through a linear Kalman filter. Evaluations on both synthetic and real datasets demonstrate that our approach provides favorable performance compared to existing state-of-the-art methods while extending their working range to the Atlanta world.
keywords: {Simultaneous localization and mapping;Cameras;Three-dimensional displays;Tracking;Kalman filters;Visualization;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196561&isnumber=9196508

Y. Fan, R. Wang and Y. Mao, "Stereo Visual Inertial Odometry with Online Baseline Calibration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1084-1090.
doi: 10.1109/ICRA40945.2020.9197581
Abstract: Stereo-vision devices have rigorous requirements for extrinsic parameter calibration. In Stereo Visual Inertial Odometry (VIO), inaccuracy in or changes to camera extrinsic parameters may lead to serious degradation in estimation performance. In this manuscript, we propose an online calibration method for stereo VIO extrinsic parameters correction. In particular, we focus on Multi-State Constraint Kalman Filter (MSCKF [1]) framework to implement our method. The key component is to formulate stereo extrinsic parameters as part of the state variables and model the Jacobian of feature reprojection error with respect to stereo extrinsic parameters as sub-block of update Jacobian. Therefore we can estimate stereo extrinsic parameters simultaneously with inertial measurement unit (IMU) states and camera poses. Experiments on EuRoC dataset and real-world outdoor dataset demonstrate that the proposed algorithm produce higher positioning accuracy than the original S-MSCKF [2], and the noise of camera extrinsic parameters are self-corrected within the system.
keywords: {Cameras;Calibration;Estimation;Visualization;Acceleration;Jacobian matrices;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197581&isnumber=9196508

S. -S. Huang, Z. -Y. Ma, T. -J. Mu, H. Fu and S. -M. Hu, "Lidar-Monocular Visual Odometry using Point and Line Features," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1091-1097.
doi: 10.1109/ICRA40945.2020.9196613
Abstract: We introduce a novel lidar-monocular visual odometry approach using point and line features. Compared to previous point-only based lidar-visual odometry, our approach leverages more environment structure information by introducing both point and line features into pose estimation. We provide a robust method for point and line depth extraction, and formulate the extracted depth as prior factors for point-line bundle adjustment. This method greatly reduces the features' 3D ambiguity and thus improves the pose estimation accuracy. Besides, we also provide a purely visual motion tracking method and a novel scale correction scheme, leading to an efficient lidar-monocular visual odometry system with high accuracy. The evaluations on the public KITTI odometry benchmark show that our technique achieves more accurate pose estimation than the state-of-the-art approaches, and is sometimes even better than those leveraging semantic information.
keywords: {Feature extraction;Cameras;Bundle adjustment;Laser radar;Image segmentation;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196613&isnumber=9196508

K. J. Doherty, D. P. Baxter, E. Schneeweiss and J. J. Leonard, "Probabilistic Data Association via Mixture Models for Robust Semantic SLAM," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1098-1104.
doi: 10.1109/ICRA40945.2020.9197382
Abstract: Modern robotic systems sense the environment geometrically, through sensors like cameras, lidar, and sonar, as well as semantically, often through visual models learned from data, such as object detectors. We aim to develop robots that can use all of these sources of information for reliable navigation, but each is corrupted by noise. Rather than assume that object detection will eventually achieve near perfect performance across the lifetime of a robot, in this work we represent and cope with the semantic and geometric uncertainty inherent in object detection methods. Specifically, we model data association ambiguity, which is typically non-Gaussian, in a way that is amenable to solution within the common nonlinear Gaussian formulation of simultaneous localization and mapping (SLAM). We do so by eliminating data association variables from the inference process through max-marginalization, preserving standard Gaussian posterior assumptions. The result is a max-mixture-type model that accounts for multiple data association hypotheses. We provide experimental results on indoor and outdoor semantic navigation tasks with noisy odometry and object detection and find that the ability of the proposed approach to represent multiple hypotheses, including the "null" hypothesis, gives substantial robustness advantages in comparison to alternative semantic SLAM approaches.
keywords: {Semantics;Simultaneous localization and mapping;Robustness;Optimization;Object detection;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197382&isnumber=9196508

Y. Zhao, J. S. Smith, S. H. Karumanchi and P. A. Vela, "Closed-Loop Benchmarking of Stereo Visual-Inertial SLAM Systems: Understanding the Impact of Drift and Latency on Tracking Accuracy," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1105-1112.
doi: 10.1109/ICRA40945.2020.9197003
Abstract: Visual-inertial SLAM is essential for robot navigation in GPS-denied environments, e.g. indoor, underground. Conventionally, the performance of visual-inertial SLAM is evaluated with open-loop analysis, with a focus on the drift level of SLAM systems. In this paper, we raise the question on the importance of visual estimation latency in closed-loop navigation tasks, such as accurate trajectory tracking. To understand the impact of both drift and latency on visualinertial SLAM systems, a closed-loop benchmarking simulation is conducted, where a robot is commanded to follow a desired trajectory using the feedback from visual-inertial estimation. By extensively evaluating the trajectory tracking performance of representative state-of-the-art visual-inertial SLAM systems, we reveal the importance of latency reduction in visual estimation module of these systems. The findings suggest directions of future improvements for visual-inertial SLAM.
keywords: {Visualization;Navigation;Simultaneous localization and mapping;Benchmark testing;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197003&isnumber=9196508

L. Pan, C. -M. Chew and G. H. Lee, "PointAtrousGraph: Deep Hierarchical Encoder-Decoder with Point Atrous Convolution for Unorganized 3D Points," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1113-1120.
doi: 10.1109/ICRA40945.2020.9197499
Abstract: Motivated by the success of encoding multi-scale contextual information for image analysis, we propose our PointAtrousGraph (PAG) - a deep permutation-invariant hierarchical encoder-decoder for efficiently exploiting multi-scale edge features in point clouds. Our PAG is constructed by several novel modules, such as Point Atrous Convolution (PAC), Edgepreserved Pooling (EP) and Edge-preserved Unpooling (EU). Similar with atrous convolution, our PAC can effectively enlarge receptive fields of filters and thus densely learn multi-scale point features. Following the idea of non-overlapping maxpooling operations, we propose our EP to preserve critical edge features during subsampling. Correspondingly, our EU modules gradually recover spatial information for edge features. In addition, we introduce chained skip subsampling/upsampling modules that directly propagate edge features to the final stage. Particularly, our proposed auxiliary loss functions can further improve our performance. Experimental results show that our PAG outperform previous state-of-the-art methods on various 3D semantic perception applications.
keywords: {Three-dimensional displays;Picture archiving and communication systems;Convolution;Semantics;Image edge detection;Task analysis;Decoding},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197499&isnumber=9196508

C. Reymann and S. Lacroix, "Learning error models for graph SLAM," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1121-1127.
doi: 10.1109/ICRA40945.2020.9196864
Abstract: Following recent developments, this paper investigates the possibility to predict uncertainty models for monocular graph SLAM using topological features of the problem. An architecture to learn relative (i.e. inter-keyframe) uncertainty models using the resistance distance in the covisibility graph is presented. The proposed architecture is applied to simulated UAV coverage path planning trajectories and an analysis of the approaches strengths and shortcomings is provided.
keywords: {Simultaneous localization and mapping;Resistance;Uncertainty;Computational modeling;Computer architecture;Predictive models;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196864&isnumber=9196508

M. Cornia, L. Baraldi and R. Cucchiara, "SMArT: Training Shallow Memory-aware Transformers for Robotic Explainability," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1128-1134.
doi: 10.1109/ICRA40945.2020.9196653
Abstract: The ability to generate natural language explanations conditioned on the visual perception is a crucial step towards autonomous agents which can explain themselves and communicate with humans. While the research efforts in image and video captioning are giving promising results, this is often done at the expense of the computational requirements of the approaches, limiting their applicability to real contexts. In this paper, we propose a fully-attentive captioning algorithm which can provide state-of-the-art performances on language generation while restricting its computational demands. Our model is inspired by the Transformer model and employs only two Transformer layers in the encoding and decoding stages. Further, it incorporates a novel memory-aware encoding of image regions. Experiments demonstrate that our approach achieves competitive results in terms of caption quality while featuring reduced computational demands. Further, to evaluate its applicability on autonomous agents, we conduct experiments on simulated scenes taken from the perspective of domestic robots.
keywords: {Decoding;Computational modeling;Visualization;Magnetic heads;Robots;Natural languages;Encoding},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196653&isnumber=9196508

L. K√§stner, V. C. Frasineanu and J. Lambrecht, "A 3D-Deep-Learning-based Augmented Reality Calibration Method for Robotic Environments using Depth Sensor Data," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1135-1141.
doi: 10.1109/ICRA40945.2020.9197155
Abstract: Augmented Reality and mobile robots are gaining increased attention within industries due to the high potential to make processes cost and time efficient. To facilitate augmented reality, a calibration between the Augmented Reality device and the environment is necessary. This is a challenge when dealing with mobile robots due to the mobility of all entities making the environment dynamic. On this account, we propose a novel approach to calibrate Augmented Reality devices using 3D depth sensor data. We use the depth camera of a Head Mounted Augmented Reality Device, the Microsoft Hololens, for deep learning-based calibration. Therefore, we modified a neural network based on the recently published VoteNet architecture which works directly on raw point cloud input observed by the Hololens. We achieve satisfying results and eliminate external tools like markers, thus enabling a more intuitive and flexible work flow for Augmented Reality integration. The results are adaptable to work with all depth cameras and are promising for further research. Furthermore, we introduce an open source 3D point cloud labeling tool, which is to our knowledge the first open source tool for labeling raw point cloud data.
keywords: {Robot sensing systems;Three-dimensional displays;Calibration;Neural networks;Augmented reality;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197155&isnumber=9196508

X. Chen, A. Ghadirzadeh, M. Bj√∂rkman and P. Jensfelt, "Adversarial Feature Training for Generalizable Robotic Visuomotor Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1142-1148.
doi: 10.1109/ICRA40945.2020.9197505
Abstract: Deep reinforcement learning (RL) has enabled training action-selection policies, end-to-end, by learning a function which maps image pixels to action outputs. However, it's application to visuomotor robotic policy training has been limited because of the challenge of large-scale data collection when working with physical hardware. A suitable visuomotor policy should perform well not just for the task-setup it has been trained for, but also for all varieties of the task, including novel objects at different viewpoints surrounded by task-irrelevant objects. However, it is impractical for a robotic setup to sufficiently collect interactive samples in a RL framework to generalize well to novel aspects of a task. In this work, we demonstrate that by using adversarial training for domain transfer, it is possible to train visuomotor policies based on RL frameworks, and then transfer the acquired policy to other novel task domains. We propose to leverage the deep RL capabilities to learn complex visuomotor skills for uncomplicated task setups, and then exploit transfer learning to generalize to new task domains provided only still images of the task in the target domain. We evaluate our method on two real robotic tasks, picking and pouring, and compare it to a number of prior works, demonstrating its superiority.
keywords: {Task analysis;Training;Visualization;Feature extraction;Robots;Trajectory;Clutter},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197505&isnumber=9196508

R. Chitnis, S. Tulsiani, S. Gupta and A. Gupta, "Efficient Bimanual Manipulation Using Learned Task Schemas," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1149-1155.
doi: 10.1109/ICRA40945.2020.9196958
Abstract: We address the problem of effectively composing skills to solve sparse-reward tasks in the real world. Given a set of parameterized skills (such as exerting a force or doing a top grasp at a location), our goal is to learn policies that invoke these skills to efficiently solve such tasks. Our insight is that for many tasks, the learning process can be decomposed into learning a state-independent task schema (a sequence of skills to execute) and a policy to choose the parameterizations of the skills in a state-dependent manner. For such tasks, we show that explicitly modeling the schema's state-independence can yield significant improvements in sample efficiency for model-free reinforcement learning algorithms. Furthermore, these schemas can be transferred to solve related tasks, by simply re-learning the parameterizations with which the skills are invoked. We find that doing so enables learning to solve sparse-reward tasks on real-world robotic systems very efficiently. We validate our approach experimentally over a suite of robotic bimanual manipulation tasks, both in simulation and on real hardware. See videos at http://tinyurl.com/chitnis-schema.
keywords: {Task analysis;Learning (artificial intelligence);Neural networks;Force;Geometry;End effectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196958&isnumber=9196508

Q. Kuang, J. Wu, J. Pan and B. Zhou, "Real-Time UAV Path Planning for Autonomous Urban Scene Reconstruction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1156-1162.
doi: 10.1109/ICRA40945.2020.9196558
Abstract: Unmanned aerial vehicles (UAVs) are frequently used for large-scale scene mapping and reconstruction. However, in most cases, drones are operated manually, which should be more effective and intelligent. In this article, we present a method of real-time UAV path planning for autonomous urban scene reconstruction. Considering the obstacles and time costs, we utilize the top view to generate the initial path. Then we estimate the building heights and take close-up pictures that reveal building details through a SLAM framework. To predict the coverage of the scene, we propose a novel method which combines information on reconstructed point clouds and possible coverage areas. The experimental results reveal that the reconstruction quality of our method is good enough. Our method is also more time-saving than the state-of-the-arts.
keywords: {Buildings;Image reconstruction;Three-dimensional displays;Path planning;Drones;Cameras;Layout},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196558&isnumber=9196508

S. Shi, J. Chen and Y. Xiong, "A Fast Marching Gradient Sampling Strategy for Motion Planning using an Informed Certificate Set," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1163-1168.
doi: 10.1109/ICRA40945.2020.9196685
Abstract: We present a novel fast marching gradient sampling strategy to accelerate the convergence speed of sampling-based motion planning algorithms. This strategy is based on an informed certificate set which consists of the robot states with exact collision status as well as the minimum distance and the gradient to the nearest obstacle. The informed certificate set covers almost the whole planning space such that it contains rich information for the planner. The best quality point in this set is selected as the marching seed to guide the search graph move steadily to the goal set. The distance and gradient information of the marching seed helps to generate a new sample with almost sure collision status. When a feasible solution has been found, this set can construct the restricted subset that can improve current path quality. This marching gradient sampling strategy is applied to the RRT and RRT* algorithms. Simulation experiments demonstrate that the convergence speed to a feasible solution or to the optimal solution is almost twice faster than that of the safety certificate algorithms.
keywords: {Planning;Safety;Convergence;Algorithms;Robots;Data structures;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196685&isnumber=9196508

Y. Luo et al., "Privacy-Aware UAV Flights through Self-Configuring Motion Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1169-1175.
doi: 10.1109/ICRA40945.2020.9197564
Abstract: During flights, an unmanned aerial vehicle (UAV) may not be allowed to move across certain areas due to soft constraints such as privacy restrictions. Current methods on self-adaption focus mostly on motion planning such that the trajectory does not trespass predetermined restricted areas. When the environment is cluttered with uncertain obstacles, however, these motion planning algorithms are not flexible enough to find a trajectory that satisfies additional privacy-preserving requirements within a tight time budget during the flights. In this paper, we propose a privacy risk aware motion planning method through the reconfiguration of privacy-sensitive sensors. It minimises environmental impact by re-configuring the sensor during flight, while still guaranteeing the safety and energy hard constraints such as collision avoidance and timeliness. First, we formulate a model for assessing privacy risks of dynamically detected restricted areas. In case the UAV cannot find a feasible solution to satisfy both hard and soft constraints from the current configuration, our decision making method can then produce an optimal reconfiguration of the privacy-sensitive sensor with a more efficient trajectory. We evaluate the proposal through various simulations with different settings in a virtual environment and also validate the approach through real test flights on DJI Matrice 100 UAV.
keywords: {Privacy;Planning;Cameras;Sensors;Trajectory;Safety;Unmanned aerial vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197564&isnumber=9196508

B. Lacevic and D. Osmankovic, "Improved C-Space Exploration and Path Planning for Robotic Manipulators Using Distance Information," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1176-1182.
doi: 10.1109/ICRA40945.2020.9196920
Abstract: We present a simple method to quickly explore C-spaces of robotic manipulators and thus facilitate path planning. The method is based on a novel geometrical structure called generalized bur. It is a star-like tree, rooted at a given point in free C-space, with an arbitrary number of guaranteed collision-free edges computed using distance information from the workspace and simple forward kinematics. Generalized bur captures large portions of free C-space, enabling accelerated exploration. The workspace is assumed to be decomposable into a finite set of (possibly overlapping) convex obstacles. When plugged in a suitable RRT-like planning algorithm, generalized burs enable significant performance improvements, while at the same time enabling exact collision-free paths.
keywords: {Collision avoidance;Robot kinematics;Kinematics;Manipulators;Path planning;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196920&isnumber=9196508

A. √ñ. √ñnol, R. Corcodel, P. Long and T. Padƒ±r, "Tuning-Free Contact-Implicit Trajectory Optimization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1183-1189.
doi: 10.1109/ICRA40945.2020.9196805
Abstract: We present a contact-implicit trajectory optimization framework that can plan contact-interaction trajectories for different robot architectures and tasks using a trivial initial guess and without requiring any parameter tuning. This is achieved by using a relaxed contact model along with an automatic penalty adjustment loop for suppressing the relaxation. Moreover, the structure of the problem enables us to exploit the contact information implied by the use of relaxation in the previous iteration, such that the solution is explicitly improved with little computational overhead. We test the proposed approach in simulation experiments for non-prehensile manipulation using a 7-DOF arm and a mobile robot and for planar locomotion using a humanoid-like robot in zero gravity. The results demonstrate that our method provides an out-of-the-box solution with good performance for a wide range of applications.
keywords: {Robots;Task analysis;Trajectory optimization;Tuning;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196805&isnumber=9196508

B. Zhou, F. Gao, J. Pan and S. Shen, "Robust Real-time UAV Replanning Using Guided Gradient-based Optimization and Topological Paths," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1208-1214.
doi: 10.1109/ICRA40945.2020.9196996
Abstract: Gradient-based trajectory optimization (GTO) has gained wide popularity for quadrotor trajectory replanning. However, it suffers from local minima, which is not only fatal to safety but also unfavorable for smooth navigation. In this paper, we propose a replanning method based on GTO addressing this issue systematically. A path-guided optimization (PGO) approach is devised to tackle infeasible local minima, which improves the replanning success rate significantly. A topological path searching algorithm is developed to capture a collection of distinct useful paths in 3-D environments, each of which then guides an independent trajectory optimization. It activates a more comprehensive exploration of the solution space and output superior replanned trajectories. Benchmark evaluation shows that our method outplays state-of-the-art methods regarding replanning success rate and optimality. Challenging experiments of aggressive autonomous flight are presented to demonstrate the robustness of our method. We will release our implementation as an open-source package1.
keywords: {Splines (mathematics);Linear programming;Trajectory optimization;Robustness;Safety},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196996&isnumber=9196508

R. Reinhart, T. Dang, E. Hand, C. Papachristos and K. Alexis, "Learning-based Path Planning for Autonomous Exploration of Subterranean Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1215-1221.
doi: 10.1109/ICRA40945.2020.9196662
Abstract: In this work we present a new methodology on learning-based path planning for autonomous exploration of subterranean environments using aerial robots. Utilizing a recently proposed graph-based path planner as a "training expert" and following an approach relying on the concepts of imitation learning, we derive a trained policy capable of guiding the robot to autonomously explore underground mine drifts and tunnels. The algorithm utilizes only a short window of range data sampled from the onboard LiDAR and achieves an exploratory behavior similar to that of the training expert with a more than an order of magnitude reduction in computational cost, while simultaneously relaxing the need to maintain a consistent and online reconstructed map of the environment. The trained path planning policy is extensively evaluated both in simulation and experimentally within field tests relating to the autonomous exploration of underground mines.
keywords: {Robot sensing systems;Path planning;Training;Training data;Planning;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196662&isnumber=9196508

J. Lee et al., "Visual-Inertial Telepresence for Aerial Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1222-1229.
doi: 10.1109/ICRA40945.2020.9197394
Abstract: This paper presents a novel telepresence system for enhancing aerial manipulation capabilities. It involves not only a haptic device, but also a virtual reality that provides a 3D visual feedback to a remotely-located teleoperator in real-time. We achieve this by utilizing onboard visual and inertial sensors, an object tracking algorithm and a pregenerated object database. As the virtual reality has to closely match the real remote scene, we propose an extension of a marker tracking algorithm with visual-inertial odometry. Both indoor and outdoor experiments show benefits of our proposed system in achieving advanced aerial manipulation tasks, namely grasping, placing, force exertion and peg-in-hole insertion.
keywords: {Three-dimensional displays;Manipulators;Visualization;Cameras;Task analysis;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197394&isnumber=9196508

H. Yang, M. -S. Kim and D. Lee, "Distributed Rotor-Based Vibration Suppression for Flexible Object Transport and Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1230-1236.
doi: 10.1109/ICRA40945.2020.9196908
Abstract: The RVM (Robot-based Vibration Suppression Modules) is proposed for the manipulation and transport of a large flexible object. Since the RVM is easily attachable/detachable to the object, this RVM allows distributing over the manipulated object so that it is scalable to the object size. The composition of the system is partly motivated by the MAGMaS (Multiple Aerial-Ground Manipulator System) [1]- [3], however, since the quadrotor usage is mechanically too complicated and its design is not optimized for manipulation, thus we overcome these limitations using distributed RVMs and newly developed theory. For this, we first provide a constrained optimization problem of RVM design with the minimum number of rotors, so that the feasible thrust force is maximized while it minimizes undesirable wrench and its own weight. Then, we derive the full dynamics and elucidate a controllability condition with multiple distributed RVMs and show that even if multiple, their structures turn out similar to [2] composed with a single quadrotor. We also elucidate the optimal placement of the RVM via the usage of controllability gramian which is not even alluded in [2] and established for the first time here. Experiments are performed to demonstrate the effectiveness of the proposed theory.
keywords: {Rotors;Vibrations;Mathematical model;Manipulators;Controllability;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196908&isnumber=9196508

D. Lee, H. Seo, D. Kim and H. J. Kim, "Aerial Manipulation using Model Predictive Control for Opening a Hinged Door," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1237-1242.
doi: 10.1109/ICRA40945.2020.9197524
Abstract: Existing studies for environment interaction with an aerial robot have been focused on interaction with static surroundings. However, to fully explore the concept of an aerial manipulation, interaction with moving structures should also be considered. In this paper, a multirotor-based aerial manipulator opening a daily-life moving structure, a hinged door, is presented. In order to address the constrained motion of the structure and to avoid collisions during operation, model predictive control (MPC) is applied to the derived coupled system dynamics between the aerial manipulator and the door involving state constraints. By implementing a constrained version of differential dynamic programming (DDP), MPC can generate position setpoints to the disturbance observer (DOB)-based robust controller in real-time, which is validated by our experimental results.
keywords: {Manipulators;Vehicle dynamics;Mathematical model;Dynamics;Trajectory;Servomotors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197524&isnumber=9196508

B. Jeon, Y. Lee and H. J. Kim, "Integrated Motion Planner for Real-time Aerial Videography with a Drone in a Dense Environment," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1243-1249.
doi: 10.1109/ICRA40945.2020.9196703
Abstract: This work suggests an integrated approach for a drone (or multirotor) to perform an autonomous videography task in a 3-D obstacle environment by following a moving object. The proposed system includes 1) a target motion prediction module which can be applied to dense environments and 2) a hierarchical chasing planner. Leveraging covariant optimization, the prediction module estimates the future motion of the target assuming it efforts to avoid the obstacles. The other module, chasing planner, is in a bi-level structure composed of preplanner and smooth planner. In the first phase, we exploit a graph-search method to plan a chasing corridor which incorporates safety and visibility of target. In the subsequent phase, we generate a smooth and dynamically feasible trajectory within the corridor using quadratic programming (QP). We validate our approach with multiple complex scenarios and actual experiments. The source code and the experiment video can be found in https://github.com/icsl-Jeon/traj_gen_vis and https://www.youtube.com/watch?v=_JSwXBwYRl8.
keywords: {Drones;Trajectory;Safety;Optimization;Measurement;Shape;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196703&isnumber=9196508

Y. Lyu, C. Dong and J. M. Dolan, "FG-GMM-based Interactive Behavior Estimation for Autonomous Driving Vehicles in Ramp Merging Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1250-1255.
doi: 10.1109/ICRA40945.2020.9197218
Abstract: Interactive behavior is important for autonomous driving vehicles, especially for scenarios like ramp merging which require significant social interaction between autonomous driving vehicles and human-driven cars. This paper enhances our previous Probabilistic Graphical Model (PGM) merging control model for the interactive behavior of autonomous driving vehicles. To better estimate the interactive behavior for autonomous driving cars, a Factor Graph (FG) is used to describe the dependency among observations and estimate other cars‚Äô intentions. Real trajectories are used to approximate the model instead of human-designed models or cost functions. Forgetting factors and a Gaussian Mixture Model (GMM) are also applied in the intention estimation process for stabilization, interpolation and smoothness. The advantage of the factor graph is that the relationship between its nodes can be described by self-defined functions, instead of probabilistic relationships as in PGM, giving more flexibility. Continuity of GMM also provides higher accuracy than the previous discrete speed transition model. The proposed method enhances the overall performance of intention estimation, in terms of collision rate and average distance between cars after merging, which means it is safer and more efficient.
keywords: {Merging;Automobiles;Estimation;Autonomous vehicles;Probabilistic logic;Mathematical model;Roads},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197218&isnumber=9196508

A. Miller, K. Rim, P. Chopra, P. Kelkar and M. Likhachev, "Cooperative Perception and Localization for Cooperative Driving," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1256-1262.
doi: 10.1109/ICRA40945.2020.9197463
Abstract: Fully autonomous vehicles are expected to share the road with less advanced vehicles for a significant period of time. Furthermore, an increasing number of vehicles on the road are equipped with a variety of low-fidelity sensors which provide some perception and localization data, but not at a high enough quality for full autonomy. In this paper, we develop a perception and localization system that allows a vehicle with low-fidelity sensors to incorporate high-fidelity observations from a vehicle in front of it, allowing both vehicles to operate with full autonomy. The resulting system generates perception and localization information that is both low-noise in regions covered by high-fidelity sensors and avoids false negatives in areas only observed by low-fidelity sensors, while dealing with latency and dropout of the communication link between the two vehicles. At its core, the system uses a set of Extended Kalman filters which incorporate observations from both vehicles' sensors and extrapolate them using information about the road geometry. The perception and localization algorithms are evaluated both in simulation and on real vehicles as part of a full cooperative driving system.
keywords: {Sensor systems;Time measurement;Roads;Fuses;Current measurement;Bandwidth},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197463&isnumber=9196508

T. Manderson, S. Wapnick, D. Meger and G. Dudek, "Learning to Drive Off Road on Smooth Terrain in Unstructured Environments Using an On-Board Camera and Sparse Aerial Images," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1263-1269.
doi: 10.1109/ICRA40945.2020.9196879
Abstract: We present a method for learning to drive on smooth terrain while simultaneously avoiding collisions in challenging off-road and unstructured outdoor environments using only visual inputs. Our approach applies a hybrid model-based and model-free reinforcement learning method that is entirely self-supervised in labeling terrain roughness and collisions using on-board sensors. Notably, we provide both first-person and overhead aerial image inputs to our model. We nd that the fusion of these complementary inputs improves planning foresight and makes the model robust to visual obstructions. Our results show the ability to generalize to environments with plentiful vegetation, various types of rock, and sandy trails. During evaluation, our policy attained 90% smooth terrain traversal and reduced the proportion of rough terrain driven over by 6.1 times compared to a model using only first-person imagery. Video and project details can be found at www.cim.mcgill.ca/mrl/offroad_driving/.
keywords: {Predictive models;Navigation;Cameras;Planning;Computational modeling;Visualization;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196879&isnumber=9196508

R. Chandra, U. Bhattacharya, T. Randhavane, A. Bera and D. Manocha, "RoadTrack: Realtime Tracking of Road Agents in Dense and Heterogeneous Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1270-1277.
doi: 10.1109/ICRA40945.2020.9196612
Abstract: We present a realtime tracking algorithm, Road-Track, to track heterogeneous road-agents in dense traffic videos. Our approach is designed for dense traffic scenarios that consist of different road-agents such as pedestrians, two-wheelers, cars, buses, etc. sharing the road. We use the tracking-by-detection approach where we track a road-agent by matching the appearance or bounding box region in the current frame with the predicted bounding box region propagated from the previous frame. Roadtrack uses a novel motion model called the Simultaneous Collision Avoidance and Interaction (SimCAI) model to predict the motion of road-agents by modeling collision avoidance and interactions between the road-agents for the next frame. We demonstrate the advantage of RoadTrack on a dataset of dense traffic videos and observe an accuracy of 75.8% on this dataset, outperforming prior state-of-the-art tracking algorithms by at least 5.2%. RoadTrack operates in realtime at approximately 30 fps and is at least 4√ó faster than prior tracking algorithms on standard tracking datasets.
keywords: {Tracking;Predictive models;Roads;Videos;Collision avoidance;Automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196612&isnumber=9196508

D. Frisch and U. D. Hanebeck, "Association-Free Multilateration Based on Times of Arrival," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1294-1300.
doi: 10.1109/ICRA40945.2020.9197455
Abstract: Multilateration systems reconstruct the location of a target that transmits electromagnetic or acoustic signals. The employed measurements for localization are the times of arrival (TOAs) of the transmitted signal, measured by a number of spatially distributed receivers at known positions. We present a novel multilateration algorithm to localize multiple targets that transmit indistinguishable signals at unknown times. That is, each receiver measures merely a set of TOAs with no association to the targets. Our method does not need any prior information. Therefore, it can provide uncorrelated, static measurements to be introduced into a separate tracker subsequently, or an initialization routine for multi target trackers.
keywords: {Receivers;Noise measurement;Position measurement;Optimization;Acoustic measurements;Target tracking;Acoustics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197455&isnumber=9196508

L. Tang, Y. Wang, Q. Luo, X. Ding and R. Xiong, "Adversarial Feature Disentanglement for Place Recognition Across Changing Appearance," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1301-1307.
doi: 10.1109/ICRA40945.2020.9196518
Abstract: When robots move autonomously for long-term, varied appearance such as the transition from day to night and seasonal variation brings challenges to visual place recognition. Defining an appearance condition (e.g. a season, a kind of weather) as a domain, we consider that the desired representation for place recognition (i) should be domain-unrelated so that images from different time can be matched regardless of varied appearance, (ii) should be learned in a self-supervised manner without the need of massive manually labeled data, and (iii) should be able to train among multiple domains in one model to keep limited model complexity. This paper sets to find domain-unrelated features across extremely changing appearance, which can be used as image descriptors to match between images collected at different conditions. We propose to use the adversarial network to disentangle domain-unrelated and domain-related features, which are named place and appearance features respectively. During training, only domain information is needed without requiring manually aligned image sequences. Experiments demonstrated that our method can disentangle place and appearance features in both toy case and images from the real world, and the place feature is qualified in place recognition tasks under different appearance conditions. The proposed network is also adaptable to multiple domains without increasing model capacity and shows favorable generalization.
keywords: {Feature extraction;Training;Image reconstruction;Image recognition;Robustness;Machine learning;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196518&isnumber=9196508

L. Zhou, S. Wang and M. Kaess, "A Fast and Accurate Solution for Pose Estimation from 3D Correspondences," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1308-1314.
doi: 10.1109/ICRA40945.2020.9197023
Abstract: Estimating pose from given 3D correspondences, including point-to-point, point-to-line and point-to-plane correspondences, is a fundamental task in computer vision with many applications. We present a fast and accurate solution for the least-squares problem of this task. Previous works mainly focus on studying the way to find the global minimizer of the least-squares problem. However, existing works that show the ability to achieve the global minimizer are still unsuitable for real-time applications. Furthermore, as one of contributions of this paper, we prove that there exist ambiguous configurations for any number of lines and planes. These configurations have several solutions in theory, which makes the correct solution may come from a local minimizer when the data are with noise. Previous works based on convex optimization which is unable to find local minimizers do not work in the ambiguous configuration. Our algorithm is efficient and able to reveal local minimizers. We employ the Cayley-Gibbs-Rodriguez (CGR) parameterization of the rotation to derive a general rational cost for the three cases of 3D correspondences. The main contribution of this paper is to solve the first-order optimality conditions of the least-squares problem, which are of a complicated rational form. The central idea of our algorithm is to introduce some intermediate unknowns to simplify the problem. Extensive experimental results show that our algorithm is more stable than previous algorithms when the number N of correspondences is small. Besides, when N is large, our algorithm achieves the same accuracy as the state-of-the-art algorithm [1], but our algorithm is about 7 times faster than [1] in real applications.
keywords: {Three-dimensional displays;Pose estimation;Cost function;Approximation algorithms;Real-time systems;Iterative closest point algorithm;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197023&isnumber=9196508

J. Fabian Schmid, S. F. Simon and R. Mester, "Ground Texture Based Localization Using Compact Binary Descriptors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1315-1321.
doi: 10.1109/ICRA40945.2020.9197221
Abstract: Ground texture based localization is a promising approach to achieve high-accuracy positioning of vehicles. We present a self-contained method that can be used for global localization as well as for subsequent local localization updates, i.e. it allows a robot to localize without any knowledge of its current whereabouts, but it can also take advantage of a prior pose estimate to reduce computation time significantly. Our method is based on a novel matching strategy, which we call identity matching, that is based on compact binary feature descriptors. Identity matching treats pairs of features as matches only if their descriptors are identical. While other methods for global localization are faster to compute, our method reaches higher localization success rates, and can switch to local localization after the initial localization.
keywords: {Feature extraction;Cameras;Robots;Latches;Task analysis;Asphalt;Pose estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197221&isnumber=9196508

I. Hofstetter, M. Sprunk, F. Ries and M. Haueis, "Reliable Data Association for Feature-Based Vehicle Localization using Geometric Hashing Methods," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1322-1328.
doi: 10.1109/ICRA40945.2020.9196601
Abstract: Reliable data association represents a main challenge of feature-based vehicle localization and is the key to integrity of localization. Independent of the type of features used, incorrect associations between detected and mapped features will provide erroneous position estimates. Only if the uniqueness of a local environment is represented by the features that are stored in the map, the reliability of localization is enhanced. In this work, a new approach based on Geometric Hashing is introduced to the field of data association for feature-based vehicle localization. Without any information on a prior position, the proposed method allows to efficiently search large map regions for plausible feature associations. Therefore, odometry and GNSS-based inputs can be neglected, which reduces the risk of error propagation and enables safe localization. The approach is demonstrated on approximately 10min of data recorded in an urban scenario. Cylindrical objects without distinctive descriptors, which were extracted from LiDAR data, serve as localization features. Experimental results both demonstrate the feasibility as well as limitations of the approach.
keywords: {Feature extraction;Reliability;Data mining;Noise measurement;Standards;Visualization;Object recognition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196601&isnumber=9196508

A. F. Abdelrahman, A. Mitrevski and P. G. Pl√∂ger, "Context-Aware Task Execution Using Apprenticeship Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1329-1335.
doi: 10.1109/ICRA40945.2020.9197476
Abstract: An essential measure of autonomy in assistive service robots is adaptivity to the various contexts of human-oriented tasks, which are subject to subtle variations in task parameters that determine optimal behaviour. In this work, we propose an apprenticeship learning approach to achieving context-aware action generalization on the task of robot-to-human object hand-over. The procedure combines learning from demonstration and reinforcement learning: a robot first imitates a demonstrator's execution of the task and then learns contextualized variants of the demonstrated action through experience. We use dynamic movement primitives as compact motion representations, and a model-based C-REPS algorithm for learning policies that can specify hand-over position, conditioned on context variables. Policies are learned using simulated task executions, before transferring them to the robot and evaluating emergent behaviours. We additionally conduct a user study involving participants assuming different postures and receiving an object from a robot, which executes hand-overs by either imitating a demonstrated motion, or adapting its motion to hand-over positions suggested by the learned policy. The results confirm the hypothesized improvements in the robot's perceived behaviour when it is context-aware and adaptive, and provide useful insights that can inform future developments.
keywords: {Robots;Task analysis;Trajectory;Context modeling;Encoding;Adaptation models;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197476&isnumber=9196508

R. Rayyes, H. Donat and J. Steil, "Hierarchical Interest-Driven Goal Babbling for Efficient Bootstrapping of Sensorimotor skills," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1336-1342.
doi: 10.1109/ICRA40945.2020.9196763
Abstract: We propose a novel hierarchical online learning scheme for fast and efficient bootstrapping of sensorimotor skills. Our scheme permits rapid data-driven robot model learning in a "learning while behaving" fashion. It is updated continuously to adapt to time-dependent changes and driven by an intrinsic motivation signal. It utilizes an online associative radial basis function network, which is the first associative dynamic network to be constructed from scratch with high stability. Moreover, we propose a parameter-sharing technique to increase efficiency, stabilize the online scheme, avoid exhaustive parameter tuning, and speed up the learning process. We apply our proposed algorithms on a 7-DoF physical robot manipulator and demonstrate their performance and efficiency.
keywords: {Task analysis;Current measurement;Robot sensing systems;Service robots;Stability analysis;Measurement uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196763&isnumber=9196508

V. Florence, J. J. Corso and B. Griffin, "Robot-Supervised Learning for Object Segmentation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1343-1349.
doi: 10.1109/ICRA40945.2020.9196543
Abstract: To be effective in unstructured and changing environments, robots must learn to recognize new objects. Deep learning has enabled rapid progress for object detection and segmentation in computer vision; however, this progress comes at the price of human annotators labeling many training examples. This paper addresses the problem of extending learning-based segmentation methods to robotics applications where annotated training data is not available. Our method enables pixelwise segmentation of grasped objects. We factor the problem of segmenting the object from the background into two sub-problems: (1) segmenting the robot manipulator and object from the background and (2) segmenting the object from the manipulator. We propose a kinematics-based foreground segmentation technique to solve (1). To solve (2), we train a self-recognition network that segments the robot manipulator. We train this network without human supervision, leveraging our foreground segmentation technique from (1) to label a training set of images containing the robot manipulator without a grasped object. We demonstrate experimentally that our method outperforms state-of-the-art adaptable in-hand object segmentation. We also show that a training set composed of automatically labelled images of grasped objects improves segmentation performance on a test set of images of the same objects in the environment.
keywords: {Robot kinematics;Manipulators;Image segmentation;Robot sensing systems;Object segmentation;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196543&isnumber=9196508

R. Sheikh, A. Milioto, P. Lottes, C. Stachniss, M. Bennewitz and T. Schultz, "Gradient and Log-based Active Learning for Semantic Segmentation of Crop and Weed for Agricultural Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1350-1356.
doi: 10.1109/ICRA40945.2020.9196722
Abstract: Annotated datasets are essential for supervised learning. However, annotating large datasets is a tedious and time-intensive task. This paper addresses active learning in the context of semantic segmentation with the goal of reducing the human labeling effort. Our application is agricultural robotics and we focus on the task of distinguishing between crop and weed plants from image data. A key challenge in this application is the transfer of an existing semantic segmentation CNN to a new field, in which growth stage, weeds, soil, and weather conditions differ. We propose a novel approach that, given a trained model on one field together with rough foreground segmentation, refines the network on a substantially different field providing an effective method of selecting samples to annotate for supporting the transfer. We evaluated our approach on two challenging datasets from the agricultural robotics domain and show that we achieve a higher accuracy with a smaller number of samples compared to random sampling as well as entropy based sampling, which consequently reduces the required human labeling effort.
keywords: {Image segmentation;Semantics;Task analysis;Agriculture;Robots;Training;Sugar industry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196722&isnumber=9196508

T. S. Lembono, C. Mastalli, P. Fernbach, N. Mansard and S. Calinon, "Learning How to Walk: Warm-starting Optimal Control Solver with Memory of Motion," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1357-1363.
doi: 10.1109/ICRA40945.2020.9196727
Abstract: In this paper, we propose a framework to build a memory of motion for warm-starting an optimal control solver for the locomotion task of a humanoid robot. We use HPP Loco3D, a versatile locomotion planner, to generate offline a set of dynamically consistent whole-body trajectory to be stored as the memory of motion. The learning problem is formulated as a regression problem to predict a single-step motion given the desired contact locations, which is used as a building block for producing multi-step motions. The predicted motion is then used as a warm-start for the fast optimal control solver Crocoddyl. We have shown that the approach manages to reduce the required number of iterations to reach the convergence from ~9.5 to only ~3.0 iterations for the single-step motion and from ~6.2 to ~4.5 iterations for the multi-step motion, while maintaining the solution's quality.
keywords: {Trajectory;Databases;Optimal control;Task analysis;Legged locomotion;Ground penetrating radar},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196727&isnumber=9196508

T. Westenbroek et al., "Feedback Linearization for Uncertain Systems via Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1364-1371.
doi: 10.1109/ICRA40945.2020.9197158
Abstract: We present a novel approach to control design for nonlinear systems which leverages model-free policy optimization techniques to learn a linearizing controller for a physical plant with unknown dynamics. Feedback linearization is a technique from nonlinear control which renders the input-output dynamics of a nonlinear plant linear under application of an appropriate feedback controller. Once a linearizing controller has been constructed, desired output trajectories for the nonlinear plant can be tracked using a variety of linear control techniques. However, the calculation of a linearizing controller requires a precise dynamics model for the system. As a result, model-based approaches for learning exact linearizing controllers generally require a simple, highly structured model of the system with easily identifiable parameters. In contrast, the model-free approach presented in this paper is able to approximate the linearizing controller for the plant using general function approximation architectures. Specifically, we formulate a continuous-time optimization problem over the parameters of a learned linearizing controller whose optima are the set of parameters which best linearize the plant. We derive conditions under which the learning problem is (strongly) convex and provide guarantees which ensure the true linearizing controller for the plant is recovered. We then discuss how model-free policy optimization algorithms can be used to solve a discrete-time approximation to the problem using data collected from the real-world plant. The utility of the framework is demonstrated in simulation and on a real-world robotic platform.
keywords: {Feedback linearization;Conferences;Automation;Uncertain systems;Learning (artificial intelligence);Control design;Nonlinear systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197158&isnumber=9196508

B. van Amsterdam, M. J. Clarkson and D. Stoyanov, "Multi-Task Recurrent Neural Network for Surgical Gesture Recognition and Progress Prediction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1380-1386.
doi: 10.1109/ICRA40945.2020.9197301
Abstract: Surgical gesture recognition is important for surgical data science and computer-aided intervention. Even with robotic kinematic information, automatically segmenting surgical steps presents numerous challenges because surgical demonstrations are characterized by high variability in style, duration and order of actions. In order to extract discriminative features from the kinematic signals and boost recognition accuracy, we propose a multi-task recurrent neural network for simultaneous recognition of surgical gestures and estimation of a novel formulation of surgical task progress. To show the effectiveness of the presented approach, we evaluate its application on the JIGSAWS dataset, that is currently the only publicly available dataset for surgical gesture recognition featuring robot kinematic data. We demonstrate that recognition performance improves in multi-task frameworks with progress estimation without any additional manual labelling and training.
keywords: {Task analysis;Training;Kinematics;Estimation;Needles;Gesture recognition;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197301&isnumber=9196508

N. Yilmaz, J. Y. Wu, P. Kazanzides and U. Tumerdem, "Neural Network based Inverse Dynamics Identification and External Force Estimation on the da Vinci Research Kit," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1387-1393.
doi: 10.1109/ICRA40945.2020.9197445
Abstract: Most current surgical robotic systems lack the ability to sense tool/tissue interaction forces, which motivates research in methods to estimate these forces from other available measurements, primarily joint torques. These methods require the internal joint torques, due to the robot inverse dynamics, to be subtracted from the measured joint torques. This paper presents the use of neural networks to estimate the inverse dynamics of the da Vinci surgical robot, which enables estimation of the external environment forces. Experiments with motions in free space demonstrate that the neural networks can estimate the internal joint torques within 10% normalized rootmean-square error (NRMSE), which outperforms model-based approaches in the literature. Comparison with an external force sensor shows that the method is able to estimate environment forces within about 10% NRMSE.
keywords: {Robots;Dynamics;Force;Estimation;Training;Biological neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197445&isnumber=9196508

O. Melon, M. Geisert, D. Surovik, I. Havoutis and M. Fallon, "Reliable Trajectories for Dynamic Quadrupeds using Analytical Costs and Learned Initializations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1410-1416.
doi: 10.1109/ICRA40945.2020.9196562
Abstract: Dynamic traversal of uneven terrain is a major objective in the field of legged robotics. The most recent model predictive control approaches for these systems can generate robust dynamic motion of short duration; however, planning over a longer time horizon may be necessary when navigating complex terrain. A recently-developed framework, Trajectory Optimization for Walking Robots (TOWR), computes such plans but does not guarantee their reliability on real platforms, under uncertainty and perturbations. We extend TOWR with analytical costs to generate trajectories that a state-of-the-art whole-body tracking controller can successfully execute. To reduce online computation time, we implement a learning-based scheme for initialization of the nonlinear program based on offline experience. The execution of trajectories as long as 16 footsteps and 5.5 s over different terrains by a real quadruped demonstrates the effectiveness of the approach on hardware. This work builds toward an online system which can efficiently and robustly replan dynamic trajectories.
keywords: {Legged locomotion;Dynamics;Foot;Trajectory optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196562&isnumber=9196508

A. Bratta, R. Orsolino, M. Focchi, V. Barasuol, G. G. Muscolo and C. Semini, "On the Hardware Feasibility of Nonlinear Trajectory Optimization for Legged Locomotion based on a Simplified Dynamics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1417-1423.
doi: 10.1109/ICRA40945.2020.9196903
Abstract: Simplified models are useful to increase the computational efficiency of a motion planning algorithm, but their lack of accuracy have to be managed. We propose two feasibility constraints to be included in a Single Rigid Body Dynamics-based trajectory optimizer in order to obtain robust motions in challenging terrain. The first one finds an approximate relationship between joint-torque limits and admissible contact forces, without requiring the joint positions. The second one proposes a leg model to prevent leg collision with the environment. Such constraints have been included in a simplified nonlinear non-convex trajectory optimization problem. We demonstrate the feasibility of the resulting motion plans both in simulation and on the Hydraulically actuated Quadruped (HyQ) robot, considering experiments on an irregular terrain.
keywords: {Legged locomotion;Foot;Collision avoidance;Force;Trajectory;Aerodynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196903&isnumber=9196508

V. S. Raghavan, D. Kanoulas, D. G. Caldwell and N. G. Tsagarakis, "Agile Legged-Wheeled Reconfigurable Navigation Planner Applied on the CENTAURO Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1424-1430.
doi: 10.1109/ICRA40945.2020.9197407
Abstract: Hybrid legged-wheeled robots such as the CEN-TAURO, are capable of varying their footprint polygon to carry out various agile motions. This property can be advantageous for wheeled-only planning in cluttered spaces, which is our focus. In this paper, we present an improved algorithm that builds upon our previously introduced preliminary footprint varying A* planner, which was based on the rectangular symmetry of the foot support polygon. In particular, we introduce a Theta* based planner with trapezium-like search, which aims to further reduce the limitations imposed upon the wheeled-only navigation of the CENTAURO robot by the low-dimensional search space, maintaining the real-time computational efficiency. The method is tested on the simulated and real full-size CENTAURO robot in cluttered environments.
keywords: {Robot kinematics;Mobile robots;Planning;Wheels;Navigation;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197407&isnumber=9196508

G. Xin, J. Smith, D. Rytz, W. Wolfslag, H. -C. Lin and M. Mistry, "Bounded haptic teleoperation of a quadruped robot‚Äôs foot posture for sensing and manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1431-1437.
doi: 10.1109/ICRA40945.2020.9197501
Abstract: This paper presents a control framework to teleoperate a quadruped robot's foot for operator-guided haptic exploration of the environment. Since one leg of a quadruped robot typically only has 3 actuated degrees of freedom (DoFs), the torso is employed to assist foot posture control via a hierarchical whole-body controller. The foot and torso postures are controlled by two analytical Cartesian impedance controllers cascaded by a null space projector. The contact forces acting on supporting feet are optimized by quadratic programming (QP). The foot's Cartesian impedance controller may also estimate contact forces from trajectory tracking errors, and relay the force-feedback to the operator. A 7D haptic joystick, Sigma.7, transmits motion commands to the quadruped robot ANYmal, and renders the force feedback. Furthermore, the joystick's motion is bounded by mapping the foot's feasible force polytope constrained by the friction cones and torque limits in order to prevent the operator from driving the robot to slipping or falling over. Experimental results demonstrate the efficiency of the proposed framework.
keywords: {Impedance;Aerospace electronics;Robot kinematics;Haptic interfaces;Torso;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197501&isnumber=9196508

S. Noh and A. M. Dollar, "Pinbot: A Walking Robot with Locking Pin Arrays for Passive Adaptability to Rough Terrains," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1438-1444.
doi: 10.1109/ICRA40945.2020.9197342
Abstract: To date, many control strategies for legged robots have been proposed for stable locomotion over rough and unstructured terrains. However, these approaches require sensing information throughout locomotion, which may be noisy or unavailable at times. An alternative solution to rough terrain locomotion is a legged robot design that can passively adapt to the variations in the terrain without requiring knowledge of them. This paper presents one such solution in the design of a walking robot that employs pin array mechanisms to passively adapt to rough terrains. The pins are passively dropped over the terrain to conform to its variations and then locked to provide a statically stable stance. Locomotion is achieved with parallel four-bar linkages that swing forward the platforms in an alternating manner. Experimental evaluation of the robot demonstrates that the pin arrays enable legged locomotion over rough terrains under open-loop control.
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197342&isnumber=9196508

K. Green, R. L. Hatton and J. Hurst, "Planning for the Unexpected: Explicitly Optimizing Motions for Ground Uncertainty in Running," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1445-1451.
doi: 10.1109/ICRA40945.2020.9197049
Abstract: We propose a method to generate actuation plans for a reduced order, dynamic model of bipedal running. This method explicitly enforces robustness to ground uncertainty. The plan generated is not a fixed body trajectory that is aggressively stabilized: instead, the plan interacts with the passive dynamics of the reduced order model to create emergent robustness. The goal is to create plans for legged robots that will be robust to imperfect perception of the environment, and to work with dynamics that are too complex to optimize in real-time. Working within this dynamic model of legged locomotion, we optimize a set of disturbance cases together with the nominal case, all with linked inputs. The input linking is nontrivial due to the hybrid dynamics of the running model but our solution is effective and has analytical gradients. The optimization procedure proposed is significantly slower than a standard trajectory optimization, but results in robust gaits that reject disturbances extremely effectively without any replanning required.
keywords: {Legged locomotion;Springs;Dynamics;Foot;Robustness;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197049&isnumber=9196508

T. Kulvicius, S. Herzog, T. L√ºddecke, M. Tamosiunaite and F. W√∂rg√∂tter, "One-Shot Multi-Path Planning for Robotic Applications Using Fully Convolutional Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1460-1466.
doi: 10.1109/ICRA40945.2020.9196719
Abstract: Path planning is important for robot action execution, since a path or a motion trajectory for a particular action has to be defined first before the action can be executed. Most of the current approaches are iterative methods where the trajectory is generated by predicting the next state based on the current state. Here we propose a novel method by utilising a fully convolutional neural network, which allows generation of complete paths even for several agents with one network prediction iteration. We demonstrate that our method is able to successfully generate optimal or close to optimal paths (less than 10% longer) in more than 99% of the cases for single path predictions in 2D and 3D environments. Furthermore, we show that the network is - without specific training on such cases - able to create (close to) optimal paths in 96% of the cases for two and in 84% of the cases for three simultaneously generated paths.
keywords: {Two dimensional displays;Three-dimensional displays;Training;Robots;Path planning;Prediction algorithms;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196719&isnumber=9196508

D. Fridovich-Keil, E. Ratner, L. Peters, A. D. Dragan and C. J. Tomlin, "Efficient Iterative Linear-Quadratic Approximations for Nonlinear Multi-Player General-Sum Differential Games," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1475-1481.
doi: 10.1109/ICRA40945.2020.9197129
Abstract: Many problems in robotics involve multiple decision making agents. To operate efficiently in such settings, a robot must reason about the impact of its decisions on the behavior of other agents. Differential games offer an expressive theoretical framework for formulating these types of multi-agent problems. Unfortunately, most numerical solution techniques scale poorly with state dimension and are rarely used in real-time applications. For this reason, it is common to predict the future decisions of other agents and solve the resulting decoupled, i.e., single-agent, optimal control problem. This decoupling neglects the underlying interactive nature of the problem; however, efficient solution techniques do exist for broad classes of optimal control problems. We take inspiration from one such technique, the iterative linear-quadratic regulator (ILQR), which solves repeated approximations with linear dynamics and quadratic costs. Similarly, our proposed algorithm solves repeated linear-quadratic games. We experimentally benchmark our algorithm in several examples with a variety of initial conditions and show that the resulting strategies exhibit complex interactive behavior. Our results indicate that our algorithm converges reliably and runs in real-time. In a three-player, 14-state simulated intersection problem, our algorithm initially converges in <; 0.25 s. Receding horizon invocations converge in <; 50 ms in a hardware collision-avoidance test.
keywords: {Games;Heuristic algorithms;Approximation algorithms;Optimal control;Iterative methods;Trajectory;Automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197129&isnumber=9196508

T. K. Jespersen et al., "Path-Following Model Predictive Control of Ballbots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1498-1504.
doi: 10.1109/ICRA40945.2020.9196634
Abstract: This paper introduces a novel approach for model predictive control of ballbots for path-following tasks. Ballbots are dynamically unstable mobile robots which are designed to balance on a single ball. The model presented in this paper is a simplied version of a full quaternion-based model of ballbots' underactuated dynamics which is suited for online implementation. Furthermore, the approach is extended to handle nearby obstacles directly in the MPC formulation. The presented controller is validated through simulation on a high fidelity model as well as through real-world experiments on a physical ballbot system.
keywords: {Robots;Solid modeling;Friction;Quaternions;Planning;Acceleration;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196634&isnumber=9196508

C. Eilers, J. Eschmann, R. Menzenbach, B. Belousov, F. Muratore and J. Peters, "Underactuated Waypoint Trajectory Optimization for Light Painting Photography," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1505-1510.
doi: 10.1109/ICRA40945.2020.9196516
Abstract: Despite their abundance in robotics and nature, underactuated systems remain a challenge for control engineering. Trajectory optimization provides a generally applicable solution, however its efficiency strongly depends on the skill of the engineer to frame the problem in an optimizer-friendly way. This paper proposes a procedure that automates such problem reformulation for a class of tasks in which the desired trajectory is specified by a sequence of waypoints. The approach is based on introducing auxiliary optimization variables that represent waypoint activations. To validate the proposed method, a letter drawing task is set up where shapes traced by the tip of a rotary inverted pendulum are visualized using long exposure photography.
keywords: {Linear programming;Task analysis;Trajectory optimization;Painting;Photography},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196516&isnumber=9196508

S. Dafarra, G. Romualdi, G. Metta and D. Pucci, "Whole-Body Walking Generation using Contact Parametrization: A Non-Linear Trajectory Optimization Approach," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1511-1517.
doi: 10.1109/ICRA40945.2020.9196801
Abstract: In this paper, we describe a planner capable of generating walking trajectories by using the centroidal dynamics and the full kinematics of a humanoid robot model. The interaction between the robot and the walking surface is modeled explicitly through a novel contact parametrization. The approach is complementarity-free and does not need a predefined contact sequence. By solving an optimal control problem we obtain walking trajectories. In particular, through a set of constraints and dynamic equations, we model the robot in contact with the ground. We describe the objective the robot needs to achieve with a set of tasks. The whole optimal control problem is transcribed into an optimization problem via a Direct Multiple Shooting approach and solved with an off-the-shelf solver. We show that it is possible to achieve walking motions automatically by specifying a minimal set of references, such as a constant desired Center of Mass velocity and a reference point on the ground.
keywords: {Legged locomotion;Foot;Force;Trajectory;Robot kinematics;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196801&isnumber=9196508

M. V. Otubela and C. McGinn, "Controlling Fast Height Variation of an Actively Articulated Wheeled Humanoid Robot Using Center of Mass Trajectory," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1518-1524.
doi: 10.1109/ICRA40945.2020.9196569
Abstract: Hybrid wheel-legged robots have begun to demonstrate the ability to adapt to complex terrain traditionally inaccessible to purely wheeled morphologies. Further research is needed into how their dynamics can be optimally controlled for developing highly adaptive behaviours on challenging terrain. Using optimal center of mass (COM) kinematic trajectories, this work examines the nonlinear dynamics control problem for fast height adaptation on the hybrid humanoid platform known as Aerobot. We explore the dynamics control problem through experimentation with an offline trajectory optimisation (TO) method and a task-space inverse dynamics (TSID) controller for varying the robot's height. Our TO approach uses sequential quadratic programming (SQP) to solve optimal 7th order spline coefficients for the robot's kinematics. The nonlinear Zero Moment Point (ZMP) is used to model a stability criterion that is constrained in the TO problem to ensure dynamic stability. Our TSID controller follows motion plans based on using task jacobians and a simplified passive dynamics model of the Aerobot platform. Results exhibit fast height adaptation on the Aerobot platform with significantly differing results between the control methods that prompts new research into how it may be controlled online.
keywords: {Aerodynamics;Mathematical model;Acceleration;Robot kinematics;Stability analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196569&isnumber=9196508

A. Aydinoglu, V. M. Preciado and M. Posa, "Contact-Aware Controller Design for Complementarity Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1525-1531.
doi: 10.1109/ICRA40945.2020.9197568
Abstract: While many robotic tasks, like manipulation and locomotion, are fundamentally based in making and breaking contact with the environment, state-of-the-art control policies struggle to deal with the hybrid nature of multi-contact motion. Such controllers often rely heavily upon heuristics or, due to the combinatoric structure in the dynamics, are unsuitable for real-time control. Principled deployment of tactile sensors offers a promising mechanism for stable and robust control, but modern approaches often use this data in an ad hoc manner, for instance to guide guarded moves. In this work, by exploiting the complementarity structure of contact dynamics, we propose a control framework which can close the loop on rich, tactile sensors. Critically, this framework is non-combinatoric, enabling optimization algorithms to automatically synthesize provably stable control policies. We demonstrate this approach on three different underactuated, multi-contact robotics problems.
keywords: {Lyapunov methods;Control systems;Force;Dynamics;Task analysis;Tactile sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197568&isnumber=9196508

X. Lou, Y. Yang and C. Choi, "Learning to Generate 6-DoF Grasp Poses with Reachability Awareness," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1532-1538.
doi: 10.1109/ICRA40945.2020.9197413
Abstract: Motivated by the stringent requirements of unstructured real-world where a plethora of unknown objects reside in arbitrary locations of the surface, we propose a voxel-based deep 3D Convolutional Neural Network (3D CNN) that generates feasible 6-DoF grasp poses in unrestricted workspace with reachability awareness. Unlike the majority of works that predict if a proposed grasp pose within the restricted workspace will be successful solely based on grasp pose stability, our approach further learns a reachability predictor that evaluates if the grasp pose is reachable or not from robot's own experience. To avoid the laborious real training data collection, we exploit the power of simulation to train our networks on a large-scale synthetic dataset. This work is an early attempt that simultaneously learns grasping reachability while proposing feasible grasp poses with 3D CNN. Experimental results in both simulation and real-world demonstrate that our approach outperforms several other methods and achieves 82.5% grasping success rate on unknown objects.
keywords: {Grasping;Three-dimensional displays;Robot kinematics;Planning;Measurement;Data models;Grasping;Deep Learning in Robotics and Automation;Perception for Grasping and Manipulation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197413&isnumber=9196508

M. Sorour, K. Elgeneidy, M. Hanheide, M. Abdalmjed, A. Srinivasan and G. Neumann, "Enhancing Grasp Pose Computation in Gripper Workspace Spheres," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1539-1545.
doi: 10.1109/ICRA40945.2020.9196863
Abstract: In this paper, enhancement to the novel grasp planning algorithm based on gripper workspace spheres is presented. Our development requires a registered point cloud of the target from different views, assuming no prior knowledge of the object, nor any of its properties. This work features a new set of metrics for grasp pose candidates evaluation, as well as exploring the impact of high object sampling on grasp success rates. In addition to gripper position sampling, we now perform orientation sampling about the x, y, and z-axes, hence the grasping algorithm no longer require object orientation estimation. Successful experiments have been conducted on a simple jaw gripper (Franka Panda gripper) as well as a complex, high Degree of Freedom (DoF) hand (Allegro hand) as a proof of its versatility. Higher grasp success rates of 76% and 85.5% respectively has been reported by real world experiments.
keywords: {Grippers;Three-dimensional displays;Ellipsoids;Grasping;Measurement;Shape;Planning;grasping;manipulation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196863&isnumber=9196508

J. Xu, M. Danielczuk, J. Ichnowski, J. Mahler, E. Steinbach and K. Goldberg, "Minimal Work: A Grasp Quality Metric for Deformable Hollow Objects," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1546-1552.
doi: 10.1109/ICRA40945.2020.9197062
Abstract: Robot grasping of deformable hollow objects such as plastic bottles and cups is challenging, as the grasp should resist disturbances while minimally deforming the object so as not to damage it or dislodge liquids. We propose minimal work as a novel grasp quality metric that combines wrench resistance and object deformation. We introduce an efficient algorithm to compute the work required to resist an external wrench for a manipulation task by solving a linear program. The algorithm first computes the minimum required grasp force and an estimation of the gripper jaw displacements based on the object's empirical stiffness at different locations. The work done by the jaws is the product of the grasp force and the displacements. Grasps requiring minimal work are considered to be of high quality. We collect 460 physical grasps with a UR5 robot and a Robotiq gripper. We consider a grasp to be successful if it completes the task without damaging the object or dislodging the content. Physical experiments suggest that the minimal work quality metric reaches 74.2% balanced accuracy, a metric that is the raw accuracy normalized by the number of successful and failed real-world grasps, and is up to 24.2% higher than classical wrench-based quality metrics.
keywords: {Measurement;Force;Task analysis;Strain;Computational modeling;Friction;Grippers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197062&isnumber=9196508

Y. Choi et al., "Hierarchical 6-DoF Grasping with Approaching Direction Selection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1553-1559.
doi: 10.1109/ICRA40945.2020.9196678
Abstract: In this paper, we tackle the problem of 6-DoF grasp detection which is crucial for robot grasping in cluttered real-world scenes. Unlike existing approaches which synthesize 6-DoF grasp data sets and train grasp quality networks with input grasp representations based on point clouds, we rather take a novel hierarchical approach which does not use any 6-DoF grasp data. We cast the 6-DoF grasp detection problem as a robot arm approaching direction selection problem using the existing 4-DoF grasp detection algorithm, by exploiting a fully convolutional grasp quality network for evaluating the quality of an approaching direction. To select the best approaching direction with the highest grasp quality, we propose an approaching direction selection method which leverages a geometry-based prior and a derivative-free optimization method. Specifically, we optimize the direction iteratively using the cross entropy method with initial samples of surface normal directions. Our algorithm efficiently finds diverse 6-DoF grasps by the novel way of evaluating and optimizing approaching directions. We validate that the proposed method outperforms other selection methods in scenarios with cluttered objects in a physics-based simulator. Finally, we show that our method outperforms the state-of-the-art grasp detection method in real-world experiments with robots.
keywords: {Grasping;Three-dimensional displays;Grippers;Service robots;Manipulators;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196678&isnumber=9196508

E. D. Rimon, F. T. Pokorny and W. Wan, "Geometric Characterization of Two-Finger Basket Grasps of 2-D Objects: Contact Space Formulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1560-1566.
doi: 10.1109/ICRA40945.2020.9196946
Abstract: This paper considers basket grasps, where a two-finger robot hand forms a basket that can safely lift and carry rigid objects in a 2-D gravitational environment. The two-finger basket grasps form special points in a high-dimensional configuration space of the object and two-finger robot hand. This paper establishes that all two-finger basket grasps can be found in a low-dimensional contact space that parametrizes the two-finger contacts along the supported object boundary. Using contact space, each basket grasp is associated with its depth that provides a security measure while carrying the object, as well as its safety margin away from a critical finger opening where the object drops-off into its intended destination. Geometric techniques that compute the depth and drop-off finger opening are described and illustrated with detailed graphical and numerical examples.
keywords: {Robots;Gravity;Search problems;Security;Layout;Safety;Air pollution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196946&isnumber=9196508

I. An, B. Jo, Y. Kwon, J. -w. Choi and S. -e. Yoon, "Robust Sound Source Localization considering Similarity of Back-Propagation Signals," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1574-1580.
doi: 10.1109/ICRA40945.2020.9196743
Abstract: We present a novel, robust sound source localization algorithm considering back-propagation signals. Sound propagation paths are estimated by generating direct and reflection acoustic rays based on ray tracing in a backward manner. We then compute the back-propagation signals by designing and using the impulse response of the backward sound propagation based on the acoustic ray paths. For identifying the 3D source position, we use a well-established Monte Carlo localization method. Candidates for a source position are determined by identifying convergence regions of acoustic ray paths. Those candidates are validated by measuring similarities between back-propagation signals, under the assumption that the back-propagation signals of different acoustic ray paths should be similar near the ground-truth sound source position. Thanks to considering similarities of back-propagation signals, our approach can localize a source position with an averaged error of 0.55 m in a room of 7 m by 7 m area with 3 m height in tested environments. We also place additional 67 dB and 77 dB white noise at the background, to test the robustness of our approach. Overall, we observe a 7 % to 100 % improvement in accuracy over the state-of-the-art method.
keywords: {Acoustics;Direction-of-arrival estimation;Array signal processing;Three-dimensional displays;Microphone arrays;Position measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196743&isnumber=9196508

J. H. Christensen, S. Hornauer and S. X. Yu, "BatVision: Learning to See 3D Spatial Layout with Two Ears," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1581-1587.
doi: 10.1109/ICRA40945.2020.9196934
Abstract: Many species have evolved advanced non-visual perception while artificial systems fall behind. Radar and ultrasound complement camera-based vision but they are often too costly and complex to set up for very limited information gain. In nature, sound is used effectively by bats, dolphins, whales, and humans for navigation and communication. However, it is unclear how to best harness sound for machine perception.Inspired by bats' echolocation mechanism, we design a low- cost BatVision system that is capable of seeing the 3D spatial layout of space ahead by just listening with two ears. Our system emits short chirps from a speaker and records returning echoes through microphones in an artificial human pinnae pair. During training, we additionally use a stereo camera to capture color images for calculating scene depths. We train a model to predict depth maps and even grayscale images from the sound alone. During testing, our trained BatVision provides surprisingly good predictions of 2D visual scenes from two 1D audio signals. Such a sound to vision system would benefit robot navigation and machine vision, especially in low-light or no-light conditions. Our code and data are publicly available.
keywords: {Microphones;Visualization;Ear;Chirp;Cameras;Three-dimensional displays;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196934&isnumber=9196508

X. Liu, X. Liu, D. Guo, H. Liu, F. Sun and H. Min, "Self-Supervised Learning for Alignment of Objects and Sound," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1588-1594.
doi: 10.1109/ICRA40945.2020.9197566
Abstract: The sound source separation problem has many useful applications in the field of robotics, such as human-robot interaction, scene understanding, etc. However, it remains a very challenging problem. In this paper, we utilize both visual and audio information of videos to perform the sound source separation task. A self-supervised learning framework is proposed to implement the object detection and sound separation modules simultaneously. Such an approach is designed to better find the alignment between the detected objects and separated sound components. Our experiments, conducted on both the synthetic and real datasets, validate this approach and demonstrate the effectiveness of the proposed model in the task of object and sound alignment.
keywords: {Visualization;Videos;Feature extraction;Object detection;Spectrogram;Training;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197566&isnumber=9196508

A. R. Sekkat, Y. Dupuis, P. Vasseur and P. Honeine, "The OmniScape Dataset," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1603-1608.
doi: 10.1109/ICRA40945.2020.9197144
Abstract: Despite the utility and benefits of omnidirectional images in robotics and automotive applications, there are no datasets of omnidirectional images available with semantic segmentation, depth map, and dynamic properties. This is due to the time cost and human effort required to annotate ground truth images. This paper presents a framework for generating omnidirectional images using images that are acquired from a virtual environment. For this purpose, we demonstrate the relevance of the proposed framework on two well-known simulators: CARLA Simulator, which is an open-source simulator for autonomous driving research, and Grand Theft Auto V (GTA V), which is a very high quality video game. We explain in details the generated OmniScape dataset, which includes stereo fisheye and catadioptric images acquired from the two front sides of a motorcycle, including semantic segmentation, depth map, intrinsic parameters of the cameras and the dynamic parameters of the motorcycle. It is worth noting that the case of two-wheeled vehicles is more challenging than cars due to the specific dynamic of these vehicles.
keywords: {Cameras;Semantics;Vehicle dynamics;Motorcycles;Image segmentation;Virtual environments;Roads},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197144&isnumber=9196508

K. Park, H. Park, H. Lee, S. Park and J. Kim, "An ERT-based Robotic Skin with Sparsely Distributed Electrodes: Structure, Fabrication, and DNN-based Signal Processing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1617-1624.
doi: 10.1109/ICRA40945.2020.9197361
Abstract: Electrical resistance tomography (ERT) has previously been utilized to develop a large-scale tactile sensor because this approach enables the estimation of the conductivity distribution among the electrodes based on a known physical model. Such a sensor made with a stretchable material can conform to a curved surface. However, this sensor cannot fully cover a cylindrical surface because in such a configuration, the edges of the sensor must meet each other. The electrode configuration becomes irregular in this edge region, which may degrade the sensor performance. In this paper, we introduce an ERT-based robotic skin with evenly and sparsely distributed electrodes. For implementation, we sprayed a carbon nanotube (CNT)-dispersed solution to form a conductive sensing domain on a cylindrical surface. The electrodes were firmly embedded in the surface so that the wires were not exposed to the outside. The sensor output images were estimated using a deep neural network (DNN), which was trained with noisy simulation data. An indentation experiment revealed that the localization error of the sensor was 5.2 ¬± 3.3 mm, which is remarkable performance with only 30 electrodes. A frame rate of up to 120 Hz could be achieved with a sensing domain area of 90 cm2. The proposed approach simplifies the fabrication of 3D-shaped sensors, allowing them to be easily applied to existing robot arms in a seamless and robust manner.
keywords: {Robot sensing systems;Electrodes;Conductivity;Image reconstruction;Inverse problems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197361&isnumber=9196508

Z. Wu, A. Gao, N. Liu, Z. Jin and G. -Z. Yang, "FBG-Based Triaxial Force Sensor Integrated with an Eccentrically Configured Imaging Probe for Endoluminal Optical Biopsy," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1625-1631.
doi: 10.1109/ICRA40945.2020.9197128
Abstract: Accurate force sensing is important for endoluminal intervention in terms of both safety and lesion targeting. This paper develops an FBG-based force sensor for robotic bronchoscopy by configuring three FBG sensors at the lateral side of a conical substrate. It allows a large and eccentric inner lumen for the interventional instrument, enabling a flexible imaging probe inside to perform optical biopsy. The force sensor is embodied with a laser-profiled continuum robot and thermo drift is fully compensated by three temperature sensors integrated on the circumference surface of the sensor substrate. Different decoupling approaches are investigated, and nonlinear decoupling is adopted based on the cross-validation SVM and a Gaussian kernel function, achieving an accuracy of 10.58 mN, 14.57 mN and 26.32 mN along X, Y and Z axis, respectively. The tissue test is also investigated to further demonstrate the feasibility of the developed triaxial force sensor.
keywords: {Robot sensing systems;Temperature sensors;Force;Force sensors;Optical fibers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197128&isnumber=9196508

H. Lee, H. Park, G. Serhat, H. Sun and K. J. Kuchenbecker, "Calibrating a Soft ERT-Based Tactile Sensor with a Multiphysics Model and Sim-to-real Transfer Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1632-1638.
doi: 10.1109/ICRA40945.2020.9196732
Abstract: Tactile sensors based on electrical resistance tomography (ERT) have shown many advantages for implementing a soft and scalable whole-body robotic skin; however, calibration is challenging because pressure reconstruction is an ill-posed inverse problem. This paper introduces a method for calibrating soft ERT-based tactile sensors using sim-to-real transfer learning with a finite element multiphysics model. The model is composed of three simple models that together map contact pressure distributions to voltage measurements. We optimized the model parameters to reduce the gap between the simulation and reality. As a preliminary study, we discretized the sensing points into a 6 by 6 grid and synthesized single- and two-point contact datasets from the multiphysics model. We obtained another single-point dataset using the real sensor with the same contact location and force used in the simulation. Our new deep neural network architecture uses a de-noising network to capture the simulation-to-real gap and a reconstruction network to estimate contact force from voltage measurements. The proposed approach showed 82% hit rate for localization and 0.51 N of force estimation error performance in singlecontact tests and 78.5% hit rate for localization and 5.0 N of force estimation error in two-point contact tests. We believe this new calibration method has the possibility to improve the sensing performance of ERT-based tactile sensors.
keywords: {Fabrics;Computational modeling;Tactile sensors;Mathematical model;Electrodes;Force;Conductivity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196732&isnumber=9196508

Z. Ding, N. F. Lepora and E. Johns, "Sim-to-Real Transfer for Optical Tactile Sensing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1639-1645.
doi: 10.1109/ICRA40945.2020.9197512
Abstract: Deep learning and reinforcement learning methods have been shown to enable learning of flexible and complex robot controllers. However, the reliance on large amounts of training data often requires data collection to be carried out in simulation, with a number of sim-to-real transfer methods being developed in recent years. In this paper, we study these techniques for tactile sensing using the TacTip optical tactile sensor, which consists of a deformable tip with a camera observing the positions of pins inside this tip. We designed a model for soft body simulation which was implemented using the Unity physics engine, and trained a neural network to predict the locations and angles of edges when in contact with the sensor. Using domain randomisation techniques for sim-to-real transfer, we show how this framework can be used to accurately predict edges with less than 1 mm prediction error in real-world testing, without any real-world data at all.
keywords: {Robot sensing systems;Pins;Force;Strain;Data models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197512&isnumber=9196508

Y. Zhu, K. Lu and K. Hauser, "Semi-Empirical Simulation of Learned Force Response Models for Heterogeneous Elastic Objects," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1646-1652.
doi: 10.1109/ICRA40945.2020.9197077
Abstract: This paper presents a semi-empirical method for simulating contact with elastically deformable objects whose force response is learned using entirely data-driven models. A point-based surface representation and an inhomogeneous, nonlinear force response model are learned from a robotic arm acquiring force-displacement curves from a small number of poking interactions. The simulator then estimates displacement and force response when the deformable object is in contact with an arbitrary rigid object. It does so by estimating displacements by solving a Hertzian contact model, and sums the expected forces at individual surface points through querying the learned point stiffness models as a function of their expected displacements. Experiments on a variety of challenging objects show that our approach learns force response with sufficient accuracy to generate plausible contact response for novel rigid objects.
keywords: {Force;Probes;Deformable models;Data models;Robot sensing systems;Strain},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197077&isnumber=9196508

R. Ouyang and R. Howe, "Low-Cost Fiducial-based 6-Axis Force-Torque Sensor," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1653-1659.
doi: 10.1109/ICRA40945.2020.9196925
Abstract: Commercial six-axis force-torque sensors suffer from being some combination of expensive, fragile, and hard-touse. We propose a new fiducial-based design which addresses all three points. The sensor uses an inexpensive webcam and can be fabricated using a consumer-grade 3D printer. Open-source software is used to estimate the 3D pose of the fiducials on the sensor, which is then used to calculate the applied force-torque. A browser-based (installation free) interface demonstrates ease-of-use. The sensor is very light and can be dropped or thrown with little concern. We characterize our prototype in dynamic conditions under compound loading, finding a mean R2 of over 0.99 for the Fx, Fy, Mx, and My axes, and over 0.87 and 0.90 for the Fz and Mz axes respectively. The open source design files allow the sensor to be adapted for diverse applications ranging from robot fingers to human-computer interfaces, while the sdesign principle allows for quick changes with minimal technical expertise. This approach promises to bring six-axis force-torque sensing to new applications where the precision, cost, and fragility of traditional strain-gauge based sensors are not appropriate. The open-source sensor design can be viewed at http://sites.google.com/view/fiducialforcesensor.
keywords: {Robot sensing systems;Force;Three-dimensional displays;Webcams;Sensitivity;Prototypes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196925&isnumber=9196508

Y. Wang, K. Huang, X. Peng, H. Li and L. Kneip, "Reliable frame-to-frame motion estimation for vehicle-mounted surround-view camera systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1660-1666.
doi: 10.1109/ICRA40945.2020.9197176
Abstract: Modern vehicles are often equipped with a surround-view multi-camera system. The current interest in autonomous driving invites the investigation of how to use such systems for a reliable estimation of relative vehicle displacement. Existing camera pose algorithms either work for a single camera, make overly simplified assumptions, are computationally expensive, or simply become degenerate under non-holonomic vehicle motion. In this paper, we introduce a new, reliable solution able to handle all kinds of relative displacements in the plane despite the possibly non-holonomic characteristics. We furthermore introduce a novel two-view optimization scheme which minimizes a geometrically relevant error without relying on 3D point related optimization variables. Our method leads to highly reliable and accurate frame-to-frame visual odometry with a full-size, vehicle-mounted surround-view camera system.
keywords: {Conferences;Automation;Reliability;Motion estimation;Cameras;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197176&isnumber=9196508

G. J. Stein, C. Bradley, V. Preston and N. Roy, "Enabling Topological Planning with Monocular Vision," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1667-1673.
doi: 10.1109/ICRA40945.2020.9197484
Abstract: Topological strategies for navigation meaningfully reduce the space of possible actions available to a robot, allowing use of heuristic priors or learning to enable computationally efficient, intelligent planning. The challenges in estimating structure with monocular SLAM in low texture or highly cluttered environments have precluded its use for topological planning in the past. We propose a robust sparse map representation that can be built with monocular vision and overcomes these shortcomings. Using a learned sensor, we estimate high-level structure of an environment from streaming images by detecting sparse "vertices" (e.g., boundaries of walls) and reasoning about the structure between them. We also estimate the known free space in our map, a necessary feature for planning through previously unknown environments. We show that our mapping technique can be used on real data and is sufficient for planning and exploration in simulated multi-agent search and learned subgoal planning applications.
keywords: {Planning;Image edge detection;Navigation;Robot sensing systems;Buildings;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197484&isnumber=9196508

M. Gridseth and T. D. Barfoot, "DeepMEL: Compiling Visual Multi-Experience Localization into a Deep Neural Network," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1674-1681.
doi: 10.1109/ICRA40945.2020.9197362
Abstract: Vision-based path following allows robots to autonomously repeat manually taught paths. Stereo Visual Teach and Repeat (VT&R) [1] accomplishes accurate and robust long-range path following in unstructured outdoor environments across changing lighting, weather, and seasons by relying on colour-constant imaging [2] and multi-experience localization [3]. We leverage multi-experience VT&R together with two datasets of outdoor driving on two separate paths spanning different times of day, weather, and seasons to teach a deep neural network to predict relative pose for visual odometry (VO) and for localization with respect to a path. In this paper we run experiments exclusively on datasets to study how the network generalizes across environmental conditions. Based on the results we believe that our system achieves relative pose estimates sufficiently accurate for in-the-loop path following and that it is able to localize radically different conditions against each other directly (i.e. winter to spring and day to night), a capability that our hand-engineered system does not have.
keywords: {Pose estimation;Image edge detection;Neural networks;Robots;Lighting;Snow},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197362&isnumber=9196508

L. Xie, A. Markham and N. Trigoni, "SnapNav: Learning Mapless Visual Navigation with Sparse Directional Guidance and Visual Reference," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1682-1688.
doi: 10.1109/ICRA40945.2020.9197523
Abstract: Learning-based visual navigation still remains a challenging problem in robotics, with two overarching issues: how to transfer the learnt policy to unseen scenarios, and how to deploy the system on real robots. In this paper, we propose a deep neural network based visual navigation system, SnapNav. Unlike map-based navigation or Visual-Teach-and-Repeat (VT&R), SnapNav only receives a few snapshots of the environment combined with directional guidance to allow it to execute the navigation task. Additionally, SnapNav can be easily deployed on real robots due to a two-level hierarchy: a high level commander that provides directional commands and a low level controller that provides real-time control and obstacle avoidance. This also allows us to effectively use simulated and real data to train the different layers of the hierarchy, facilitating robust control. Extensive experimental results show that SnapNav achieves a highly autonomous navigation ability compared to baseline models, enabling sparse, map-less navigation in previously unseen environments.
keywords: {Robots;Navigation;Visualization;Task analysis;Training;Collision avoidance;Turning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197523&isnumber=9196508

A. Rosinol, M. Abate, Y. Chang and L. Carlone, "Kimera: an Open-Source Library for Real-Time Metric-Semantic Localization and Mapping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1689-1696.
doi: 10.1109/ICRA40945.2020.9196885
Abstract: We provide an open-source C++ library for real-time metric-semantic visual-inertial Simultaneous Localization And Mapping (SLAM). The library goes beyond existing visual and visual-inertial SLAM libraries (e.g., ORB-SLAM, VINS-Mono, OKVIS, ROVIO) by enabling mesh reconstruction and semantic labeling in 3D. Kimera is designed with modularity in mind and has four key components: a visual-inertial odometry (VIO) module for fast and accurate state estimation, a robust pose graph optimizer for global trajectory estimation, a lightweight 3D mesher module for fast mesh reconstruction, and a dense 3D metric-semantic reconstruction module. The modules can be run in isolation or in combination, hence Kimera can easily fall back to a state-of-the-art VIO or a full SLAM system. Kimera runs in real-time on a CPU and produces a 3D metric-semantic mesh from semantically labeled images, which can be obtained by modern deep learning methods. We hope that the flexibility, computational efficiency, robustness, and accuracy afforded by Kimera will build a solid basis for future metric-semantic SLAM and perception research, and will allow researchers across multiple areas (e.g., VIO, SLAM, 3D reconstruction, segmentation) to benchmark and prototype their own efforts without having to start from scratch.
keywords: {Three-dimensional displays;Simultaneous localization and mapping;Robustness;Semantics;Libraries;Visualization;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196885&isnumber=9196508

M. Chanc√°n and M. Milford, "CityLearn: Diverse Real-World Environments for Sample-Efficient Navigation Policy Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1697-1704.
doi: 10.1109/ICRA40945.2020.9197336
Abstract: Visual navigation tasks in real-world environments often require both self-motion and place recognition feedback. While deep reinforcement learning has shown success in solving these perception and decision-making problems in an end-to-end manner, these algorithms require large amounts of experience to learn navigation policies from high-dimensional data, which is generally impractical for real robots due to sample complexity. In this paper, we address these problems with two main contributions. We first leverage place recognition and deep learning techniques combined with goal destination feedback to generate compact, bimodal image representations that can then be used to effectively learn control policies from a small amount of experience. Second, we present an interactive framework, CityLearn, that enables for the first time training and deployment of navigation algorithms across city-sized, realistic environments with extreme visual appearance changes. CityLearn features more than 10 benchmark datasets, often used in visual place recognition and autonomous driving research, including over 100 recorded traversals across 60 cities around the world. We evaluate our approach on two CityLearn environments, training our navigation policy on a single traversal per dataset. Results show our method can be over 2 orders of magnitude faster than when using raw images, and can also generalize across extreme visual changes including day to night and summer to winter transitions.
keywords: {Navigation;Visualization;Task analysis;Robot sensing systems;Machine learning;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197336&isnumber=9196508

I. Huang and R. Bajcsy, "High Resolution Soft Tactile Interface for Physical Human-Robot Interaction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1705-1711.
doi: 10.1109/ICRA40945.2020.9197365
Abstract: If robots and humans are to coexist and cooperate in society, it would be useful for robots to be able to engage in tactile interactions. Touch is an intuitive communication tool as well as a fundamental method by which we assist each other physically. Tactile abilities are challenging to engineer in robots, since both mechanical safety and sensory intelligence are imperative. Existing work reveals a trade-off between these principles- tactile interfaces that are high in resolution are not easily adapted to human-sized geometries, nor are they generally compliant enough to guarantee safety. On the other hand, soft tactile interfaces deliver intrinsically safe mechanical properties, but their non-linear characteristics render them difficult for use in timely sensing and control. We propose a robotic system that is equipped with a completely soft and therefore safe tactile interface that is large enough to interact with human upper limbs, while producing high resolution tactile sensory readings via depth camera imaging of the soft interface. We present and validate a data-driven model that maps point cloud data to contact forces, and verify its efficacy by demonstrating two real-world applications. In particular, the robot is able to react to a human finger's pokes and change its pose based on the tactile input. In addition, we also demonstrate that the robot can act as an assistive device that dynamically supports and follows a human forearm from underneath.
keywords: {Robot sensing systems;Cameras;Safety;Task analysis;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197365&isnumber=9196508

C. M. Thalman and H. Lee, "Design and Validation of a Soft Robotic Ankle-Foot Orthosis (SR-AFO) Exosuit for Inversion and Eversion Ankle Support," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1735-1741.
doi: 10.1109/ICRA40945.2020.9197531
Abstract: This paper presents a soft robotic ankle-foot orthosis (SR-AFO) exosuit designed to provide support to the human ankle in the frontal plane without restricting natural motion in the sagittal plane. The SR-AFO exosuit incorporates inflatable fabric-based actuators with a hollow cylinder design which requires less volume than the commonly used solid cylinder design for the same deflection. The actuators were modeled and characterized using finite element analysis techniques and experimentally validated. The SR-AFO exosuit was evaluated on healthy participants in both a sitting position using a wearable ankle robot and a standing position using a dual-axis robotic platform to characterize the effect of the exosuit on the change of 2D ankle stiffness in the sagittal and frontal planes. For both sitting and standing test protocols, a trend of increasing ankle stiffness in the frontal plane was observed up to 50 kPa while stiffness in the sagittal plane remained relatively constant over pressure levels. During quiet standing, the exosuit could effectively change eversion stiffness at the ankle joint from about 20 to 70 Nm/rad at relatively low- pressure levels (<; 30 kPa). Eversion stiffness was 84.9 Nm/rad at 50 kPa, an increase of 387.5% from the original free foot stiffness.
keywords: {Actuators;Fabrics;Solids;Structural beams;Load modeling;Soft robotics;Soft Robotics;Wearable Robots;Assistive Robots;Rehabilitation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197531&isnumber=9196508

E. -Y. Chia et al., "Velocity Field based Active-Assistive Control for Upper Limb Rehabilitation Exoskeleton Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1742-1748.
doi: 10.1109/ICRA40945.2020.9196766
Abstract: There are limitations of conventional active-assistive control for upper limb rehabilitation exoskeleton robot, such as 1). prior time-dependent trajectories are generally required, 2). task-based rehabilitation exercise involving multi-joint motion is hard to implement, and 3). assistive mechanism normally is so inflexible that the resulting exercise performed by the subjects becomes inefficient. In this paper, we propose a novel velocity field based active-assistive control system to address these issues. First, we design a Kalman filter based interactive torque observer to obtain subjects' active intention of motion. Next, a joint-position-dependent velocity field which can be automatically generated via the task motion pattern is proposed to provide the time-independent assistance to the subjects. We further propose a novel integration method that combines the active and assistive motions based on the performance and the involvement of subjects to guide them to perform the task more voluntarily and precisely. The experiment results show that both the execution time and the subjects' torque exertion are reduced while performing both given single joint tasks and task-oriented multi-joint tasks as compared with the related work in the literature. To sum up, the proposed system not only can efficiently retain subjects' active intention but also can assist them to accomplish the rehabilitation task more precisely.
keywords: {Task analysis;Torque;Robots;Kalman filters;Observers;Control systems;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196766&isnumber=9196508

M. Dragusanu, T. L. Baldi, Z. Iqbal, D. Prattichizzo and M. Malvezzi, "Design, Development, and Control of a Tendon-actuated Exoskeleton for Wrist Rehabilitation and Training," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1749-1754.
doi: 10.1109/ICRA40945.2020.9197013
Abstract: Robot rehabilitation is an emerging and promising topic that incorporates robotics with neuroscience and rehabilitation to define new methods for supporting patients with neurological diseases. As a consequence, the rehabilitation process could increase the efficacy exploiting the potentialities of robot-mediated therapies. Nevertheless, nowadays clinical effectiveness is not enough to widely introduce robotic technologies in such social contexts. In this paper we propose a step further, presenting an innovative exoskeleton for wrist flexion/extension and adduction/abduction motion training. It is designed to be wearable and easy to control and manage. It can be used by the patient in collaboration with the therapist or autonomously. The paper introduces the main steps of device design and development and presents some tests conducted with an user with limited wrist mobility.
keywords: {Exoskeletons;Wrist;Robots;Sensors;Tracking;Magnetometers;Medical treatment},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197013&isnumber=9196508

N. A. Kumar, W. Hong and P. Hur, "Impedance Control of a Transfemoral Prosthesis using Continuously Varying Ankle Impedances and Multiple Equilibria," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1755-1761.
doi: 10.1109/ICRA40945.2020.9197565
Abstract: Impedance controllers are popularly used in the field of lower limb prostheses and exoskeleton development. Such controllers assume the joint to be a spring-damper system described by a discrete set of equilibria and impedance parameters. These parameters are estimated via a least squares optimization that minimizes the difference between the controller's output torque and human joint torque. Other researchers have used perturbation studies to determine empirical values for ankle impedance. The resulting values vary greatly from the prior least squares estimates. While perturbation studies are more credible, they require immense investment. This paper extended the least squares approach to reproduce the results of perturbation studies. The resulting ankle impedance parameters were successfully tested on a powered transfemoral prosthesis, AMPRO II. Further, the paper investigated the effect of multiple equilibria on the least squares estimation and the performance of the impedance controller. Finally, the paper uses the proposed least squares optimization method to estimate knee impedance.
keywords: {Impedance;Damping;Torque;Optimization;Knee;Prosthetics;Perturbation methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197565&isnumber=9196508

C. Vassallo et al., "Gait patterns generation based on basis functions interpolation for the TWIN lower-limb exoskeleton," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1778-1784.
doi: 10.1109/ICRA40945.2020.9197250
Abstract: Since the uprising of new biomedical orthotic devices, exoskeletons have been put in the spotlight for their possible use in rehabilitation. Even if these products might share some commonalities among them in terms of overall structure, degrees of freedom and possible actions, they quite often differ in their approach on how to generate a feasible, stable and comfortable gait trajectory pattern. This paper introduces three proposed trajectories that were generated by using a basis function interpolation method and by working closely with two major rehabilitation centers in Italy. The whole procedure has been focused on the concepts of a configurable walk for patients that suffer from spinal cord injuries. We tested the solutions on a group of healthy volunteers and on a spinal-cord injury patient with the use of the new TWIN exoskeleton developed at the Rehab Technologies Lab at the Italian Institute of Technology.
keywords: {Trajectory;Legged locomotion;Exoskeletons;Torso;Hip;Foot;Knee},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197250&isnumber=9196508

D. Kent and S. Chernova, "Human-Centric Active Perception for Autonomous Observation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1785-1791.
doi: 10.1109/ICRA40945.2020.9197201
Abstract: As robot autonomy improves, robots are increasingly being considered in the role of autonomous observation systems - free-flying cameras capable of actively tracking human activity within some predefined area of interest. In this work, we formulate the autonomous observation problem through multi-objective optimization, presenting a novel Semi-MDP formulation of the autonomous human observation problem that maximizes observation rewards while accounting for both human- and robot-centric costs. We demonstrate that the problem can be solved with both scalarization-based Multi-Objective MDP methods and Constrained MDP methods, and discuss the relative benefits of each approach. We validate our work on activity tracking using a NASA Astrobee robot operating within a simulated International Space Station environment.
keywords: {Task analysis;Cameras;Robot vision systems;Collision avoidance;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197201&isnumber=9196508

P. Kratzer, M. Toussaint and J. Mainprice, "Prediction of Human Full-Body Movements with Motion Optimization and Recurrent Neural Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1792-1798.
doi: 10.1109/ICRA40945.2020.9197290
Abstract: Human movement prediction is difficult as humans naturally exhibit complex behaviors that can change drastically from one environment to the next. In order to alleviate this issue, we propose a prediction framework that decouples short-term prediction, linked to internal body dynamics, and long-term prediction, linked to the environment and task constraints. In this work we investigate encoding short-term dynamics in a recurrent neural network, while we account for environmental constraints, such as obstacle avoidance, using gradient-based trajectory optimization. Experiments on real motion data demonstrate that our framework improves the prediction with respect to state-of-the-art motion prediction methods, as it accounts to beforehand unseen environmental structures. Moreover we demonstrate on an example, how this framework can be used to plan robot trajectories that are optimized to coordinate with a human partner.
keywords: {Optimization;Trajectory;Predictive models;Recurrent neural networks;Collision avoidance;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197290&isnumber=9196508

L. v. der Spaa, M. Gienger, T. Bates and J. Kober, "Predicting and Optimizing Ergonomics in Physical Human-Robot Cooperation Tasks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1799-1805.
doi: 10.1109/ICRA40945.2020.9197296
Abstract: This paper presents a method to incorporate ergonomics into the optimization of action sequences for bi-manual human-robot cooperation tasks with continuous physical interaction. Our first contribution is a novel computational model of the human that allows prediction of an ergonomics assessment corresponding to each step in a task. The model is learned from human motion capture data in order to predict the human pose as realistically as possible. The second contribution is a combination of this prediction model with an informed graph search algorithm, which allows computation of human-robot cooperative plans with improved ergonomics according to the incorporated method for ergonomic assessment. The concepts have been evaluated in simulation and in a small user study in which the subjects manipulate a large object with a 32 DoF bimanual mobile robot as partner. For all subjects, the ergonomic-enhanced planner shows their reduced ergonomic cost compared to a baseline planner.
keywords: {Ergonomics;Robots;Task analysis;Optimization;Predictive models;Computational modeling;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197296&isnumber=9196508

S. Jamieson, J. P. How and Y. Girdhar, "Active Reward Learning for Co-Robotic Vision Based Exploration in Bandwidth Limited Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1806-1812.
doi: 10.1109/ICRA40945.2020.9196922
Abstract: We present a novel POMDP problem formulation for a robot that must autonomously decide where to go to collect new and scientifically relevant images given a limited ability to communicate with its human operator. From this formulation we derive constraints and design principles for the observation model, reward model, and communication strategy of such a robot, exploring techniques to deal with the very high-dimensional observation space and scarcity of relevant training data. We introduce a novel active reward learning strategy based on making queries to help the robot minimize path "regret" online, and evaluate it for suitability in autonomous visual exploration through simulations. We demonstrate that, in some bandwidth-limited environments, this novel regret-based criterion enables the robotic explorer to collect up to 17% more reward per mission than the next-best criterion.
keywords: {Robot sensing systems;Semantics;Bandwidth;Computational modeling;Visualization;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196922&isnumber=9196508

M. Bdiwi, A. -K. Harsch, P. Reindel and M. Putz, "VariPath: A Database for Modelling the Variance of Human Pathways in Manual and HRC Processes with Heavy-Duty Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1821-1826.
doi: 10.1109/ICRA40945.2020.9196699
Abstract: Unlike robots, humans do not have constant movements. Their pathways are individually changeable and influenced by circumstances. This paper presents a method to investigate human pathway variations in a real study. In systematically selected tasks, human pathways are examined for 100 participants in manual and human-robot collaboration (HRC) scenarios. As a result, the variations of pathways are presented depending on various features: e.g. in nearly all cases the variance of women's walking pathways is smaller than that of men. VariPath database can be used in any planning process of manual or HRC scenarios to ensure safety and efficiency.
keywords: {Legged locomotion;Service robots;Task analysis;Planning;Atmospheric measurements;Particle measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196699&isnumber=9196508

Y. Yang, Z. Liu, Y. Wang, S. Liu and M. Y. Wang, "A Compact and Low-cost Robotic Manipulator Driven by Supercoiled Polymer Actuators," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1827-18533.
doi: 10.1109/ICRA40945.2020.9197390
Abstract: The supercoiled polymer (SCP) actuator is a novel artificial muscle, which is manufactured by twisting and coiling polymer fibers. This new artificial muscle is soft, low-cost and shows good linearity. Being utilized as an actuator, the artificial muscle could generate significant mechanical power in a muscle-like form upon electrical activation by Joule heating. In this study, we adopt this new artificial muscle to actuate a novel designed robotic manipulator, which is composed of two parts. The first part is a robotic arm based on the inspiration of the musculoskeletal system. The arm is fabricated with two ball-and-socket joints as skeleton and SCP actuators as driven muscles. The second part is a Fin Ray Effect inspired soft gripper that can perform grasping tasks on fragile objects. The manipulator prototype is fabricated and experimental tests are conducted including both simple but effective control of the bio-inspired arm as well as characterization of the gripper. Lastly, a pick and place demonstration of a fragile fruit is performed utilizing the proposed manipulator. We envision that the bio-inspired robotic manipulator design driven by SCP actuators could potentially be used in other robotic applications.
keywords: {Actuators;Manipulators;Muscles;Grippers;Polymers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197390&isnumber=9196508

T. Shimizu, K. Tadakuma, M. Watanabe, E. Takane, M. Konyo and S. Tadokoro, "Internally-Balanced Magnetic Mechanisms Using a Magnetic Spring for Producing a Large Amplified Clamping Force," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1840-1846.
doi: 10.1109/ICRA40945.2020.9197151
Abstract: To detach a permanent magnet using a control force much smaller than its original attractive force, the internally-balanced magnetic unit (IB Magnet) was invented. It has been applied to magnetic devices such as wall-climbing robots, ceiling-dangling drones, and modular swarm robots. In contrast to its significant reduction rate with regard to the control force, the IB Magnet has two major problems in its nonlinear spring, which serves the purpose of cancelling out the internal force on the magnet. These problems include the complicated design procedure and the trade-off relationship between balancing the precision and the volume of the mechanism. This paper proposes a principle for a new balancing method for the IB Magnet. This method uses a like-pole pair of magnets as a magnetic spring, whose repulsive force should equal the attractive force of an unlike-pole pair. To verify the proposed principle, a prototype of the IB Magnet was designed using a magnetic spring and verified through experiments such that its reduction rate is comparable to those of conventional IB Magnets. Moreover, a robotic clamp was developed as an application example that contains the proposed IB Magnets as its internal mechanism.
keywords: {Springs;Force;Magnetic noise;Magnetic shielding;Magnetic levitation;Magnetic liquids;Magnetic separation;Mechanism Design of Manipulators;Force Control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197151&isnumber=9196508

B. Zhao, L. Zeng, B. Wu and K. Xu, "A Continuum Manipulator with Closed-form Inverse Kinematics and Independently Tunable Stiffness," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1847-1853.
doi: 10.1109/ICRA40945.2020.9196688
Abstract: Continuum manipulators can accomplish various tasks in confined spaces, benefiting from their compliant structures and improved dexterity. Confined and unstructured spaces may require both enhanced stiffness of a continuum manipulator for precision and payload, as well as compliance for safe interaction. Thus, studies have been consistently dedicated to design continuum or articulated manipulators with tunable stiffness to adapt to different operating conditions. This paper presents a continuum manipulator with independently tunable stiffness where the stiffness variation does not affect the movement of the manipulator's end-effector. Moreover, the proposed continuum manipulator is found to have analytical inverse kinematics. The design concept, analytical kinematics, system construction and experimental characterizations are presented. The results showed that the manipulator's stiffness can be increased up to 3.61 times of the minimal value, demonstrating the effectiveness of the proposed idea.
keywords: {Manipulators;Kinematics;Shape;Electron tubes;Friction;Payloads},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196688&isnumber=9196508

W. Hong, A. Schmitz, W. Bai, P. Berthet-Rayne, L. Xie and G. -Z. Yang, "Design and Compensation Control of a Flexible Instrument for Endoscopic Surgery," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1860-1866.
doi: 10.1109/ICRA40945.2020.9196955
Abstract: Snake-like robots for endoscopic surgery make it possible to reach deep-seated lesions. With the use of small flexible tendon-driven instruments, it is possible to perform bimanual micro-surgical tasks that are challenging for standard endoscopic surgeries. Existing devices, however, lack articulated wrists and rolling motion of the end-effector. This paper presents a new instrument design with a distal-roll gripper for snake-like robots. The developed 5 DoFs miniaturized instruments with a diameter of 3 mm enable the deployment into narrow endoluminal channels. Issues related to actuation coupling, tendon slack, and backlash are addressed. Experimental results show that the distal-roll gripper can rotate 106¬∞, and the actuated joints can achieve good repeatability and accuracy with the proposed compensation control scheme.
keywords: {Tendons;Instruments;Grippers;Gears;Robots;Joints;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196955&isnumber=9196508

K. Y. Cadmus To, C. Yoo, S. Anstee and R. Fitch, "Distance and Steering Heuristics for Streamline-Based Flow Field Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1867-1873.
doi: 10.1109/ICRA40945.2020.9196555
Abstract: Motion planning for vehicles under the influence of flow fields can benefit from the idea of streamline-based planning, which exploits ideas from fluid dynamics to achieve computational efficiency. Important to such planners is an efficient means of computing the travel distance and direction between two points in free space, but this is difficult to achieve in strong incompressible flows such as ocean currents. We propose two useful distance functions in analytical form that combine Euclidean distance with values of the stream function associated with a flow field, and with an estimation of the strength of the opposing flow between two points. Further, we propose steering heuristics that are useful for steering towards a sampled point. We evaluate these ideas by integrating them with RRT* and comparing the algorithm's performance with state-of-the-art methods in an artificial flow field and in actual ocean prediction data in the region of the dominant East Australian Current between Sydney and Brisbane. Results demonstrate the method's computational efficiency and ability to find high-quality paths outperforming state-of-the-art methods, and show promise for practical use with autonomous marine robots.
keywords: {Planning;Aerospace electronics;Vehicle dynamics;Two dimensional displays;Space exploration;Space vehicles;Oceans},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196555&isnumber=9196508

M. Modasshir and I. Rekleitis, "Enhancing Coral Reef Monitoring Utilizing a Deep Semi-Supervised Learning Approach," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1874-1880.
doi: 10.1109/ICRA40945.2020.9196528
Abstract: Coral species detection underwater is a challenging problem. There are many cases when even the experts (marine biologists) fail to recognize corals, hence limiting ground truth annotation for training a robust detection system. Identifying coral species is fundamental for enabling the monitoring of coral reefs, a task currently performed by humans, which can be automated with the use of underwater robots. By employing temporal cues using a tracker on a high confidence prediction by a convolutional neural network-based object detector, we augment the collected dataset for the retraining of the object detector. However, using trackers to extract examples also introduces hard or mislabelled samples, which is counterproductive and will deteriorate the performance of the detector. In this work, we show that employing a simple deep neural network to filter out hard or mislabelled samples can help regulate sample extraction. We empirically evaluate our approach in a coral object dataset, collected via an Autonomous Underwater Vehicle (AUV) and human divers, that shows the benefit of incorporating extracted examples obtained from tracking. This work also demonstrates how controlling sample generation by tracking using a simple deep neural network can further improve an object detector.
keywords: {Detectors;Training;Object detection;Monitoring;Tracking;Predictive models;Semantics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196528&isnumber=9196508

T. Wang, W. Lu, Z. Yan and D. Liu, "DOB-Net: Actively Rejecting Unknown Excessive Time-Varying Disturbances," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1881-1887.
doi: 10.1109/ICRA40945.2020.9196641
Abstract: This paper presents an observer-integrated Reinforcement Learning (RL) approach, called Disturbance OB-server Network (DOB-Net), for robots operating in environments where disturbances are unknown and time-varying, and may frequently exceed robot control capabilities. The DOB-Net integrates a disturbance dynamics observer network and a controller network. Originated from conventional DOB mechanisms, the observer is built and enhanced via Recurrent Neural Networks (RNNs), encoding estimation of past values and prediction of future values of unknown disturbances in RNN hidden state. Such encoding allows the controller generate optimal control signals to actively reject disturbances, under the constraints of robot control capabilities. The observer and the controller are jointly learned within policy optimization by advantage actor critic. Numerical simulations on position regulation tasks have demonstrated that the proposed DOB-Net significantly outperforms conventional feedback controllers and classical RL policy.
keywords: {Observers;History;Vehicle dynamics;Robots;Optimization;Optimal control;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196641&isnumber=9196508

A. Branch et al., "Demonstration of Autonomous Nested Search for Local Maxima Using an Unmanned Underwater Vehicle," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1888-1895.
doi: 10.1109/ICRA40945.2020.9196625
Abstract: Ocean Worlds represent one of the best chances for extra-terrestrial life in our solar system. A new mission concept must be developed to explore these oceans. This mission would require traversing the 10s of km thick icy shell and releasing a submersible into the ocean below. During the transit of the icy shell and the exploration of the ocean, the vehicle(s) would be out of contact with Earth for weeks or potentially months at a time. During this time the vehicle must have sufficient autonomy to locate and study scientific targets of interest. One such target of interest is hydrothermal venting. We have previously developed an autonomous nested search method to locate and investigate sources of hydrothermal venting by locating local maxima in hydrothermal vent emissions. In this work we demonstrate this approach on board an OceanServer Iver2 AUV in Chesapeake Bay, MD using simulated sensor data from a hydrothermal plume model. This represents the first step towards the deployment of this approach in conditions analogous to those that we might expect on an Ocean World.
keywords: {Vents;Oceans;Vehicle dynamics;Underwater vehicles;Earth;Numerical models;Base stations},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196625&isnumber=9196508

E. Iscar and M. Johnson-Roberson, "Towards distortion based underwater domed viewport camera calibration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1896-1902.
doi: 10.1109/ICRA40945.2020.9197036
Abstract: Photogrammetry techniques used for 3D reconstructions and motion estimation from images are based on projective geometry that models the image formation process. However, in the underwater setting, refraction of light rays at the housing interface introduce non-linear effects in the image formation. These effects produce systematic errors if not accounted for, and severely degrade the quality of the acquired images. In this paper, we present a novel approach to the calibration of cameras inside spherical domes with large offsets between dome and camera centers. Such large offsets not only amplify the effect of refraction, but also introduce blur in the image that corrupts feature extractors used to establish image-world correspondences in existing refractive calibration methods. We propose using the point spread function (PSF) as a complete description of the optical system and introduce a procedure to recover the camera pose inside the dome based on the measurement of the distortions. Results on a collected dataset show the method is capable of recovering the camera pose with high accuracy.
keywords: {Cameras;Calibration;Three-dimensional displays;Optical distortion;Solid modeling;Distortion;Adaptive optics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197036&isnumber=9196508

O. Mohseni, F. Gagey, G. Zhao, A. Seyfarth and M. A. Sharbafi, "How far are Pneumatic Artificial Muscles from biological muscles?," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1909-1915.
doi: 10.1109/ICRA40945.2020.9197177
Abstract: There is a long history demonstrating humans' tendency to create artificial copies of living creatures. For moving machines called robots, actuators play a key role in developing human-like movements. Among different types of actuation, PAMs (pneumatic artificial muscles) are known as the most similar ones to biological muscles. In addition to similarities in force generation mechanism (tension based), the well-accepted argumentation from Klute et al., states that the PAM force-length (fl) behavior is close to biological muscles, while the force-velocity (fv) pattern is different. Using the multiplicative formulation of the pressure (as an activation term), fl and fv beside an additive passive parallel elastic element, we present a new model of PAM. This muscle-based model can predict PAM dynamic behaviors with high precision. With a second experiment on a two-segmented leg, the proposed model is verified to predict the generated forces of PAMs in an antagonistic arrangement. Such a dynamic muscle-like model of artificial muscles can be used for the design and control of legged robots to generate robust, efficient and versatile gaits.
keywords: {Muscles;Mathematical model;Force;Biological system modeling;Robots;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197177&isnumber=9196508

G. Quere et al., "Shared Control Templates for Assistive Robotics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1956-1962.
doi: 10.1109/ICRA40945.2020.9197041
Abstract: Light-weight robotic manipulators can be used to restore the manipulation capability of people with a motor disability. However, manipulating the environment poses a complex task, especially when the control interface is of low bandwidth, as may be the case for users with impairments. Therefore, we propose a constraint-based shared control scheme to define skills which provide support during task execution. This is achieved by representing a skill as a sequence of states, with specific user command mappings and different sets of constraints being applied in each state. New skills are defined by combining different types of constraints and conditions for state transitions, in a human-readable format. We demonstrate its versatility in a pilot experiment with three activities of daily living. Results show that even complex, high-dimensional tasks can be performed with a low-dimensional interface using our shared control approach.
keywords: {Task analysis;Robot kinematics;Manipulators;Wheelchairs;Manifolds;Rehabilitation robotics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197041&isnumber=9196508

H. Chen, H. Tan, A. Kuntz, M. Bansal and R. Alterovitz, "Enabling Robots to Understand Incomplete Natural Language Instructions Using Commonsense Reasoning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1963-1969.
doi: 10.1109/ICRA40945.2020.9197315
Abstract: Enabling robots to understand instructions provided via spoken natural language would facilitate interaction between robots and people in a variety of settings in homes and workplaces. However, natural language instructions are often missing information that would be obvious to a human based on environmental context and common sense, and hence does not need to be explicitly stated. In this paper, we introduce Language-Model-based Commonsense Reasoning (LMCR), a new method which enables a robot to listen to a natural language instruction from a human, observe the environment around it, and automatically fill in information missing from the instruction using environmental context and a new commonsense reasoning approach. Our approach first converts an instruction provided as unconstrained natural language into a form that a robot can understand by parsing it into verb frames. Our approach then fills in missing information in the instruction by observing objects in its vicinity and leveraging commonsense reasoning. To learn commonsense reasoning automatically, our approach distills knowledge from large unstructured textual corpora by training a language model. Our results show the feasibility of a robot learning commonsense knowledge automatically from web-based textual corpora, and the power of learned commonsense reasoning models in enabling a robot to autonomously perform tasks based on incomplete natural language instructions.
keywords: {Natural languages;Robot sensing systems;Cognition;Task analysis;Semantics;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197315&isnumber=9196508

R. Gomez, D. Szapiro, L. Merino and K. Nakamura, "A Holistic Approach in Designing Tabletop Robot‚Äôs Expressivity," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1970-1976.
doi: 10.1109/ICRA40945.2020.9197016
Abstract: Defining a robot's expressivity is a difficult task that requires thoughtful consideration of the potential of various robot modalities and a model of communication that humans understand. Humanoid and zoomorphic-designed robots can easily take cues from human and animals, respectively when designing their expressivity. However, a robot design that is neither human nor animal-like does not have a clear model to follow in terms of designing expressivity. Animation presents a potential model in these circumstances as animated characters in movies take various forms, sizes, shapes and styles, and are successful in defining expressivity that is widely accepted across different languages and cultures. In this paper, we discuss the development and design of the expressivity of Haru, a table top robot that is neither human nor animal-like and the application of animation expertise to the holistic treatment of the different modalities. The method maximizes animation techniques and expertise normally applied to movies to generate expressivity that is then transferred to the robot hardware. Experimental results show that the robot's expressivity generated using our method is easily understood and are preferred to the conventional approach of generating expressions.
keywords: {Animation;Hardware;Neck;Light emitting diodes;Mouth;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197016&isnumber=9196508

R. Bormann, X. Wang, J. Xu and J. Schmidt, "DirtNet: Visual Dirt Detection for Autonomous Cleaning Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1977-1983.
doi: 10.1109/ICRA40945.2020.9196559
Abstract: Visual dirt detection is becoming an important capability of modern professional cleaning robots both for optimizing their wet cleaning results and for facilitating demand-oriented daily vacuum cleaning. This paper presents a robust, fast, and reliable dirt and office item detection system for these tasks based on an adapted YOLOv3 framework. Its superiority over state-of-the-art dirt detection systems is demonstrated in several experiments. The paper furthermore features a dataset generator for creating any number of realistic training images from a small set of real scene, dirt, and object examples.
keywords: {Cleaning;Object detection;Robots;Training;Task analysis;Image resolution;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196559&isnumber=9196508

Z. Zeng, A. R√∂fer and O. C. Jenkins, "Semantic Linking Maps for Active Visual Object Search," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 1984-1990.
doi: 10.1109/ICRA40945.2020.9196830
Abstract: We aim for mobile robots to function in a variety of common human environments. Such robots need to be able to reason about the locations of previously unseen target objects. Landmark objects can help this reasoning by narrowing down the search space significantly. More specifically, we can exploit background knowledge about common spatial relations between landmark and target objects. For example, seeing a table and knowing that cups can often be found on tables aids the discovery of a cup. Such correlations can be expressed as distributions over possible pairing relationships of objects. In this paper, we propose an active visual object search strategy method through our introduction of the Semantic Linking Maps (SLiM) model. SLiM simultaneously maintains the belief over a target object's location as well as landmark objects' locations, while accounting for probabilistic inter-object spatial relations. Based on SLiM, we describe a hybrid search strategy that selects the next best view pose for searching for the target object based on the maintained belief. We demonstrate the efficiency of our SLiM-based search strategy through comparative experiments in simulated environments. We further demonstrate the realworld applicability of SLiM-based search in scenarios with a Fetch mobile manipulation robot.
keywords: {Search problems;Robots;Probabilistic logic;Semantics;Buildings;Inference algorithms;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196830&isnumber=9196508

R. T. Rodrigues, P. Miraldo, D. V. Dimarogonas and A. Pedro Aguiar, "Active Depth Estimation: Stability Analysis and its Applications," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2002-2008.
doi: 10.1109/ICRA40945.2020.9196670
Abstract: Recovering the 3D structure of the surrounding environment is an essential task in any vision-controlled Structure-from-Motion (SfM) scheme. This paper focuses on the theoretical properties of the SfM, known as the incremental active depth estimation. The term incremental stands for estimating the 3D structure of the scene over a chronological sequence of image frames. Active means that the camera actuation is such that it improves estimation performance. Starting from a known depth estimation filter, this paper presents the stability analysis of the filter in terms of the control inputs of the camera. By analyzing the convergence of the estimator using the Lyapunov theory, we relax the constraints on the projection of the 3D point in the image plane when compared to previous results. Nonetheless, our method is capable of dealing with the cameras' limited field-of-view constraints. The main results are validated through experiments with simulated data.
keywords: {Cameras;Three-dimensional displays;Stability analysis;Asymptotic stability;Convergence;Estimation error},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196670&isnumber=9196508

L. Chen, F. Liu, Y. Zhao, W. Wang, X. Yuan and J. Zhu, "VALID: A Comprehensive Virtual Aerial Image Dataset," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2009-2016.
doi: 10.1109/ICRA40945.2020.9197186
Abstract: Aerial imagery plays an important role in land-use planning, population analysis, precision agriculture, and unmanned aerial vehicle tasks. However, existing aerial image datasets generally suffer from the problem of inaccurate labeling, single ground truth type, and few category numbers. In this work, we implement a simulator that can simultaneously acquire diverse visual ground truth data in the virtual environment. Based on that, we collect a comprehensive Virtual AeriaL Image Dataset named VALID, consisting of 6690 high-resolution images, all annotated with panoptic segmentation on 30 categories, object detection with oriented bounding box, and binocular depth maps, collected in 6 different virtual scenes and 5 various ambient conditions (sunny, dusk, night, snow and fog). To our knowledge, VALID is the first aerial image dataset that can provide panoptic level segmentation and complete dense depth maps. We analyze the characteristics of VALID and evaluate state-of-the-art methods for multiple tasks to provide reference baselines. The experiment results demonstrate that VALID is well presented and challenging. The dataset is available at https://sites.google.com/view/valid-dataset/.
keywords: {Image segmentation;Semantics;Task analysis;Object detection;Image color analysis;Benchmark testing;Labeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197186&isnumber=9196508

H. Wang, C. Wang and L. Xie, "Intensity Scan Context: Coding Intensity and Geometry Relations for Loop Closure Detection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2095-2101.
doi: 10.1109/ICRA40945.2020.9196764
Abstract: Loop closure detection is an essential and challenging problem in simultaneous localization and mapping (SLAM). It is often tackled with light detection and ranging (LiDAR) sensor due to its view-point and illumination invariant properties. Existing works on 3D loop closure detection often leverage on matching of local or global geometrical-only descriptors which discard intensity reading. In this paper we explore the intensity property from LiDAR scan and show that it can be effective for place recognition. We propose a novel global descriptor, intensity scan context (ISC), that explores both geometry and intensity characteristics. To improve the efficiency for loop closure detection, an efficient two-stage hierarchical re-identification process is proposed, including binary-operation based fast geometric relation retrieval and intensity structure re-identification. Thorough experiments including both local experiment and public datasets test have been conducted to evaluate the performance of the proposed method. Our method achieves better recall rate and recall precision than existing geometric-only methods.
keywords: {Geometry;Laser radar;Three-dimensional displays;Histograms;Simultaneous localization and mapping;Rough surfaces;Surface roughness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196764&isnumber=9196508

B. Li, D. Zou, D. Sartori, L. Pei and W. Yu, "TextSLAM: Visual SLAM with Planar Text Features," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2102-2108.
doi: 10.1109/ICRA40945.2020.9197233
Abstract: We propose to integrate text objects in man-made scenes tightly into the visual SLAM pipeline. The key idea of our novel text-based visual SLAM is to treat each detected text as a planar feature which is rich of textures and semantic meanings. The text feature is compactly represented by three parameters and integrated into visual SLAM by adopting the illumination-invariant photometric error. We also describe important details involved in implementing a full pipeline of text-based visual SLAM. To our best knowledge, this is the first visual SLAM method tightly coupled with the text features. We tested our method in both indoor and outdoor environments. The results show that with text features, the visual SLAM system becomes more robust and produces much more accurate 3D text maps that could be useful for navigation and scene understanding in robotic or augmented reality applications.
keywords: {Simultaneous localization and mapping;Three-dimensional displays;Visualization;Feature extraction;Navigation;Cameras;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197233&isnumber=9196508

K. Wang, K. Wang and S. Shen, "FlowNorm: A Learning-based Method for Increasing Convergence Range of Direct Alignment," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2109-2115.
doi: 10.1109/ICRA40945.2020.9197118
Abstract: Many approaches have been proposed to estimate camera poses by directly minimizing photometric error. However, due to the non-convex property of direct alignment, proper initialization is still required for these methods. Many robust norms (e.g. Huber norm) have been proposed to deal with the outlier terms caused by incorrect initializations. These robust norms are solely defined on the magnitude of each error term. In this paper, we propose a novel robust norm, named FlowNorm, that exploits the information from both the local error term and the global image registration information. While the local information is defined on patch alignments, the global information is estimated using a learning-based network. Using both the local and global information, we achieve a large convergence range in which images can be aligned given large view angle changes or small overlaps. We further demonstrate the usability of the proposed robust norm by integrating it into the direct methods DSO and BA-Net, and generate more robust and accurate results in real-time.
keywords: {Optimization;Convergence;Cameras;Robustness;Optical imaging;Learning systems;Nonlinear optics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197118&isnumber=9196508

J. Kuo, M. Muglikar, Z. Zhang and D. Scaramuzza, "Redesigning SLAM for Arbitrary Multi-Camera Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2116-2122.
doi: 10.1109/ICRA40945.2020.9197553
Abstract: Adding more cameras to SLAM systems improves robustness and accuracy but complicates the design of the visual front-end significantly. Thus, most systems in the literature are tailored for specific camera configurations. In this work, we aim at an adaptive SLAM system that works for arbitrary multi-camera setups. To this end, we revisit several common building blocks in visual SLAM. In particular, we propose an adaptive initialization scheme, a sensor-agnostic, information- theoretic keyframe selection algorithm, and a scalable voxel- based map. These techniques make little assumption about the actual camera setups and prefer theoretically grounded methods over heuristics. We adapt a state-of-the-art visual- inertial odometry with these modifications, and experimental results show that the modified pipeline can adapt to a wide range of camera setups (e.g., 2 to 6 cameras in one experiment) without the need of sensor-specific modifications or tuning.
keywords: {Cameras;Simultaneous localization and mapping;Three-dimensional displays;Uncertainty;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197553&isnumber=9196508

M. Henein, J. Zhang, R. Mahony and V. Ila, "Dynamic SLAM: The Need For Speed," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2123-2129.
doi: 10.1109/ICRA40945.2020.9196895
Abstract: The static world assumption is standard in most simultaneous localisation and mapping (SLAM) algorithms. Increased deployment of autonomous systems to unstructured dynamic environments is driving a need to identify moving objects and estimate their velocity in real-time. Most existing SLAM based approaches rely on a database of 3D models of objects or impose significant motion constraints. In this paper, we propose a new feature-based, model-free, object-aware dynamic SLAM algorithm that exploits semantic segmentation to allow estimation of motion of rigid objects in a scene without the need to estimate the object poses or have any prior knowledge of their 3D models. The algorithm generates a map of dynamic and static structure and has the ability to extract velocities of rigid moving objects in the scene. Its performance is demonstrated on simulated, synthetic and real-world datasets.
keywords: {Simultaneous localization and mapping;Heuristic algorithms;Dynamics;Three-dimensional displays;Solid modeling;Tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196895&isnumber=9196508

K. M. Jatavallabhula, G. Iyer and L. Paull, "‚àáSLAM: Dense SLAM meets Automatic Differentiation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2130-2137.
doi: 10.1109/ICRA40945.2020.9197519
Abstract: The question of "representation" is central in the context of dense simultaneous localization and mapping (SLAM). Learning-based approaches have the potential to leverage data or task performance to directly inform the representation. However, blending representation learning approaches with "classical" SLAM systems has remained an open question, because of their highly modular and complex nature. A SLAM system transforms raw sensor inputs into a distribution over the state(s) of the robot and the environment. If this transformation (SLAM) were expressible as a differentiable function, we could leverage task-based error signals over the outputs of this function to learn representations that optimize task performance. However, this is infeasible as several components of a typical dense SLAM system are non-differentiable. In this work, we propose ‚àáSLAM (gradSLAM), a methodology for posing SLAM systems as differentiable computational graphs, which unifies gradient-based learning and SLAM. We propose differentiable trust-region optimizers, surface measurement and fusion schemes, and raycasting, without sacrificing accuracy. This amalgamation of dense SLAM with computational graphs enables us to backprop all the way from 3D maps to 2D pixels, opening up new possibilities in gradient-based learning for SLAM1.
keywords: {Simultaneous localization and mapping;Optimization;Three-dimensional displays;Damping;Task analysis;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197519&isnumber=9196508

T. Choi, S. Kang and T. P. Pavlic, "Learning local behavioral sequences to better infer non-local properties in real multi-robot systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2138-2144.
doi: 10.1109/ICRA40945.2020.9196728
Abstract: When members of a multi-robot team follow regular motion rules sensitive to robots and other environmental factors within sensing range, the team itself may become an informational fabric for gaining situational awareness without explicit signalling among robots. In our previous work [1], we used machine learning to develop a scalable module, trained only on data from 3-robot teams, that could predict the positions of all robots in larger multi-robot teams based only on observations of the movement of a robot's nearest neighbor. Not only was this approach scalable from 3-to-many robots, but it did not require knowledge of the control laws of the robots under observation, as would a traditional observer-based approach. However, performance was only tested in simulation and could only be a substitute for explicit communication for short periods of time or in cases of very low sensing noise. In this work, we apply more sophisticated machine learning methods to data from a physically realized robotic team to develop Remote Teammate Localization (ReTLo) modules that can be used in realistic environments. To be specific, we adopt Long-Short-Term-Memory (LSTM) [2] to learn the evolution of behaviors in a modular team, which has the effect of greatly reducing errors from regression outcomes. In contrast with our previous work in simulation, all of the experiments conducted in this work were conducted on the Thymio physical, two-wheeled robotic platform.
keywords: {Robot sensing systems;Robot kinematics;Training;Multi-robot systems;Machine learning;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196728&isnumber=9196508

Y. Cho, G. Kim and A. Kim, "Unsupervised Geometry-Aware Deep LiDAR Odometry," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2145-2152.
doi: 10.1109/ICRA40945.2020.9197366
Abstract: Learning-based ego-motion estimation approaches have recently drawn strong interest from researchers, mostly focusing on visual perception. A few learning-based approaches using Light Detection and Ranging (LiDAR) have been re-ported; however, they heavily rely on a supervised learning manner. Despite the meaningful performance of these approaches, supervised training requires ground-truth pose labels, which is the bottleneck for real-world applications. Differing from these approaches, we focus on unsupervised learning for LiDAR odometry (LO) without trainable labels. Achieving trainable LO in an unsupervised manner, we introduce the uncertainty-aware loss with geometric confidence, thereby al-lowing the reliability of the proposed pipeline. Evaluation on the KITTI, Complex Urban, and Oxford RobotCar datasets demonstrate the prominent performance of the proposed method compared to conventional model-based methods. The proposed method shows a comparable result against SuMa (in KITTI), LeGO-LOAM (in Complex Urban), and Stereo-VO (in Oxford RobotCar). The video and extra-information of the paper are described in https://sites.google.com/view/deeplo.
keywords: {Three-dimensional displays;Laser radar;Training;Estimation;Two dimensional displays;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197366&isnumber=9196508

N. Soans, E. Asali, Y. Hong and P. Doshi, "SA-Net: Robust State-Action Recognition for Learning from Observations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2153-2159.
doi: 10.1109/ICRA40945.2020.9197393
Abstract: Learning from observation (LfO) offers a new paradigm for transferring task behavior to robots. LfO requires the robot to observe the task being performed and decompose the sensed streaming data into sequences of state-action pairs, which are then input to LfO methods. Thus, recognizing the state-action pairs correctly and quickly in sensed data is a crucial prerequisite. We present SA-Net a deep neural network architecture that recognizes state-action pairs from RGB-D data streams. SA-Net performs well in two replicated robotic applications of LfO - one involving mobile ground robots and another involving a robotic manipulator - which demonstrates that the architecture could generalize well to differing contexts. Comprehensive evaluations including deployment on a physical robot show that SA-Net significantly improves on the accuracy of the previous methods under various conditions.
keywords: {Image recognition;Task analysis;Robot sensing systems;Feature extraction;Robot kinematics;Object detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197393&isnumber=9196508

C. -E. Tsai and J. Oh, "A Generative Approach for Socially Compliant Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2160-2166.
doi: 10.1109/ICRA40945.2020.9197497
Abstract: Robots navigating in human crowds need to optimize their paths not only for their task performance but also for their compliance to social norms. One of the key challenges in this context is the lack of standard metrics for evaluating and optimizing a socially compliant behavior. Existing works in social navigation can be grouped according to the differences in their optimization objectives. For instance, the reinforcement learning approaches tend to optimize on the comfort aspect of the socially compliant navigation, whereas the inverse reinforcement learning approaches are designed to achieve natural behavior. In this paper, we propose NaviGAN, a generative navigation algorithm that jointly optimizes both of the comfort and naturalness aspects. Our approach is designed as an adversarial training framework that can learn to generate a navigation path that is both optimized for achieving a goal and for complying with latent social rules. A set of experiments has been carried out on multiple datasets to demonstrate the strengths of the proposed approach quantitatively. We also perform extensive experiments using a physical robot in a realworld environment to qualitatively evaluate the trained social navigation behavior. The video recordings of the robot experiments can be found in the link: https://youtu.be/61blDymjCpw.
keywords: {Navigation;Robots;Force;Generators;Trajectory;Learning (artificial intelligence);Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197497&isnumber=9196508

A. Singh et al., "Scalable Multi-Task Imitation Learning with Autonomous Improvement," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2167-2173.
doi: 10.1109/ICRA40945.2020.9197020
Abstract: While robot learning has demonstrated promising results for enabling robots to automatically acquire new skills, a critical challenge in deploying learning-based systems is scale: acquiring enough data for the robot to effectively generalize broadly. Imitation learning, in particular, has remained a stable and powerful approach for robot learning, but critically relies on expert operators for data collection. In this work, we target this challenge, aiming to build an imitation learning system that can continuously improve through autonomous data collection, while simultaneously avoiding the explicit use of reinforcement learning, to maintain the stability, simplicity, and scalability of supervised imitation. To accomplish this, we cast the problem of imitation with autonomous improvement into a multi-task setting. We utilize the insight that, in a multi-task setting, a failed attempt at one task might represent a successful attempt at another task. This allows us to leverage the robot's own trials as demonstrations for tasks other than the one that the robot actually attempted. Using an initial dataset of multitask demonstration data, the robot autonomously collects trials which are only sparsely labeled with a binary indication of whether the trial accomplished any useful task or not. We then embed the trials into a learned latent space of tasks, trained using only the initial demonstration dataset, to draw similarities between various trials, enabling the robot to achieve one-shot generalization to new tasks. In contrast to prior imitation learning approaches, our method can autonomously collect data with sparse supervision for continuous improvement, and in contrast to reinforcement learning algorithms, our method can effectively improve from sparse, task-agnostic reward signals.
keywords: {Task analysis;Robots;Learning (artificial intelligence);Standards;Trajectory;Data collection;Learning systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197020&isnumber=9196508

A. K. Tanwani, P. Sermanet, A. Yan, R. Anand, M. Phielipp and K. Goldberg, "Motion2Vec: Semi-Supervised Representation Learning from Surgical Videos," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2174-2181.
doi: 10.1109/ICRA40945.2020.9197324
Abstract: Learning meaningful visual representations in an embedding space can facilitate generalization in downstream tasks such as action segmentation and imitation. In this paper, we learn a motion-centric representation of surgical video demonstrations by grouping them into action segments/subgoals/options in a semi-supervised manner. We present Motion2Vec, an algorithm that learns a deep embedding feature space from video observations by minimizing a metric learning loss in a Siamese network: images from the same action segment are pulled together while pushed away from randomly sampled images of other segments, while respecting the temporal ordering of the images. The embeddings are iteratively segmented with a recurrent neural network for a given parametrization of the embedding space after pre-training the Siamese network. We only use a small set of labeled video segments to semantically align the embedding space and assign pseudo-labels to the remaining unlabeled data by inference on the learned model parameters. We demonstrate the use of this representation to imitate surgical suturing kinematic motions from publicly available videos of the JIGSAWS dataset. Results give 85.5% segmentation accuracy on average suggesting performance improvement over several state-of-the-art baselines, while kinematic pose imitation gives 0.94 centimeter error in position per observation on the test set. Videos, code and data are available at: https://sites.google.com/view/motion2vec.
keywords: {Videos;Motion segmentation;Image segmentation;Measurement;Hidden Markov models;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197324&isnumber=9196508

M. Mizuno and T. Kubota, "A New Path Planning Architecture to Consider Motion Uncertainty in Natural Environment," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2182-2188.
doi: 10.1109/ICRA40945.2020.9197238
Abstract: This paper proposes a new path planning algorithm to consider motion uncertainty for wheeled robots in rough environments. The proposed method uses particles to express the uncertainty propagation in complicated environments constructed with various types of terrain. Also, RRT (Rapidly-exploring Random Tree) is expanded based on the uncertainty of each node in order to prevent increasing the accumulated position uncertainty. As a result, the generated path reduces the times of path-following and re-planning based on inaccurate localization information. The effectiveness of the proposed method is evaluated in simulation using motion uncertainty models obtained by experiments. The results show that the proposed method decreases the position uncertainty while keeping the probability to avoid collisions and to reach the goal area compared with conventional approaches.
keywords: {Uncertainty;Robot kinematics;Path planning;Mobile robots;Planning;Global Positioning System},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197238&isnumber=9196508

K. Solovey, L. Janson, E. Schmerling, E. Frazzoli and M. Pavone, "Revisiting the Asymptotic Optimality of RRT," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2189-2195.
doi: 10.1109/ICRA40945.2020.9196553
Abstract: RRT* is one of the most widely used sampling-based algorithms for asymptotically-optimal motion planning. RRT* laid the foundations for optimality in motion planning as a whole, and inspired the development of numerous new algorithms in the field, many of which build upon RRT* itself. In this paper, we first identify a logical gap in the optimality proof of RRT*, which was developed by Karaman and Frazzoli (2011). Then, we present an alternative and mathematically-rigorous proof for asymptotic optimality. Our proof suggests that the connection radius used by RRT* should be increased from Œ≥ (log n/n)1/d to Œ≥' (log n/n)1/(d+1) in order to account n n for the additional dimension of time that dictates the samples' ordering. Here Œ≥, Œ≥' are constants, and n, d are the number of samples and the dimension of the problem, respectively.
keywords: {Robustness;Robots;Heuristic algorithms;Manganese;Planning;Aerodynamics;Safety},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196553&isnumber=9196508

M. Tsao, K. Solovey and M. Pavone, "Sample Complexity of Probabilistic Roadmaps via Œµ-nets," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2196-2202.
doi: 10.1109/ICRA40945.2020.9196917
Abstract: We study fundamental theoretical aspects of probabilistic roadmaps (PRM) in the finite time (non-asymptotic) regime. In particular, we investigate how completeness and optimality guarantees of the approach are influenced by the underlying deterministic sampling distribution X and connection radius r > 0. We develop the notion of (Œ¥, Œµ)-completeness of the parameters X, r, which indicates that for every motion-planning problem of clearance at least Œ¥ > 0, PRM using X, r returns a solution no longer than 1+Œµ times the shortest Œ¥-clear path. Leveraging the concept of e-nets, we characterize in terms of lower and upper bounds the number of samples needed to guarantee (Œ¥, Œµ)-completeness. This is in contrast with previous work which mostly considered the asymptotic regime in which the number of samples tends to infinity. In practice, we propose a sampling distribution inspired by e-nets that achieves nearly the same coverage as grids while using fewer samples.
keywords: {Planning;Complexity theory;Probabilistic logic;Two dimensional displays;Robots;Collision avoidance;Benchmark testing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196917&isnumber=9196508

H. Su, Y. Hu, Z. Li, A. Knoll, G. Ferrigno and E. De Momi, "Reinforcement Learning Based Manipulation Skill Transferring for Robot-assisted Minimally Invasive Surgery," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2203-2208.
doi: 10.1109/ICRA40945.2020.9196588
Abstract: The complexity of surgical operation can be released significantly if surgical robots can learn the manipulation skills by imitation from complex tasks demonstrations such as puncture, suturing, and knotting, etc.. This paper proposes a reinforcement learning algorithm based manipulation skill transferring technique for robot-assisted Minimally Invasive Surgery by Teaching by Demonstration. It employed Gaussian mixture model and Gaussian mixture Regression based dynamic movement primitive to model the high-dimensional human-like manipulation skill after multiple demonstrations. Furthermore, this approach fascinates the learning and trial phase performed offline, which reduces the risks and cost for the practical surgical operation. Finally, it is demonstrated by transferring manipulation skills for reaching and puncture using a KUKA LWR4+ robot in a lab setup environment. The results show the effectiveness of the proposed approach for modelling and learning of human manipulation skill.
keywords: {Learning (artificial intelligence);Robots;Surgery;Trajectory;Task analysis;Shape;Education},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196588&isnumber=9196508

Y. Lu and M. Kamgarpour, "Safe Mission Planning under Dynamical Uncertainties," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2209-2215.
doi: 10.1109/ICRA40945.2020.9196515
Abstract: This paper considers safe robot mission planning in uncertain dynamical environments. This problem arises in applications such as surveillance, emergency rescue, and autonomous driving. It is a challenging problem due to mod-eling and integrating dynamical uncertainties into a safe planning framework, and finding a solution in a computationally tractable way. In this work, we first develop a probabilistic model for dynamical uncertainties. Then, we provide a framework to generate a path that maximizes safety for complex missions by incorporating the uncertainty model. We also devise a Monte Carlo method to obtain a safe path efficiently. Finally, we evaluate the performance of our approach and compare it to potential alternatives in several case studies.
keywords: {Uncertainty;Planning;Automata;Computational modeling;Hazards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196515&isnumber=9196508

D. Fridovich-Keil, V. Rubies-Royo and C. J. Tomlin, "An Iterative Quadratic Method for General-Sum Differential Games with Feedback Linearizable Dynamics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2216-2222.
doi: 10.1109/ICRA40945.2020.9196517
Abstract: Iterative linear-quadratic (ILQ) methods are widely used in the nonlinear optimal control community. Recent work has applied similar methodology in the setting of multi-player general-sum differential games. Here, ILQ methods are capable of finding local equilibria in interactive motion planning problems in real-time. As in most iterative procedures, however, this approach can be sensitive to initial conditions and hyperparameter choices, which can result in poor computational performance or even unsafe trajectories. In this paper, we focus our attention on a broad class of dynamical systems which are feedback linearizable, and exploit this structure to improve both algorithmic reliability and runtime. We showcase our new algorithm in three distinct traffic scenarios, and observe that in practice our method converges significantly more often and more quickly than was possible without exploiting the feedback linearizable structure.
keywords: {Games;Heuristic algorithms;Planning;Feedback linearization;Iterative methods;Vehicle dynamics;Optimal control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196517&isnumber=9196508

Y. H. Tan and B. M. Chen, "A Morphable Aerial-Aquatic Quadrotor with Coupled Symmetric Thrust Vectoring," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2223-2229.
doi: 10.1109/ICRA40945.2020.9196687
Abstract: Hybrid aerial-aquatic vehicles have the unique ability of travelling in both air and water and can benefit from both lower fluid resistance in air and energy efficient position holding in water. However, they have to address the differing requirements which make optimising a single design difficult. While existing examples have shown the possibility of such vehicles, they are mostly structurally identical to normal aerial vehicles with minor adjustments to work underwater. Instead of using rotational acceleration to direct a component of thrust in surge and sway, we propose a quadrotor based vehicle that tilts its rotors about the respective arm so that a larger component of thrust can be directed in the lateral plane or in the opposite direction without rotating the vehicle body. A small-scale prototype of this design is presented here, detailing the design considerations including mechanical actuation, static stability and waterproofing.
keywords: {Buoyancy;Robots;Force;Torque;Prototypes;Propellers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196687&isnumber=9196508

K. Yang and Q. Quan, "An Autonomous Intercept Drone with Image-based Visual Servo," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2230-2236.
doi: 10.1109/ICRA40945.2020.9197539
Abstract: For most people on the ground, facing an unwanted drone buzzing around overhead, there is not a lot that we can do, especially if it is out of gun (radio wave gun or shotgun) range. A solution to this is to use intercept drones that seek out and bring down other drones. In order to make the interception autonomous, an image-based visual servo algorithm is designed with a forward-looking monocular camera. The control command, namely the angular velocity and thrust, is generated for intercept drones to implement accurate and fast interception. The proposed method is demonstrated in both hardware-in-the-loop simulation and demonstrative flight experiments.
keywords: {Cameras;Visualization;Mathematical model;Drones;Channel models;Servomotors;Angular velocity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197539&isnumber=9196508

P. Prajapati, S. Parekh and V. Vashista, "On the Human Control of a Multiple Quadcopters with a Cable-suspended Payload System," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2253-2258.
doi: 10.1109/ICRA40945.2020.9197279
Abstract: A quadcopter is an under-actuated system with only four control inputs for six degrees of freedom, and yet the human control of a quadcopter is simple enough to be learned with some practice. In this work, we consider the problem of human control of a multiple quadcopters system to transport a cable-suspended payload. The coupled dynamics of the system, due to the inherent physical constraints, is used to develop a leader-follower architecture where the leader quadcopter is controlled directly by a human operator and the followers are controlled with the proposed Payload Attitude Controller and Cable Attitude Controller. Experiments, where a human operator flew a two quadcopters system to transport a cable-suspended payload, were conducted to study the performance of proposed controller. The results demonstrated successful implementation of human control in these systems. This work presents the possibility of enabling manual control for on-the-go maneuvering of the quadcopter-payload system which motivates aerial transportation in the unknown environments.
keywords: {Payloads;Oscillators;Angular velocity;Attitude control;Vehicle dynamics;Trajectory;Quadcopters;Human control;Cable-suspended payload;Collaborative transportation;Multi-agents},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197279&isnumber=9196508

Q. -H. Pham et al., "A 3D Dataset: Towards Autonomous Driving in Challenging Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2267-2273.
doi: 10.1109/ICRA40945.2020.9197385
Abstract: With the increasing global popularity of self-driving cars, there is an immediate need for challenging real-world datasets for benchmarking and training various computer vision tasks such as 3D object detection. Existing datasets either represent simple scenarios or provide only day-time data. In this paper, we introduce a new challenging A*3D dataset which consists of RGB images and LiDAR data with a significant diversity of scene, time, and weather. The dataset consists of high-density images (&#x2248; 10 times more than the pioneering KITTI dataset), heavy occlusions, a large number of nighttime frames (&#x2248; 3 times the nuScenes dataset), addressing the gaps in the existing datasets to push the boundaries of tasks in autonomous driving research to more challenging highly diverse environments. The dataset contains 39K frames, 7 classes, and 230K 3D object annotations. An extensive 3D object detection benchmark evaluation on the A*3D dataset for various attributes such as high density, day-time/night-time, gives interesting insights into the advantages and limitations of training and testing 3D object detection in real-world setting.
keywords: {Three-dimensional displays;Laser radar;Autonomous vehicles;Cameras;Calibration;Object detection;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197385&isnumber=9196508

H. Yi et al., "SegVoxelNet: Exploring Semantic Context and Depth-aware Features for 3D Vehicle Detection from Point Cloud," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2274-2280.
doi: 10.1109/ICRA40945.2020.9196556
Abstract: 3D vehicle detection based on point cloud is a challenging task in real-world applications such as autonomous driving. Despite significant progress has been made, we observe two aspects to be further improved. First, the semantic context information in LiDAR is seldom explored in previous works, which may help identify ambiguous vehicles. Second, the distribution of point cloud on vehicles varies continuously with increasing depths, which may not be well modeled by a single model. In this work, we propose a unified model SegVoxelNet to address the above two problems. A semantic context encoder is proposed to leverage the free-of-charge semantic segmentation masks in the bird's eye view. Suspicious regions could be highlighted while noisy regions are suppressed by this module. To better deal with vehicles at different depths, a novel depth-aware head is designed to explicitly model the distribution differences and each part of the depth-aware head is made to focus on its own target detection range. Extensive experiments on the KITTI dataset show that the proposed method outperforms the state-of-the-art alternatives in both accuracy and efficiency with point cloud as input only.
keywords: {Three-dimensional displays;Semantics;Feature extraction;Two dimensional displays;Vehicle detection;Head;Convolution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196556&isnumber=9196508

K. Nishi and M. Shimosaka, "Fine-Grained Driving Behavior Prediction via Context-Aware Multi-Task Inverse Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2281-2287.
doi: 10.1109/ICRA40945.2020.9197126
Abstract: Research on advanced driver assistance systems for reducing risks to vulnerable road users (VRUs) has recently gained popularity because the traffic accident reduction rate for VRUs is still small. Dealing with unexpected VRU movements on residential roads requires proficient acceleration and deceleration. Although fine-grained prediction of driving behavior through inverse reinforcement learning (IRL) has been reported with promising results in recent years, learning of a precise model fails when driving strategies vary with contextual factors, i.e., weather, time of day, road width, and traffic direction. In this work, we propose a novel multi-task IRL approach with a multilinear reward function to incorporate contextual information into the model. This approach can provide precise long-term prediction of fine-grained driving behavior while adjusting to context. Experimental results using actual driving data over 141 km with various contexts and roads confirm the success of this approach in terms of predicting defensive driving strategy even in unknown situations.
keywords: {Roads;Context modeling;Task analysis;Vehicles;Hidden Markov models;Safety;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197126&isnumber=9196508

D. Pannen, M. Liebner, W. Hempel and W. Burgard, "How to Keep HD Maps for Automated Driving Up To Date," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2288-2294.
doi: 10.1109/ICRA40945.2020.9197419
Abstract: The current state of the art in automotive high definition digital (HD) map generation based on dedicated mapping vehicles cannot reliably keep these maps up to date because of the low traversal frequencies. Anonymized data collected from the fleet of vehicles that is already on the road provides a huge potential to outperform such state of the art solutions in robustness, safety and up-to-dateness of the map while achieving comparable quality. We thus present a solution based on crowdsourced data to (i) detect changes in the map independent of the type of change, (ii) automatically trigger map update jobs for parts of the map, and (iii) create and integrate map patches to keep the map always up to date. The developed solution provides a crowdsourced up to date HD map to make reliable prior information on lane markings and road edges available to automated driving functions.
keywords: {Roads;Vehicle dynamics;Topology;Robot sensing systems;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197419&isnumber=9196508

A. Frickenstein et al., "Binary DAD-Net: Binarized Driveable Area Detection Network for Autonomous Driving," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2295-2301.
doi: 10.1109/ICRA40945.2020.9197119
Abstract: Driveable area detection is a key component for various applications in the field of autonomous driving (AD), such as ground-plane detection, obstacle detection and maneuver planning. Additionally, bulky and over-parameterized networks can be easily forgone and replaced with smaller networks for faster inference on embedded systems. The driveable area detection, posed as a two class segmentation task, can be efficiently modeled with slim binary networks. This paper proposes a novel binarized driveable area detection network (binary DAD-Net), which uses only binary weights and activations in the encoder, the bottleneck, and the decoder part. The latent space of the bottleneck is efficiently increased (√ó32‚Üí√ó16 downsampling) through binary dilated convolutions, learning more complex features. Along with automatically generated training data, the binary DAD-Net outperforms state-of-the-art semantic segmentation networks on public datasets. In comparison to a full-precision model, our approach has a √ó14.3 reduced compute complexity on an FPGA and it requires only 0.9MB memory resources. Therefore, commodity SIMD-based AD-hardware is capable of accelerating the binary DAD-Net.
keywords: {Convolutional codes;Task analysis;Semantics;Decoding;Training;Autonomous vehicles;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197119&isnumber=9196508

W. Wen et al., "UrbanLoco: A Full Sensor Suite Dataset for Mapping and Localization in Urban Scenes," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2310-2316.
doi: 10.1109/ICRA40945.2020.9196526
Abstract: Mapping and localization is a critical module of autonomous driving, and significant achievements have been reached in this field. Beyond Global Navigation Satellite System (GNSS), research in point cloud registration, visual feature matching, and inertia navigation has greatly enhanced the accuracy and robustness of mapping and localization in different scenarios. However, highly urbanized scenes are still challenging: LIDAR- and camera-based methods perform poorly with numerous dynamic objects; the GNSS-based solutions experience signal loss and multi-path problems; the inertia measurement units (IMU) suffer from drifting. Unfortunately, current public datasets either do not adequately address this urban challenge or do not provide enough sensor information related to map-ping and localization. Here we present UrbanLoco: a mapping/localization dataset collected in highly-urbanized environments with a full sensor-suite. The dataset includes 13 trajectories collected in San Francisco and Hong Kong, covering a total length of over 40 kilometers. Our dataset includes a wide variety of urban terrains: urban canyons, bridges, tunnels, sharp turns, etc. More importantly, our dataset includes information from LIDAR, cameras, IMU, and GNSS receivers. Now the dataset is publicly available through the link in the footnote 1.
keywords: {Global navigation satellite system;Cameras;Laser radar;Urban areas;Robot sensing systems;Trajectory;Satellites},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196526&isnumber=9196508

C. Peng and D. Weikersdorfer, "Map As the Hidden Sensor: Fast Odometry-Based Global Localization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2317-2323.
doi: 10.1109/ICRA40945.2020.9197225
Abstract: Accurate and robust global localization is essential to robotics applications. We propose a novel global localization method that employs the map traversability as a hidden observation. The resulting map-corrected odometry localization is able to provide an accurate belief tensor of the robot state. Our method can be used for blind robots in dark or highly reflective areas. In contrast to odometry drift in the long-term, our method using only odometry and the map converges in long-term. Our method can also be integrated with other sensors to boost the localization performance. The algorithm does not have any initial state assumption and tracks all possible robot states at all times. Therefore, our method is global and is robust in the event of ambiguous observations. We parallel each step of our algorithm such that it can be performed in real-time (up to ~300 Hz) using GPU. We validate our algorithm in different publicly available floor-plans and show that it is able to converge to the ground truth fast while being robust to ambiguities.
keywords: {Robot sensing systems;Tensile stress;Trajectory;Robustness;Uncertainty;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197225&isnumber=9196508

W. Deng, L. Bertoni, S. Kreiss and A. Alahi, "Joint Human Pose Estimation and Stereo 3D Localization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2324-2330.
doi: 10.1109/ICRA40945.2020.9197069
Abstract: We present an end-to-end trainable Neural Network architecture for stereo imaging that jointly locates and estimates human body poses in 3D. Our method defines a 2D pose for each human in a stereo pair of images and uses a correlation layer with a composite field to associate each left-right pair of joints. In absence of a stereo pose dataset, we show that we can train our method with synthetic data only and test it on real-world images (i.e., our training stage is domain invariant). Our method is particularly suitable for autonomous vehicles. We achieve state-of-the-art results for the 3D localization task on the challenging real-world KITTI dataset while running four times faster.
keywords: {Three-dimensional displays;Correlation;Two dimensional displays;Pose estimation;Uncertainty;Decoding;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197069&isnumber=9196508

B. Wagstaff, V. Peretroukhin and J. Kelly, "Self-Supervised Deep Pose Corrections for Robust Visual Odometry," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2331-2337.
doi: 10.1109/ICRA40945.2020.9197562
Abstract: We present a self-supervised deep pose correction (DPC) network that applies pose corrections to a visual odometry estimator to improve its accuracy. Instead of regressing inter-frame pose changes directly, we build on prior work that uses data-driven learning to regress pose corrections that account for systematic errors due to violations of modelling assumptions. Our self-supervised formulation removes any requirement for six-degrees-of-freedom ground truth and, in contrast to expectations, often improves overall navigation accuracy compared to a supervised approach. Through extensive experiments, we show that our self-supervised DPC network can significantly enhance the performance of classical monocular and stereo odometry estimators and substantially out-performs state-of-the-art learning-only approaches.
keywords: {Image reconstruction;Cameras;Training;Lighting;Pipelines;Robustness;Visual odometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197562&isnumber=9196508

H. Tanaka, "Ultra-High-Accuracy Visual Marker for Indoor Precise Positioning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2338-2343.
doi: 10.1109/ICRA40945.2020.9196535
Abstract: Indoor positioning technology is essential for indoor mobile robots and drones. However, there has never been a general-purpose technology or infrastructure that enables indoor positioning with an accuracy of less than 10 cm. We have developed an attitude measurement method using multiple dynamic moires with a lenticular lens and developed an ultra- high-accuracy visual marker with an attitude estimation error of less than 0.1¬∞. We also developed a calculation method that minimizes the marker position error by reminimizing reprojection error using its good attitude accuracy. We proved that accurate local positioning with a position error of about 1 cm in a marker coordinate system is possible even when a marker is shot from a distance of 10 m. In addition, a demonstration test was performed in a public space, and it was shown that high-accuracy global positioning with a position error of about 10 cm is possible.
keywords: {Visualization;Lenses;Position measurement;Cameras;Measurement uncertainty;Pose estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196535&isnumber=9196508

Y. Cao, C. Yang, R. Li, A. Knoll and G. Beltrame, "Accurate position tracking with a single UWB anchor," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2344-2350.
doi: 10.1109/ICRA40945.2020.9197345
Abstract: Accurate localization and tracking are a fundamental requirement for robotic applications. Localization systems like GPS, optical tracking, simultaneous localization and mapping (SLAM) are used for daily life activities, research, and commercial applications. Ultra-wideband (UWB) technology provides another venue to accurately locate devices both indoors and outdoors. In this paper, we study a localization solution with a single UWB anchor, instead of the traditional multi-anchor setup. Besides the challenge of a single UWB ranging source, the only other sensor we require is a low-cost 9 DoF inertial measurement unit (IMU). Under such a configuration, we propose continuous monitoring of UWB range changes to estimate the robot speed when moving on a line. Combining speed estimation with orientation estimation from the IMU sensor, the system becomes temporally observable. We use an Extended Kalman Filter (EKF) to estimate the pose of a robot. With our solution, we can effectively correct the accumulated error and maintain accurate tracking of a moving robot.
keywords: {Robot sensing systems;Estimation;Observability;Velocity measurement;Distance measurement;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197345&isnumber=9196508

M. Tucker et al., "Preference-Based Learning for Exoskeleton Gait Optimization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2351-2357.
doi: 10.1109/ICRA40945.2020.9196661
Abstract: This paper presents a personalized gait optimization framework for lower-body exoskeletons. Rather than optimizing numerical objectives such as the mechanical cost of transport, our approach directly learns from user prefer-ences, e.g., for comfort. Building upon work in preference-based interactive learning, we present the CoSpar algorithm. CoSpar prompts the user to give pairwise preferences between trials and suggest improvements; as exoskeleton walking is a non-intuitive behavior, users can provide preferences more easily and reliably than numerical feedback. We show that CoSpar performs competitively in simulation and demonstrate a prototype implementation of CoSpar on a lower-body exoskeleton to optimize human walking trajectory features. In the experiments, CoSpar consistently found user-preferred parameters of the exoskeleton's walking gait, which suggests that it is a promising starting point for adapting and personalizing exoskeletons (or other assistive devices) to individual users.
keywords: {Exoskeletons;Legged locomotion;Optimization;Bayes methods;Reliability;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196661&isnumber=9196508

S. Chen and J. T. Wen, "Adaptive Neural Trajectory Tracking Control for Flexible-Joint Robots with Online Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2358-2364.
doi: 10.1109/ICRA40945.2020.9197051
Abstract: Collaborative robots and space manipulators contain significant joint flexibility. It complicates the control design, compromises the control bandwidth, and limits the tracking accuracy. The imprecise knowledge of the flexible joint dynamics compounds the challenge. In this paper, we present a new control architecture for controlling flexible-joint robots. Our approach uses a multi-layer neural network to approximate unknown dynamics needed for the feedforward control. The network may be viewed as a linear-in-parameter representation of the robot dynamics, with the nonlinear basis of the robot dynamics connected to the linear output layer. The output layer weights are updated based on the tracking error and the nonlinear basis. The internal weights of the nonlinear basis are updated by online backpropagation to further reduce the tracking error. To use time scale separation to reduce the coupling of the two steps - the update of the internal weights is at a lower rate compared to the update of the output layer weights. With the update of the output layer weights, our controller adapts quickly to the unknown dynamics change and disturbances (such as attaching a load). The update of the internal weights would continue to improve the converge of the nonlinear basis functions. We show the stability of the proposed scheme under the "outer loop" control, where the commanded joint position is considered as the control input. Simulation and physical experiments are conducted to demonstrate the performance of the proposed controller on a Baxter robot, which exhibits significant joint flexibility due to the series-elastic joint actuators.
keywords: {Artificial neural networks;Trajectory;Manipulator dynamics;Aerodynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197051&isnumber=9196508

F. Lin, C. Fu, Y. He, F. Guo and Q. Tang, "BiCF: Learning Bidirectional Incongruity-Aware Correlation Filter for Efficient UAV Object Tracking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2365-2371.
doi: 10.1109/ICRA40945.2020.9196530
Abstract: Correlation filters (CFs) have shown excellent performance in unmanned aerial vehicle (UAV) tracking scenarios due to their high computational efficiency. During the UAV tracking process, viewpoint variations are usually accompanied by changes in the object and background appearance, which poses a unique challenge to CF-based trackers. Since the appearance is gradually changing over time, an ideal tracker can not only forward predict the object position but also backtrack to locate its position in the previous frame. There exist response-based errors in the reversibility of the tracking process containing the information on the changes in appearance. However, some existing methods do not consider the forward and backward errors based on while using only the current training sample to learn the filter. For other ones, the applicants of considerable historical training samples impose a computational burden on the UAV. In this work, a novel bidirectional incongruity-aware correlation filter (BiCF) is proposed. By integrating the response-based bidirectional incongruity error into the CF, BiCF can Efficiently learn the changes in appearance and suppress the inconsistent error. Extensive experiments on 243 challenging sequences from three UAV datasets (UAV123, UAVDT, and DTB70) are conducted to demonstrate that BiCF favorably outperforms other 25 state-of-the-art trackers and achieves a real-time speed of 45.4 FPS on a single CPU, which can be applied in UAV Efficiently.
keywords: {Unmanned aerial vehicles;Training;Target tracking;Correlation;Robustness;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196530&isnumber=9196508

C. -Y. Chai, W. -H. Peng and S. -L. Tsao, "Adaptive Unknown Object Rearrangement Using Low-Cost Tabletop Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2372-2378.
doi: 10.1109/ICRA40945.2020.9197356
Abstract: Studies on object rearrangement planning typically consider known objects. Some learning-based methods can predict the movement of an unknown object after single-step interaction, but require intermediate targets, which are generated manually, to achieve the rearrangement task. In this work, we propose a framework for unknown object rearrangement. Our system first models an object through a small-amount of identification actions and adjust the model parameters during task execution. We implement the proposed framework based on a low-cost tabletop robot (under 180 USD) to demonstrate the advantages of using a physics engine to assist action prediction. Experimental results reveal that after running our adaptive learning procedure, the robot can successfully arrange a novel object using an average of five discrete pushes on our tabletop environment and satisfy a precise 3.5 cm translation and 5¬∞ rotation criterion.
keywords: {Physics;Engines;Task analysis;Optimization;Robots;Adaptation models;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197356&isnumber=9196508

G. Paolo, A. Laflaqui√®re, A. Coninx and S. Doncieux, "Unsupervised Learning and Exploration of Reachable Outcome Space," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2379-2385.
doi: 10.1109/ICRA40945.2020.9196819
Abstract: Performing Reinforcement Learning in sparse rewards settings, with very little prior knowledge, is a challenging problem since there is no signal to properly guide the learning process. In such situations, a good search strategy is fundamental. At the same time, not having to adapt the algorithm to every single problem is very desirable. Here we introduce TAXONS, a Task Agnostic eXploration of Outcome spaces through Novelty and Surprise algorithm. Based on a population-based divergent-search approach, it learns a set of diverse policies directly from high-dimensional observations, without any task-specific information. TAXONS builds a repertoire of policies while training an autoencoder on the high-dimensional observation of the final state of the system to build a low-dimensional outcome space. The learned outcome space, combined with the reconstruction error, is used to drive the search for new policies. Results show that TAXONS can find a diverse set of controllers, covering a good part of the ground-truth outcome space, while having no information about such space.
keywords: {Task analysis;Robots;Training;Space exploration;Aerospace electronics;Extraterrestrial measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196819&isnumber=9196508

C. D. McKinnon and A. P. Schoellig, "Context-aware Cost Shaping to Reduce the Impact of Model Error in Receding Horizon Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2386-2392.
doi: 10.1109/ICRA40945.2020.9197521
Abstract: This paper presents a method to enable a robot using stochastic Model Predictive Control (MPC) to achieve high performance on a repetitive path-following task. In particular, we consider the case where the accuracy of the model for robot dynamics varies significantly over the path-motivated by the fact that the models used in MPC must be computationally efficient, which limits their expressive power. Our approach is based on correcting the cost predicted using a simple learned dynamics model over the MPC horizon. This discourages the controller from taking actions that lead to higher cost than would have been predicted using the dynamics model. In addition, stochastic MPC provides a quantitative measure of safety by limiting the probability of violating state and input constraints over the prediction horizon. Our approach is unique in that it combines both online model learning and cost learning over the prediction horizon and is geared towards operating a robot in changing conditions. We demonstrate our algorithm in simulation and experiment on a ground robot that uses a stereo camera for localization.
keywords: {Robots;Computational modeling;Predictive models;Aerodynamics;Cost function;Task analysis;Stochastic processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197521&isnumber=9196508

Y. Zhang, L. Zhao and S. Huang, "Aortic 3D Deformation Reconstruction using 2D X-ray Fluoroscopy and 3D Pre-operative Data for Endovascular Interventions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2393-2399.
doi: 10.1109/ICRA40945.2020.9197410
Abstract: Current clinical endovascular interventions rely on 2D guidance for catheter manipulation. Although an aortic 3D surface is available from the pre-operative CT/MRI imaging, it cannot be used directly as a 3D intra-operative guidance since the vessel will deform during the procedure. This paper aims to reconstruct the live 3D aortic deformation by fusing the static 3D model from the pre-operative data and the 2D live imaging from fluoroscopy. In contrast to some existing deformation reconstruction frameworks which require 3D observations such as RGB-D or stereo images, fluoroscopy only presents 2D information. In the proposed framework, a 2D-3D registration is performed and the reconstruction process is formulated as a non-linear optimization problem based on the deformation graph approach. Detailed simulations and phantom experiments are conducted and the result demonstrates the reconstruction accuracy and robustness, as well as the potential clinical value of this framework.
keywords: {Three-dimensional displays;Strain;Solid modeling;Image reconstruction;X-ray imaging;Two dimensional displays;Deformable models;aortic deformation reconstruction;fluoroscopy;endovascular interventions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197410&isnumber=9196508

Y. Chen, H. Yang, X. Liu and K. Xu, "Design and Kinematic Modeling of a Novel Steerable Needle for Image-Guided Insertion," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2400-2406.
doi: 10.1109/ICRA40945.2020.9196960
Abstract: Needle-based procedures, such as biopsy and percutaneous tumor ablation, highly depend on the accuracy of needle placement. The accuracy is significantly affected by the needle-tissue interaction no matter what needles (straight or steerable) are used. Due to the unknown tissue mechanics, it is challenging to achieve high accuracy in practice. This paper hence proposes a needle design with an articulated tip for increased steerability and improved needle path consistency. Due to the passive needle tip articulation, tissue mechanics always plays a dominant role such that the needle creates similar paths with approximately piece-wise constant curvature in different tissues. Kinematics model for the proposed needle is presented. The algorithms of path planning and needle tip pose estimation under external imaging modality are developed. Experimental verifications were conducted to demonstrate the needle's steerability as well as the target-reaching capability with obstacles avoidance.
keywords: {Needles;Kinematics;Fasteners;Path planning;Shape;Electron tubes;Laser beam cutting},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196960&isnumber=9196508

P. Baksic, H. Courtecuisse, C. Duriez and B. Bayle, "Robotic needle insertion in moving soft tissues using constraint-based inverse Finite Element simulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2407-2413.
doi: 10.1109/ICRA40945.2020.9197515
Abstract: This paper introduces a method for robotic steering of a flexible needle inside moving and deformable tissues. The method relies on a set of objective functions allowing to automatically steer the needle along a predefined path. In order to follow the desired trajectory, an inverse problem linking the motion of the robot end effector with the objective functions is solved using a Finite Element simulation. The main contribution of the article is the new constraint-based formulation of the objective functions allowing to: 1) significantly reduce the computation time; 2) increase the accuracy and stability of the simulation-guided needle insertion. The method is illustrated, and its performances are characterized in a realistic framework, using a direct simulation of the respiratory motion generated from in vivo data of a pig. Despite the highly non-linear behavior of the numerical simulation and the significant deformations occurring during the insertion, the obtained performances enable the possibility to follow the trajectory with the desired accuracy for medical purpose.
keywords: {Needles;Robots;Mathematical model;Linear programming;Computational modeling;Numerical models;Inverse problems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197515&isnumber=9196508

W. Chi et al., "Collaborative Robot-Assisted Endovascular Catheterization with Generative Adversarial Imitation Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2414-2420.
doi: 10.1109/ICRA40945.2020.9196912
Abstract: Master-slave systems for endovascular catheterization have brought major clinical benefits including reduced radiation doses to the operators, improved precision and stability of the instruments, as well as reduced procedural duration. Emerging deep reinforcement learning (RL) technologies could potentially automate more complex endovascular tasks with enhanced success rates, more consistent motion and reduced fatigue and cognitive workload of the operators. However, the complexity of the pulsatile flows within the vasculature and non-linear behavior of the instruments hinder the use of model-based approaches for RL. This paper describes model-free generative adversarial imitation learning to automate a standard arterial catherization task. The automation policies have been trained in a pre-clinical setting. Detailed validation results show high success rates after skill transfer to a different vascular anatomical model. The quality of the catheter motions also shows less mean and maximum contact forces compared to manual-based approaches.
keywords: {Catheters;Robots;Task analysis;Training;Catheterization;Instruments;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196912&isnumber=9196508

A. Segato, L. Sestini, A. Castellano and E. De Momi, "GA3C Reinforcement Learning for Surgical Steerable Catheter Path Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2429-2435.
doi: 10.1109/ICRA40945.2020.9196954
Abstract: Path planning algorithms for steerable catheters, must guarantee anatomical obstacles avoidance, reduce the insertion length and ensure the compliance with needle kinematics. The majority of the solutions in literature focuses on graph based or sampling based methods, both limited by the impossibility to directly obtain smooth trajectories. In this work we formulate the path planning problem as a reinforcement learning problem and show that the trajectory planning model, generated from the training, can provide the user with optimal trajectories in terms of obstacle clearance and kinematic constraints. We obtain 2D and 3D environments from MRI images processing and we implement a GA3C algorithm to create a path planning model, able to generalize on different patients anatomies. The curvilinear trajectories obtained from the model in 2D and 3D environments are compared to the ones obtained by A* and RRT* algorithms. Our method achieves state-of-the-art performances in terms of obstacle avoidance, trajectory smoothness and computational time proving this algorithm as valid planning method for complex environments.
keywords: {Trajectory;Needles;Three-dimensional displays;Learning (artificial intelligence);Catheters;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196954&isnumber=9196508

O. Villarreal, V. Barasuol, P. M. Wensing, D. G. Caldwell and C. Semini, "MPC-based Controller with Terrain Insight for Dynamic Legged Locomotion," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2436-2442.
doi: 10.1109/ICRA40945.2020.9197312
Abstract: We present a novel control strategy for dynamic legged locomotion in complex scenarios that considers information about the morphology of the terrain in contexts when only on-board mapping and computation are available. The strategy is built on top of two main elements: first a contact sequence task that provides safe foothold locations based on a convolutional neural network to perform fast and continuous evaluation of the terrain in search of safe foothold locations; then a model predictive controller that considers the foothold locations given by the contact sequence task to optimize target ground reaction forces. We assess the performance of our strategy through simulations of the hydraulically actuated quadruped robot HyQReal traversing rough terrain under realistic on-board sensing and computing conditions.
keywords: {Legged locomotion;Trajectory;Task analysis;Computational modeling;Dynamics;Foot},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197312&isnumber=9196508

P. Chand, S. Veer and I. Poulakakis, "An Adaptive Supervisory Control Approach to Dynamic Locomotion Under Parametric Uncertainty," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2443-2449.
doi: 10.1109/ICRA40945.2020.9197120
Abstract: This paper presents an adaptive control scheme for robotic systems that operate in the face of-potentially large-structured uncertainty. The proposed adaptive controller employs an on-line supervisor that utilizes logic-based switching among a finite set of controllers to identify uncertain parameters, and adapt the behavior of the system based on a current estimate of their value. To achieve this, the adaptive control approach in this paper combines on-line parameter estimation and feedback control while avoiding some of the inherent difficulties of classical adaptive control strategies. Furthermore, the proposed supervisory control architecture is modular as it relies on established "off-the-shelf" feedback control law and estimator design approaches, instead of cus-tomizing the overall design to the specific requirements of an adaptive control algorithm. We demonstrate the efficacy of the method on the problem of a dynamically-walking bipedal robot delivering a payload of unknown mass, and show that, by switching to the controller that is the "best" according to a current estimate of the uncertainty, the system maintains a low energy cost during its operation.
keywords: {Switches;Uncertainty;Robots;Supervisory control;Adaptive control;Libraries},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197120&isnumber=9196508

O. Sim et al., "Joint Space Position/Torque Hybrid Control of the Quadruped Robot for Locomotion and Push Reaction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2450-2456.
doi: 10.1109/ICRA40945.2020.9197230
Abstract: This paper proposes a novel algorithm for joint space position/torque hybrid control of a mammal-type quadruped robot. With this control algorithm, the robot demonstrated both dynamic locomotion and push reaction abilities without the need for torque control in the ab/ad joints. Based on the tipping and slipping condition of the legged robot, we showed that reaction to a typical push in the horizontal direction does not require full contact-force-control in the frontal plane. Furthermore, we showed that position/torque hybrid control in Cartesian space is directly applicable to joint space hybrid control due to the joint configuration of the quadruped robot. We conducted experiments on our legged robot platform to verify the performance of our hybrid control algorithm. With this approach, the robot displayed stability while walking and reacting to external push disturbances.
keywords: {Force;Aerospace electronics;Legged locomotion;Torque;Robot kinematics;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197230&isnumber=9196508

E. Ambrose and A. D. Ames, "Improved Performance on Moving-Mass Hopping Robots with Parallel Elasticity," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2457-2463.
doi: 10.1109/ICRA40945.2020.9197070
Abstract: Robotic Hopping is challenging from the perspective of both modeling the dynamics as well as the mechanical design due to the short period of ground contact in which to actuate on the world. Previous work has demonstrated stable hopping on a moving-mass robot, wherein a single spring was utilized below the body of the robot. This paper finds that the addition of a spring in parallel to the actuator greatly improves the performance of moving mass hopping robots. This is demonstrated through the design of a novel one-dimensional hopping robot. For this robot, a rigorous trajectory optimization method is developed using hybrid systems models with experimentally tuned parameters. Simulation results are used to study the effects of a parallel spring on energetic efficiency, stability, and hopping effort. We find that the double-spring model had 2.5x better energy efficiency than the single-spring model, and was able to hop using 40% less peak force from the actuator. Furthermore, the double-spring model produces stable hopping without the need for stabilizing controllers. These concepts are demonstrated experimentally on a novel hopping robot, wherein hop heights up to 40cm were achieved with comparable efficiency and stability.
keywords: {Springs;Actuators;Force;Robot kinematics;Dynamics;Jacobian matrices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197070&isnumber=9196508

D. Kim et al., "Vision Aided Dynamic Exploration of Unstructured Terrain with a Small-Scale Quadruped Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2464-2470.
doi: 10.1109/ICRA40945.2020.9196777
Abstract: Legged robots have been highlighted as promising mobile platforms for disaster response and rescue scenarios because of their rough terrain locomotion capability. In cluttered environments, small robots are desirable as they can maneuver through small gaps, narrow paths, or tunnels. However small robots have their own set of difficulties such as limited space for sensors, limited obstacle clearance, and scaled-down walking speed. In this paper, we extensively address these difficulties via effective sensor integration and exploitation of dynamic locomotion and jumping. We integrate two Intel RealSense sensors into the MIT Mini-Cheetah, a 0.3 m tall, 9 kg quadruped robot. Simple and effective filtering and evaluation algorithms are used for foothold adjustment and obstacle avoidance. We showcase the exploration of highly irregular terrain using dynamic trotting and jumping with the small-scale, fully sensorized Mini-Cheetah quadruped robot.
keywords: {Cameras;Robot vision systems;Robot kinematics;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196777&isnumber=9196508

L. Zhou, V. Tzoumas, G. J. Pappas and P. Tokekar, "Distributed Attack-Robust Submodular Maximization for Multi-Robot Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2479-2485.
doi: 10.1109/ICRA40945.2020.9197243
Abstract: We aim to guard swarm-robotics applications against denial-of-service (DoS) attacks that result in withdrawals of robots. We focus on applications requiring the selection of actions for each robot, among a set of available ones, e.g., which trajectory to follow. Such applications are central in large-scale robotic applications, e.g., multi-robot motion planning for target tracking. But the current attack-robust algorithms are centralized, and scale quadratically with the problem size (e.g., number of robots). In this paper, we propose a general-purpose distributed algorithm towards robust optimization at scale, with local communications only. We name it distributed robust maximization (DRM). DRM proposes a divide-and-conquer approach that distributively partitions the problem among K cliques of robots. The cliques optimize in parallel, independently of each other. That way, DRM also offers computational speed-ups up to 1/K2 the running time of its centralized counterparts. K depends on the robots' communication range, which is given as input to DRM. DRM also achieves a close-to-optimal performance. We demonstrate DRM's performance in Gazebo and MATLAB simulations, in scenarios of active target tracking with multiple robots. We observe DRM achieves significant computational speed-ups (it is 3 to 4 orders faster) and, yet, nearly matches the tracking performance of its centralized counterparts.
keywords: {Planning;Target tracking;Robot kinematics;Partitioning algorithms;Robot sensing systems;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197243&isnumber=9196508

C. D. Alvarenga, N. Basilico and S. Carpin, "Multirobot Patrolling Against Adaptive Opponents with Limited Information," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2486-2492.
doi: 10.1109/ICRA40945.2020.9197287
Abstract: We study a patrolling problem where multiple agents are tasked with protecting an environment where one or more adversaries are trying to compromise targets of varying value. The objective of the patrollers is to move between targets to quickly spot when an attack is taking place and then diffuse it. Differently from most related literature, we do not assume that attackers have full knowledge of the strategies followed by the patrollers, but rather build a model at run time through repeated observations of how often they visit certain targets. We study three different solutions to this problem. The first two partition the environment using either a fast heuristic or an exact method that is significantly more time consuming. The third method, instead does not partition the environment, but rather lets every patroller roam over the entire environment. After having identified strengths and weaknesses of each method, we contrast their performances against attackers using different algorithms to decide whether to attack or not.
keywords: {Robot kinematics;Task analysis;Delays;Optimization;Games},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197287&isnumber=9196508

S. Moon and E. W. Frew, "Distributed Optimization of Nonlinear, Non-Gaussian, Communication-Aware Information using Particle Methods," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2493-2499.
doi: 10.1109/ICRA40945.2020.9197404
Abstract: This paper presents a distributed optimization framework and its local utility design for communication-aware information gathering by mobile robotic sensor networks. The main idea of the optimization is that each robot decides based on its local utility that considers the decisions of other neighbor robots higher in a given hierarchy. The local utility is designed as conditional mutual information that captures sensing and communication properties. Sampling procedures using a specific measurement set and particle methods are applied to compute the designed utility, which allows nonlinear, non-Gaussian properties of targets, sensing, and communication. Simulation results describe the presented distributed optimization shows more improved estimates and entropy reduction than another approach that does not consider communication properties. Simulation results also verify the presented distributed optimization using the described approach for information computation has better results than using other approaches that simplify the communication-aware information.
keywords: {Robot sensing systems;Optimization;Mutual information;Planning;Atmospheric measurements;Particle measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197404&isnumber=9196508

A. T. Becker et al., "Targeted Drug Delivery: Algorithmic Methods for Collecting a Swarm of Particles with Uniform, External Forces," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2508-2514.
doi: 10.1109/ICRA40945.2020.9196551
Abstract: We investigate algorithmic approaches for targeted drug delivery in a complex, maze-like environment, such as a vascular system. The basic scenario is given by a large swarm of micro-scale particles ("agents") and a particular target region ("tumor") within a system of passageways. Agents are too small to contain on-board power or computation and are instead controlled by a global external force that acts uniformly on all particles, such as an applied fluidic flow or electromagnetic field. The challenge is to deliver all agents to the target region with a minimum number of actuation steps. We provide a number of results for this challenge. We show that the underlying problem is NP-hard, which explains why previous work did not provide provably efficient algorithms. We also develop a number of algorithmic approaches that greatly improve the worst-case guarantees for the number of required actuation steps. We evaluate our algorithmic approaches by a number of simulations, both for deterministic algorithms and searches supported by deep learning, which show that the performance is practically promising.
keywords: {Magnetic resonance imaging;Robots;Tumors;Force;Blood;Electromagnetics;Machine learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196551&isnumber=9196508

G. Tang, W. Sun and K. Hauser, "Enhancing Bilevel Optimization for UAV Time-Optimal Trajectory using a Duality Gap Approach," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2515-2521.
doi: 10.1109/ICRA40945.2020.9196789
Abstract: Time-optimal trajectories for dynamic robotic vehicles are difficult to compute even for state-of-the-art nonlinear programming (NLP) solvers, due to nonlinearity and bang-bang control structure. This paper presents a bilevel optimization framework that addresses these problems by decomposing the spatial and temporal variables into a hierarchical optimization. Specifically, the original problem is divided into an inner layer, which computes a time-optimal velocity profile along a given geometric path, and an outer layer, which refines the geometric path by a Quasi-Newton method. The inner optimization is convex and efficiently solved by interior-point methods. The gradients of the outer layer can be analytically obtained using sensitivity analysis of parametric optimization problems. A novel contribution is to introduce a duality gap in the inner optimization rather than solving it to optimality; this lets the optimizer realize warm-starting of the interior-point method, avoids non-smoothness of the outer cost function caused by active inequality constraint switching. Like prior bilevel frameworks, this method is guaranteed to return a feasible solution at any time, but converges faster than gap-free bilevel optimization. Numerical experiments on a drone model with velocity and acceleration limits show that the proposed method performs faster and more robustly than gap-free bilevel optimization and general NLP solvers.
keywords: {Trajectory;Cost function;Switches;Acceleration;Robustness;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196789&isnumber=9196508

G. I. Boutselis, Z. Wang and E. A. Theodorou, "Constrained Sampling-based Trajectory Optimization using Stochastic Approximation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2522-2528.
doi: 10.1109/ICRA40945.2020.9197284
Abstract: We propose a sampling-based trajectory optimization methodology for constrained problems. We extend recent works on stochastic search to deal with box control constraints, as well as nonlinear state constraints for discrete dynamical systems. Regarding the former, our strategy is to optimize over truncated parameterized distributions on control inputs. Furthermore, we show how non-smooth penalty functions can be incorporated into our framework to handle state constraints. Simulations on cartpole and quadcopter show that our approach outperforms previous methods on constrained sampling-based optimization, in terms of quality of solutions and convergence speed.
keywords: {Heuristic algorithms;Trajectory optimization;Convergence;Approximation algorithms;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197284&isnumber=9196508

C. Zelch, J. Peters and O. von Stryk, "Learning Control Policies from Optimal Trajectories," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2529-2535.
doi: 10.1109/ICRA40945.2020.9196791
Abstract: The ability to optimally control robotic systems offers significant advantages for their performance. While time-dependent optimal trajectories can numerically be computed for high dimensional nonlinear system dynamic models, constraints and objectives, finding optimal feedback control policies for such systems is hard. This is unfortunate, as without a policy, the control of real-world systems requires frequent correction or replanning to compensate for disturbances and model errors.In this paper, a feedback control policy is learned from a set of optimal reference trajectories using Gaussian processes. Information from existing trajectories and the current policy is used to find promising start points for the computation of further optimal trajectories. This aspect is important as it avoids exhaustive sampling of the complete state space, which is impractical due to the high dimensional state space, and to focus on the relevant region.The presented method has been applied in simulation to a swing-up problem of an underactuated pendulum and an energy-minimal point-to-point movement of a 3-DOF industrial robot.
keywords: {Trajectory;Computational modeling;Task analysis;Numerical models;Robots;Feedback control;Optimal control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196791&isnumber=9196508

C. Mastalli et al., "Crocoddyl: An Efficient and Versatile Framework for Multi-Contact Optimal Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2536-2542.
doi: 10.1109/ICRA40945.2020.9196673
Abstract: We introduce Crocoddyl (Contact RObot COntrol by Differential DYnamic Library), an open-source framework tailored for efficient multi-contact optimal control. Crocoddyl efficiently computes the state trajectory and the control policy for a given predefined sequence of contacts. Its efficiency is due to the use of sparse analytical derivatives, exploitation of the problem structure, and data sharing. It employs differential geometry to properly describe the state of any geometrical system, e.g. floating-base systems. Additionally, we propose a novel optimal control algorithm called Feasibility-driven Differential Dynamic Programming (FDDP). Our method does not add extra decision variables which often increases the computation time per iteration due to factorization. FDDP shows a greater globalization strategy compared to classical Differential Dynamic Programming (DDP) algorithms. Concretely, we propose two modifications to the classical DDP algorithm. First, the backward pass accepts infeasible state-control trajectories. Second, the rollout keeps the gaps open during the early "exploratory" iterations (as expected in multipleshooting methods with only equality constraints). We showcase the performance of our framework using different tasks. With our method, we can compute highly-dynamic maneuvers (e.g. jumping, front-flip) within few milliseconds.
keywords: {Optimal control;Trajectory;Optimization;Heuristic algorithms;Dynamic programming;Robots;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196673&isnumber=9196508

J. Zhang, W. Zhang, R. Song, L. Ma and Y. Li, "Grasp for Stacking via Deep Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2543-2549.
doi: 10.1109/ICRA40945.2020.9197508
Abstract: Integrated robotic arm system should contain both grasp and place actions. However, most grasping methods focus more on how to grasp objects, while ignoring the placement of the grasped objects, which limits their applications in various industrial environments. In this research, we propose a model-free deep Q-learning method to learn the grasping-stacking strategy end-to-end from scratch. Our method maps the images to the actions of the robotic arm through two deep networks: the grasping network (GNet) using the observation of the desk and the pile to infer the gripper's position and orientation for grasping, and the stacking network (SNet) using the observation of the platform to infer the optimal location when placing the grasped object. To make a long-range planning, the two observations are integrated in the grasping for stacking network (GSN). We evaluate the proposed GSN on a grasping-stacking task in both simulated and real-world scenarios.
keywords: {Grasping;Stacking;Task analysis;Feature extraction;Manipulators;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197508&isnumber=9196508

W. Liu, A. Daruna and S. Chernova, "CAGE: Context-Aware Grasping Engine," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2550-2556.
doi: 10.1109/ICRA40945.2020.9197289
Abstract: Semantic grasping is the problem of selecting stable grasps that are functionally suitable for specific object manipulation tasks. In order for robots to effectively perform object manipulation, a broad sense of contexts, including object and task constraints, needs to be accounted for. We introduce the Context-Aware Grasping Engine, which combines a novel semantic representation of grasp contexts with a neural network structure based on the Wide & Deep model, capable of capturing complex reasoning patterns. We quantitatively validate our approach against three prior methods on a novel dataset consisting of 14,000 semantic grasps for 44 objects, 7 tasks, and 6 different object states. Our approach outperformed all baselines by statistically significant margins, producing new insights into the importance of balancing memorization and generalization of contexts for semantic grasping. We further demonstrate the effectiveness of our approach on robot experiments in which the presented model successfully achieved 31 of 32 suitable grasps. The code and data are available at: https://github.com/wliu88/railsemanticgrasping.
keywords: {Semantics;Task analysis;Grasping;Feature extraction;Robots;Cognition;Context modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197289&isnumber=9196508

A. Wolff, S. Praisler, I. Tcenov and G. Gilboa, "Super-Pixel Sampler: a Data-driven Approach for Depth Sampling and Reconstruction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2588-2594.
doi: 10.1109/ICRA40945.2020.9197191
Abstract: Depth acquisition, based on active illumination, is essential for autonomous and robotic navigation. LiDARs (Light Detection And Ranging) with mechanical, fixed, sampling templates are commonly used in today's autonomous vehicles. An emerging technology, based on solid-state depth sensors, with no mechanical parts, allows fast and adaptive scans. In this paper, we propose an adaptive, image-driven, fast, sampling and reconstruction strategy. First, we formulate a piece-wise planar depth model and estimate its validity for indoor and outdoor scenes. Our model and experiments predict that, in the optimal case, adaptive sampling strategies with about 20-60 piece-wise planar structures can approximate well a depth map. This translates to requiring a single depth sample for every 1200 RGB samples (less than 0.1%), providing strong motivation to investigate an adaptive framework. Second, we introduce SPS (Super-Pixel Sampler), a simple, generic, sampling and reconstruction algorithm, based on super-pixels. Our sampling improves grid and random sampling, consistently, for a wide variety of reconstruction methods. Third, we propose an extremely simple and fast reconstruction for our sampler. It achieves state-of-the-art results, compared to complex image- guided depth completion algorithms, reducing the required sampling rate by a factor of 3-4. A single-pixel prototype sampler built in our lab illustrates the concept.
keywords: {Image reconstruction;Adaptation models;Estimation;Cameras;Robot sensing systems;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197191&isnumber=9196508

E. Heiden, Z. Liu, R. K. Ramachandran and G. S. Sukhatme, "Physics-based Simulation of Continuous-Wave LIDAR for Localization, Calibration and Tracking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2595-2601.
doi: 10.1109/ICRA40945.2020.9197138
Abstract: Light Detection and Ranging (LIDAR) sensors play an important role in the perception stack of autonomous robots, supplying mapping and localization pipelines with depth measurements of the environment. While their accuracy outperforms other types of depth sensors, such as stereo or time-of-flight cameras, the accurate modeling of LIDAR sensors requires laborious manual calibration that typically does not take into account the interaction of laser light with different surface types, incidence angles and other phenomena that significantly influence measurements. In this work, we introduce a physically plausible model of a 2D continuous-wave LIDAR that accounts for the surface-light interactions and simulates the measurement process in the Hokuyo URG-04LX LIDAR. Through automatic differentiation, we employ gradient-based optimization to estimate model parameters from real sensor measurements.
keywords: {Laser radar;Measurement by laser beam;Mathematical model;Sensor phenomena and characterization;Surface emitting lasers;Laser modes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197138&isnumber=9196508

C. Sui, K. He, Z. Wang, C. Lyu, H. Guo and Y. -H. Liu, "A Spatial-temporal Multiplexing Method for Dense 3D Surface Reconstruction of Moving Objects," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2602-2608.
doi: 10.1109/ICRA40945.2020.9197462
Abstract: Three-dimensional reconstruction of dynamic objects is important for robotic applications, for example, the robotic recognition and manipulation. In this paper, we present a novel 3D surface reconstruction method for moving objects. The proposed method combines the spatial-multiplexing and time-multiplexing structured-light techniques that have advantages of less image acquisition time and accurate 3D reconstruction, respectively. A set of spatial-temporal encoded patterns are designed, where a spatial-encoded texture map is embedded into the temporal-encoded three-step phase-shifting fringes. The specifically designed spatial-coded texture assigns high-uniqueness codeword to any window on the image which helps to eliminate the phase ambiguity. In addition, the texture is robust to noise and image blur. Combining this texture with high-frequency phase-shifting fringes, high reconstruction accuracy would be ensured. This method only requires 3 patterns to uniquely encode a surface, which facilitates the fast image acquisition for each reconstruction step. A filtering stereo matching algorithm is proposed for the spatial-temporal multiplexing method to improve the matching reliability. Moreover, the reconstruction precision is further enhanced by a correspondence refinement algorithm. Experiments validate the performance of the proposed method including the high accuracy, the robustness to noise and the ability to reconstruct moving objects.
keywords: {Image reconstruction;Multiplexing;Three-dimensional displays;Surface reconstruction;Robots;Encoding;Reliability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197462&isnumber=9196508

Y. S. Park, Y. -S. Shin and A. Kim, "PhaRaO: Direct Radar Odometry using Phase Correlation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2617-2623.
doi: 10.1109/ICRA40945.2020.9197231
Abstract: Recent studies in radar-based navigation present promising navigation performance using scanning radars. These scanning radar-based odometry methods are mostly feature-based; they detect and match salient features within a radar image. Differing from existing feature-based methods, this paper reports on a method using direct radar odometry, PhaRaO, which infers relative motion from a pair of radar scans via phase correlation. Specifically, we apply the Fourier Mellin transform (FMT) for Cartesian and log-polar radar images to sequentially estimate rotation and translation. In doing so, we decouple rotation and translation estimations in a coarse-to-fine manner to achieve real-time performance. The proposed method is evaluated using large-scale radar data obtained from various environments. The inferred trajectory yields a 2.34% (translation) and 2.93¬∞ (rotation) Relative Error (RE) over a 4km path length on average for the odometry estimation.
keywords: {Correlation;Radar imaging;Estimation;Image resolution;Feature extraction;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197231&isnumber=9196508

A. Dewan and W. Burgard, "DeepTemporalSeg: Temporally Consistent Semantic Segmentation of 3D LiDAR Scans," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2624-2630.
doi: 10.1109/ICRA40945.2020.9197193
Abstract: Understanding the semantic characteristics of the environment is a key enabler for autonomous robot operation. In this paper, we propose a deep convolutional neural network (DCNN) for semantic segmentation of a LiDAR scan into the classes car, pedestrian and bicyclist. This architecture is based on dense blocks and efficiently utilizes depth separable convolutions to limit the number of parameters while still maintaining the state-of-the-art performance. To make the predictions from the DCNN temporally consistent, we propose a Bayes filter based method. This method uses the predictions from the neural network to recursively estimate the current semantic state of a point in a scan. This recursive estimation uses the knowledge gained from previous scans, thereby making the predictions temporally consistent and robust towards isolated erroneous predictions. We compare the performance of our proposed architecture with other state-of-the-art neural network architectures and report substantial improvement. For the proposed Bayes filter approach, we shows results on various sequences in the KITTI tracking benchmark.
keywords: {Semantics;Laser radar;Image segmentation;Task analysis;Three-dimensional displays;Neural networks;Automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197193&isnumber=9196508

S. Cruciani, D. Almeida, D. Kragic and Y. Karayiannidis, "Discrete Bimanual Manipulation for Wrench Balancing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2631-2637.
doi: 10.1109/ICRA40945.2020.9196527
Abstract: Dual-arm robots can overcome grasping force and payload limitations of a single arm by jointly grasping an object. However, if the distribution of mass of the grasped object is not even, each arm will experience different wrenches that can exceed its payload limits. In this work, we consider the problem of balancing the wrenches experienced by a dual-arm robot grasping a rigid tray. The distribution of wrenches among the robot arms changes due to objects being placed on the tray. We present an approach to reduce the wrench imbalance among arms through discrete bimanual manipulation. Our approach is based on sequential sliding motions of the grasp points on the surface of the object, to attain a more balanced configuration. We validate our modeling approach and system design through a set of robot experiments.
keywords: {Manipulators;Force;Grippers;Planning;Grasping;Payloads},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196527&isnumber=9196508

B. Ward-Cherrier, N. Pestell and N. F. Lepora, "NeuroTac: A Neuromorphic Optical Tactile Sensor applied to Texture Recognition," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2654-2660.
doi: 10.1109/ICRA40945.2020.9197046
Abstract: Developing artificial tactile sensing capabilities that rival human touch is a long-term goal in robotics and prosthetics. Gradually more elaborate biomimetic tactile sensors are being developed and applied to grasping and manipulation tasks to help achieve this goal. Here we present the neuroTac, a novel neuromorphic optical tactile sensor. The neuroTac combines the biomimetic hardware design from the TacTip sensor which mimicks the layered papillae structure of human glabrous skin, with an event-based camera (DAVIS240, iniVation) and algorithms which transduce contact information in the form of spike trains. The performance of the sensor is evaluated on a texture classification task, with four spike coding methods being implemented and compared: Intensive, Spatial, Temporal and Spatiotemporal. We found timing-based coding methods performed with the highest accuracy over both artificial and natural textures. The spike-based output of the neuroTac could enable the development of biomimetic tactile perception algorithms in robotics as well as non-invasive and invasive haptic feedback methods in prosthetics.
keywords: {Encoding;Neuromorphics;Tactile sensors;Cameras;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197046&isnumber=9196508

H. Mao and J. Xiao, "Reducing Uncertainty in Pose Estimation under Complex Contacts via Force Forecast," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2661-2667.
doi: 10.1109/ICRA40945.2020.9197190
Abstract: How to reduce uncertainty in object pose estimation under complex contacts is crucial to autonomous robotic manipulation and assembly. In this paper, we introduce an approach through forecasting contact force from simulated complex contacts with calibration based on real force sensing. A constraint-based haptic simulation algorithm is used with sphere-tree representation of contacting objects to compute contact poses and forces, and through matching the computed forces to measured real force data via a regression model, the least-uncertain estimate of the relative contact pose is obtained. Our approach can handle multi-region complex contacts and does not make any assumption about contact types or contact locations. It also does not have restriction on object shapes. We have applied the force forecast approach to reducing uncertainty in estimating object poses in challenging peg-in-hole robotic assembly tasks and demonstrate the effectiveness of the approach by successful completion of contact-rich two-pin and three-pin real peg-in-hole assembly tasks with complex shapes of pins and holes.
keywords: {Force;Uncertainty;Robot sensing systems;Task analysis;Calibration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197190&isnumber=9196508

N. Fallahinia and S. A. Mascaro, "Comparison of Constrained and Unconstrained Human Grasp Forces Using Fingernail Imaging and Visual Servoing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2668-2674.
doi: 10.1109/ICRA40945.2020.9196963
Abstract: Fingernail imaging has been proven to be effective in prior works [1], [2] for estimating the 3D fingertip forces with a maximum RMS estimation error of 7%. In the current research, fingernail imaging is used to perform unconstrained grasp force measurement on multiple fingers to study human grasping. Moreover, two robotic arms with mounted cameras and a visual tracking system have been devised to keep the human fingers in the camera frame during the experiments. Experimental tests have been conducted for six human subjects under both constrained and unconstrained grasping conditions, and the results indicate a significant difference in force collaboration among the fingers between the two grasping conditions. Another interesting result according to the experiments is that in comparison to constrained grasping, unconstrained grasp forces are more evenly distributed over the fingers and there is less force variation (more steadiness) in each finger force. These results validate the importance of measuring grasp forces in an unconstrained manner in order to study how humans naturally grasp objects.
keywords: {Grasping;Force;Estimation;Cameras;Mathematical model;Force measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196963&isnumber=9196508

H. Li et al., "Robust and Efficient Estimation of Absolute Camera Pose for Monocular Visual Odometry," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2675-2681.
doi: 10.1109/ICRA40945.2020.9196814
Abstract: Given a set of 3D-to-2D point correspondences corrupted by outliers, we aim to robustly estimate the absolute camera pose. Existing methods robust to outliers either fail to guarantee high robustness and efficiency simultaneously, or require an appropriate initial pose and thus lack generality. In contrast, we propose a novel approach based on the robust "L2-minimizing estimate" (L2E) loss. We first define a novel cost function by integrating the projection constraint into the L2E loss. Then to efficiently obtain the global minimum of this function, we propose a hybrid strategy of a local optimizer and branch-and-bound. For branch-and-bound, we derive effective function bounds. Our approach can handle high outlier ratios, leading to high robustness. It can run reliably regardless of whether the initial pose is appropriate, providing high generality. Moreover, given a decent initial pose, it is suitable for real-time applications. Experiments on synthetic and real-world datasets showed that our approach outperforms state-of-the-art methods in terms of robustness and/or efficiency.
keywords: {Robustness;Pose estimation;Cameras;Cost function;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196814&isnumber=9196508

J. Lin, H. Zhu and J. Alonso-Mora, "Robust Vision-based Obstacle Avoidance for Micro Aerial Vehicles in Dynamic Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2682-2688.
doi: 10.1109/ICRA40945.2020.9197481
Abstract: In this paper, we present an on-board vision-based approach for avoidance of moving obstacles in dynamic environments. Our approach relies on an efficient obstacle detection and tracking algorithm based on depth image pairs, which provides the estimated position, velocity and size of the obstacles. Robust collision avoidance is achieved by formulating a chance-constrained model predictive controller (CC-MPC) to ensure that the collision probability between the micro aerial vehicle (MAV) and each moving obstacle is below a specified threshold. The method takes into account MAV dynamics, state estimation and obstacle sensing uncertainties. The proposed approach is implemented on a quadrotor equipped with a stereo camera and is tested in a variety of environments, showing effective on-line collision avoidance of moving obstacles.
keywords: {Collision avoidance;Uncertainty;Cameras;Robustness;Sensors;Predictive models;State estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197481&isnumber=9196508

J. Chen, Y. Liu, S. J. Carey and P. Dudek, "Proximity Estimation Using Vision Features Computed On Sensor," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2689-2695.
doi: 10.1109/ICRA40945.2020.9197370
Abstract: This paper presents a monocular vision based proximity estimation system using abstract features, such as corner points, blobs and edges, as inputs to a neural network. An experimental vehicle was built using a vision system integrating the SCAMP-5 vision chip, a micro-controller, and an RC model car. The vision chip includes image sensor with embedded 256√ó256 processor SIMD array. The pixel processor array chip was programmed to capture images and run the feature algorithms directly on the focal plane, and then digest them so that only sparse feature description data were read-out in the form of 40 values. By logging the vision output and the output from three infrared proximity sensors, training data were obtained to train three fully connected layer-recurrent neural networks with fewer than 700 parameters each. The trained neural network was able to estimate the proximity to the level of accuracy sufficient for a reactive collision avoidance behaviour to be achieved. The latency of the control system, from image capture to neural network output, was under 4ms, enabling the vehicles to avoid obstacles while moving at 0.64m/s to 1.8m/s in the experiment.
keywords: {Hardware;Estimation;Neural networks;Machine vision;Feature extraction;Registers;Image edge detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197370&isnumber=9196508

L. Gao, J. Su, J. Cui, X. Zeng, X. Peng and L. Kneip, "Efficient Globally-Optimal Correspondence-Less Visual Odometry for Planar Ground Vehicles," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2696-2702.
doi: 10.1109/ICRA40945.2020.9196595
Abstract: The motion of planar ground vehicles is often non-holonomic, and as a result may be modelled by the 2 DoF Ackermann steering model. We analyse the feasibility of estimating such motion with a downward facing camera that exerts fronto-parallel motion with respect to the ground plane. This turns the motion estimation into a simple image registration problem in which we only have to identify a 2-parameter planar homography. However, one difficulty that arises from this setup is that ground-plane features are indistinctive and thus hard to match between successive views. We encountered this difficulty by introducing the first globally-optimal, correspondence-less solution to plane-based Ackermann motion estimation. The solution relies on the branch-and-bound optimisation technique. Through the low-dimensional parametrisation, a derivation of tight bounds, and an efficient implementation, we demonstrate how this technique is eventually amenable to accurate real-time motion estimation. We prove its property of global optimality and analyse the impact of assuming a locally constant centre of rotation. Our results on real data finally demonstrate a significant advantage over the more traditional, correspondence-based hypothesise-and-test schemes.
keywords: {Cameras;Optimization;Transmission line matrix methods;Land vehicles;Motion estimation;Image registration;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196595&isnumber=9196508

J. S. Smith, R. Xu and P. Vela, "egoTEB: Egocentric, Perception Space Navigation Using Timed-Elastic-Bands," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2703-2709.
doi: 10.1109/ICRA40945.2020.9196721
Abstract: The TEB hierarchical planner for real-time navigation through unknown environments is highly effective at balancing collision avoidance with goal directed motion. Designed over several years and publications, it implements a multi-trajectory optimization based synthesis method for identifying topologically distinct trajectory candidates through navigable space. Unfortunately, the underlying factor graph approach to the optimization problem induces a mismatch between grid-based representations and the optimization graph, which leads to several time and optimization inefficiencies. This paper explores the impact of using egocentric, perception space representations for the local planning map. Doing so alleviates many of the identified issues related to TEB and leads to a new method called egoTEB. Timing experiments and Monte Carlo evaluations in benchmark worlds quantify the benefits of egoTEB for navigation through uncertain environments.
keywords: {Trajectory;Optimization;Navigation;Planning;Robots;Collision avoidance;Topology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196721&isnumber=9196508

R. Jeong et al., "Self-Supervised Sim-to-Real Adaptation for Visual Robotic Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2718-2724.
doi: 10.1109/ICRA40945.2020.9197326
Abstract: Collecting and automatically obtaining reward signals from real robotic visual data for the purposes of training reinforcement learning algorithms can be quite challenging and time-consuming. Methods for utilizing unlabeled data can have a huge potential to further accelerate robotic learning. We consider here the problem of performing manipulation tasks from pixels. In such tasks, choosing an appropriate state representation is crucial for planning and control. This is even more relevant with real images where noise, occlusions and resolution affect the accuracy and reliability of state estimation. In this work, we learn a latent state representation implicitly with deep reinforcement learning in simulation, and then adapt it to the real domain using unlabeled real robot data. We propose to do so by optimizing sequence-based self- supervised objectives. These use the temporal nature of robot experience, and can be common in both the simulated and real domains, without assuming any alignment of underlying states in simulated and unlabeled real images. We further propose a novel such objective, the Contrastive Forward Dynamics loss, which combines dynamics model learning with time-contrastive techniques. The learned state representation that results from our methods can be used to robustly solve a manipulation task in simulation and to successfully transfer the learned skill on a real system. We demonstrate the effectiveness of our approaches by training a vision-based reinforcement learning agent for cube stacking. Agents trained with our method, using only 5 hours of unlabeled real robot data for adaptation, shows a clear improvement over domain randomization, and standard visual domain adaptation techniques for sim-to-real transfer.
keywords: {Robots;Task analysis;Adaptation models;Visualization;Stacking;Data models;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197326&isnumber=9196508

K. Arndt, M. Hazara, A. Ghadirzadeh and V. Kyrki, "Meta Reinforcement Learning for Sim-to-real Domain Adaptation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2725-2731.
doi: 10.1109/ICRA40945.2020.9196540
Abstract: Modern reinforcement learning methods suffer from low sample efficiency and unsafe exploration, making it infeasible to train robotic policies entirely on real hardware. In this work, we propose to address the problem of sim-to-real domain transfer by using meta learning to train a policy that can adapt to a variety of dynamic conditions, and using a task-specific trajectory generation model to provide an action space that facilitates quick exploration. We evaluate the method by performing domain adaptation in simulation and analyzing the structure of the latent space during adaptation. We then deploy this policy on a KUKA LBR 4+ robot and evaluate its performance on a task of hitting a hockey puck to a target. Our method shows more consistent and stable domain adaptation than the baseline, resulting in better overall performance.
keywords: {Adaptation models;Task analysis;Trajectory;Robots;Training;Learning (artificial intelligence);Heuristic algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196540&isnumber=9196508

M. Hwasser, D. Kragic and R. Antonova, "Variational Auto-Regularized Alignment for Sim-to-Real Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2732-2738.
doi: 10.1109/ICRA40945.2020.9197130
Abstract: General-purpose simulators can be a valuable data source for flexible learning and control approaches. However, training models or control policies in simulation and then directly applying to hardware can yield brittle control. Instead, we propose a novel way to use simulators as regularizers. Our approach regularizes a decoder of a variational autoencoder to a black-box simulation, with the latent space bound to a subset of simulator parameters. This enables successful encoder training from a small number of real-world trajectories (10 in our experiments), yielding a latent space with simulation parameter distribution that matches the real-world setting. We use a learnable mixture for the latent prior/posterior, which implies a highly flexible class of densities for the posterior fit. Our approach is scalable and does not require restrictive distributional assumptions. We demonstrate ability to recover matching parameter distributions on a range of benchmarks, challenging custom simulation environments and several real-world scenarios. Our experiments using ABB YuMi robot hardware show ability to help reinforcement learning approaches overcome cases of severe sim-to-real mismatch.
keywords: {Hardware;Decoding;Computational modeling;Neural networks;Training;Trajectory;Benchmark testing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197130&isnumber=9196508

M. J. Sorocky, S. Zhou and A. P. Schoellig, "Experience Selection Using Dynamics Similarity for Efficient Multi-Source Transfer Learning Between Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2739-2745.
doi: 10.1109/ICRA40945.2020.9196744
Abstract: In the robotics literature, different knowledge transfer approaches have been proposed to leverage the experience from a source task or robot-real or virtual-to accelerate the learning process on a new task or robot. A commonly made but infrequently examined assumption is that incorporating experience from a source task or robot will be beneficial. In practice, inappropriate knowledge transfer can result in negative transfer or unsafe behaviour. In this work, inspired by a system gap metric from robust control theory, the ŒΩ-gap, we present a data-efficient algorithm for estimating the similarity between pairs of robot systems. In a multi-source inter-robot transfer learning setup, we show that this similarity metric allows us to predict relative transfer performance and thus informatively select experiences from a source robot before knowledge transfer. We demonstrate our approach with quadrotor experiments, where we transfer an inverse dynamics model from a real or virtual source quadrotor to enhance the tracking performance of a target quadrotor on arbitrary hand-drawn trajectories. We show that selecting experiences based on the proposed similarity metric effectively facilitates the learning of the target quadrotor, improving performance by 62% compared to a poorly selected experience.
keywords: {Measurement;Task analysis;Heuristic algorithms;Robot sensing systems;Robust control;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196744&isnumber=9196508

B. Balaji et al., "DeepRacer: Autonomous Racing Platform for Experimentation with Sim2Real Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2746-2754.
doi: 10.1109/ICRA40945.2020.9197465
Abstract: DeepRacer is a platform for end-to-end experimentation with RL and can be used to systematically investigate the key challenges in developing intelligent control systems. Using the platform, we demonstrate how a 1/18th scale car can learn to drive autonomously using RL with a monocular camera. It is trained in simulation with no additional tuning in the physical world and demonstrates: 1) formulation and solution of a robust reinforcement learning algorithm, 2) narrowing the reality gap through joint perception and dynamics, 3) distributed on-demand compute architecture for training optimal policies, and 4) a robust evaluation method to identify when to stop training. It is the first successful large-scale deployment of deep reinforcement learning on a robotic control agent that uses only raw camera images as observations and a model-free learning method to perform robust path planning. We open source our code and video demo on GitHub2.
keywords: {Training;Automobiles;Robots;Computational modeling;Cameras;Robustness;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197465&isnumber=9196508

M. Legrand, N. Jarrass√©, F. Richer and G. Morel, "A closed-loop and ergonomic control for prosthetic wrist rotation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2763-2769.
doi: 10.1109/ICRA40945.2020.9197554
Abstract: Beyond the ultimate goal of prosthetics, repairing all the capabilities of amputees, the development line of upper-limb prostheses control mainly relies on three aspects: the robustness, the intuitiveness and the reduction of mental fatigue. Many complex structures and algorithms are proposed but no one question a common open-loop nature, where the user is the one in charge of correcting errors. Yet, closing the control loop at the prosthetic level may help to improve the three main lines of research cited above. One major issue to build a closed-loop control is the definition of a reliable error signal; this paper proposes to use body compensations, naturally exhibited by prostheses users when the motion of their device is inaccurate, as such. The described control scheme measures these compensatory movements and makes the prosthesis move in order to bring back the user into an ergonomic posture. The function of the prosthesis is no longer to perform a given motion but rather to correct the posture of its user while s/he focus on performing an endpoint task. This concept was validated and compared to a standard open-loop scheme, for the control of a prosthetic wrist, with five healthy subjects completing a dedicated task with a customized transradial prosthesis. Results show that the presented closed-loop control allows for more intuitiveness and less mental burden without enhancing body compensation.
keywords: {Prosthetics;Task analysis;Wrist;Ergonomics;Wires;Robots;Muscles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197554&isnumber=9196508

J. Montero, M. Gherardini, F. Clemente and C. Cipriani, "Comparison of online algorithms for the tracking of multiple magnetic targets in a myokinetic control interface," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2770-2776.
doi: 10.1109/ICRA40945.2020.9196804
Abstract: Magnetic tracking algorithms can be used to determine the position and orientation of magnetic markers or devices. These techniques are particularly interesting for biomedical applications such as teleoperated surgical robots or the control of upper limb prostheses. The performance of different algorithms used for magnetic tracking was compared in the past. However, in most cases, those algorithms were required to track a single magnet.Here we investigated the performance of three localization algorithms in tracking up to 9 magnets: two optimization-based (Levenberg-Marquardt algorithm, LMA, and Trust Region Reflective algorithm, TRRA) and one recursion-based (Unscented Kalman Filter, UKF). The tracking accuracy of the algorithms and their computation time were investigated through simulations.The accuracy of the three algorithms, when tracking up to six magnets, was similar, leading to estimation errors varying from 0.06 ¬± 0.02 mm to 2.26 ¬± 0.07 mm within a 100 mm √ó 54 mm √ó 100 mm workspace, at the highest sampling frequency. In all cases, computation times under 300 ms for the UKF and 45 ms for the LMA/TRRA were obtained. The TRRA showed the best tracking performance overall.These outcomes are of interest for a wide range of robotics applications that require remote tracking.
keywords: {Magnetostatics;Magnetic separation;Robots;Magnetic sensors;Magnetic devices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196804&isnumber=9196508

Z. Zhang, H. Liu, Z. Jiao, Y. Zhu and S. -C. Zhu, "Congestion-aware Evacuation Routing using Augmented Reality Devices," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2798-2804.
doi: 10.1109/ICRA40945.2020.9197494
Abstract: We present a congestion-aware routing solution for indoor evacuation, which produces real-time individual-customized evacuation routes among multiple destinations while keeping tracks of all evacuees&#x2019; locations. A population density map, obtained on-the-fly by aggregating locations of evacuees from user-end Augmented Reality (AR) devices, is used to model the congestion distribution inside a building. To efficiently search the evacuation route among all destinations, a variant of A<sup>&#x22C6;</sup> algorithm is devised to obtain the optimal solution in a single pass. In a series of simulated studies, we show that the proposed algorithm is more computationally optimized compared to classic path planning algorithms; it generates a more time-efficient evacuation route for each individual that minimizes the overall congestion. A complete system using AR devices is implemented for a pilot study in real-world environments, demonstrating the efficacy of the proposed approach.
keywords: {Sociology;Statistics;Routing;Real-time systems;Path planning;Robots;Headphones},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197494&isnumber=9196508

M. Ostanin, S. Mikhel, A. Evlampiev, V. Skvortsova and A. Klimchik, "Human-robot interaction for robotic manipulator programming in Mixed Reality," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2805-2811.
doi: 10.1109/ICRA40945.2020.9196965
Abstract: The paper presents an approach for interactive programming of the robotic manipulator using mixed reality. The developed system is based on the HoloLens glasses connected through Robotic Operation System to Unity engine and robotic manipulators. The system gives a possibility to recognize the real robot location by the point cloud analysis, to use virtual markers and menus for the task creation, to generate a trajectory for execution in the simulator or on the real manipulator. It also provides the possibility of scaling virtual and real worlds for more accurate planning. The proposed framework has been tested on pick-and-place and contact operations execution by UR10e and KUKA iiwa robots.
keywords: {Virtual reality;Trajectory;Collision avoidance;Manipulators;Programming;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196965&isnumber=9196508

P. Zhao et al., "Heart Rate Sensing with a Robot Mounted mmWave Radar," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2812-2818.
doi: 10.1109/ICRA40945.2020.9197437
Abstract: Heart rate monitoring at home is a useful metric for assessing health e.g. of the elderly or patients in post-operative recovery. Although non-contact heart rate monitoring has been widely explored, typically using a static, wall-mounted device, measurements are limited to a single room and sensitive to user orientation and position. In this work, we propose mBeats, a robot mounted millimeter wave (mmWave) radar system that provide periodic heart rate measurements under different user poses, without interfering in a users daily activities. mBeats contains a mmWave servoing module that adaptively adjusts the sensor angle to the best reflection pro le. Furthermore, mBeats features a deep neural network predictor, which can estimate heart rate from the lower leg and additionally provides estimation uncertainty. Through extensive experiments, we demonstrate accurate and robust operation of mBeats in a range of scenarios. We believe by integrating mobility and adaptability, mBeats can empower many down-stream healthcare applications at home, such as palliative care, post-operative rehabilitation and telemedicine.
keywords: {Heart rate;Robot sensing systems;Radar;Monitoring;Estimation;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197437&isnumber=9196508

A. Prado, X. Cao, X. Ding and S. K. Agrawal, "Prediction of Gait Cycle Percentage Using Instrumented Shoes with Artificial Neural Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2834-2840.
doi: 10.1109/ICRA40945.2020.9196747
Abstract: Gait training is widely used to treat gait abnormalities. Traditional gait measurement systems are limited to instrumented laboratories. Even though gait measurements can be made in these settings, it is challenging to estimate gait parameters robustly in real-time for gait rehabilitation, especially when walking over-ground. In this paper, we present a novel approach to track the continuous gait cycle during overground walking outside the laboratory. In this approach, we instrument standard footwear with a sensorized insole and an inertial measurement unit. Artificial neural networks are used on the raw data obtained from the insoles and IMUs to compute the continuous percentage of the gait cycle for the entire walking session. We show in this paper that when tested with novel subjects, we can predict the gait cycle with a Root Mean Square Error (RMSE) of 7.2%. The onset of each cycle can be detected within an RMSE time of 41.5 ms with a 99% detection rate. The algorithm was tested with 18840 strides collected from 24 adults. In this paper, we tested a combination of fully-connected layers, an Encoder-Decoder using convolutional layers, and recurrent layers to identify an architecture that provided the best performance.
keywords: {Training;Instruments;Foot;Legged locomotion;Prediction algorithms;Footwear;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196747&isnumber=9196508

J. Shimizu, T. Otani, H. Mizukami, K. Hashimoto and A. Takanishi, "Flow Compensation for Hydraulic Direct-Drive System with a Single-rod Cylinder Applied to Biped Humanoid Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2857-2863.
doi: 10.1109/ICRA40945.2020.9196956
Abstract: Biped robots require massive power on each leg while walking, hopping, and running. We have developed a flow-based control system-called hydraulic direct drive system- that can achieve high output while avoiding spatial limitations. To implement the proposed system with simple equipment configuration, a pump and single-rod cylinder are connected in a closed loop. However, because compensation for flow rate is impossible in a completely closed loop, owing to the difference in the pressure receiving area caused by the rod, a passive flow compensation valve is employed. This valve has a simple structure and is easy to implement. Further, an additional sensor is required to detect the open/close state because the valve state will cause an error in flow control. Therefore, we implemented a model in the controller to predict the state of the flow compensation valve and formulated a method of switching from flow control to pressure control according to the predicted state. Experimental results indicate that the error of the joint angle is reduced to less than 1.6 degrees for walking patterns, and stable walking is realized when the system is installed in biped humanoid robots.
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196956&isnumber=9196508

A. Orlofsky, C. Liu, S. Kamrava, A. Vaziri and S. M. Felton, "Mechanically Programmed Miniature Origami Grippers," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2872-2878.
doi: 10.1109/ICRA40945.2020.9196545
Abstract: This paper presents a robotic gripper design that can perform customizable grasping tasks at the millimeter scale. The design is based on the origami string, a mechanism with a single degree of freedom that can be mechanically programmed to approximate arbitrary paths in space. By using this concept, we create miniature fingers that bend at multiple joints with a single actuator input. The shape and stiffness of these fingers can be varied to fit different grasping tasks by changing the crease pattern of the string. We show that the experimental behavior of these strings follows their analytical models and that they can perform a variety of tasks including pinching, wrapping, and twisting common objects such as pencils, bottle caps, and blueberries.
keywords: {Grippers;Kinematics;Grasping;Actuators;Springs;Steel;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196545&isnumber=9196508

J. Shintake, D. Zappetti, T. Peter, Y. Ikemoto and D. Floreano, "Bio-inspired Tensegrity Fish Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2887-2892.
doi: 10.1109/ICRA40945.2020.9196675
Abstract: This paper presents a method to create fish-like robots with tensegrity systems and describes a prototype modeled on the body shape of the rainbow trout with a length of 400 mm and a mass of 102 g that is driven by a waterproof servomotor. The structure of the tensegrity robot consists of rigid body segments and elastic cables that represent bone/tissue and muscles of fish, respectively. This structural configuration employing the tensegrity class 2 is much simpler than other tensegrity-based underwater robots. It also allows the tuning of the mechanical stiffness, which is often said to be an important factor in fish swimming. In our robot, the body stiffness can be tuned by changing the cross-section of the cables and their pre-stretch ratio. We characterize the robot in terms of body stiffness, swimming speed, and thrust force while varying the body stiffness i.e., the cross-section of the elastic cables. The results show that the body stiffness of the robot can be designed to approximate that of the real fish and modulate its performance characteristics. The measured swimming speed of the robot is 0.23 m/s (0.58 BL/s), which is comparable to other fish robots of the same type. Strouhal number of the robot 0.54 is close to that of the natural counterpart, suggesting that the presented method is an effective engineering approach to realize the swimming characteristics of real fish.
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196675&isnumber=9196508

J. E. S. Soucie, H. M. Sosik and Y. Girdhar, "Gaussian-Dirichlet Random Fields for Inference over High Dimensional Categorical Observations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2924-2931.
doi: 10.1109/ICRA40945.2020.9196713
Abstract: We propose a generative model for the spatio-temporal distribution of high dimensional categorical observations. These are commonly produced by robots equipped with an imaging sensor such as a camera, paired with an image classifier, potentially producing observations over thousands of categories. The proposed approach combines the use of Dirichlet distributions to model sparse co-occurrence relations between the observed categories using a latent variable, and Gaussian processes to model the latent variable's spatio-temporal distribution. Experiments in this paper show that the resulting model is able to efficiently and accurately approximate the temporal distribution of high dimensional categorical measurements such as taxonomic observations of microscopic organisms in the ocean, even in unobserved (held out) locations, far from other samples. This work's primary motivation is to enable deployment of informative path planning techniques over high dimensional categorical fields, which until now have been limited to scalar or low dimensional vector observations.
keywords: {Gaussian processes;Biological system modeling;Spatiotemporal phenomena;Graphical models;Data models;Robots;Oceans},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196713&isnumber=9196508

P. Schorr, F. Schale, J. M. Otterbach, L. Zentner, K. Zimmermann and V. B√∂hm, "Investigation of a Multistable Tensegrity Robot applied as Tilting Locomotion System," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2932-2938.
doi: 10.1109/ICRA40945.2020.9196706
Abstract: This paper describes the development of a tilting locomotion system based on a compliant tensegrity structure with multiple stable equilibrium configurations. A tensegrity structure featuring 4 stable equilibrium states is considered. The mechanical model of the structure is presented and the according equations of motion are derived. The variation of the length of selected structural members allows to influence the prestress state and the corresponding shape of the tensegrity structure. Based on bifurcation analyses a reliable actuation strategy to control the current equilibrium state is designed. In this work, the tensegrity structure is assumed to be in contact with a horizontal plane due to gravity. The derived actuation strategy is utilized to generate tilting locomotion by successively changing the equilibrium state. Numerical simulations are evaluated considering the locomotion characteristics. In order to validate this theoretical approach a prototype is developed. Experiments regarding to the equilibrium configurations, the actuation strategy and the locomotion characteristics are evaluated using image processing tools and motion capturing. The results verify the theoretical data and confirm the working principle of the investigated tilting locomotion system. This approach represents a feasible actuation strategy to realize a reliable tilting locomotion utilizing the multistability of compliant tensegrity structures.
keywords: {Prototypes;Bifurcation;Robots;Mathematical model;Shape;Reliability;Topology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196706&isnumber=9196508

Y. Zhong, R. Du, L. Wu and H. Yu, "A Novel Articulated Soft Robot Capable of Variable Stiffness through Bistable Structure," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2939-2945.
doi: 10.1109/ICRA40945.2020.9197479
Abstract: Soft robot has demonstrated promise in unstructured and dynamic environments due to unique advantages, such as safe interaction, adaptiveness, easy to actuate, and easy fabrication. However, the highly dissipative nature of elastic materials results in small stiffness of soft robot which limits certain functions, such as force transmission, position accuracy, and load capability. In this paper, we present a novel articulated soft robot with variable stiffness. The robot is constructed by rigid joints and compliant bistable structures in series. Each joint can be independently locked through triggering the bistable structure to touch the mechanical constrain. Thus, the bending stiffness of the joint can be magnified which increases the stiffness of the articulated soft robot. Through this construction method, even driven by only one servomotor, the robot demonstrates variable workspace and stiffness which have the potential of dexterous manipulation and maintaining shape under tip load.
keywords: {Soft robotics;Manipulators;Force;Springs;Kinematics;Shape;Articulated Soft Robot;Variable Stiffness;Bistable Structure;Locking Function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197479&isnumber=9196508

H. Wang et al., "Modeling and Experiments on the Swallowing and Disgorging Characteristics of an Underwater Continuum Manipulator," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2946-2952.
doi: 10.1109/ICRA40945.2020.9196780
Abstract: Soft robots apply compliant materials to perform motions and behaviors not typically achievable by rigid robots. An underwater, compliant, multi-segment continuum manipulator that can bend, swallow, disgorge is developed in this study. The manipulator is driven by McKibben water hydraulic artificial muscle (WHAM). The mechanical properties of the WHAM are tested and analyzed experimentally. The kinematics model, which concerns about the variable diameter structure of the soft grippers, are established to simulate the behaviors of the manipulator among the bending, swallowing and disgorging procedure. A mouth-tongue collaborative soft robot assembled with another single-segment soft robot arm is presented. And its functions are experimentally testified. The distinctive functions were verified according to the experimental results.
keywords: {Manipulators;Muscles;Grippers;Kinematics;Hydraulic systems;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196780&isnumber=9196508

Y. Sun et al., "Salamanderbot: A soft-rigid composite continuum mobile robot to traverse complex environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2953-2959.
doi: 10.1109/ICRA40945.2020.9196790
Abstract: Soft robots are theoretically well-suited to rescue and exploration applications where their flexibility allows for the traversal of highly cluttered environments. However, most existing mobile soft robots are not fast or powerful enough to effectively traverse three dimensional environments. In this paper, we introduce a new mobile robot with a continuously deformable slender body structure, the SalamanderBot, which combines the flexibility and maneuverability of soft robots, with the speed and power of traditional mobile robots. It consists of a cable-driven bellows-like origami module based on the Yoshimura crease pattern mounted between sets of powered wheels. The origami structure allows the body to deform as necessary to adapt to complex environments and terrains, while the wheels allow the robot to reach speeds of up to 303.1 mm/s (2.05 body-length/s). Salamanderbot can climb up to 60-degree slopes and perform sharp turns with a minimum turning radius of 79.9 mm (0.54 body-length).
keywords: {Mobile robots;Wheels;Gears;Manipulators;DC motors;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196790&isnumber=9196508

S. Pulleyking and J. Schultz, "Flexure Hinge-based Biomimetic Thumb with a Rolling-Surface Metacarpal Joint," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2960-2966.
doi: 10.1109/ICRA40945.2020.9196578
Abstract: The human thumb's state contribution to grasping and dexterous manipulation of objects is a function of the kinematic multiplicity of joints and structure of the bones, joints, and ligaments. This paper looks at the design and evaluation of a human-like thumb for use in a robotic hand, where the thumb's state contribution to grasping and dexterous manipulation is a function of a simplified kinematic model based on that of the human thumb, but also on empirical trials of surgical techniques to retain functionality while reducing the number of joints in the thumb. Motion Capture Data of the End Effector is analyzed with the measured excursion of the tendons to determine the relationship between tendon velocities and task-space velocities. After validating the procedure experimentally, a simplified metric is proposed to represent this data, and shows that our prototype is predicted to have a relatively smooth mapping between tendon excursion velocity and end effector velocity.
keywords: {Joints;Fasteners;Thumb;Ellipsoids;Robots;Prototypes;Ceramics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196578&isnumber=9196508

S. Raj, R. P. Manu Aatitya, S. Jack Samuel, J. V. Karthik and D. Ezhilarasi, "Ibex: A reconfigurable ground vehicle with adaptive terrain navigation capability," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2975-2980.
doi: 10.1109/ICRA40945.2020.9196571
Abstract: This paper presents a unique unmanned ground vehicle with a dynamic wheelbase and an adaptive thrust based friction optimization scheme that aids in the traversal of steep slopes and slippery surfaces. The vehicle is capable of adapting itself to the surface topography using an impedance-based stabilization module to minimize the mechanical oscillatory transients induced during its motion. A detailed analysis of its modules has been elucidated in this paper based on the vehicle parameters. The proposed methodologies have been integrated and tested on a customized prototype. Experimental validation and simulation for the proposed modules at various terrain conditions have been carried out to authenticate its performance.
keywords: {Force;Wheels;Surface topography;Surface impedance;Land vehicles;Kinematics;Drag},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196571&isnumber=9196508

Y. Yue et al., "Day and Night Collaborative Dynamic Mapping in Unstructured Environment Based on Multimodal Sensors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2981-2987.
doi: 10.1109/ICRA40945.2020.9197072
Abstract: Enabling long-term operation during day and night for collaborative robots requires a comprehensive understanding of the unstructured environment. Besides, in the dynamic environment, robots must be able to recognize dynamic objects and collaboratively build a global map. This paper proposes a novel approach for dynamic collaborative mapping based on multimodal environmental perception. For each mission, robots first apply heterogeneous sensor fusion model to detect humans and separate them to acquire static observations. Then, the collaborative mapping is performed to estimate the relative position between robots and local 3D maps are integrated into a globally consistent 3D map. The experiment is conducted in the day and night rainforest with moving people. The results show the accuracy, robustness, and versatility in 3D map fusion missions.
keywords: {Collaboration;Three-dimensional displays;Simultaneous localization and mapping;Cameras;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197072&isnumber=9196508

T. Hojnik, L. Pond, R. Dungavell, P. Flick and J. Roberts, "Generating Locomotion with Effective Wheel Radius Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2988-2994.
doi: 10.1109/ICRA40945.2020.9196825
Abstract: Travel over sloped terrain is difficult as an incline changes the interaction between each wheel and the ground resulting in an unbalanced load distribution which can lead to loss of traction and instability. This paper presents a novel approach to generating wheel rotation for primary locomotion by only changing its centre of rotation, or as a complimentary locomotion source to increase versatility of a plain centre hub drive. This is done using linear actuators within a wheel to control the position of the centre hub and induce a moment on the wheel from gravity. In doing so our platform allows for active ride height selection and individual wheel pose control. We present the system with calculations outlining the theoretical properties and perform experiments to validate the concept under loading via multiple gaits to show motion on slopes, and sustained motion over extended distance. We envision applications in conjunction to assist current motor drives and increasing slope traversability by allowing body pose and centre of gravity manipulation, or as a primary locomotion system.
keywords: {Wheels;Gravity;Acceleration;Mathematical model;Torque;Axles;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196825&isnumber=9196508

M. Azkarate, L. Gerdes, L. Joudrier and C. J. P√©rez-del-Pulgar, "A GNC Architecture for Planetary Rovers with Autonomous Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3003-3009.
doi: 10.1109/ICRA40945.2020.9197122
Abstract: This paper proposes a Guidance, Navigation, and Control (GNC) architecture for planetary rovers targeting the conditions of upcoming Mars exploration missions such as Mars 2020 and the Sample Fetching Rover (SFR). The navigation requirements of these missions demand a control architecture featuring autonomous capabilities to achieve a fast and long traverse. The proposed solution presents a two-level architecture where the efficient navigation (lower) level is always active and the full navigation (upper) level is enabled according to the difficulty of the terrain. The first level is an efficient implementation of the basic functionalities for autonomous navigation based on hazard detection, local path replanning, and trajectory control with visual odometry. The second level implements an adaptive SLAM algorithm that improves the relative localization, evaluates the traversability of the terrain ahead for a more optimal path planning, and performs global (absolute) localization that corrects the pose drift during longer traverses. The architecture provides a solution for long-range, low supervision, and fast planetary exploration. Both navigation levels have been validated on planetary analog field test campaigns.
keywords: {Hazards;Navigation;Space vehicles;Autonomous robots;Computer architecture;Cameras;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197122&isnumber=9196508

Y. -L. Lee, M. -Y. Tseng, Y. -C. Luo, D. -R. Yu and W. -C. Chiu, "Learning Face Recognition Unsupervisedly by Disentanglement and Self-Augmentation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3018-3024.
doi: 10.1109/ICRA40945.2020.9197348
Abstract: As the growth of smart home, healthcare, and home robot applications, learning a face recognition system which is specific for a particular environment and capable of self-adapting to the temporal changes in appearance (e.g., caused by illumination or camera position) is nowadays an important topic. In this paper, given a video of a group of people, which simulates the surveillance video in a smart home environment, we propose a novel approach which unsuper- visedly learns a face recognition model based on two main components: (1) a triplet network that extracts identity-aware feature from face images for performing face recognition by clustering, and (2) an augmentation network that is conditioned on the identity-aware features and aims at synthesizing more face samples. Particularly, the training data for the triplet network is obtained by using the spatiotemporal characteristic of face samples within a video, while the augmentation network learns to disentangle a face image into identity-aware and identity-irrelevant features thus is able to generate new faces of the same identity but with variance in appearance. With taking the richer training data produced by augmentation network, the triplet network is further fine-tuned and achieves better performance in face recognition. Extensive experiments not only show the efficacy of our model in learning an environment- specific face recognition model unsupervisedly, but also verify its adaptability to various appearance changes.
keywords: {Adaptation models;Face recognition;Surveillance;Robot vision systems;Training data;Smart homes;Medical services},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197348&isnumber=9196508

J. Massardi, M. Gravel and √â. Beaudry, "PARC: A Plan and Activity Recognition Component for Assistive Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3025-3031.
doi: 10.1109/ICRA40945.2020.9196856
Abstract: Mobile robot assistants have many applications, such as helping people in their daily living activities. These robots have to detect and recognize the actions and goals of the humans they are assisting. While there are several wide-spread plan and activity recognition solutions for controlled environments with many built-in sensors, like smart-homes, there is a lack of such systems for mobile robots operating in open settings, such as an apartment. We propose a module for the recognition of activities and goals for daily living by mobile robots, in real time and for complex activities. Our approach recognizes human-object interaction using an RGB-D camera to infer low-level actions which are sent to a goal recognition algorithm. Results show that our approach is both in real time and requires little computational resources, which facilitates its deployment on a mobile and low-cost robotics platform.
keywords: {Activity recognition;Hidden Markov models;Robot sensing systems;Feature extraction;Clustering algorithms;Activity recognition;Plan recognition;Computer vision;Robotic assistant;Activities For Daily Living;Object affordance;Particle filter},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196856&isnumber=9196508

A. Benbihi, S. Arravechia, M. Geist and C. Pradalier, "Image-Based Place Recognition on Bucolic Environment Across Seasons From Semantic Edge Description," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3032-3038.
doi: 10.1109/ICRA40945.2020.9197529
Abstract: Most of the research effort on image-based place recognition is designed for urban environments. In bucolic environments such as natural scenes with low texture and little semantic content, the main challenge is to handle the variations in visual appearance across time such as illumination, weather, vegetation state or viewpoints. The nature of the variations is different and this leads to a different approach to describing a bucolic scene. We introduce a global image description computed from its semantic and topological information. It is built from the wavelet transforms of the image's semantic edges. Matching two images is then equivalent to matching their semantic edge transforms. This method reaches state-of-the-art image retrieval performance on two multi-season environment-monitoring datasets: the CMU-Seasons and the Symphony Lake dataset. It also generalizes to urban scenes on which it is on par with the current baselines NetVLAD and DELF.
keywords: {Image edge detection;Semantics;Image segmentation;Image retrieval;Feature extraction;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197529&isnumber=9196508

X. -H. Zhou et al., "A Multilayer-Multimodal Fusion Architecture for Pattern Recognition of Natural Manipulations in Percutaneous Coronary Interventions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3039-3045.
doi: 10.1109/ICRA40945.2020.9197111
Abstract: The increasingly-used robotic systems can provide precise delivery and reduce X-ray radiation to medical staff in percutaneous coronary interventions (PCI), but natural manipulations of interventionalists are forgone in most robot-assisted procedures. Therefore, it is necessary to explore natural manipulations to design more advanced human-robot interfaces (HRI). In this study, a multilayer-multimodal fusion architecture is proposed to recognize six typical subpatterns of guidewire manipulations in conventional PCI. The synchronously acquired multimodal behaviors from ten subjects are used as the inputs of the fusion architecture. Six classification-based and two rule-based fusion algorithms are evaluated for performance comparisons. Experimental results indicate that the multimodal fusion brings significant accuracy improvement in comparison with single-modal schemes. Furthermore, the proposed architecture can achieve the overall accuracy of 96.90%, much higher than that of a singlelayer recognition architecture (92.56%). These results have indicated the potential of the proposed method for facilitating the development of HRI for robot-assisted PCI.
keywords: {Sensors;Robots;Muscles;Feature extraction;Force;Catheters;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197111&isnumber=9196508

C. Schulz and A. Zell, "Real-Time Graph-Based SLAM with Occupancy Normal Distributions Transforms," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3106-3111.
doi: 10.1109/ICRA40945.2020.9197325
Abstract: Simultaneous Localization and Mapping (SLAM) is one of the basic problems in mobile robotics. While most approaches are based on occupancy grid maps, Normal Distributions Transforms (NDT) and mixtures like Occupancy Normal Distribution Transforms (ONDT) have been shown to represent sensor measurements more accurately. In this work, we slightly re-formulate the (O)NDT matching function such that it becomes a least squares problem that can be solved with various robust numerical and analytical non-linear optimizers. Further, we propose a novel global (O)NDT scan matcher for loop closure. In our evaluation, our NDT and ONDT methods are able to outperform the occupancy grid map based ones we adopted from Google's Cartographer implementation.
keywords: {Simultaneous localization and mapping;Cost function;Google;Jacobian matrices;Gaussian distribution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197325&isnumber=9196508

N. Chebrolu, T. L√§be and C. Stachniss, "Spatio-Temporal Non-Rigid Registration of 3D Point Clouds of Plants," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3112-3118.
doi: 10.1109/ICRA40945.2020.9197569
Abstract: Analyzing sensor data of plants and monitoring plant performance is a central element in different agricultural robotics applications. In plant science, phenotyping refers to analyzing plant traits for monitoring growth, for describing plant properties, or characterizing the plant's overall performance. It plays a critical role in the agricultural tasks and in plant breeding. Recently, there is a rising interest in using 3D data obtained from laser scanners and 3D cameras to develop automated non-intrusive techniques for estimating plant traits. In this paper, we address the problem of registering 3D point clouds of the plants over time, which is a backbone of applications interested in tracking spatio-temporal traits of individual plants. Registering plants over time is challenging due to its changing topology, anisotropic growth, and non-rigid motion in between scans. We propose a novel approach that exploits the skeletal structure of the plant and determines correspondences over time and drives the registration process. Our approach explicitly accounts for the non-rigidity and the growth of the plant over time in the registration. We tested our approach on a challenging dataset acquired over the course of two weeks and successfully registered the 3D plant point clouds recorded with a laser scanner forming a basis for developing systems for automated temporal plant-trait analysis.
keywords: {Three-dimensional displays;Skeleton;Hidden Markov models;Strain;Topology;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197569&isnumber=9196508

R. Nakashima and A. Seki, "Uncertainty-Based Adaptive Sensor Fusion for Visual-Inertial Odometry under Various Motion Characteristics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3119-3125.
doi: 10.1109/ICRA40945.2020.9197397
Abstract: We propose an uncertainty-based sensor fusion framework for visual-inertial odometry, which is the task of estimating relative motion using images and measurements from inertial measurement units. Visual-inertial odometry enables robust and scale-aware estimation of motion by incorporating sensor states, such as metric scale, velocity, and the direction of gravity, into the estimation. However, the observability of the states depends on sensor motion. For example, if the sensor moves in a constant velocity, scale and velocity cannot be observed from inertial measurements. Under these degenerate motions, existing methods may produce inaccurate results because they incorporate erroneous states estimated from non-informative inertial measurements. Our proposed framework is able to avoid this situation by adaptively switching estimation modes, which represents the states that should be incorporated, based on their uncertainties. These uncertainties can be obtained at a small computational cost by reusing the Jacobian matrices computed in bundle adjustment. Our approach consistently outperformed conventional sensor fusion in datasets with different motion characteristics, namely, the KITTI odometry dataset recorded by a ground vehicle and the EuRoC MAV dataset captured from a micro aerial vehicle.
keywords: {Estimation;Bundle adjustment;Motion measurement;Velocity measurement;Uncertainty;Sensor fusion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197397&isnumber=9196508

J. Lin and F. Zhang, "Loam livox: A fast, robust, high-precision LiDAR odometry and mapping package for LiDARs of small FoV," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3126-3131.
doi: 10.1109/ICRA40945.2020.9197440
Abstract: LiDAR odometry and mapping (LOAM) has been playing an important role in autonomous vehicles, due to its ability to simultaneously localize the robot's pose and build high-precision, high-resolution maps of the surrounding environment. This enables autonomous navigation and safe path planning of autonomous vehicles. In this paper, we present a robust, real-time LOAM algorithm for LiDARs with small FoV and irregular samplings. By taking effort on both frontend and back-end, we address several fundamental challenges arising from such LiDARs, and achieve better performance in both precision and efficiency compared to existing baselines. To share our findings and to make contributions to the community, we open source our codes on Github1.
keywords: {Laser radar;Feature extraction;Three-dimensional displays;Measurement by laser beam;Laser noise;Real-time systems;Spinning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197440&isnumber=9196508

S. Suresh, P. Sodhi, J. G. Mangelson, D. Wettergreen and M. Kaess, "Active SLAM using 3D Submap Saliency for Underwater Volumetric Exploration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3132-3138.
doi: 10.1109/ICRA40945.2020.9196939
Abstract: In this paper, we present an active SLAM framework for volumetric exploration of 3D underwater environments with multibeam sonar. Recent work in integrated SLAM and planning performs localization while maintaining volumetric free-space information. However, an absence of informative loop closures can lead to imperfect maps, and therefore unsafe behavior. To solve this, we propose a navigation policy that reduces vehicle pose uncertainty by balancing between volumetric exploration and revisitation. To identify locations to revisit, we build a 3D visual dictionary from real-world sonar data and compute a metric of submap saliency. Revisit actions are chosen based on propagated pose uncertainty and sensor information gain. Loop closures are integrated as constraints in our pose-graph SLAM formulation and these deform the global occupancy grid map. We evaluate our performance in simulation and real-world experiments, and highlight the advantages over an uncertainty-agnostic framework.
keywords: {Simultaneous localization and mapping;Three-dimensional displays;Uncertainty;Conferences;Automation;Sonar;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196939&isnumber=9196508

X. Shi et al., "Are We Ready for Service Robots? The OpenLORIS-Scene Datasets for Lifelong SLAM," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3139-3145.
doi: 10.1109/ICRA40945.2020.9196638
Abstract: Service robots should be able to operate autonomously in dynamic and daily changing environments over an extended period of time. While Simultaneous Localization And Mapping (SLAM) is one of the most fundamental problems for robotic autonomy, most existing SLAM works are evaluated with data sequences that are recorded in a short period of time. In real-world deployment, there can be out-of-sight scene changes caused by both natural factors and human activities. For example, in home scenarios, most objects may be movable, replaceable or deformable, and the visual features of the same place may be significantly different in some successive days. Such out-of-sight dynamics pose great challenges to the robustness of pose estimation, and hence a robot‚Äôs long-term deployment and operation. To differentiate the forementioned problem from the conventional works which are usually evaluated in a static setting in a single run, the term lifelong SLAM is used here to address SLAM problems in an ever-changing environment over a long period of time. To accelerate lifelong SLAM research, we release the OpenLORIS-Scene datasets. The data are collected in real-world indoor scenes, for multiple times in each place to include scene changes in real life. We also design benchmarking metrics for lifelong SLAM, with which the robustness and accuracy of pose estimation are evaluated separately. The datasets and benchmark are available online at lifelong-robotic-vision.github.io/dataset/scene.
keywords: {Simultaneous localization and mapping;Robot kinematics;Cameras;Synchronization;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196638&isnumber=9196508

S. Herath, H. Yan and Y. Furukawa, "RoNIN: Robust Neural Inertial Navigation in the Wild: Benchmark, Evaluations, & New Methods," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3146-3152.
doi: 10.1109/ICRA40945.2020.9196860
Abstract: This paper sets a new foundation for data-driven inertial navigation research, where the task is the estimation of horizontal positions and heading direction of a moving subject from a sequence of IMU sensor measurements from a phone. In contrast to existing methods, our method can handle varying phone orientations and placements.More concretely, the paper presents 1) a new benchmark containing more than 40 hours of IMU sensor data from 100 human subjects with ground-truth 3D trajectories under natural human motions; 2) novel neural inertial navigation architectures, making significant improvements for challenging motion cases; and 3) qualitative and quantitative evaluations of the competing methods over three inertial navigation benchmarks. We share the code and data to promote further research. (http://ronin.cs.sfu.ca).
keywords: {Inertial navigation;Three-dimensional displays;Robustness;Estimation;Trajectory;Task analysis;Gravity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196860&isnumber=9196508

D. Oh, D. Ji, C. Jang, Y. Hyun, H. S. Bae and S. Hwang, "Segmenting 2K-Videos at 36.5 FPS with 24.3 GFLOPs: Accurate and Lightweight Realtime Semantic Segmentation Network," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3153-3160.
doi: 10.1109/ICRA40945.2020.9196510
Abstract: We propose a fast and lightweight end-to-end convolutional network architecture for real-time segmentation of high resolution videos, NfS-SegNet, that can segement 2K-videos at 36.5 FPS with 24.3 GFLOPS. This speed and computation-efficiency is due to following reasons: 1) The encoder network, NfS-Net, is optimized for speed with simple building blocks without memory-heavy operations such as depthwise convolutions, and outperforms state-of-the-art lightweight CNN architectures such as SqueezeNet [2], Mo- bileNet v1 [3] & v2 [4] and ShuffleNet v1 [5] & v2 [6] on image classification with significantly higher speed. 2) The NfS- SegNet has an asymmetric architecture with deeper encoder and shallow decoder, whose design is based on our empirical finding that the decoder is the main bottleneck in computation with relatively small contribution to the final performance. 3) Our novel uncertainty-aware knowledge distillation method guides the teacher model to focus its knowledge transfer on the most difficult image regions. We validate the performance of NfS-SegNet with the CITYSCAPE [1] benchmark, on which it achieves state-of-the-art performance among lightweight segementation models in terms of both accuracy and speed.
keywords: {Knowledge engineering;Computational modeling;Real-time systems;Computer architecture;Semantics;Uncertainty;Videos},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196510&isnumber=9196508

F. Kluger, H. Ackermann, M. Y. Yang and B. Rosenhahn, "Temporally Consistent Horizon Lines," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3161-3167.
doi: 10.1109/ICRA40945.2020.9197170
Abstract: The horizon line is an important geometric feature for many image processing and scene understanding tasks in computer vision. For instance, in navigation of autonomous vehicles or driver assistance, it can be used to improve 3D reconstruction as well as for semantic interpretation of dynamic environments. While both algorithms and datasets exist for single images, the problem of horizon line estimation from video sequences has not gained attention. In this paper, we show how convolutional neural networks are able to utilise the temporal consistency imposed by video sequences in order to increase the accuracy and reduce the variance of horizon line estimates. A novel CNN architecture with an improved residual convolutional LSTM is presented for temporally consistent horizon line estimation. We propose an adaptive loss function that ensures stable training as well as accurate results. Furthermore, we introduce an extension of the KITTI dataset which contains precise horizon line labels for 43699 images across 72 video sequences. A comprehensive evaluation shows that the proposed approach consistently achieves superior performance compared with existing methods.
keywords: {Video sequences;Cameras;Three-dimensional displays;Observers;Task analysis;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197170&isnumber=9196508

M. Jegorova, A. I. Karjalainen, J. Vazquez and T. Hospedales, "Full-Scale Continuous Synthetic Sonar Data Generation with Markov Conditional Generative Adversarial Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3168-3174.
doi: 10.1109/ICRA40945.2020.9197353
Abstract: Deployment and operation of autonomous underwater vehicles is expensive and time-consuming. High-quality realistic sonar data simulation could be of benefit to multiple applications, including training of human operators for post-mission analysis, as well as tuning and validation of autonomous target recognition (ATR) systems for underwater vehicles. Producing realistic synthetic sonar imagery is a challenging problem as the model has to account for specific artefacts of real acoustic sensors, vehicle attitude, and a variety of environmental factors. We propose a novel method for generating realistic-looking sonar side-scans of full-length missions, called Markov Conditional pix2pix (MC-pix2pix). Quantitative assessment results confirm that the quality of the produced data is almost indistinguishable from real. Furthermore, we show that bootstrapping ATR systems with MC-pix2pix data can improve the performance. Synthetic data is generated 18 times faster than real acquisition speed, with full user control over the topography of the generated data.
keywords: {Sonar;Training;Semantics;Data models;Gallium nitride;Training data;Markov processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197353&isnumber=9196508

M. P. Strub and J. D. Gammell, "Adaptively Informed Trees (AIT): Fast Asymptotically Optimal Path Planning through Adaptive Heuristics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3191-3198.
doi: 10.1109/ICRA40945.2020.9197338
Abstract: Informed sampling-based planning algorithms exploit problem knowledge for better search performance. This knowledge is often expressed as heuristic estimates of solution cost and used to order the search. The practical improvement of this informed search depends on the accuracy of the heuristic.Selecting an appropriate heuristic is difficult. Heuristics applicable to an entire problem domain are often simple to define and inexpensive to evaluate but may not be beneficial for a specific problem instance. Heuristics specific to a problem instance are often difficult to define or expensive to evaluate but can make the search itself trivial.This paper presents Adaptively Informed Trees (AIT*), an almost-surely asymptotically optimal sampling-based planner based on BIT*. AIT* adapts its search to each problem instance by using an asymmetric bidirectional search to simultaneously estimate and exploit a problem-specific heuristic. This allows it to quickly find initial solutions and converge towards the optimum. AIT* solves the tested problems as fast as RRT-Connect while also converging towards the optimum.
keywords: {Search problems;Image edge detection;Approximation algorithms;Planning;Heuristic algorithms;Databases;Path planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197338&isnumber=9196508

Z. Kingston, A. M. Wells, M. Moll and L. E. Kavraki, "Informing Multi-Modal Planning with Synergistic Discrete Leads," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3199-3205.
doi: 10.1109/ICRA40945.2020.9197545
Abstract: Robotic manipulation problems are inherently continuous, but typically have underlying discrete structure, e.g., whether or not an object is grasped. This means many problems are multi-modal and in particular have a continuous infinity of modes. For example, in a pick-and-place manipulation domain, every grasp and placement of an object is a mode. Usually manipulation problems require the robot to transition into different modes, e.g., going from a mode with an object placed to another mode with the object grasped. To successfully find a manipulation plan, a planner must find a sequence of valid single-mode motions as well as valid transitions between these modes. Many manipulation planners have been proposed to solve tasks with multi-modal structure. However, these methods require mode-specific planners and fail to scale to very cluttered environments or to tasks that require long sequences of transitions. This paper presents a general layered planning approach to multi-modal planning that uses a discrete "lead" to bias search towards useful mode transitions. The difficulty of achieving specific mode transitions is captured online and used to bias search towards more promising sequences of modes. We demonstrate our planner on complex scenes and show that significant performance improvements are tied to both our discrete "lead" and our continuous representation.
keywords: {Planning;Manifolds;Task analysis;Lead;Probabilistic logic;Robot motion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197545&isnumber=9196508

C. Cao, J. Zhang, M. Travers and H. Choset, "Hierarchical Coverage Path Planning in Complex 3D Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3206-3212.
doi: 10.1109/ICRA40945.2020.9196575
Abstract: State-of-the-art coverage planning methods perform well in simple environments but take an ineffectively long time to converge to an optimal solution in complex three-dimensional (3D) environments. As more structures are present in the same volume of workspace, these methods slow down as they spend more time searching for all of the nooks and crannies concealed in three-dimensional spaces. This work presents a method for coverage planning that employs a multi-resolution hierarchical framework to solve the problem at two different levels, producing much higher efficiency than the state-of-the-art. First, a high-level algorithm separates the environment into multiple subspaces at different resolutions and computes an order of the subspaces for traversal. Second, a low-level sampling-based algorithm solves for paths within the subspaces for detailed coverage. In experiments, we evaluate our method using real-world datasets from complex three-dimensional scenes. Our method finds paths that are constantly shorter and converges at least ten times faster than the state-of-the-art. Further, we show results of a physical experiment where a lightweight UAV follows the paths to realize the coverage.
keywords: {Planning;Robot sensing systems;Cameras;Octrees;Three-dimensional displays;Surface treatment},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196575&isnumber=9196508

I. Spasojevic, V. Murali and S. Karaman, "Perception-aware time optimal path parameterization for quadrotors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3213-3219.
doi: 10.1109/ICRA40945.2020.9197157
Abstract: The increasing popularity of quadrotors has given rise to a class of predominantly vision-driven vehicles. This paper addresses the problem of perception-aware time optimal path parametrization for quadrotors. Although many different choices of perceptual modalities are available, the low weight and power budgets of quadrotor systems makes a camera ideal for on-board navigation and estimation algorithms. However, this does come with a set of challenges. The limited field of view of the camera can restrict the visibility of salient regions in the environment, which dictates the necessity to consider perception and planning jointly. The main contribution of this paper is an efficient time optimal path parametrization algorithm for quadrotors with limited field of view constraints. We show in a simulation study that a state-of-the-art controller can track planned trajectories, and we validate the proposed algorithm on a quadrotor platform in experiments.
keywords: {Trajectory;Cameras;Planning;Task analysis;Aerodynamics;Heuristic algorithms;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197157&isnumber=9196508

N. Buckman, A. Pierson, S. Karaman and D. Rus, "Generating Visibility-Aware Trajectories for Cooperative and Proactive Motion Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3220-3226.
doi: 10.1109/ICRA40945.2020.9196809
Abstract: The safety of an autonomous vehicle not only depends on its own perception of the world around it, but also on the perception and recognition from other vehicles. If an ego vehicle considers the uncertainty other vehicles have about itself, then by reducing the estimated uncertainty it can increase its safety. In this paper, we focus on how an ego vehicle plans its trajectories through the blind spots of other vehicles. We create visibility-aware planning, where the ego vehicle chooses its trajectories such that it reduces the perceived uncertainty other vehicles may have about the state of the ego vehicle. We present simulations of traffic and highway environments, where an ego vehicle must pass another vehicle, make a lane change, or traverse a partially-occluded intersection. Emergent behavior shows that when using visibility-aware planning, the ego vehicle spends less time in a blind spot, and may slow down before entering the blind spot so as to increase the likelihood other vehicles perceive the ego vehicle.
keywords: {Trajectory;Uncertainty;Planning;Safety;Autonomous vehicles;Splines (mathematics)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196809&isnumber=9196508

M. Selvaggio, L. A. Ramirez, N. D. Naclerio, B. Siciliano and E. W. Hawkes, "An obstacle-interaction planning method for navigation of actuated vine robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3227-3233.
doi: 10.1109/ICRA40945.2020.9196587
Abstract: The field of soft robotics is grounded on the idea that, due to their inherent compliance, soft robots can safely interact with the environment. Thus, the development of effective planning and control pipelines for soft robots should incorporate reliable robot-environment interaction models. This strategy enables soft robots to effectively exploit contacts to autonomously navigate and accomplish tasks in the environment. However, for a class of soft robots, namely vine-inspired, tip-extending or "vine" robots, such interaction models and the resulting planning and control strategies do not exist. In this paper, we analyze the behavior of vine robots interacting with their environment and propose an obstacle-interaction model that characterizes the bending and wrinkling deformation induced by the environment. Starting from this, we devise a novel obstacle-interaction planning method for these robots. We show how obstacle interactions can be effectively leveraged to enlarge the set of reachable workspace for the robot tip, and verify our findings with both simulated and real experiments. Our work improves the capabilities of this new class of soft robot, helping to advance the field of soft robotics.
keywords: {Soft robotics;Strain;Deformable models;Planning;Kinematics;Pneumatic systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196587&isnumber=9196508

G. Wang et al., "Distributed Consensus Control of Multiple UAVs in a Constrained Environment," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3234-3240.
doi: 10.1109/ICRA40945.2020.9196926
Abstract: In this paper, we investigate the consensus problem of multiple unmanned aerial vehicles (UAVs) in the presence of environmental constraints under a general communication topology containing a directed spanning tree. First, based on a position transformation function, we propose a novel dynamic reference position and yaw angle for each UAV to cope with both the asymmetric topology and the constraints. Then, the backstepping-like design methodology is presented to derive a local tracking controller for each UAV such that its position and yaw angle can converge to the reference ones. The proposed protocol is distributed in the sense that, the input update of each UAV dynamically relies only on local state information from its neighborhood set and the constraints, and it does not require any additional centralized information. It is demonstrated that under the proposed protocol, all UAVs reach consensus without violation of the environmental constraints. Finally, simulation and experimental results are provided to demonstrate the performance of the protocol.
keywords: {Topology;Decentralized control;Protocols;Unmanned aerial vehicles;Tracking loops;Heuristic algorithms;Attitude control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196926&isnumber=9196508

G. Shi, W. H√∂nig, Y. Yue and S. -J. Chung, "Neural-Swarm: Decentralized Close-Proximity Multirotor Control Using Learned Interactions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3241-3247.
doi: 10.1109/ICRA40945.2020.9196800
Abstract: In this paper, we present Neural-Swarm, a nonlinear decentralized stable controller for close-proximity flight of multirotor swarms. Close-proximity control is challenging due to the complex aerodynamic interaction effects between multirotors, such as downwash from higher vehicles to lower ones. Conventional methods often fail to properly capture these interaction effects, resulting in controllers that must maintain large safety distances between vehicles, and thus are not capable of close-proximity flight. Our approach combines a nominal dynamics model with a regularized permutation-invariant Deep Neural Network (DNN) that accurately learns the high-order multi-vehicle interactions. We design a stable nonlinear tracking controller using the learned model. Experimental results demonstrate that the proposed controller significantly outperforms a baseline nonlinear tracking controller with up to four times smaller worst-case height tracking errors. We also empirically demonstrate the ability of our learned model to generalize to larger swarm sizes.
keywords: {Vehicle dynamics;Aerodynamics;Neural networks;Rotors;Stability analysis;Training;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196800&isnumber=9196508

S. Agarwal and S. Akella, "Line Coverage with Multiple Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3248-3254.
doi: 10.1109/ICRA40945.2020.9197292
Abstract: The line coverage problem is the coverage of linear environment features (e.g., road networks, power lines), modeled as 1D segments, by one or more robots while respecting resource constraints (e.g., battery capacity, flight time) for each of the robots. The robots incur direction dependent costs and resource demands as they traverse the edges. We treat the line coverage problem as an optimization problem, with the total cost of the tours as the objective, by formulating it as a mixed integer linear program (MILP). The line coverage problem is NP-hard and hence we develop a heuristic algorithm, Merge-Embed-Merge (MEM). We compare it against the optimal MILP approach and a baseline heuristic algorithm, Extended Path Scanning. We show the MEM algorithm is fast and suitable for real-time applications. To tackle large-scale problems, our approach performs graph simplification and graph partitioning, followed by robot tour generation for each of the partitioned subgraphs. We demonstrate our approach on a large graph with 4,658 edges and 4,504 vertices that represents an urban region of about 16 sq. km. We compare the performance of the algorithms on several small road networks and experimentally demonstrate the approach using UAVs on the UNC Charlotte campus road network.
keywords: {Roads;Task analysis;Robot sensing systems;Routing;Heuristic algorithms;Partitioning algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197292&isnumber=9196508

R. Funada, M. Santos, T. Gencho, J. Yamauchi, M. Fujita and M. Egerstedt, "Visual Coverage Maintenance for Quadcopters Using Nonsmooth Barrier Functions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3255-3261.
doi: 10.1109/ICRA40945.2020.9196650
Abstract: This paper presents a coverage control algorithm for teams of quadcopters with downward facing visual sensors that prevents the appearance of coverage holes in-between the monitored areas while maximizing the coverage quality as much as possible. We derive necessary and sufficient conditions for preventing the appearance of holes in-between the fields of views among trios of robots. Because this condition can be expressed as logically combined constraints, control nonsmooth barrier functions are implemented to enforce it. An algorithm which extends control nonsmooth barrier functions to hybrid systems is implemented to manage the switching among barrier functions caused by the changes of the robots composing trio. The performance and validity of the proposed algorithm are evaluated in simulation as well as on a team of quadcopters.
keywords: {Visualization;Monitoring;Robot sensing systems;Switches;Space missions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196650&isnumber=9196508

P. Kaniarasu, G. C. Haynes and M. Marchetti-Bowick, "Goal-Directed Occupancy Prediction for Lane-Following Actors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3270-3276.
doi: 10.1109/ICRA40945.2020.9197495
Abstract: Predicting the possible future behaviors of vehicles that drive on shared roads is a crucial task for safe autonomous driving. Many existing approaches to this problem strive to distill all possible vehicle behaviors into a simplified set of high-level actions. However, these action categories do not suffice to describe the full range of maneuvers possible in the complex road networks we encounter in the real world. To combat this deficiency, we propose a new method that leverages the mapped road topology to reason over possible goals and predict the future spatial occupancy of dynamic road actors. We show that our approach is able to accurately predict future occupancy that remains consistent with the mapped lane geometry and naturally captures multi-modality based on the local scene context while also not suffering from the mode collapse problem observed in prior work.
keywords: {Roads;Predictive models;Trajectory;Topology;Geometry;Task analysis;Autonomous vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197495&isnumber=9196508

K. D. Katyal, G. D. Hager and C. -M. Huang, "Intent-Aware Pedestrian Prediction for Adaptive Crowd Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3277-3283.
doi: 10.1109/ICRA40945.2020.9197434
Abstract: Mobile robots capable of navigating seamlessly and safely in pedestrian rich environments promise to bring robotic assistance closer to our daily lives. In this paper we draw on insights of how humans move in crowded spaces to explore how to recognize pedestrian navigation intent, how to predict pedestrian motion and how a robot may adapt its navigation policy dynamically when facing unexpected human movements. Our approach is to develop algorithms that replicate this behavior. We experimentally demonstrate the effectiveness of our prediction algorithm using real-world pedestrian datasets and achieve comparable or better prediction accuracy compared to several state-of-the-art approaches. Moreover, we show that confidence of pedestrian prediction can be used to adjust the risk of a navigation policy adaptively to afford the most comfortable level as measured by the frequency of personal space violation in comparison with baselines. Furthermore, our adaptive navigation policy is able to reduce the number of collisions by 43% in the presence of novel pedestrian motion not seen during training.
keywords: {Navigation;Trajectory;Robots;Prediction algorithms;Training;Collision avoidance;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197434&isnumber=9196508

A. Ligocki, A. Jelinek and L. Zalud, "Brno Urban Dataset - The New Data for Self-Driving Agents and Mapping Tasks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3284-3290.
doi: 10.1109/ICRA40945.2020.9197277
Abstract: Autonomous driving is a dynamically growing field of research, where quality and amount of experimental data is critical. Although several rich datasets are available these days, the demands of researchers and technical possibilities are evolving. Through this paper, we bring a new dataset recorded in Brno - Czech Republic. It offers data from four WUXGA cameras, two 3D LiDARs, inertial measurement unit, infrared camera and especially differential RTK GNSS receiver with centimetre accuracy which, to the best knowledge of the authors, is not available from any other public dataset so far. In addition, all the data are precisely timestamped with submillisecond precision to allow wider range of applications. At the time of publishing of this paper, recordings of more than 350 km of rides in varying environment are shared at: https://github.com/RoboticsBUT/Brno-Urban-Dataset.
keywords: {Cameras;Sensors;Global Positioning System;Global navigation satellite system;Receivers;Laser radar;Synchronization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197277&isnumber=9196508

L. Zhang, W. Ding, J. Chen and S. Shen, "Efficient Uncertainty-aware Decision-making for Automated Driving Using Guided Branching," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3291-3297.
doi: 10.1109/ICRA40945.2020.9197302
Abstract: Decision-making in dense traffic scenarios is challenging for automated vehicles (AVs) due to potentially stochastic behaviors of other traffic participants and perception uncertainties (e.g., tracking noise and prediction errors, etc.). Although the partially observable Markov decision process (POMDP) provides a systematic way to incorporate these uncertainties, it quickly becomes computationally intractable when scaled to the real-world large-size problem. In this paper, we present an efficient uncertainty-aware decision-making (EUDM) framework, which generates long-term lateral and longitudinal behaviors in complex driving environments in real-time. The computation complexity is controlled to an appropriate level by two novel techniques, namely, the domain-specific closed-loop policy tree (DCP-Tree) structure and conditional focused branching (CFB) mechanism. The key idea is utilizing domain-specific expert knowledge to guide the branching in both action and intention space. The proposed framework is validated using both onboard sensing data captured by a real vehicle and an interactive multi-agent simulation platform. We also release the code of our framework to accommodate benchmarking.
keywords: {Planning;Decision making;Uncertainty;Semantics;Vegetation;Aerospace electronics;Safety},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197302&isnumber=9196508

M. Peng, Z. Gong, C. Sun, L. Chen and D. Cao, "Imitative Reinforcement Learning Fusing Vision and Pure Pursuit for Self-driving," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3298-3304.
doi: 10.1109/ICRA40945.2020.9197027
Abstract: Autonomous urban driving navigation is still an open problem and has ample room for improvement in unknown complex environments and terrible weather conditions. In this paper, we propose a two-stage framework, called IPP-RL, to handle these problems. IPP means an Imitation learning method fusing visual information with the additional steering angle calculated by Pure-Pursuit (PP) method, and RL means using Reinforcement Learning for further training. In our IPP model, the visual information captured by camera can be compensated by the calculated steering angle, thus it could perform well under bad weather conditions. However, imitation learning performance is limited by the driving data severely. Thus we use a reinforcement learning method-Deep Deterministic Policy Gradient (DDPG)-in the second stage training, which shares the learned weights from pretrained IPP model. In this way, our IPP-RL can lower the dependency of imitation learning on demonstration data and solve the problem of low exploration efficiency caused by randomly initialized weights in reinforcement learning. Moreover, we design a more reasonable reward function and use the n-step return to update the critic-network in DDPG. Our experiments on CARLA driving benchmark demonstrate that our IPP-RL is robust to lousy weather conditions and shows remarkable generalization capability in unknown environments on navigation task.
keywords: {Learning (artificial intelligence);Meteorology;Robustness;Task analysis;Navigation;Training;Autonomous vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197027&isnumber=9196508

A. Savkin, T. Lapotre, K. Strauss, U. Akbar and F. Tombari, "Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3305-3311.
doi: 10.1109/ICRA40945.2020.9197024
Abstract: In the autonomous driving area synthetic data is crucial for cover specific traffic scenarios which autonomous vehicle must handle. This data commonly introduces domain gap between synthetic and real domains. In this paper we deploy data augmentation to generate custom traffic scenarios with VRUs in order to improve pedestrian recognition. We provide a pipeline for augmentation of the Cityscapes dataset with virtual pedestrians. In order to improve augmentation realism of the pipeline we reveal a novel generative network architecture for adversarial learning of the data-set lighting conditions. We also evaluate our approach on the tasks of semantic and instance segmentation.
keywords: {Solid modeling;Semantics;Three-dimensional displays;Autonomous vehicles;Training;Cameras;Pipelines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197024&isnumber=9196508

Z. Zhou, M. Yang, C. Wang and B. Wang, "ROI-cloud: A Key Region Extraction Method for LiDAR Odometry and Localization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3312-3318.
doi: 10.1109/ICRA40945.2020.9197059
Abstract: We present a novel key region extraction method of point cloud, ROI-cloud, for LiDAR odometry and localization with autonomous robots. Traditional methods process massive point cloud data in every region within the field of view. In dense urban environments, however, processing redundant and dynamic regions of point cloud is time-consuming and harmful to the results of matching algorithms. In this paper, a voxelized cube set, ROI-cloud, is proposed to solve this problem by exclusively reserving the regions of interest for better point set registration and pose estimation. 3D space is firstly voxelized into weighted cubes. The key idea is to update their weights continually and extract cubes with high importance as key regions. By extracting geometrical features of a LiDAR scan, the importance of each cube is evaluated as a new measurement. With the help of on-board IMU/odometry data as well as new measurements, the weights of cubes are updated recursively through Bayes filtering. Thus, dynamic and redundant point cloud inside cubes with low importance are discarded by means of Monte Carlo sampling. Our method is validated on various datasets, and results indicate that the ROI-cloud improves the existing method in both accuracy and speed.
keywords: {Feature extraction;Three-dimensional displays;Laser radar;Heuristic algorithms;Vehicle dynamics;Robots;Urban areas},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197059&isnumber=9196508

Q. Zhou, T. Sattler, M. Pollefeys and L. Leal-Taix√©, "To Learn or Not to Learn: Visual Localization from Essential Matrices," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3319-3326.
doi: 10.1109/ICRA40945.2020.9196607
Abstract: Visual localization is the problem of estimating a camera within a scene and a key technology for autonomous robots. State-of-the-art approaches for accurate visual localization use scene-specific representations, resulting in the overhead of constructing these models when applying the techniques to new scenes. Recently, learned approaches based on relative pose estimation have been proposed, carrying the promise of easily adapting to new scenes. However, they are currently significantly less accurate than state-of-the-art approaches. In this paper, we are interested in analyzing this behavior. To this end, we propose a novel framework for visual localization from relative poses. Using a classical feature-based approach within this framework, we show state-of-the-art performance. Replacing the classical approach with learned alternatives at various levels, we then identify the reasons for why deep learned approaches do not perform well. Based on our analysis, we make recommendations for future work.
keywords: {Cameras;Visualization;Three-dimensional displays;Pipelines;Pose estimation;Image retrieval},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196607&isnumber=9196508

S. Hausler and M. Milford, "Hierarchical Multi-Process Fusion for Visual Place Recognition," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3327-3333.
doi: 10.1109/ICRA40945.2020.9197360
Abstract: Combining multiple complementary techniques together has long been regarded as a way to improve performance. In visual localization, multi-sensor fusion, multi-process fusion of a single sensing modality, and even combinations of different localization techniques have been shown to result in improved performance. However, merely fusing together different localization techniques does not account for the varying performance characteristics of different localization techniques. In this paper we present a novel, hierarchical localization system that explicitly benefits from three varying characteristics of localization techniques: the distribution of their localization hypotheses, their appearance- and viewpointinvariant properties, and the resulting differences in where in an environment each system works well and fails. We show how two techniques deployed hierarchically work better than in parallel fusion, how combining two different techniques works better than two levels of a single technique, even when the single technique has superior individual performance, and develop two and three-tier hierarchical structures that progressively improve localization performance. Finally, we develop a stacked hierarchical framework where localization hypotheses from techniques with complementary characteristics are concatenated at each layer, significantly improving retention of the correct hypothesis through to the final localization stage. Using two challenging datasets, we show the proposed system outperforming state-of-the-art techniques.
keywords: {Databases;Visualization;Feature extraction;Robots;Pipelines;Histograms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197360&isnumber=9196508

T. Caselitz, M. Krawez, J. Sundram, M. Van Loock and W. Burgard, "Camera Tracking in Lighting Adaptable Maps of Indoor Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3334-3340.
doi: 10.1109/ICRA40945.2020.9197471
Abstract: Tracking the pose of a camera is at the core of visual localization methods used in many applications. As the observations of a camera are inherently affected by lighting, it has always been a challenge for these methods to cope with varying lighting conditions. Thus far, this issue has mainly been approached with the intent to increase robustness by choosing lighting invariant map representations. In contrast, our work aims at explicitly exploiting lighting effects for camera tracking. To achieve this, we propose a lighting adaptable map representation for indoor environments that allows real-time rendering of the scene illuminated by an arbitrary subset of the lamps contained in the model. Our method for estimating the light setting from the current camera observation enables us to adapt the model according to the lighting conditions present in the scene. As a result, lighting effects like cast shadows do no longer act as disturbances that demand robustness but rather as beneficial features when matching observations against the map. We leverage these capabilities in a direct dense camera tracking approach and demonstrate its performance in realworld experiments in scenes with varying lighting conditions.
keywords: {Lighting;Cameras;Visualization;Indoor environments;Estimation;Mathematical model;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197471&isnumber=9196508

S. Garg and M. Milford, "Fast, Compact and Highly Scalable Visual Place Recognition through Sequence-based Matching of Overloaded Representations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3341-3348.
doi: 10.1109/ICRA40945.2020.9196827
Abstract: Visual place recognition algorithms trade off three key characteristics: their storage footprint, their computational requirements, and their resultant performance, often expressed in terms of recall rate. Significant prior work has investigated highly compact place representations, sub-linear computational scaling and sub-linear storage scaling techniques, but have always involved a significant compromise in one or more of these regards, and have only been demonstrated on relatively small datasets. In this paper we present a novel place recognition system which enables for the first time the combination of ultra-compact place representations, near sub-linear storage scaling and extremely lightweight compute requirements. Our approach exploits the inherently sequential nature of much spatial data in the robotics domain and inverts the typical target criteria, through intentionally coarse scalar quantization-based hashing that leads to more collisions but is resolved by sequence-based matching. For the first time, we show how effective place recognition rates can be achieved on a new very large 10 million place dataset, requiring only 8 bytes of storage per place and 37K unitary operations to achieve over 50% recall for matching a sequence of 100 frames, where a conventional stateof-the-art approach both consumes 1300 times more compute and fails catastrophically. We present analysis investigating the effectiveness of our hashing overload approach under varying sizes of quantized vector length, comparison of near miss matches with the actual match selections and characterise the effect of variance re-scaling of data on quantization. Resource link: https://github.com/oravus/CoarseHash.
keywords: {Quantization (signal);Visualization;Indexes;Robots;Principal component analysis;Benchmark testing;Image recognition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196827&isnumber=9196508

T. Nguyen, K. Mohta, C. J. Taylor and V. Kumar, "Vision-based Multi-MAV Localization with Anonymous Relative Measurements Using Coupled Probabilistic Data Association Filter," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3349-3355.
doi: 10.1109/ICRA40945.2020.9196793
Abstract: We address the localization of robots in a multi-MAV system where external infrastructure like GPS or motion capture systems may not be available. Our approach lends itself to implementation on platforms with several constraints on size, weight, and power (SWaP). Particularly, our framework fuses the onboard VIO with the anonymous, visual-based robot-to-robot detection to estimate all robot poses in one common frame, addressing three main challenges: 1) the initial configuration of the robot team is unknown, 2) the data association between each vision-based detection and robot targets is unknown, and 3) the vision-based detection yields false negatives, false positives, inaccurate, and provides noisy bearing, distance measurements of other robots. Our approach extends the Coupled Probabilistic Data Association Filter [1] to cope with nonlinear measurements. We demonstrate the superior performance of our approach over a simple VIO-based method in a simulation with the measurement models statistically modeled using the real experimental data. We also show how onboard sensing, estimation, and control can be used for formation flight.
keywords: {Robot kinematics;Robot sensing systems;Noise measurement;Probabilistic logic;Task analysis;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196793&isnumber=9196508

H. Bharadhwaj, S. Yamaguchi and S. -i. Maeda, "MANGA: Method Agnostic Neural-policy Generalization and Adaptation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3356-3362.
doi: 10.1109/ICRA40945.2020.9197398
Abstract: In this paper we target the problem of transferring policies across multiple environments with different dynamics parameters and motor noise variations, by introducing a framework that decouples the processes of policy learning and system identification. Efficiently transferring learned policies to an unknown environment with changes in dynamics configurations in the presence of motor noise is very important for operating robots in the real world, and our work is a novel attempt in that direction. We introduce MANGA: Method Agnostic Neural-policy Generalization and Adaptation, that trains dynamics conditioned policies and efficiently learns to estimate the dynamics parameters of the environment given off-policy state-transition rollouts in the environment. Our scheme is agnostic to the type of training method used - both reinforcement learning (RL) and imitation learning (IL) strategies can be used. We demonstrate the effectiveness of our approach by experimenting with four different MuJoCo agents and comparing against previously proposed transfer baselines.
keywords: {Training;Robots;Task analysis;Encoding;Decoding;Heuristic algorithms;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197398&isnumber=9196508

J. Choi et al., "Fast Adaptation of Deep Reinforcement Learning-Based Navigation Skills to Human Preference," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3363-3370.
doi: 10.1109/ICRA40945.2020.9197159
Abstract: Deep reinforcement learning (RL) is being actively studied for robot navigation due to its promise of superior performance and robustness. However, most existing deep RL navigation agents are trained using fixed parameters, such as maximum velocities and weightings of reward components. Since the optimal choice of parameters depends on the use-case, it can be difficult to deploy such existing methods in a variety of real-world service scenarios. In this paper, we propose a novel deep RL navigation method that can adapt its policy to a wide range of parameters and reward functions without expensive retraining. Additionally, we explore a Bayesian deep learning method to optimize these parameters that requires only a small amount of preference data. We empirically show that our method can learn diverse navigation skills and quickly adapt its policy to a given performance metric or to human preference. We also demonstrate our method in real-world scenarios.
keywords: {Navigation;Collision avoidance;Bayes methods;Training;Robot kinematics;Machine learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197159&isnumber=9196508

E. Pignat, T. Lembono and S. Calinon, "Variational Inference with Mixture Model Approximation for Applications in Robotics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3395-3401.
doi: 10.1109/ICRA40945.2020.9197166
Abstract: We propose to formulate the problem of representing a distribution of robot configurations (e.g. joint angles) as that of approximating a product of experts. Our approach uses variational inference, a popular method in Bayesian computation, which has several practical advantages over sampling-based techniques. To be able to represent complex and multimodal distributions of configurations, mixture models are used as approximate distribution. We show that the problem of approximating a distribution of robot configurations while satisfying multiple objectives arises in a wide range of problems in robotics, for which the properties of the proposed approach have relevant consequences. Several applications are discussed, including learning objectives from demonstration, planning, and warm-starting inverse kinematics problems. Simulated experiments are presented with a 7-DoF Panda arm and a 28-DoF Talos humanoid.
keywords: {Robots;Mixture models;Kinematics;Bayes methods;Optimization;Task analysis;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197166&isnumber=9196508

H. Maruyama, H. Hashim, R. Yanagawa and F. Arai, "Injection of a Fluorescent Microsensor into a Specific Cell by Laser Manipulation and Heating with Multiple Wavelengths of Light," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3437-3442.
doi: 10.1109/ICRA40945.2020.9197234
Abstract: In this study, we propose the manipulation and cell injection of a fluorescent microsensor using multiple wavelengths of light. The fluorescent microsensor is made of a 1-Œºm polystyrene particle containing infrared (IR: 808 nm) absorbing dye and Rhodamine B. The polystyrene particle can be manipulated in water using a 1064-nm laser because the refractive index of the polystyrene is 1.6 (refractive index of water: 1.3). The IR absorbing dye absorbs 808-nm light but does not absorb the 1064-nm laser. Rhodamine B is a temperature-sensitive fluorescent dye (excitation wavelength: 488 nm, emission wavelength: 560 nm). The functions of manipulation, heating for injection, and temperature measurement are achieved by different wavelengths of 1064 nm, 808 nm, and 488 nm, respectively. The temperature increase of fluorescent microsensor with 808-nm (40 mW, 10 s) laser was approximately 15¬∞C, and enough for injection of fluorescent microsensor. We demonstrated manipulation and injection of the microsensor into Madin-Darby canine kidney cell using 1064-nm and 808-nm lasers. These results confirmed the effectiveness of our proposed cell injection of a fluorescent microsensor using multiple wavelengths of light.
keywords: {Microsensors;Fluorescence;Semiconductor lasers;Heating systems;Measurement by laser beam;Laser excitation;Temperature measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197234&isnumber=9196508

D. J. Gonzalez and H. H. Asada, "Passive Quadrupedal Gait Synchronization for Extra Robotic Legs Using a Dynamically Coupled Double Rimless Wheel Model," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3451-3457.
doi: 10.1109/ICRA40945.2020.9196773
Abstract: The Extra Robotic Legs (XRL) system is a robotic augmentation worn by a human operator consisting of two articulated robot legs that walk with the operator and help bear a heavy backpack payload. It is desirable for the Human-XRL quadruped system to walk with the rear legs lead the front by 25% of the gait period, minimizing the energy lost from foot impacts while maximizing balance stability. Unlike quadrupedal robots, the XRL cannot command the human's limbs to coordinate quadrupedal locomotion. Using a pair of Rimless Wheel models, it is shown that the systems coupled with a spring and damper converge to the desired 25% phase difference. A Poincar√© return map was generated using numerical simulation to examine the convergence properties to different coupler design parameters, and initial conditions. The Dynamically Coupled Double Rimless Wheel system was physically realized with a spring and dashpot chosen from the theoretical results, and initial experiments indicate that the desired synchronization properties may be achieved within several steps using this set of passive components alone.
keywords: {Legged locomotion;Wheels;Synchronization;Couplers;Robot kinematics;Human Augmentation;Supernumerary Robotic Limbs;Exoskeletons;Locomotion;Nonlinear Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196773&isnumber=9196508

L. Li, I. Tokuda and F. Asano, "Optimal Fast Entrainment Waveform for Indirectly Controlled Limit Cycle Walker Against External Disturbances," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3458-3463.
doi: 10.1109/ICRA40945.2020.9196525
Abstract: After occasional perturbation, it is crucial to spontaneously control the limit cycle walking so that it quickly returns to its closed orbit in phase space. Otherwise, its stability can not be sufficiently guaranteed if the speed of recovery is slow while successive perturbation is applied. The accumulated deviation may eventually drive the phase outside the basin of attraction, leading to failure of the walking. In this sense, a control law that quickly recovers the disturbed phase before encountering the following perturbations is indispensable. With this consideration, here we analytically derive an optimal fast entrainment waveform that maximizes the speed of phase recovery based on phase reduction theory. Our theoretical method is numerically evaluated using a limit cycle walker, which is indirectly controlled by the oscillation of a wobbling mass via entrainment effect. The obtained waveform is used as the desired trajectory of the wobbling motion. The simulation results show that the waveform we derived achieves the best performance among all candidates. Our method helps to enhance the stability of limit cycle walking.
keywords: {Limit-cycles;Legged locomotion;Perturbation methods;Mathematical model;Oscillators;Convergence;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196525&isnumber=9196508

P. Gao, Z. Zhang, R. Guo, H. Lu and H. Zhang, "Correspondence Identification in Collaborative Robot Perception through Maximin Hypergraph Matching," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3488-3494.
doi: 10.1109/ICRA40945.2020.9196594
Abstract: Correspondence identification is an essential problem for collaborative multi-robot perception, with the objective of deciding the correspondence of objects that are observed in the field of view of each robot. In this paper, we introduce a novel maximin hypergraph matching approach that formulates correspondence identification as a hypergraph matching problem. The proposed approach incorporates both spatial relationships and appearance features of objects to improve representation capabilities. It also integrates the maximin theorem to optimize the worst-case scenario in order to address distractions caused by non-covisible objects. In addition, we design an optimization algorithm to address the formulated non-convex non-continuous optimization problem. We evaluate our approach and compare it with seven previous techniques in two application scenarios, including multi-robot coordination on real robots and connected autonomous driving in simulations. Experimental results have validated the effectiveness of our approach in identifying object correspondence from partially overlapped views in collaborative perception, and have shown that the proposed maximin hypergraph matching approach outperforms previous techniques and obtains state-of-the-art performance.
keywords: {Collaboration;Robot kinematics;Object recognition;Optimization;Robot sensing systems;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196594&isnumber=9196508

O. Shorinwa, J. Yu, T. Halsted, A. Koufos and M. Schwager, "Distributed Multi-Target Tracking for Autonomous Vehicle Fleets," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3495-3501.
doi: 10.1109/ICRA40945.2020.9197241
Abstract: We present a scalable distributed target tracking algorithm based on the alternating direction method of multipliers that is well-suited for a fleet of autonomous cars communicating over a vehicle-to-vehicle network. Each sensing vehicle communicates with its neighbors to execute iterations of a Kalman filter-like update such that each agent's estimate approximates the centralized maximum a posteriori estimate without requiring the communication of measurements. We show that our method outperforms the Consensus Kalman Filter in recovering the centralized estimate given a fixed communication bandwidth. We also demonstrate the algorithm in a high fidelity urban driving simulator (CARLA), in which 50 autonomous cars connected on a time-varying communication network track the positions and velocities of 50 target vehicles using on-board cameras.
keywords: {Sensors;Target tracking;Kalman filters;Microsoft Windows;Estimation;Trajectory;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197241&isnumber=9196508

K. P. Jain and M. W. Mueller, "Flying batteries: In-flight battery switching to increase multirotor flight time," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3510-3516.
doi: 10.1109/ICRA40945.2020.9197580
Abstract: We present a novel approach to increase the flight time of a multirotor via mid-air docking and in-flight battery switching. A main quadcopter flying using a primary battery has a docking platform attached to it. A `flying battery' - a small quadcopter carrying a secondary battery - is equipped with docking legs that can mate with the main quadcopter's platform. Connectors between the legs and the platform establish electrical contact on docking, and enable power transfer from the secondary battery to the main quadcopter. A custom-designed circuit allows arbitrary switching between the primary battery and secondary battery. We demonstrate the concept in a flight experiment involving repeated docking, battery switching, and undocking. This is shown in the video attachment. The experiment increases the flight time of the main quadcopter by a factor of 4.7√ó compared to solo flight, and 2.2√ó a theoretical limit for that given multirotor. Importantly, this increase in flight time is not associated with a large increase in overall vehicle mass or size, leaving the main quadcopter in fundamentally the same safety class.
keywords: {Batteries;Switches;Legged locomotion;Switching circuits;Aerodynamics;Connectors;Propellers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197580&isnumber=9196508

E. Krimsky and S. H. Collins, "Optimal Control of an Energy-Recycling Actuator for Mobile Robotics Applications," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3559-3565.
doi: 10.1109/ICRA40945.2020.9196870
Abstract: Actuator power consumption is a limiting factor in mobile robot design. In this paper we introduce the concept of an energy-recycling actuator, which uses an array of springs and clutches to capture and return elastic energy in parallel with an electric motor. Engaging and disengaging clutches appropriately could reduce electrical energy consumption without sacrificing controllability, but presents a challenging control problem. We formulated the optimal control objective of minimizing actuator power consumption as a mixed-integer quadratic program (MIQP) and solved for the global minimum. For a given actuator design and a wide range of simulated torque and rotation patterns, all corresponding to zero net work over one cycle, we compared optimized actuator energy consumption to that of an optimized gear motor with simple parallel elasticity. The simulated energy-recycling actuator consumed less electrical energy: 57% less on average and 80% less in the best case. These results demonstrate an effective approach to optimal control of this type of system, and suggest that energy-recycling actuators could substantially reduce power consumption in some robotics applications.
keywords: {Springs;Actuators;Torque;Power demand;Force;Robots;Gears;Optimization and optimal control;force control;prosthetics and exoskeletons},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196870&isnumber=9196508

T. Schoels, L. Palmieri, K. O. Arras and M. Diehl, "An NMPC Approach using Convex Inner Approximations for Online Motion Planning with Guaranteed Collision Avoidance," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3574-3580.
doi: 10.1109/ICRA40945.2020.9197206
Abstract: Even though mobile robots have been around for decades, trajectory optimization and continuous time collision avoidance remain subject of active research. Existing methods trade off between path quality, computational complexity, and kinodynamic feasibility. This work approaches the problem using a nonlinear model predictive control (NMPC) framework, that is based on a novel convex inner approximation of the collision avoidance constraint. The proposed Convex Inner ApprOximation (CIAO) method finds kinodynamically feasible and continuous time collision free trajectories, in few iterations, typically one. For a feasible initialization, the approach is guaranteed to find a feasible solution, i.e. it preserves feasibility. Our experimental evaluation shows that CIAO outperforms state of the art baselines in terms of planning efficiency and path quality. Experiments show that it also efficiently scales to high-dimensional systems. Furthermore real-world experiments demonstrate its capability of unifying trajectory optimization and tracking for safe motion planning in dynamic environments.
keywords: {Collision avoidance;Robots;Trajectory optimization;Planning;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197206&isnumber=9196508

M. Khansari, D. Kappler, J. Luo, J. Bingham and M. Kalakrishnan, "Action Image Representation: Learning Scalable Deep Grasping Policies with Zero Real World Data," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3597-3603.
doi: 10.1109/ICRA40945.2020.9197415
Abstract: This paper introduces Action Image, a new grasp proposal representation that allows learning an end-to-end deep-grasping policy. Our model achieves 84% grasp success on 172 real world objects while being trained only in simulation on 48 objects with just naive domain randomization. Similar to computer vision problems, such as object detection, Action Image builds on the idea that object features are invariant to translation in image space. Therefore, grasp quality is invariant when evaluating the object-gripper relationship; a successful grasp for an object depends on its local context, but is independent of the surrounding environment. Action Image represents a grasp proposal as an image and uses a deep convolutional network to infer grasp quality. We show that by using an Action Image representation, trained networks are able to extract local, salient features of grasping tasks that generalize across different objects and environments. We show that this representation works on a variety of inputs, including color images (RGB), depth images (D), and combined color-depth (RGB-D). Our experimental results demonstrate that networks utilizing an Action Image representation exhibit strong domain transfer between training on simulated data and inference on real-world sensor streams. Finally, our experiments show that a network trained with Action Image improves grasp success (84% vs. 53%) over a baseline model with the same structure, but using actions encoded as vectors.
keywords: {Grasping;Robot sensing systems;Image representation;Proposals;Grippers;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197415&isnumber=9196508

H. Cheng, D. Ho and M. Q. . -H. Meng, "High Accuracy and Efficiency Grasp Pose Detection Scheme with Dense Predictions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3604-3610.
doi: 10.1109/ICRA40945.2020.9197333
Abstract: Learning-based grasp pose detection algorithms have boosted the performance of robot grasping, but they usually need manually fine-tuning steps to find the balance between detection accuracy and efficient. In this paper, we discard these intermediate procedures, like sampling grasps and generating grasp proposals, and propose an end-to-end grasp pose detection model. Our model uses the RGB image as the input and predicts the single grasp pose in each small grid of the image. Furthermore, the best grasps are found by non-maximum suppression (NMS) strategy. The clustering and ranking procedures are left for NMS while the network only generates dense grasp predictions, which keeps the network simple and efficient. To achieve dense predictions, the predicted grasps of our detection model are represented by the 6 channels images with each pixel location representing a rated grasp. To the best of our knowledge, our model is the first neural network that attaches a grasp pose in pixel level. The model achieves 96.5% accuracy which costs 14ms for prediction of a 480√ó360 resolution RGB image in Cornell Grasp Dataset, and 90.4% robot grasping success rate for unknown objects with a parallel plate gripper in the real environment.
keywords: {Predictive models;Solid modeling;Grippers;Robots;Three-dimensional displays;Feature extraction;Image edge detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197333&isnumber=9196508

X. Chen et al., "Transferable Active Grasping and Real Embodied Dataset," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3611-3618.
doi: 10.1109/ICRA40945.2020.9197185
Abstract: Grasping in cluttered scenes is challenging for robot vision systems, as detection accuracy can be hindered by partial occlusion of objects. We adopt a reinforcement learning (RL) framework and 3D vision architectures to search for feasible viewpoints for grasping by the use of hand-mounted RGB-D cameras. To overcome the disadvantages of photo-realistic environment simulation, we propose a large-scale dataset called Real Embodied Dataset (RED), which includes full-viewpoint real samples on the upper hemisphere with amodal annotation and enables a simulator that has real visual feedback. Based on this dataset, a practical 3-stage transferable active grasping pipeline is developed, that is adaptive to unseen clutter scenes. In our pipeline, we propose a novel mask-guided reward to overcome the sparse reward issue in grasping and ensure category-irrelevant behavior. The grasping pipeline and its possible variants are evaluated with extensive experiments both in simulation and on a real-world UR-5 robotic arm.
keywords: {Grasping;Clutter;Cameras;Image segmentation;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197185&isnumber=9196508

P. Ni, W. Zhang, X. Zhu and Q. Cao, "PointNet++ Grasping: Learning An End-to-end Spatial Grasp Generation Algorithm from Sparse Point Clouds," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3619-3625.
doi: 10.1109/ICRA40945.2020.9196740
Abstract: Grasping for novel objects is important for robot manipulation in unstructured environments. Most of current works require a grasp sampling process to obtain grasp candidates, combined with local feature extractor using deep learning. This pipeline is time-costly, expecially when grasp points are sparse such as at the edge of a bowl.In this paper, we propose an end-to-end approach to directly predict the poses, categories and scores (qualities) of all the grasps. It takes the whole sparse point clouds as the input and requires no sampling or search process. Moreover, to generate training data of multi-object scene, we propose a fast multi-object grasp detection algorithm based on Ferrari Canny metrics. A single-object dataset (79 objects from YCB object set, 23.7k grasps) and a multi-object dataset (20k point clouds with annotations and masks) are generated. A PointNet++ based network combined with multi-mask loss is introduced to deal with different training points. The whole weight size of our network is only about 11.6M, which takes about 102ms for a whole prediction process using a GeForce 840M GPU. Our experiment shows our work get 71.43% success rate and 91.60% completion rate, which performs better than current state-of-art works.
keywords: {Three-dimensional displays;Feature extraction;Grasping;Measurement;Training;Cameras;Pipelines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196740&isnumber=9196508

S. Sajjan et al., "Clear Grasp: 3D Shape Estimation of Transparent Objects for Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3634-3642.
doi: 10.1109/ICRA40945.2020.9197518
Abstract: Transparent objects are a common part of everyday life, yet they possess unique visual properties that make them incredibly difficult for standard 3D sensors to produce accurate depth estimates for. In many cases, they often appear as noisy or distorted approximations of the surfaces that lie behind them. To address these challenges, we present ClearGrasp - a deep learning approach for estimating accurate 3D geometry of transparent objects from a single RGB-D image for robotic manipulation. Given a single RGB-D image of transparent objects, ClearGrasp uses deep convolutional networks to infer surface normals, masks of transparent surfaces, and occlusion boundaries. It then uses these outputs to refine the initial depth estimates for all transparent surfaces in the scene. To train and test ClearGrasp, we construct a large-scale synthetic dataset of over 50,000 RGB-D images, as well as a real-world test benchmark with 286 RGB-D images of transparent objects and their ground truth geometries. The experiments demonstrate that ClearGrasp is substantially better than monocular depth estimation baselines and is capable of generalizing to real-world images and novel objects. We also demonstrate that ClearGrasp can be applied out-of-the-box to improve grasping algorithms' performance on transparent objects. Code, data, and benchmarks will be released. Supplementary materials: https://sites.google.com/view/cleargrasp.
keywords: {Three-dimensional displays;Geometry;Estimation;Solid modeling;Cameras;Image edge detection;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197518&isnumber=9196508

G. Gao, M. Lauri, Y. Wang, X. Hu, J. Zhang and S. Frintrop, "6D Object Pose Regression via Supervised Learning on Point Clouds," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3643-3649.
doi: 10.1109/ICRA40945.2020.9197461
Abstract: This paper addresses the task of estimating the 6 degrees of freedom pose of a known 3D object from depth information represented by a point cloud. Deep features learned by convolutional neural networks from color information have been the dominant features to be used for inferring object poses, while depth information receives much less attention. However, depth information contains rich geometric information of the object shape, which is important for inferring the object pose. We use depth information represented by point clouds as the input to both deep networks and geometry-based pose refinement and use separate networks for rotation and translation regression. We argue that the axis-angle representation is a suitable rotation representation for deep learning, and use a geodesic loss function for rotation regression. Ablation studies show that these design choices outperform alternatives such as the quaternion representation and L2 loss, or regressing translation and rotation with the same network. Our simple yet effective approach clearly outperforms state-of-the-art methods on the YCB-video dataset.
keywords: {Three-dimensional displays;Pose estimation;Feature extraction;Image color analysis;Supervised learning;Rotation measurement;Quaternions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197461&isnumber=9196508

T. Grenzd√∂rffer, M. G√ºnther and J. Hertzberg, "YCB-M: A Multi-Camera RGB-D Dataset for Object Recognition and 6DoF Pose Estimation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3650-3656.
doi: 10.1109/ICRA40945.2020.9197426
Abstract: While a great variety of 3D cameras have been introduced in recent years, most publicly available datasets for object recognition and pose estimation focus on one single camera. In this work, we present a dataset of 32 scenes that have been captured by 7 different 3D cameras, totaling 49,294 frames. This allows evaluating the sensitivity of pose estimation algorithms to the specifics of the used camera and the development of more robust algorithms that are more independent of the camera model. Vice versa, our dataset enables researchers to perform a quantitative comparison of the data from several different cameras and depth sensing technologies and evaluate their algorithms before selecting a camera for their specific task. The scenes in our dataset contain 20 different objects from the common benchmark YCB object and model set [1], [2]. We provide full ground truth 6DoF poses for each object, per-pixel segmentation, 2D and 3D bounding boxes and a measure of the amount of occlusion of each object. We have also performed an initial evaluation of the cameras using our dataset on a state-of-the-art object recognition and pose estimation system [3].
keywords: {Cameras;Robot vision systems;Three-dimensional displays;Pose estimation;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197426&isnumber=9196508

X. Deng, Y. Xiang, A. Mousavian, C. Eppner, T. Bretl and D. Fox, "Self-supervised 6D Object Pose Estimation for Robot Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3665-3671.
doi: 10.1109/ICRA40945.2020.9196714
Abstract: To teach robots skills, it is crucial to obtain data with supervision. Since annotating real world data is time-consuming and expensive, enabling robots to learn in a self- supervised way is important. In this work, we introduce a robot system for self-supervised 6D object pose estimation. Starting from modules trained in simulation, our system is able to label real world images with accurate 6D object poses for self-supervised learning. In addition, the robot interacts with objects in the environment to change the object configuration by grasping or pushing objects. In this way, our system is able to continuously collect data and improve its pose estimation modules. We show that the self-supervised learning improves object segmentation and 6D pose estimation performance, and consequently enables the system to grasp objects more reliably. A video showing the experiments can be found at https://youtu.be/W1Y0Mmh1Gd8.
keywords: {Three-dimensional displays;Pose estimation;Cameras;Training;Manipulators;Grasping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196714&isnumber=9196508

A. C. Abad and A. Ranasinghe, "Low-cost GelSight with UV Markings: Feature Extraction of Objects Using AlexNet and Optical Flow without 3D Image Reconstruction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3680-3685.
doi: 10.1109/ICRA40945.2020.9197264
Abstract: GelSight sensor has been used to study microgeometry of objects since 2009 in tactile sensing applications. Elastomer, reflective coating, lighting, and camera were the main challenges of making a GelSight sensor within a short period. The recent addition of permanent markers to the GelSight was a new era in shear/slip studies. In our previous studies, we introduced Ultraviolet (UV) ink and UV LEDs as a new form of marker and lighting respectively. UV ink markers are invisible using ordinary LED but can be made visible using UV LED. Currently, recognition of objects or surface textures using GelSight sensor is done using fusion of camera-only images and GelSight captured images with permanent markings. Those images are fed to Convolutional Neural Networks (CNN) to classify objects. However, our novel approach in using low-cost GelSight sensor with UV markings, the 3D height map to 2D image conversion, and the additional non-Gelsight captured images for training the CNN can be eliminated. AlexNet and optical flow algorithm have been used for feature recognition of five coins without UV markings and shear/slip of the coin in GelSight with UV markings respectively. Our results on confusion matrix show that, on average coin recognition can reach 93.4% without UV markings using AlexNet. Therefore, our novel method of using GelSight with UV markings would be useful to recognize full/partial object, shear/slip, and force applied to the objects without any 3D image reconstruction.
keywords: {Prototypes;Light emitting diodes;Feature extraction;Image recognition;Three-dimensional displays;Lighting;Coatings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197264&isnumber=9196508

Z. Chua, A. M. Okamura and D. R. Deo, "Evaluation of Non-collocated Force Feedback Driven by Signal-independent Noise," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3686-3692.
doi: 10.1109/ICRA40945.2020.9197112
Abstract: Individuals living with paralysis or amputation can operate robotic prostheses using input signals based on their intent or attempt to move. Because sensory function is lost or diminished in these individuals, haptic feedback must be non-collocated. The intracortical brain computer interface (iBCI) has enabled a variety of neural prostheses for people with paralysis. An important attribute of the iBCI is that its input signal contains signal-independent noise. To understand the effects of signal-independent noise on a system with non-collocated haptic feedback and inform iBCI-based prostheses control strategies, we conducted an experiment with a conventional haptic interface as a proxy for the iBCI. Ablebodied users were tasked with locating an indentation within a virtual environment using input from their right hand. Non-collocated haptic feedback of the interaction forces in the virtual environment was augmented with noise of three different magnitudes and simultaneously rendered on users' left hands. We found increases in distance error of the guess of the indentation location, mean time per trial, mean peak absolute displacement and speed of tool movements during localization for the highest noise level compared to the other two levels. The findings suggest that users have a threshold of disturbance rejection and that they attempt to increase their signal-to-noise ratio through their exploratory actions.
keywords: {Force;Haptic interfaces;Task analysis;Noise measurement;Virtual environments;Signal to noise ratio;Probes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197112&isnumber=9196508

P. Nadeau, M. Abbott, D. Melville and H. S. Stuart, "Tactile sensing based on fingertip suction flow for submerged dexterous manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3701-3707.
doi: 10.1109/ICRA40945.2020.9197582
Abstract: The ocean is a harsh and unstructured environment for robotic systems; high ambient pressures, saltwater corrosion and low-light conditions demand machines with robust electrical and mechanical parts that are able to sense and respond to the environment. Prior work shows that the addition of gentle suction flow to the hands of underwater robots can aid in the handling of objects during mobile manipulation tasks. The current paper explores using this suction flow mechanism as a new modality for tactile sensing; by monitoring orifice occlusion we can get a sense of how objects make contact in the hand. The electronics required for this sensor can be located remotely from the hand and the signal is insensitive to large changes in ambient pressure associated with diving depth. In this study, suction is applied to the fingertips of a two-fingered compliant gripper and suction-based tactile sensing is monitored while an object is pulled out of a pinch grasp. As a proof of concept, a recurrent neural network model was trained to predict external force trends using only the suction signals. This tactile sensing modality holds the potential to enable automated robotic behaviors or to provide operators of remotely operated vehicles with additional feedback in a robust fashion suitable for ocean deployment.
keywords: {Electron tubes;Sea measurements;Tactile sensors;Oceans},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197582&isnumber=9196508

L. G. Camara, C. G√§bert and L. P≈ôeuƒçil, "Highly Robust Visual Place Recognition Through Spatial Matching of CNN Features," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3748-3755.
doi: 10.1109/ICRA40945.2020.9196967
Abstract: We revise, improve and extend the system previously introduced by us and named SSM-VPR (Semantic and Spatial Matching Visual Place Recognition), largely boosting its performance above the current state of the art. The system encodes images of places by employing the activations of different layers of a pre-trained, off-the-shelf, VGG16 Convolutional Neural Network (CNN) architecture. It consists of two stages: given a query image of a place, (1) a list of candidates is selected from a database of places and (2) the candidates are geometrically compared with the query. The comparison is made by matching CNN features and, equally important, their spatial locations, selecting the best candidate as the recognized place. The performance of the system is maximized by finding optimal image resolutions during the second stage and by exploiting temporal correlation between consecutive frames in the employed datasets.
keywords: {Visualization;Robustness;Semantics;Task analysis;Histograms;Correlation;Simultaneous localization and mapping;Visual Place Recognition;Convolutional Neural Networks;SLAM;Loop Closure;Life-long Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196967&isnumber=9196508

A. Duburcq, Y. Chevaleyre, N. Bredeche and G. Bo√©ris, "Online Trajectory Planning Through Combined Trajectory Optimization and Function Approximation: Application to the Exoskeleton Atalante," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3756-3762.
doi: 10.1109/ICRA40945.2020.9196633
Abstract: Autonomous robots require online trajectory planning capability to operate in the real world. Efficient offline trajectory planning methods already exist, but are computationally demanding, preventing their use online. In this paper, we present a novel algorithm called Guided Trajectory Learning that learns a function approximation of solutions computed through trajectory optimization while ensuring accurate and reliable predictions. This function approximation is then used online to generate trajectories. This algorithm is designed to be easy to implement, and practical since it does not require massive computing power. It is readily applicable to any robotics systems and effortless to set up on real hardware since robust control strategies are usually already available. We demonstrate the computational performance of our algorithm on flat-foot walking with the self-balanced exoskeleton Atalante.
keywords: {Trajectory optimization;Function approximation;Task analysis;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196633&isnumber=9196508

M. Colledanchise, D. Malafronte and L. Natale, "Act, Perceive, and Plan in Belief Space for Robot Localization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3763-3769.
doi: 10.1109/ICRA40945.2020.9197097
Abstract: In this paper, we outline an interleaved acting and planning technique to rapidly reduce the uncertainty of the estimated robot's pose by perceiving relevant information from the environment, as recognizing an object or asking someone for a direction. Generally, existing localization approaches rely on low-level geometric features such as points, lines, and planes. While these approaches provide the desired accuracy, they may require time to converge, especially with incorrect initial guesses. In our approach, a task planner computes a sequence of action and perception tasks to actively obtain relevant information from the robot's perception system. We validate our approach in large state spaces, to show how the approach scales, and in real environments, to show the applicability of our method on real robots. We prove that our approach is sound, probabilistically complete, and tractable in practical cases.
keywords: {Uncertainty;Planning;Task analysis;Object detection;Robot sensing systems;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197097&isnumber=9196508

R. Patel, E. Rudnick-Cohen, S. Azarm, M. Otte, H. Xu and J. W. Herrmann, "Decentralized Task Allocation in Multi-Agent Systems Using a Decentralized Genetic Algorithm," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3770-3776.
doi: 10.1109/ICRA40945.2020.9197314
Abstract: In multi-agent collaborative search missions, task allocation is required to determine which agents will perform which tasks. We propose a new approach for decentralized task allocation based on a decentralized genetic algorithm (GA). The approach parallelizes a genetic algorithm across the team of agents, making efficient use of their computational resources. In the proposed approach, the agents continuously search for and share better solutions during task execution. We conducted simulation experiments to compare the decentralized GA approach and several existing approaches. Two objectives were considered: a min-sum objective (minimizing the total distance traveled by all agents) and a min-time objective (minimizing the time to visit all locations of interest). The results showed that the decentralized GA approach yielded task allocations that were better on the min-time objective than those created by existing approaches and solutions that were reasonable on the min-sum objective. The decentralized GA improved min-time performance by an average of 5.6% on the larger instances. The results indicate that decentralized evolutionary approaches have a strong potential for solving the decentralized task allocation problem.
keywords: {Task analysis;Resource management;Genetic algorithms;Sociology;Statistics;Cost function;Message systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197314&isnumber=9196508

C. Nam, J. Lee, S. Hun Cheong, B. Y. Cho and C. Kim, "Fast and resilient manipulation planning for target retrieval in clutter," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3777-3783.
doi: 10.1109/ICRA40945.2020.9196652
Abstract: This paper presents a task and motion planning (TAMP) framework for a robotic manipulator in order to retrieve a target object from clutter. We consider a configuration of objects in a confined space with a high density so no collision-free path to the target exists. The robot must relocate some objects to retrieve the target without collisions. For fast completion of object rearrangement, the robot aims to optimize the number of pick-and-place actions which often determines the efficiency of a TAMP framework.We propose a task planner incorporating motion planning to generate executable plans which aims to minimize the number of pick-and-place actions. In addition to fully known and static environments, our method can deal with uncertain and dynamic situations incurred by occluded views. Our method is shown to reduce the number of pick-and-place actions compared to baseline methods (e.g., at least 28.0% of reduction in a known static environment with 20 objects).
keywords: {Planning;Task analysis;Clutter;Collision avoidance;Manipulators;Search problems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196652&isnumber=9196508

A. Bhattacharjee, L. W. Rogowski, X. Zhang and M. J. Kim, "Untethered Soft Millirobot with Magnetic Actuation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3792-3798.
doi: 10.1109/ICRA40945.2020.9197202
Abstract: This paper presents scalable designs and fabrication, actuation, and manipulation techniques for soft millirobots under uniform magnetic field control. The millirobots were fabricated through an economic and robust moulding technique using polydimethylsiloxane (PDMS), acrylonitrile butadiene styrene (ABS) filaments, and 3D printed polylactic acid (PLA) rings. The soft millirobots were simple hollow rod-like structures with different configurations of embedded permanent magnets inside of their soft-body or at their ends. The soft-robots were actuated using six different motion modes including: pivot walking, rolling, tumbling, side-tapping, wiggling, and wavy-motion under an external uniform magnetic field control system. The velocities of the millirobots under different motion modes were analyzed under varying magnetic flux densities (B). Moreover, deformation of the soft-robotic body in response to the magnetic field strength was measured and a deflection curve showing bending angle (œÜ) was produced. Soft millirobots were navigated through a maze using a combination of the available motion modes. Different arrangements of the embedded permanent magnets enabled individual soft millirobots to respond heterogeneously under the same magnetic field inputs towards performing assembly and disassembly operation as modular subunits. Overall, this soft millirobot platform shows enormous potential for minimally invasive in vivo applications.
keywords: {Robots;Permanent magnets;Magnetic resonance imaging;Programmable logic arrays;Fabrication;Plastics;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197202&isnumber=9196508

I. Akinola et al., "Accelerated Robot Learning via Human Brain Signals," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3799-3805.
doi: 10.1109/ICRA40945.2020.9196566
Abstract: In reinforcement learning (RL), sparse rewards are a natural way to specify the task to be learned. However, most RL algorithms struggle to learn in this setting since the learning signal is mostly zeros. In contrast, humans are good at assessing and predicting the future consequences of actions and can serve as good reward/policy shapers to accelerate the robot learning process. Previous works have shown that the human brain generates an error-related signal, measurable using electroencephelography (EEG), when the human perceives the task being done erroneously. In this work, we propose a method that uses evaluative feedback obtained from human brain signals measured via scalp EEG to accelerate RL for robotic agents in sparse reward settings. As the robot learns the task, the EEG of a human observer watching the robot attempts is recorded and decoded into noisy error feedback signal. From this feedback, we use supervised learning to obtain a policy that subsequently augments the behavior policy and guides exploration in the early stages of RL. This bootstraps the RL learning process to enable learning from sparse reward. Using a simple robotic navigation task as a test bed, we show that our method achieves a stable obstacle-avoidance policy with high success rate, outperforming learning from sparse rewards only that struggles to achieve obstacle avoidance behavior or fails to advance to the goal.
keywords: {Task analysis;Robots;Electroencephalography;Navigation;Hafnium;Learning (artificial intelligence);Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196566&isnumber=9196508

R. Okatani et al., "Muscle and Brain Activations in Cylindrical Rotary Controller Manipulation with Index Finger and Thumb," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3806-3811.
doi: 10.1109/ICRA40945.2020.9196520
Abstract: This study aim to confirm the effect of viscosity characteristics differences on the rotational manipulation of a cylindrical rotary controller with the index finger and thumb through a quantitative analysis and evaluation of muscle and brain activations. The target motion was a rotary manipulation with the index finger and thumb of a cylindrical rotary controller with a 50 mm diameter. The rotary motion of the controller produces a click sensation at every 12 degrees in the rotation. The experimental conditions were three conditions with different viscosity characteristics related to the rotary motion of the controller. The subjects were six right-handed healthy males with a mean age of 21.7 (S. D.: 1.03) years. We analyzed the brain activity from a near- infrared spectroscopy measurement system, the muscles activity using a surface myoelectric potential measurement device, the force data at the index finger and thumb tip using two independent six-axis force/torque sensors, and the position data using a 3D position measurement device. The experimental results showed that there was no significant difference in the questionnaire survey, muscle activity, and grasping force, respectively; however, a significant difference in brain activity was observed with increased controller viscosity. Therefore, it became clear that there was a change in the brain activity when rotating the cylindrical rotary controller with the viscosity characteristics related to the rotary motion.
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196520&isnumber=9196508

B. Specht, Z. Tayeb, E. Dean, R. Soroushmojdehi and G. Cheng, "Real-Time Robot Reach-To-Grasp Movements Control Via EOG and EMG Signals Decoding," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3812-3817.
doi: 10.1109/ICRA40945.2020.9197550
Abstract: In this paper, we propose a real-time human-robot interface (HRI) system, where Electrooculography (EOG) and Electromyography (EMG) signals were decoded to perform reach-to-grasp movements. For that, five different eye movements (up, down, left, right and rest) were classified in real-time and translated into commands to steer an industrial robot (UR-10) to one of the four approximate target directions. Thereafter, EMG signals were decoded to perform the grasping task using an attached gripper to the UR-10 robot arm. The proposed system was tested offline on three different healthy subjects, and mean validation accuracy of 93.62% and 99.50% were obtained across the three subjects for EOG and EMG decoding, respectively. Furthermore, the system was successfully tested in real-time with one subject, and mean online accuracy of 91.66% and 100% were achieved for EOG and EMG decoding, respectively. Our results obtained by combining real-time decoding of EOG and EMG signals for robot control show overall the potential of this approach to develop powerful and less complex HRI systems. Overall, this work provides a proof-of-concept for successful real-time control of robot arms using EMG and EOG signals, paving the way for the development of more dexterous and human-controlled assistive devices.
keywords: {Electrooculography;Electromyography;Real-time systems;Decoding;Electrodes;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197550&isnumber=9196508

D. Kim et al., "Simultaneous Estimations of Joint Angle and Torque in Interactions with Environments using EMG," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3818-3824.
doi: 10.1109/ICRA40945.2020.9197441
Abstract: We develop a decoding technique that estimates both the position and torque of a joint of the limb in interaction with an environment based on activities of the agonist-antagonist pair of muscles using electromyography in real time. The long short-term memory (LSTM) network is employed as the core processor of the proposed technique that is capable of learning time series of a long-time span with varying time lags. A validation that is conducted on the wrist joint shows that the decoding approach provides an agreement of greater than 95% in kinetics (i.e. torque) estimation and an agreement of greater than 85% in kinematics (i.e. angle) estimation, between the actual and estimated variables, during interactions with an environment. Also demonstrated is the fact that the proposed decoding method inherits the strengths of the LSTM network in terms of the capability of learning EMG signals and the corresponding responses with time dependency.
keywords: {Electromyography;Torque;Decoding;Wrist;Logic gates;Neural networks;Kinematics;Human-machine interaction;Electromyography (EMG);Decoding;Machine learning;Prosthesis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197441&isnumber=9196508

A. Dwivedi, J. Lara, L. K. Cheng, N. Paskaranandavadivel and M. Liarokapis, "High-Density Electromyography Based Control of Robotic Devices: On the Execution of Dexterous Manipulation Tasks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3825-3831.
doi: 10.1109/ICRA40945.2020.9196629
Abstract: Electromyography (EMG) based interfaces have been used in various robotics studies ranging from teleoperation and telemanipulation applications to the EMG based control of prosthetic, assistive, or robotic rehabilitation devices. But most of these studies have focused on the decoding of user's motion or on the control of the robotic devices in the execution of simple tasks (e.g., grasping tasks). In this work, we present a learning scheme that employs High Density Electromyography (HD-EMG) sensors to decode a set of dexterous, in-hand manipulation motions (in the object space) based on the myoelectric activations of human forearm and hand muscles. To do that, the subjects were asked to perform roll, pitch, and yaw motions manipulating two different cubes. The first cube was designed to have a center of mass coinciding with the geometric center of the cube, while for the second cube the center of mass was shifted 14 mm to the right (off-centered design). Regarding the acquisition of the myoelectric data, custom HD-EMG electrode arrays were designed and fabricated. Using these arrays, a total of 89 EMG signals were extracted. The object motion decoding was formulated as a regression problem using the Random Forests (RF) technique and the muscle importances were studied using the inherent feature variables importance calculation procedure of the RF. The muscle importance results show that different subjects use different strategies to execute the same motions on same object when the weight is off-centered. Finally, the decoded motions were used to control a five fingered robotic hand in a proof-of-concept application.
keywords: {Muscles;Electromyography;Task analysis;Electrodes;Robots;Decoding;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196629&isnumber=9196508

A. Valiton and Z. Li, "Perception-Action Coupling in Usage of Telepresence Cameras," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3846-3852.
doi: 10.1109/ICRA40945.2020.9197578
Abstract: Telepresence tele-action robots enable human workers to reliably perform difficult tasks in remote, cluttered, and human environments. However, the effort to control coordinated manipulation and active perception motions may exhaust and intimidate novice workers. We hypothesize that such cognitive efforts would be effectively reduced if the teleoperators are provided with autonomous camera selection and control aligned with the natural perception-action coupling of the human motor system. Thus, we conducted a user study to investigate the coordination of active perception control and manipulation motions performed with visual feedback from various wearable and standalone cameras in a telepresence scenario. Our study discovered rich information about telepresence camera selection to inform telepresence system configuration and possible teleoperation assistance design for reduced cognitive effort in robot teleoperation.
keywords: {Cameras;Task analysis;Robot vision systems;Robot kinematics;Telepresence;Teleoperators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197578&isnumber=9196508

G. Averta, D. Caporale, C. D. Santina, A. Bicchi and M. Bianchi, "A technical framework for human-like motion generation with autonomous anthropomorphic redundant manipulators," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3853-3859.
doi: 10.1109/ICRA40945.2020.9196937
Abstract: The need for users' safety and technology accept-ability has incredibly increased with the deployment of co-bots physically interacting with humans in industrial settings, and for people assistance. A well-studied approach to meet these requirements is to ensure human-like robot motions. Classic solutions for anthropomorphic movement generation usually rely on optimization procedures, which build upon hypotheses devised from neuroscientific literature, or capitalize on learning methods. However, these approaches come with limitations, e.g. limited motion variability or the need for high dimensional datasets. In this work, we present a technique to directly embed human upper limb principal motion modes computed through functional analysis in the robot trajectory optimization. We report on the implementation with manipulators with redundant anthropomorphic kinematic architectures - although dissimilar with respect to the human model used for functional mode extraction - via Cartesian impedance control. In our experiments, we show how human trajectories mapped onto a robotic manipulator still exhibit the main characteristics of human-likeness, e.g. low jerk values. We discuss the results with respect to the state of the art, and their implications for advanced human-robot interaction in industrial co-botics and for human assistance.
keywords: {Kinematics;Manipulators;Trajectory;Computer architecture;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196937&isnumber=9196508

S. Zhang, Y. Chen, J. Zhang and Y. Jia, "Real-Time Adaptive Assembly Scheduling in Human-Multi-Robot Collaboration According to Human Capability," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3860-3866.
doi: 10.1109/ICRA40945.2020.9196618
Abstract: Human-multi-robot collaboration is becoming more and more common in intelligent manufacturing. Optimal assembly scheduling of such systems plays a critical role in their production efficiency. Existing approaches mostly consider humans as agents with assumed or known capabilities, which leads to suboptimal performance in realistic applications where human capabilities usually change. In addition, most robot adaptation focuses on human-single-robot interaction and the adaptation in human-multi-robot interaction with changing human capability still remains challenging due to the complexity of the heterogeneous multi-agent interactions. This paper proposes a real-time adaptive assembly scheduling approach for human-multi-robot collaboration by modeling and incorporating changing human capability. A genetic algorithm is also designed to derive implementable solutions for the formulated adaptive assembly scheduling problem. The proposed approaches are validated through different simulated human-multi-robot assembly tasks and the results demonstrate the effectiveness and advantages of the proposed approaches.
keywords: {Robots;Job shop scheduling;Task analysis;Real-time systems;Schedules;Adaptive scheduling;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196618&isnumber=9196508

J. Xia et al., "Microscope-Guided Autonomous Clear Corneal Incision," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3867-3873.
doi: 10.1109/ICRA40945.2020.9196645
Abstract: Clear Corneal Incision, a challenging step in cataract surgery, and important to the overall quality of the surgery. New surgeons usually spend one full year trying to perfect their incision, but even after such rigorous training deficient incisions can still occur. This paper proposes an autonomous robotic system for this self-sealing incision. A conventional ophthalmic microscope system with a monocular camera is utilized to capture the surgical scene, ascertain the robot's position, and estimate depth information. Kinematics with a remote centre of motion (RCM) is designed for a multi-axes robot to perform the incision route. The experimental results on ex-vivo porcine eyes show the autonomous Clear Corneal Incision has a stricter three-plane structure than a surgeon-made incision, which is closer to the ideal incision.
keywords: {Robots;Surgery;Feature extraction;Iris;Cameras;Mirrors;Cataracts},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196645&isnumber=9196508

J. R. J. Realpe, G. Aiche, S. Abdelaziz and P. Poignet, "Asynchronous and decoupled control of the position and the stiffness of a spatial RCM tensegrity mechanism for needle manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3882-3888.
doi: 10.1109/ICRA40945.2020.9197507
Abstract: This paper introduces a 2-DOF spatial remote center of motion (RCM) tensegrity mechanism, based on a double parallelogram system, dedicated for percutaneous needle insertion. The originality of this mechanism is its ability to be reconfigured and its capacity to perform a decoupled modulation of its stiffness in an asynchronous way. To do so, an analytical stiffness model of the robot is established, and a control methodology is proposed. A prototype of the robot is developed and assessed experimentally. The position tracking is evaluated using a 6-DOF magnetic tracker sensor showing a root mean square error less than 0.8¬∞ in both directions of the needle guide.
keywords: {Needles;Kinematics;Mathematical model;Actuators;Modulation;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197507&isnumber=9196508

J. C. Santos, A. Chemori and M. Gouttefarde, "Redundancy Resolution Integrated Model Predictive Control of CDPRs: Concept, Implementation and Experiments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3889-3895.
doi: 10.1109/ICRA40945.2020.9197271
Abstract: This paper introduces a Model Predictive Control (MPC) strategy for fully-constrained Cable-Driven Parallel Robots. The main advantage of the proposed scheme lies in its ability to explicitly handle cable tension limits. Indeed, the cable tension distribution is performed as an integral part of the main control architecture. This characteristic significantly improves the safety of the system. Experimental results demonstrate this advantage addressing a typical pick-and-place task with two different scenarios: nominal cable tension limits and reduced maximum tension. Satisfactory tracking errors were obtained in the first scenario. In the second scenario, the desired trajectory escapes from the workspace defined by the new set of tension limits. The proposed MPC scheme is able to minimize the tracking errors without violating the tension limits. Satisfying results were also obtained regarding robustness against uncertainties on the payload mass.
keywords: {Power cables;Robots;Real-time systems;Kinematics;Payloads;Safety;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197271&isnumber=9196508

P. S. Gonthina, M. B. Wooten, I. S. Godage and I. D. Walker, "Mechanics for Tendon Actuated Multisection Continuum Arms," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3896-3902.
doi: 10.1109/ICRA40945.2020.9197006
Abstract: Tendon actuated multisection continuum arms have high potential for inspection applications in highly constrained spaces. They generate motion by axial and bending deformations. However, because of the high mechanical coupling between continuum sections, variable length-based kinematic models produce poor results. A new mechanics model for tendon actuated multisection continuum arms is proposed in this paper. The model combines the continuum arm curve parameter kinematics and concentric tube kinematics to correctly account for the large axial and bending deformations observed in the robot. Also, the model is computationally efficient and utilizes tendon tensions as the joint space variables thus eliminating the actuator length related problems such as slack and backlash. A recursive generalization of the model is also presented. Despite the high coupling between continuum sections, numerical results show that the model can be used for generating correct forward and inverse kinematic results. The model is then tested on a thin and long multisection continuum arm. The results show that the model can be used to successfully model the deformation.
keywords: {Tendons;Robots;Computational modeling;Strain;Numerical models;Kinematics;Deformable models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197006&isnumber=9196508

S. Xiang, H. Gao, Z. Liu and C. Gosselin, "Trajectory Optimization for a Six-DOF Cable-Suspended Parallel Robot with Dynamic Motions Beyond the Static Workspace," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3903-3908.
doi: 10.1109/ICRA40945.2020.9196803
Abstract: This paper presents a trajectory optimization formulation for planning dynamic trajectories of a six-degree-of-freedom (six-DOF) cable-suspended parallel robot (CSPR) that extend beyond the static workspace. The optimization is guided by low-dimensional dynamic models to overcome the local minima and accelerate the exploration of the narrow feasible state space. The dynamic similarity between the six-DOF CSPR and the three-DOF point-mass CSPR is discussed with the analyses of their feasible force polyhedra. Finally, the transition trajectories of a three-DOF CSPR are used as the initial guess of the translational part of the six-DOF motion. With the proposed approach, highly dynamic motions for a six-DOF CSPR are efficiently generated with multiple oscillations. The feasibility is demonstrated by point-to-point and periodic trajectories in the physics simulation.
keywords: {Dynamics;Planning;Robots;Trajectory optimization;Chebyshev approximation;Dynamic trajectory planning;optimization and optimal control;cable-suspended parallel robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196803&isnumber=9196508

J. Kim, J. Seol, S. Lee, S. -W. Hong and H. I. Son, "An Intelligent Spraying System with Deep Learning-based Semantic Segmentation of Fruit Trees in Orchards," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3923-3929.
doi: 10.1109/ICRA40945.2020.9197556
Abstract: This study proposes an intelligent spraying system with semantic segmentation of fruit trees in a pear orchard. A fruit tree detection system was developed using the SegNet model, a semantic segmentation structure. The system is trained with images categorized into five distinct classes. The learned deep learning model performed with an accuracy of 83.79%. Further, we fusion depth data from an RGB-D camera to prevent the tree in the background from being detected. To operate the nozzles, each image captured from the camera is separated lengthwise into quarters and mapped to the nozzles. Then, the nozzle was opened when the area of fruit trees in each zone exceeded 20%. Two types of field experiments were performed in a pear orchard to verify the effectiveness of our system. From the results obtained, we can confirm the satisfactory performance of our deep learning-based intelligent spraying system. It is expected that the introduction of this system to actual farms will signicantly reduce the amount of pesticide used and will make the work environment safer for farmers.
keywords: {Spraying;Cameras;Semantics;Image segmentation;Vegetation;Decoding;Machine learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197556&isnumber=9196508

A. You, F. Sukkar, R. Fitch, M. Karkee and J. R. Davidson, "An Efficient Planning and Control Framework for Pruning Fruit Trees," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3930-3936.
doi: 10.1109/ICRA40945.2020.9197551
Abstract: Dormant pruning is a major cost component of fresh market tree fruit production, nearly equal in scale to harvesting the fruit. However, relatively little focus has been given to the problem of pruning trees autonomously. In this paper, we introduce a robotic system consisting of an industrial manipulator, an eye-in-hand RGB-D camera configuration, and a custom pneumatic cutter. The system is capable of planning and executing a sequence of cuts while making minimal assumptions about the environment. We leverage a novel planning framework designed for high-throughput operation which builds upon previous work to reduce motion planning time and sequence cut points intelligently. In end-to-end experiments with a set of ten different branch configurations, the system achieved a high success rate in plan execution and a 1.5x speedup in throughput versus a baseline planner, representing a significant step towards the goal of practical implementation of robotic pruning.
keywords: {Planning;Cameras;Three-dimensional displays;Manipulators;Vegetation;Pipelines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197551&isnumber=9196508

A. Binch, G. P. Das, J. Pulido Fentanes and M. Hanheide, "Context Dependant Iterative Parameter Optimisation for Robust Robot Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3937-3943.
doi: 10.1109/ICRA40945.2020.9196550
Abstract: Progress in autonomous mobile robotics has seen significant advances in the development of many algorithms for motion control and path planning. However, robust performance from these algorithms can often only be expected if the parameters controlling them are tuned specifically for the respective robot model, and optimised for specific scenarios in the environment the robot is working in. Such parameter tuning can, depending on the underlying algorithm, amount to a substantial combinatorial challenge, often rendering extensive manual tuning of these parameters intractable. In this paper, we present a framework that permits the use of different navigation actions and/or parameters depending on the spatial context of the navigation task. We consider the respective navigation algorithms themselves mostly as a "black box", and find suitable parameters by means of an iterative optimisation, improving for performance metrics in simulated environments. We present a genetic algorithm incorporated into the framework, and empirically show that the resulting parameter sets lead to substantial performance improvements in both simulated and real-world environments in the domain of agricultural robots.
keywords: {Navigation;Robots;Optimization;Tuning;Robustness;Genetic algorithms;Measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196550&isnumber=9196508

B. Wingo, C. -A. Cheng, M. Murtaza, M. Zafar and S. Hutchinson, "Extending Riemmanian Motion Policies to a Class of Underactuated Wheeled-Inverted-Pendulum Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3967-3973.
doi: 10.1109/ICRA40945.2020.9196866
Abstract: Riemannian Motion Policies (RMPs) have recently been introduced as a way to specify second-order motion policies defined on robot task spaces. RMP-based approaches have the advantage of being more general than traditional approaches based on operational space control; for example, the generalized task inertia in an RMP can be fully state-dependent, which is particularly effective in designing collision avoidance bahaviors. But until now RMPs have been applied only to fully actuated systems, i.e. systems for which each degree of freedom (DoF) can be directly actuated by a control input. In this paper, we present a method that extends the RMP formalism to a class of underacutated systems whose dynamics are amenable to a decomposition into a fully-actuated subsystem and a residual dynamics. We show the efficacy of the approach by constructing a suitable decomposition for a Wheeled-Inverted-Pendulum (WIP) humanoid robot and applying our method to derive motion policies for combined locomotion and manipulation tasks. Simulation results are presented for a 7-DoF system with one degree of underactuation.
keywords: {Task analysis;Manifolds;Manipulator dynamics;Aerospace electronics;Humanoid robots;Measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196866&isnumber=9196508

T. Howison, F. Giardina and F. Iida, "Augmenting Self-Stability: Height Control of a Bernoulli Ball via Bang-Bang Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3974-3980.
doi: 10.1109/ICRA40945.2020.9197391
Abstract: Mechanical self-stability is often useful for controlling systems in uncertain and unstructured environments because it can regulate processes without explicit state observation or feedback computation. However, the performance of such systems is often not optimised, which begs the question how their dynamics can be naturally augmented by a control law to improve performance metrics. We propose a minimalistic approach to controlling mechanically self-stabilising systems by utilising model-based, feedforward bang-bang control at a global level and self-stabilizing dynamics at a local level. We demonstrate the approach in the height control problem of a sphere hovering in a vertical air jet - the so-called Bernoulli Ball. After developing a model to study the system and theoretically proving global asymptotic stability, we present the augmented controller and show how to enhance performance measures and plan behaviour. Our physical experiments show that the proposed control approach has a reduced time-to-target compared to the uncontrolled system without loss of stability (ranging from a 2.4 to 4.4 fold improvement) and that we can plan sequences of target positions at will.
keywords: {Atmospheric modeling;Dynamics;Mathematical model;Force;Asymptotic stability;Bang-bang control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197391&isnumber=9196508

S. A. Tafrishi, M. Svinin and M. Yamamoto, "Singularity-Free Inverse Dynamics for Underactuated Systems with a Rotating Mass," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3981-3987.
doi: 10.1109/ICRA40945.2020.9197306
Abstract: Motion control of underactuated systems through the inverse dynamics contains configuration singularities. These limitations in configuration space mainly stem from the inertial coupling that passive joints/bodies create. In this study, we present a model that is free from singularity while the trajectory of the rotating mass has a small-amplitude sine wave around its circle. First, we derive the modified non-linear dynamics for a rolling system. Also, the singularity regions for this underactuated system is demonstrated. Then, the wave parameters are designed under certain conditions to remove the coupling singularities. We obtain these conditions from the positive definiteness of the inertia matrix in the inverse dynamics. Finally, the simulation results are confirmed by using a prescribed Beta function on the specified states of the rolling carrier. Because our algebraic method is integrated into the non-linear dynamics, the proposed solution has a great potential to be extended to the Lagrangian mechanics with multiple degrees-of-freedom.
keywords: {Mathematical model;Couplings;Integrated circuits;Trajectory;Kinematics;Robots;Tensile stress},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197306&isnumber=9196508

P. E. Glick, N. Van Crey, M. T. Tolley and D. Ruffatto, "Robust capture of unknown objects with a highly under-actuated gripper," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 3996-4002.
doi: 10.1109/ICRA40945.2020.9197100
Abstract: Capturing large objects of unknown shape and orientation remains a challenge for most robotic grippers. We present a highly under-actuated gripper well suited for this task. Prior work shows two primary limitations to these grippers: the grip force of each link tends to decrease as the number of links increases, and the stability of an under-actuated linkage depends on the configuration of the links so grippers with many links are unlikely to be stable for arbitrary surfaces. We address these concerns by implementing two complementary methods of stabilization: using high-friction materials and scaling forces into the surface. We show that gecko-inspired adhesives provide an adhesion-controlled friction that can stabilize the gripper and improve grasp performance without the need of large normal forces. The under-actuated linkages also conform around arbitrary shapes and provide capability beyond prior adhesion-based grippers. With these high-friction interfaces, we show highly under-actuated linkages successfully grasp in many configurations without strict stability. The gripper is capable of holding over 30 N and consists of two tendon driven linkages that are each 65 cm long. This type of gripper is well suited for tasks without a predefined target geometry or orientation such as satellite servicing.
keywords: {Grippers;Friction;Couplings;Stability analysis;Force;Torque;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197100&isnumber=9196508

P. Cai, Y. Lee, Y. Luo and D. Hsu, "SUMMIT: A Simulator for Urban Driving in Massive Mixed Traffic," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4023-4029.
doi: 10.1109/ICRA40945.2020.9197228
Abstract: Autonomous driving in an unregulated urban crowd is an outstanding challenge, especially, in the presence of many aggressive, high-speed traffic participants. This paper presents SUMMIT, a high-fidelity simulator that facilitates the development and testing of crowd-driving algorithms. By leveraging the open-source OpenStreetMap map database and a heterogeneous multi-agent motion prediction model developed in our earlier work, SUMMIT simulates dense, unregulated urban traffic for heterogeneous agents at any worldwide locations that OpenStreetMap supports. SUMMIT is built as an extension of CARLA and inherits from it the physics and visual realism for autonomous driving simulation. SUMMIT supports a wide range of applications, including perception, vehicle control and planning, and end-to-end learning. We provide a context-aware planner together with benchmark scenarios and show that SUMMIT generates complex, realistic traffic behaviors in challenging crowd-driving settings.
keywords: {Roads;Robot sensing systems;Context modeling;Planning;Automobiles;Geometry;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197228&isnumber=9196508

A. G. Dharmawan, Y. Xiong, S. Foong and G. Song Soh, "A Model-Based Reinforcement Learning and Correction Framework for Process Control of Robotic Wire Arc Additive Manufacturing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4030-4036.
doi: 10.1109/ICRA40945.2020.9197222
Abstract: Robotic Wire Arc Additive Manufacturing (WAAM) utilizes a robot arm as a motion system to build 3D metallic objects by depositing weld beads one above the other in a layer by layer fashion. A key part of this approach is the process study and control of Multi-Layer Multi-Bead (MLMB) deposition, which is very sensitive to process parameters and prone to error stacking. Despite its importance, it has been receiving less attention than its single bead counterpart in literature, probably due to the higher experimental overhead and complexity of modeling. To address these challenges, this paper proposes an integrated learning-correction framework, adapted from Model-Based Reinforcement Learning, to iteratively learn the direct effect of process parameters on MLMB print while simultaneously correct for any inter-layer geometric digression such that the final output is still satisfactory. The advantage is that this learning architecture can be used in conjunction with actual parts printing (hence, in-situ study), thus minimizing the required training time and material wastage. The proposed learning framework is implemented on an actual robotic WAAM system and experimentally evaluated.
keywords: {Training;Predictive models;Process control;Adaptation models;Printing;Robots;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197222&isnumber=9196508

C. Yoo, S. Lensgraf, R. Fitch, L. M. Clemon and R. Mettu, "Toward Optimal FDM Toolpath Planning with Monte Carlo Tree Search," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4037-4043.
doi: 10.1109/ICRA40945.2020.9196945
Abstract: The most widely used methods for toolpath planning in 3D printing slice the input model into successive 2D layers to construct the toolpath. Unfortunately the methods can incur a substantial amount of wasted motion (i.e., the extruder is moving while not printing). In recent years we have introduced a new paradigm that characterizes the space of feasible toolpaths using a dependency graph on the input model, along with several algorithms that optimize objective functions (wasted motion or print time). A natural question that arises is, under what circumstances can we efficiently compute an optimal toolpath? In this paper, we give an algorithm for computing fused deposition modeling (FDM) toolpaths that utilizes Monte Carlo Tree Search (MCTS), a powerful generalpurpose method for navigating large search spaces that is guaranteed to converge to the optimal solution. Under reasonable assumptions on printer geometry that allow us to compress the dependency graph, our MCTS-based algorithm converges to find the optimal toolpath. We validate our algorithm on a dataset of 75 models and examine the performance on MCTS against our previous best local search-based algorithm in terms of toolpath quality. We show that a relatively short time budget for MCTS yields results on par with local search, while a larger time budget yields a 15% improvement in quality over local search. Additionally, we examine the properties of the models and MCTS executions that lead to better or worse results.
keywords: {Planning;Monte Carlo methods;Three-dimensional printing;Solid modeling;Clustering algorithms;Printers;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196945&isnumber=9196508

S. B. Liu and M. Althoff, "Optimizing performance in automation through modular robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4044-4050.
doi: 10.1109/ICRA40945.2020.9196590
Abstract: Flexible manufacturing and automation require robots that can be adapted to changing tasks. We propose to use modular robots that are customized from given modules for a specific task. This work presents an algorithm for proposing a module composition that is optimal with respect to performance metrics such as cycle time and energy efficiency, while considering kinematic, dynamic, and obstacle constraints. Tasks are defined as trajectories in Cartesian space, as a list of poses for the robot to reach as fast as possible, or as dexterity in a desired workspace. In a simulated comparison with commercially available industrial robots, we demonstrate the superiority of our approach in randomly generated tasks with respect to the chosen performance metrics. We use our modular robot proModular.1 for the comparison.
keywords: {Kinematics;Service robots;Collision avoidance;Trajectory;Task analysis;Heuristic algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196590&isnumber=9196508

R. Li, A. Jabri, T. Darrell and P. Agrawal, "Towards Practical Multi-Object Manipulation using Relational Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4051-4058.
doi: 10.1109/ICRA40945.2020.9197468
Abstract: Learning robotic manipulation tasks using reinforcement learning with sparse rewards is currently impractical due to the outrageous data requirements. Many practical tasks require manipulation of multiple objects, and the complexity of such tasks increases with the number of objects. Learning from a curriculum of increasingly complex tasks appears to be a natural solution, but unfortunately, does not work for many scenarios. We hypothesize that the inability of the state- of-the-art algorithms to effectively utilize a task curriculum stems from the absence of inductive biases for transferring knowledge from simpler to complex tasks. We show that graph-based relational architectures overcome this limitation and enable learning of complex tasks when provided with a simple curriculum of tasks with increasing numbers of objects. We demonstrate the utility of our framework on a simulated block stacking task. Starting from scratch, our agent learns to stack six blocks into a tower. Despite using step-wise sparse rewards, our method is orders of magnitude more data- efficient and outperforms the existing state-of-the-art method that utilizes human demonstrations. Furthermore, the learned policy exhibits zero-shot generalization, successfully stacking blocks into taller towers and previously unseen configurations such as pyramids, without any further training.
keywords: {Task analysis;Stacking;Robots;Learning (artificial intelligence);Poles and towers;Training;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197468&isnumber=9196508

N. Majcherczyk and C. Pinciroli, "SwarmMesh: A Distributed Data Structure for Cooperative Multi-Robot Applications," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4059-4065.
doi: 10.1109/ICRA40945.2020.9197403
Abstract: We present an approach to the distributed storage of data across a swarm of mobile robots that forms a shared global memory. We assume that external storage infrastructure is absent, and that each robot is capable of devoting a quota of memory and bandwidth to distributed storage. Our approach is motivated by the insight that in many applications data is collected at the periphery of a swarm topology, but the periphery also happens to be the most dangerous location for storing data, especially in exploration missions. Our approach is designed to promote data storage in the locations in the swarm that best suit a specific feature of interest in the data, while accounting for the constantly changing topology due to individual motion. We analyze two possible features of interest: the data type and the data item position in the environment. We assess the performance of our approach in a large set of simulated experiments. The evaluation shows that our approach is capable of storing quantities of data that exceed the memory of individual robots, while maintaining near-perfect data retention in high-load conditions.
keywords: {Robots;Data structures;Peer-to-peer computing;Overlay networks;Routing;Distributed databases;Topology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197403&isnumber=9196508

N. Mimmo, P. Bernard and L. Marconi, "Avalanche victim search via robust observers," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4066-4072.
doi: 10.1109/ICRA40945.2020.9196646
Abstract: This paper introduces a new approach for victim localization in avalanches that will be exploited by UAVs using the ARVA sensor. We show that the nominal ARVA measurement can be linearly related to a quantity that is sufficient to reconstruct the victim position. We explicitly deal with a robust scenario in which the measurement is actually perturbed by a noise that grows with the distance to the victim and we propose an adaptive control scheme made of a least-square identifier and a trajectory generator whose role is both to guarantee the persistence of excitation for the identifier and to steer the ARVA receiver towards the victim. We show that the system succeeds in localizing the victim in a domain where the ARVA output is sufficiently informative and illustrate its performance in simulation. This new approach could significantly reduce the searching time by providing an exploitable estimate before having reached the victim. The work is framed within the EU project AirBorne whose goals is to develop at TRL8 a drone for quick localization of victims in avalanche scenarios.
keywords: {Receivers;Transmitters;Drones;Observers;Trajectory;Electromagnetics;Adaptive control;Search and Rescue;Robust Control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196646&isnumber=9196508

M. T. Ohradzansky, A. B. Mills, E. R. Rush, D. G. Riley, E. W. Frew and J. Sean Humbert, "Reactive Control and Metric-Topological Planning for Exploration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4073-4079.
doi: 10.1109/ICRA40945.2020.9197381
Abstract: Autonomous navigation in unknown environments with the intent of exploring all traversable areas is a significant challenge for robotic platforms. In this paper, a simple yet reliable method for exploring unknown environments is presented based on bio-inspired reactive control and metric-topological planning. The reactive control algorithm is modeled after the spatial decomposition of wide and small-field patterns of optic flow in the insect visuomotor system. Centering behaviour and small obstacle detection and avoidance are achieved through wide-field integration and Fourier residual analysis of instantaneous measured nearness respectively. A topological graph is estimated using image processing techniques on a continuous occupancy grid. Node paths are rapidly generated to navigate to the nearest unexplored edge in the graph. It is shown through rigorous field-testing that the proposed control and planning method is robust, reliable, and computationally efficient.
keywords: {Optical feedback;Optical sensors;Optical imaging;Planning;Navigation;Harmonic analysis;Mathematical model;exploration;centering;control;mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197381&isnumber=9196508

K. Saulnier, N. Atanasov, G. J. Pappas and V. Kumar, "Information Theoretic Active Exploration in Signed Distance Fields," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4080-4085.
doi: 10.1109/ICRA40945.2020.9196882
Abstract: This paper focuses on exploration and occupancy mapping of unknown environments using a mobile robot. While a truncated signed distance field (TSDF) is a popular, efficient, and highly accurate representation of occupancy, few works have considered optimizing robot sensing trajectories for autonomous TSDF mapping. We propose an efficient approach for maintaining TSDF uncertainty and predicting its evolution from potential future sensor measurements without actually receiving them. Efficient uncertainty prediction is critical for long-horizon optimization of potential sensing trajectories. We develop a deterministic tree-search algorithm that evaluates the information gain between the TSDF distribution and potential observations along sequences of robot motion primitives. Efficient planning is achieved by branch-and-bound pruning of uninformative sensing trajectories. The effectiveness of our active TSDF mapping approach is evaluated in several simulated environments with complex visibility constraints.
keywords: {Robot sensing systems;Trajectory;Measurement uncertainty;Standards;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196882&isnumber=9196508

D. D. Fan, J. Nguyen, R. Thakker, N. Alatur, A. -a. Agha-mohammadi and E. A. Theodorou, "Bayesian Learning-Based Adaptive Control for Safety Critical Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4093-4099.
doi: 10.1109/ICRA40945.2020.9196709
Abstract: Deep learning has enjoyed much recent success, and applying state-of-the-art model learning methods to controls is an exciting prospect. However, there is a strong reluctance to use these methods on safety-critical systems, which have constraints on safety, stability, and real-time performance. We propose a framework which satisfies these constraints while allowing the use of deep neural networks for learning model uncertainties. Central to our method is the use of Bayesian model learning, which provides an avenue for maintaining appropriate degrees of caution in the face of the unknown. In the proposed approach, we develop an adaptive control framework leveraging the theory of stochastic CLFs (Control Lyapunov Functions) and stochastic CBFs (Control Barrier Functions) along with tractable Bayesian model learning via Gaussian Processes or Bayesian neural networks. Under reasonable assumptions, we guarantee stability and safety while adapting to unknown dynamics with probability 1. We demonstrate this architecture for high-speed terrestrial mobility targeting potential applications in safety-critical high-speed Mars rover missions.
keywords: {Safety;Adaptation models;Bayes methods;Stochastic processes;Uncertainty;Computational modeling;Switches;Robust/Adaptive Control of Robotic Systems;Robot Safety;Probability and Statistical Methods;Bayesian Adaptive Control;Deep Learning;Mars Rover},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196709&isnumber=9196508

M. Ramezani, G. Tinchev, E. Iuganov and M. Fallon, "Online LiDAR-SLAM for Legged Robots with Robust Registration and Deep-Learned Loop Closure," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4158-4164.
doi: 10.1109/ICRA40945.2020.9196769
Abstract: In this paper, we present a 3D factor-graph LiDAR-SLAM system which incorporates a state-of-the-art deeply learned feature-based loop closure detector to enable a legged robot to localize and map in industrial environments. Point clouds are accumulated using an inertial-kinematic state estimator before being aligned using ICP registration. To close loops we use a loop proposal mechanism which matches individual segments between clouds. We trained a descriptor offline to match these segments. The efficiency of our method comes from carefully designing the network architecture to minimize the number of parameters such that this deep learning method can be deployed in real-time using only the CPU of a legged robot, a major contribution of this work. The set of odometry and loop closure factors are updated using pose graph optimization. Finally we present an efficient risk alignment prediction method which verifies the reliability of the registrations. Experimental results at an industrial facility demonstrated the robustness and flexibility of our system, including autonomous following paths derived from the SLAM map.
keywords: {Laser radar;Legged locomotion;Three-dimensional displays;Simultaneous localization and mapping;Iterative closest point algorithm},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196769&isnumber=9196508

M. Muglikar, Z. Zhang and D. Scaramuzza, "Voxel Map for Visual SLAM," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4181-4187.
doi: 10.1109/ICRA40945.2020.9197357
Abstract: In modern visual SLAM systems, it is a standard practice to retrieve potential candidate map points from overlapping keyframes for further feature matching or direct tracking. In this work, we argue that keyframes are not the optimal choice for this task, due to several inherent limitations, such as weak geometric reasoning and poor scalability. We propose a voxel-map representation to efficiently retrieve map points for visual SLAM. In particular, we organize the map points in a regular voxel grid. Visible points from a camera pose are queried by sampling the camera frustum in a raycasting manner, which can be done in constant time using an efficient voxel hashing method. Compared with keyframes, the retrieved points using our method are geometrically guaranteed to fall in the camera field-of-view, and occluded points can be identified and removed to a certain extend. This method also naturally scales up to large scenes and complicated multi-camera configurations. Experimental results show that our voxel map representation is as efficient as a keyframe map with 5 keyframes and provides significantly higher localization accuracy (average 46% improvement in RMSE) on the EuRoC dataset. The proposed voxel-map representation is a general approach to a fundamental functionality in visual SLAM and widely applicable.
keywords: {Simultaneous localization and mapping;Three-dimensional displays;Cameras;Visualization;Cognition;Feature extraction;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197357&isnumber=9196508

O. Mees, M. Merklinger, G. Kalweit and W. Burgard, "Adversarial Skill Networks: Unsupervised Robot Skill Learning from Video," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4188-4194.
doi: 10.1109/ICRA40945.2020.9196582
Abstract: Key challenges for the deployment of reinforcement learning (RL) agents in the real world are the discovery, representation and reuse of skills in the absence of a reward function. To this end, we propose a novel approach to learn a task-agnostic skill embedding space from unlabeled multi-view videos. Our method learns a general skill embedding independently from the task context by using an adversarial loss. We combine a metric learning loss, which utilizes temporal video coherence to learn a state representation, with an entropy-regularized adversarial skill-transfer loss. The metric learning loss learns a disentangled representation by attracting simultaneous viewpoints of the same observations and repelling visually similar frames from temporal neighbors. The adversarial skill-transfer loss enhances re-usability of learned skill embeddings over multiple task domains. We show that the learned embedding enables training of continuous control policies to solve novel tasks that require the interpolation of previously seen skills. Our extensive evaluation with both simulation and real world data demonstrates the effectiveness of our method in learning transferable skills from unlabeled interaction videos and composing them for new tasks. Code, pretrained models and dataset are available at http://robotskills.cs.uni-freiburg.de.
keywords: {Task analysis;Entropy;Measurement;Training;Robots;Interpolation;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196582&isnumber=9196508

M. Gehrig, S. B. Shrestha, D. Mouritzen and D. Scaramuzza, "Event-Based Angular Velocity Regression with Spiking Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4195-4202.
doi: 10.1109/ICRA40945.2020.9197133
Abstract: Spiking Neural Networks (SNNs) are bio-inspired networks that process information conveyed as temporal spikes rather than numeric values. An example of a sensor providing such data is the event-camera. It only produces an event when a pixel reports a significant brightness change. Similarly, the spiking neuron of an SNN only produces a spike whenever a significant number of spikes occur within a short period of time. Due to their spike-based computational model, SNNs can process output from event-based, asynchronous sensors without any pre-processing at extremely lower power unlike standard artificial neural networks. This is possible due to specialized neuromorphic hardware that implements the highly-parallelizable concept of SNNs in silicon. Yet, SNNs have not enjoyed the same rise of popularity as artificial neural networks. This not only stems from the fact that their input format is rather unconventional but also due to the challenges in training spiking networks. Despite their temporal nature and recent algorithmic advances, they have been mostly evaluated on classification problems. We propose, for the first time, a temporal regression problem of numerical values given events from an event-camera. We specifically investigate the prediction of the 3- DOF angular velocity of a rotating event-camera with an SNN. The difficulty of this problem arises from the prediction of angular velocities continuously in time directly from irregular, asynchronous event-based input. Directly utilising the output of event-cameras without any pre-processing ensures that we inherit all the benefits that they provide over conventional cameras. That is high-temporal resolution, high-dynamic range and no motion blur. To assess the performance of SNNs on this task, we introduce a synthetic event-camera dataset generated from real-world panoramic images and show that we can successfully train an SNN to perform angular velocity regression.
keywords: {Neurons;Biological neural networks;Angular velocity;Kernel;Task analysis;Computer architecture;Neuromorphics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197133&isnumber=9196508

H. Zhan, C. S. Weerasekera, J. -W. Bian and I. Reid, "Visual Odometry Revisited: What Should Be Learnt?," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4203-4210.
doi: 10.1109/ICRA40945.2020.9197374
Abstract: In this work we present a monocular visual odometry (VO) algorithm which leverages geometry-based methods and deep learning. Most existing VO/SLAM systems with superior performance are based on geometry and have to be carefully designed for different application scenarios. Moreover, most monocular systems suffer from scale-drift issue. Some recent deep learning works learn VO in an end-to-end manner but the performance of these deep systems is still not comparable to geometry-based methods. In this work, we revisit the basics of VO and explore the right way for integrating deep learning with epipolar geometry and Perspective-n-Point (PnP) method. Specifically, we train two convolutional neural networks (CNNs) for estimating single-view depths and two-view optical flows as intermediate outputs. With the deep predictions, we design a simple but robust frame-to-frame VO algorithm (DF-VO) which outperforms pure deep learning-based and geometry-based methods. More importantly, our system does not suffer from the scale-drift issue being aided by a scale consistent single-view depth CNN. Extensive experiments on KITTI dataset shows the robustness of our system and a detailed ablation study shows the effect of different factors in our system. Code is available at here: DF-VO.
keywords: {Cameras;Adaptive optics;Geometry;Optical imaging;Machine learning;Estimation;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197374&isnumber=9196508

M. Tian, Q. Nie and H. Shen, "3D Scene Geometry-Aware Constraint for Camera Localization with Deep Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4211-4217.
doi: 10.1109/ICRA40945.2020.9196940
Abstract: Camera localization is a fundamental and key component of autonomous driving vehicles and mobile robots to localize themselves globally for further environment perception, path planning and motion control. Recently end-to-end approaches based on convolutional neural network have been much studied to achieve or even exceed 3D-geometry based traditional methods. In this work, we propose a compact network for absolute camera pose regression. Inspired from those traditional methods, a 3D scene geometry-aware constraint is also introduced by exploiting all available information including motion, depth and image contents. We add this constraint as a regularization term to our proposed network by defining a pixel-level photometric loss and an image-level structural similarity loss. To benchmark our method, different challenging scenes including indoor and outdoor environment are tested with our proposed approach and state-of-the-arts. And the experimental results demonstrate significant performance improvement of our method on both prediction accuracy and convergence efficiency.
keywords: {Cameras;Three-dimensional displays;Training;Geometry;Robot vision systems;Transforms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196940&isnumber=9196508

B. Li, T. Lu, J. Li, N. Lu, Y. Cai and S. Wang, "ACDER: Augmented Curiosity-Driven Experience Replay," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4218-4224.
doi: 10.1109/ICRA40945.2020.9197421
Abstract: Exploration in environments with sparse feed-back remains a challenging research problem in reinforcement learning (RL). When the RL agent explores the environment randomly, it results in low exploration efficiency, especially in robotic manipulation tasks with high dimensional continuous state and action space. In this paper, we propose a novel method, called Augmented Curiosity-Driven Experience Replay (ACDER), which leverages (i) a new goal-oriented curiosity-driven exploration to encourage the agent to pursue novel and task-relevant states more purposefully and (ii) the dynamic initial states selection as an automatic exploratory curriculum to further improve the sample-efficiency. Our approach complements Hindsight Experience Replay (HER) by introducing a new way to pursue valuable states. Experiments conducted on four challenging robotic manipulation tasks with binary rewards, including Reach, Push, Pick&Place and Multi-step Push. The empirical results show that our proposed method significantly outperforms existing methods in the first three basic tasks and also achieves satisfactory performance in multi-step robotic task learning.
keywords: {Task analysis;Robots;Learning (artificial intelligence);Training;Incentive schemes;Buffer storage;Games},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197421&isnumber=9196508

J. C. Kiemel, P. Mei√üner and T. Kr√∂ger, "TrueRMA: Learning Fast and Smooth Robot Trajectories with Recursive Midpoint Adaptations in Cartesian Space," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4225-4231.
doi: 10.1109/ICRA40945.2020.9196711
Abstract: We present TrueRMA, a data-efficient, model-free method to learn cost-optimized robot trajectories over a wide range of starting points and endpoints. The key idea is to calculate trajectory waypoints in Cartesian space by recursively predicting orthogonal adaptations relative to the midpoints of straight lines. We generate a differentiable path by adding circular blends around the waypoints, calculate the corresponding joint positions with an inverse kinematics solver and calculate a time-optimal parameterization considering velocity and acceleration limits. During training, the trajectory is executed in a physics simulator and costs are assigned according to a user-specified cost function which is not required to be differentiable. Given a starting point and an endpoint as input, a neural network is trained to predict midpoint adaptations that minimize the cost of the resulting trajectory via reinforcement learning. We successfully train a KUKA iiwa robot to keep a ball on a plate while moving between specified points and compare the performance of TrueRMA against two baselines. The results show that our method requires less training data to learn the task while generating shorter and faster trajectories.
keywords: {Trajectory;Robots;Kinematics;Task analysis;Training;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196711&isnumber=9196508

J. Ichnowski et al., "Fog Robotics Algorithms for Distributed Motion Planning Using Lambda Serverless Computing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4232-4238.
doi: 10.1109/ICRA40945.2020.9196651
Abstract: For robots using motion planning algorithms such as RRT and RRT*, the computational load can vary by orders of magnitude as the complexity of the local environment changes. To adaptively provide such computation, we propose Fog Robotics algorithms in which cloud-based serverless lambda computing provides parallel computation on demand. To use this parallelism, we propose novel motion planning algorithms that scale effectively with an increasing number of serverless computers. However, given that the allocation of computing is typically bounded by both monetary and time constraints, we show how prior learning can be used to efficiently allocate resources at runtime. We demonstrate the algorithms and application of learned parallel allocation in both simulation and with the Fetch commercial mobile manipulator using Amazon Lambda to complete a sequence of sporadically computationally intensive motion planning tasks.
keywords: {Planning;Parallel processing;FAA;Robot kinematics;Cloud computing;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196651&isnumber=9196508

R. Maffei, M. P. Souza, M. Mantelli, D. Pittol, M. Kolberg and V. A. M. Jorge, "Exploration of 3D terrains using potential fields with elevation-based local distortions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4239-4244.
doi: 10.1109/ICRA40945.2020.9197577
Abstract: Mobile robots can be used in numerous outdoor tasks such as patrolling, delivery and military applications. In order to deploy mobile robots in this kind of environment, where there are different challenges like slopes, elevations, or even holes, they should be able to detect such challenges and determine the best path to accomplish their tasks. In this paper, we are proposing an exploration approach based on potential fields with local distortions, in which we define preferences in uneven terrains to avoid high declivity regions without compromising the best path. The approach was implemented and tested in simulated environments, considering a ground robot embedded with two 2D LIDAR sensors, and the experiments demonstrated the efficiency of our method.
keywords: {Distortion;Robot sensing systems;Three-dimensional displays;Boundary conditions;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197577&isnumber=9196508

A. Wu, S. Sadraddini and R. Tedrake, "R3T: Rapidly-exploring Random Reachable Set Tree for Optimal Kinodynamic Planning of Nonlinear Hybrid Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4245-4251.
doi: 10.1109/ICRA40945.2020.9196802
Abstract: We introduce R3T, a reachability-based variant of the rapidly-exploring random tree (RRT) algorithm that is suitable for (optimal) kinodynamic planning in nonlinear and hybrid systems. We developed tools to approximate reachable sets using polytopes and perform sampling-based planning with them. This method has a unique advantage in hybrid systems: different dynamic modes in the reachable set can be explicitly represented using multiple polytopes. We prove that under mild assumptions, R3T is probabilistically complete in kinodynamic systems, and asymptotically optimal through rewiring. Moreover, R3T provides a formal verification method for reachability analysis of nonlinear systems. The advantages of R3T are demonstrated with case studies on nonlinear, hybrid, and contact-rich robotic systems.
keywords: {Planning;Approximation algorithms;Trajectory;Heuristic algorithms;Measurement;Robots;Silicon},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196802&isnumber=9196508

Y. Han, H. Lin, J. Banfi, K. Bala and M. Campbell, "DeepSemanticHPPC: Hypothesis-based Planning over Uncertain Semantic Point Clouds," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4252-4258.
doi: 10.1109/ICRA40945.2020.9196828
Abstract: Planning in unstructured environments is challenging - it relies on sensing, perception, scene reconstruction, and reasoning about various uncertainties. We propose DeepSemanticHPPC, a novel uncertainty-aware hypothesis-based planner for unstructured environments. Our algorithmic pipeline consists of: a deep Bayesian neural network which segments surfaces with uncertainty estimates; a flexible point cloud scene representation; a next-best-view planner which minimizes the uncertainty of scene semantics using sparse visual measurements; and a hypothesis-based path planner that proposes multiple kinematically feasible paths with evolving safety confidences given next-best-view measurements. Our pipeline iteratively decreases semantic uncertainty along planned paths, filtering out unsafe paths with high confidence. We show that our framework plans safe paths in real-world environments where existing path planners typically fail.
keywords: {Uncertainty;Three-dimensional displays;Trajectory;Semantics;Robots;Planning;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196828&isnumber=9196508

S. Sudhakar, S. Karaman and V. Sze, "Balancing Actuation and Computing Energy in Motion Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4259-4265.
doi: 10.1109/ICRA40945.2020.9197164
Abstract: We study a novel class of motion planning problems, inspired by emerging low-energy robotic vehicles, such as insect-size flyers, chip-size satellites, and high-endurance autonomous blimps, for which the energy consumed by computing hardware during planning a path can be as large as the energy consumed by actuation hardware during the execution of the same path. We propose a new algorithm, called Compute Energy Included Motion Planning (CEIMP). CEIMP operates similarly to any other anytime planning algorithm, except it stops when it estimates further computing will require more computing energy than potential savings in actuation energy. We show that CEIMP has the same asymptotic computational complexity as existing sampling-based motion planning algorithms, such as PRM*. We also show that CEIMP outperforms the average baseline of using maximum computing resources in realistic computational experiments involving 10 floor plans from MIT buildings. In one representative experiment, CEIMP outperforms the average baseline 90.6% of the time when energy to compute one more second is equal to the energy to move one more meter, and 99.7% of the time when energy to compute one more second is equal to or greater than the energy to move 3 more meters.
keywords: {Planning;Robots;Meters;Task analysis;Hardware;Buildings;Space exploration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197164&isnumber=9196508

B. Hou, S. Choudhury, G. Lee, A. Mandalika and S. S. Srinivasa, "Posterior Sampling for Anytime Motion Planning on Graphs with Expensive-to-Evaluate Edges," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4266-4272.
doi: 10.1109/ICRA40945.2020.9197014
Abstract: Collision checking is a computational bottleneck in motion planning, requiring lazy algorithms that explicitly reason about when to perform this computation. Optimism in the face of collision uncertainty minimizes the number of checks before finding the shortest path. However, this may take a prohibitively long time to compute, with no other feasible paths discovered during this period. For many real-time applications, we instead demand strong anytime performance, defined as minimizing the cumulative lengths of the feasible paths yielded over time. We introduce Posterior Sampling for Motion Planning (PSMP), an anytime lazy motion planning algorithm that leverages learned posteriors on edge collisions to quickly discover an initial feasible path and progressively yield shorter paths. PSMP obtains an expected regret bound of √ï(‚àö(SAT)) and outperforms comparative baselines on a set of 2D and 7D planning problems.
keywords: {Planning;Bayes methods;History;Uncertainty;Geometry;Learning (artificial intelligence);Search problems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197014&isnumber=9196508

S. Sun, M. Baert, B. S. van Schijndel and C. de Visser, "Upset Recovery Control for Quadrotors Subjected to a Complete Rotor Failure from Large Initial Disturbances," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4273-4279.
doi: 10.1109/ICRA40945.2020.9197239
Abstract: This study has developed a fault-tolerant controller that is able to recover a quadrotor from arbitrary initial orientations and angular velocities, despite the complete failure of a rotor. This cascaded control method includes a position/altitude controller, an almost-global convergence attitude controller, and a control allocation method based on quadratic programming. As a major novelty, a constraint of undesirable angular velocity is derived and fused into the control allocator, which significantly improves the recovery performance. For validation, we have conducted a set of Monte-Carlo simulation to test the reliability of the proposed method of recovering the quadrotor from arbitrary initial attitude/rate conditions. In addition, real-life flight tests have been performed. The results demonstrate that the post-failure quadrotor can recover after being casually tossed into the air.
keywords: {Rotors;Attitude control;Angular velocity;Fault tolerance;Fault tolerant systems;Resource management;Drones},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197239&isnumber=9196508

A. Letalenet and P. Morin, "Identification and evaluation of a force model for multirotor UAVs," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4280-4286.
doi: 10.1109/ICRA40945.2020.9197317
Abstract: This paper proposes a model identification method and evaluation of a force model for multirotor UAVs. The model incorporates propellers' aerodynamics derived from momentum and blade element theories, as well as aerodynamics of the UAV's structure and actuation dynamics. A two-steps identification approach of the model parameters is proposed. The model is identified and evaluated from outdoor experiments with flight speeds exceeding 10m/s.
keywords: {Propellers;Aerodynamics;Atmospheric modeling;Predictive models;Blades;Acceleration;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197317&isnumber=9196508

A. Yiƒüit, G. Grappe, L. Cuvillon, S. Durand and J. Gangloff, "Preliminary Study of an Aerial Manipulator with Elastic Suspension," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4287-4293.
doi: 10.1109/ICRA40945.2020.9196942
Abstract: This paper presents a preliminary study of an Aerial Manipulator suspended by a spring to a robotic carrier. The suspended aerial manipulator is actuated by six pairs of contra-rotating propellers generating a 6-DoF wrench. Simulations show path following results using a computed torque (feedback linearization) control strategy. Active vibration canceling is validated experimentally on a first prototype.
keywords: {Springs;Manipulators;Propellers;Task analysis;Grippers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196942&isnumber=9196508

R. S. Dimitrova, M. Gehrig, D. Brescianini and D. Scaramuzza, "Towards Low-Latency High-Bandwidth Control of Quadrotors using Event Cameras," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4294-4300.
doi: 10.1109/ICRA40945.2020.9197530
Abstract: Event cameras are a promising candidate to enable high speed vision-based control due to their low sensor latency and high temporal resolution. However, purely event-based feedback has yet to be used in the control of drones. In this work, a first step towards implementing low-latency high-bandwidth control of quadrotors using event cameras is taken. In particular, this paper addresses the problem of one-dimensional attitude tracking using a dualcopter platform equipped with an event camera. The event-based state estimation consists of a modified Hough transform algorithm combined with a Kalman filter that outputs the roll angle and angular velocity of the dualcopter relative to a horizon marked by a black-and-white disk. The estimated state is processed by a proportional-derivative attitude control law that computes the rotor thrusts required to track the desired attitude. The proposed attitude tracking scheme shows promising results of event-camera-driven closed loop control: the state estimator performs with an update rate of 1 kHz and a latency determined to be 12 ms, enabling attitude tracking at speeds of over 1600¬∞/s.
keywords: {Cameras;Robot vision systems;Transforms;Angular velocity;State estimation;Attitude control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197530&isnumber=9196508

M. Jacquet, G. Corsini, D. Bicego and A. Franchi, "Perception-constrained and Motor-level Nonlinear MPC for both Underactuated and Tilted-propeller UAVS," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4301-4306.
doi: 10.1109/ICRA40945.2020.9197281
Abstract: In this paper, we present a Perception-constrained Nonlinear Model Predictive Control (NMPC) framework for the real-time control of multi-rotor aerial vehicles. Our formulation considers both constraints from a perceptive sensor and realistic actuator limitations that are the rotor minimum and maximum speeds and accelerations. The formulation is meant to be generic and considers a large range of multi-rotor platforms (such as underactuated quadrotors or tilted-propellers hexarotors) since it does not rely on differential flatness for the dynamical equations, and a broad range of sensors, such as cameras, lidars, etc.... The perceptive constraints are expressed to maintain visibility of a feature point in the sensor's field of view, while performing a reference maneuver. We demonstrate both in simulation and real experiments that our framework is able to exploit the full capabilities of the multi-rotor, to achieve the motion under the aforementioned constraints, and control in real-time the platform at a motor-torque level, avoiding the use of an intermediate unconstrained trajectory tracker.
keywords: {Propellers;Task analysis;Robot sensing systems;Real-time systems;Actuators;Vehicle dynamics;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197281&isnumber=9196508

J. Welde and V. Kumar, "Coordinate-Free Dynamics and Differential Flatness of a Class of 6DOF Aerial Manipulators," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4307-4313.
doi: 10.1109/ICRA40945.2020.9196705
Abstract: In this work, we derive a coordinate-free formulation of the coupled dynamics of a class of 6DOF aerial manipulators consisting of an underactuated quadrotor equipped with a 2DOF articulated manipulator, and demonstrate that the system is differentially flat with respect to the end effector pose. In particular, we require the center of mass of the entire system to be fixed in the end effector frame, suggesting a reasonable mechanical design criterion. We make use of an inertial decoupling transformation to demonstrate differential flatness, allowing us to plan dynamically feasible trajectories for the system in the space of the 6DOF pose of the end effector, which is ideal for achieving precise manipulator tasks. Simulation results validate the flatness-based planning methodology for our dynamic model, and its usefulness is demonstrated in a simulated aerial videography task.
keywords: {Manipulator dynamics;End effectors;Trajectory;Task analysis;Planning;Vehicle dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196705&isnumber=9196508

W. Ding, M. Xu and D. Zhao, "CMTS: A Conditional Multiple Trajectory Synthesizer for Generating Safety-Critical Driving Scenarios," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4314-4321.
doi: 10.1109/ICRA40945.2020.9197145
Abstract: Naturalistic driving trajectory generation is crucial for the development of autonomous driving algorithms. However, most of the data is collected in collision-free scenarios leading to the sparsity of the safety-critical cases. When considering safety, testing algorithms in near-miss scenarios that rarely show up in off-the-shelf datasets and are costly to accumulate is a vital part of the evaluation. As a remedy, we propose a safety-critical data synthesizing framework based on variational Bayesian methods and term it as Conditional Multiple Trajectory Synthesizer (CMTS). We extend a generative model to connect safe and collision driving data by representing their distribution in the latent space and use conditional probability to adapt to different maps. Sampling from the mixed distribution enables us to synthesize the safety-critical data not shown in the safe or collision datasets. Experimental results demonstrate that the generated dataset covers many different realistic scenarios, especially the near-misses. We conclude that the use of data generated by CMTS can improve the accuracy of trajectory predictions and autonomous vehicle safety.
keywords: {Trajectory;Interpolation;Roads;Training;Aerospace electronics;Data models;Autonomous vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197145&isnumber=9196508

W. Ding, S. Hou, H. Gao, G. Wan and S. Song, "LiDAR Inertial Odometry Aided Robust LiDAR Localization System in Changing City Scenes," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4322-4328.
doi: 10.1109/ICRA40945.2020.9196698
Abstract: Environmental fluctuations pose crucial challenges to a localization system in autonomous driving. We present a robust LiDAR localization system that maintains its kinematic estimation in changing urban scenarios by using a dead reckoning solution implemented through a LiDAR inertial odometry. Our localization framework jointly uses information from complementary modalities such as global matching and LiDAR inertial odometry to achieve accurate and smooth localization estimation. To improve the performance of the LiDAR odometry, we incorporate inertial and LiDAR intensity cues into an occupancy grid based LiDAR odometry to enhance frame-to-frame motion and matching estimation. Multi-resolution occupancy grid is implemented yielding a coarse-to-fine approach to balance the odometry's precision and computational requirement. To fuse both the odometry and global matching results, we formulate a MAP estimation problem in a pose graph fusion framework that can be efficiently solved. An effective environmental change detection method is proposed that allows us to know exactly when and what portion of the map requires an update. We comprehensively validate the effectiveness of the proposed approaches using both the Apollo-SouthBay dataset and our internal dataset. The results confirm that our efforts lead to a more robust and accurate localization system, especially in dynamically changing urban scenarios.
keywords: {Laser radar;Estimation;Robustness;Roads;Windows;Optimization;Autonomous vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196698&isnumber=9196508

M. Huegle, G. Kalweit, M. Werling and J. Boedecker, "Dynamic Interaction-Aware Scene Understanding for Reinforcement Learning in Autonomous Driving," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4329-4335.
doi: 10.1109/ICRA40945.2020.9197086
Abstract: The common pipeline in autonomous driving systems is highly modular and includes a perception component which extracts lists of surrounding objects and passes these lists to a high-level decision component. In this case, leveraging the benefits of deep reinforcement learning for high-level decision making requires special architectures to deal with multiple variable-length sequences of different object types, such as vehicles, lanes or traffic signs. At the same time, the architecture has to be able to cover interactions between traffic participants in order to find the optimal action to be taken. In this work, we propose the novel Deep Scenes architecture, that can learn complex interaction-aware scene representations based on extensions of either 1) Deep Sets or 2) Graph Convolutional Networks. We present the Graph-Q and DeepScene-Q off-policy reinforcement learning algorithms, both outperforming state-ofthe-art methods in evaluations with the publicly available traffic simulator SUMO.
keywords: {Computer architecture;Autonomous vehicles;Lenses;Learning (artificial intelligence);Decision making;Predictive models;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197086&isnumber=9196508

S. Mukherjee, S. Wang and A. Wallace, "Interacting Vehicle Trajectory Prediction with Convolutional Recurrent Neural Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4336-4342.
doi: 10.1109/ICRA40945.2020.9196807
Abstract: Anticipating the future trajectories of surrounding vehicles is a crucial and challenging task in path planning for autonomy. We propose a novel Convolutional Long Short Term Memory (Conv-LSTM) based neural network architecture to predict the future positions of cars using several seconds of historical driving observations. This consists of three modules: 1) Interaction Learning to capture the effect of surrounding cars, 2) Temporal Learning to identify the dependency on past movements and 3) Motion Learning to convert the extracted features from these two modules into future positions. To continuously achieve accurate prediction, we introduce a novel feedback scheme where the current predicted positions of each car are leveraged to update future motion, encapsulating the effect of the surrounding cars. Experiments on two public datasets demonstrate that the proposed methodology can match or outperform the state-of-the-art methods for long-term trajectory prediction.
keywords: {Automobiles;Trajectory;Feature extraction;Hidden Markov models;Predictive models;Computer architecture;Road transportation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196807&isnumber=9196508

Y. Pan, J. Xue, P. Zhang, W. Ouyang, J. Fang and X. Chen, "Navigation Command Matching for Vision-based Autonomous Driving," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4343-4349.
doi: 10.1109/ICRA40945.2020.9196609
Abstract: Learning an optimal policy for autonomous driving task to confront with complex environment is a long- studied challenge. Imitative reinforcement learning is accepted as a promising approach to learn a robust driving policy through expert demonstrations and interactions with environments. However, this model utilizes non-smooth rewards, which have a negative impact on matching between navigation commands and trajectory (state-action pairs), and degrade the generalizability of an agent. Smooth rewards are crucial to discriminate actions generated from sub-optimal policy. In this paper, we propose a navigation command matching (NCM) model to address this issue. There are two key components in NCM, 1) a matching measurer produces smooth navigation rewards that measure matching between navigation commands and trajectory; 2) attention-guided agent performs actions given states where salient regions in RGB images (i.e. roadsides, lane markings and dynamic obstacles) are highlighted to amplify their influence on the final model. We obtain navigation rewards and store transitions to replay buffer after an episode, so NCM is able to discriminate actions generated from suboptimal policy. Experiments on CARLA driving benchmark show our proposed NCM outperforms previous state-of-the- art models on various tasks in terms of the percentage of successfully completed episodes. Moreover, our model improves generalizability of the agent and obtains good performance even in unseen scenarios.
keywords: {Navigation;Task analysis;Trajectory;Learning (artificial intelligence);Autonomous vehicles;Smoothing methods;Current measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196609&isnumber=9196508

R. Chandra, U. Bhattacharya, T. Mittal, X. Li, A. Bera and D. Manocha, "GraphRQI: Classifying Driver Behaviors Using Graph Spectrums," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4350-4357.
doi: 10.1109/ICRA40945.2020.9196751
Abstract: We present a novel algorithm (GraphRQI) to identify driver behaviors from road-agent trajectories. Our approach assumes that the road-agents exhibit a range of driving traits, such as aggressive or conservative driving. Moreover, these traits affect the trajectories of nearby road-agents as well as the interactions between road-agents. We represent these inter-agent interactions using unweighted and undirected traffic graphs. Our algorithm classifies the driver behavior using a supervised learning algorithm by reducing the computation to the spectral analysis of the traffic graph. Moreover, we present a novel eigenvalue algorithm to compute the spectrum efficiently. We provide theoretical guarantees for the running time complexity of our eigenvalue algorithm and show that it is faster than previous methods by 2 times. We evaluate the classification accuracy of our approach on traffic videos and autonomous driving datasets corresponding to urban traffic. In practice, GraphRQI achieves an accuracy improvement of up to 25% over prior driver behavior classification algorithms. We also use our classification algorithm to predict the future trajectories of road-agents.
keywords: {Vehicles;Trajectory;Heuristic algorithms;Eigenvalues and eigenfunctions;Laplace equations;Classification algorithms;Topology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196751&isnumber=9196508

≈û. SƒÉftescu, M. Gadd, D. De Martini, D. Barnes and P. Newman, "Kidnapped Radar: Topological Radar Localisation using Rotationally-Invariant Metric Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4358-4364.
doi: 10.1109/ICRA40945.2020.9196682
Abstract: This paper presents a system for robust, large-scale topological localisation using Frequency-Modulated Continuous-Wave scanning radar which extends the state-of-the-art by an efficient, learning-based approach to handle radar data for localisation. We learn a metric space for embedding polar radar scans using CNN and NetVLAD architectures traditionally applied to the visual domain. However, we tailor the feature extraction for more suitability to the polar nature of radar scan formation using cylindrical convolutions, anti-aliasing blurring, and azimuth-wise max-pooling; all in order to bolster the rotational invariance. The enforced metric space is then used to encode a reference trajectory, serving as a map, which is queried for nearest neighbour for recognition of places at run-time. We demonstrate the performance of our topological localisation system over the course of many repeat forays using the largest radar-focused mobile autonomy dataset released to date, totalling 280 km of urban driving, a small portion of which we also use to learn the weights of the modified architecture. As this work represents a novel application for radar, we analyse the utility of the proposed method via a comprehensive set of metrics which provide insight into the efficacy when used in a realistic system, showing improved performance over the root architecture even in the face of random rotational perturbation.
keywords: {Measurement;Radar imaging;Robot sensing systems;Azimuth;Feature extraction;Trajectory;radar;localisation;place recognition;deep learning;metric learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196682&isnumber=9196508

D. Cattaneo, M. Vaghi, S. Fontana, A. L. Ballardini and D. G. Sorrenti, "Global visual localization in LiDAR-maps through shared 2D-3D embedding space," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4365-4371.
doi: 10.1109/ICRA40945.2020.9196859
Abstract: Global localization is an important and widely studied problem for many robotic applications. Place recognition approaches can be exploited to solve this task, e.g., in the autonomous driving field. While most vision-based approaches match an image w.r.t. an image database, global visual localization within LiDAR-maps remains fairly unexplored, even though the path toward high definition 3D maps, produced mainly from LiDARs, is clear. In this work we leverage Deep Neural Network (DNN) approaches to create a shared embedding space between images and LiDAR-maps, allowing for image to 3D-LiDAR place recognition. We trained a 2D and a 3D DNN that create embeddings, respectively from images and from point clouds, that are close to each other whether they refer to the same place. An extensive experimental activity is presented to assess the effectiveness of the approach w.r.t. different learning paradigms, network architectures, and loss functions. All the evaluations have been performed using the Oxford Robotcar Dataset, which encompasses a wide range of weather and light conditions.
keywords: {Three-dimensional displays;Task analysis;Laser radar;Feature extraction;Visualization;Robots;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196859&isnumber=9196508

S. Schubert, P. Neubert and P. Protzel, "Unsupervised Learning Methods for Visual Place Recognition in Discretely and Continuously Changing Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4372-4378.
doi: 10.1109/ICRA40945.2020.9197044
Abstract: Visual place recognition in changing environments is the problem of finding matchings between two sets of observations, a query set and a reference set, despite severe appearance changes. Recently, image comparison using CNNbased descriptors showed very promising results. However, the experiments in the literature typically assume a single distinctive condition within each set (e.g., reference images are captured at daytime and the query sequence is at night). In this paper, we will demonstrate that as soon as the conditions change within one set (e.g., reference is daytime and now the query is a traversal daytime-dusk-night-dawn), different places under the same condition can suddenly look more similar than same places under different conditions. As a consequence, state-of-the-art approaches like CNN-based descriptors fail. This paper discusses this practically very important problem of in-sequence condition changes and defines a hierarchy of problem setups from (1) no in-sequence changes, (2) discrete in-sequence changes, to (3) continuous in-sequence changes. We will experimentally evaluate the effect of in-sequence condition changes on two state-of-the-art CNN-descriptors and investigate unsupervised methods to improve their performance. This includes an evaluation of the importance of statistical normalization (standardization) of descriptors, which is often omitted in existing approaches but can considerably improve results for problems up to discrete in-sequence changes. To address the practical most relevant setup of continuous changes, we investigate the application of unsupervised learning methods using two PCA-based approaches from the literature and propose a novel clustering-based extension of the statistical normalization. We experimentally demonstrate that these approaches can significantly improve place recognition performance in case of continuous in-sequence condition changes. Matlab implementations of the presented approaches are available online: www.tu-chemnitz.de/etit/proaut/cont_changing_envs.
keywords: {Standardization;Visualization;Lighting;Unsupervised learning;Principal component analysis;Dimensionality reduction;Clouds},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197044&isnumber=9196508

D. Rozenberszki and A. L. Majdik, "LOL: Lidar-only Odometry and Localization in 3D point cloud maps," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4379-4385.
doi: 10.1109/ICRA40945.2020.9197450
Abstract: In this paper we deal with the problem of odometry and localization for Lidar-equipped vehicles driving in urban environments, where a premade target map exists to localize against. In our problem formulation, to correct the accumulated drift of the Lidar-only odometry we apply a place recognition method to detect geometrically similar locations between the online 3D point cloud and the a priori offline map. In the proposed system, we integrate a state-of-the-art Lidaronly odometry algorithm with a recently proposed 3D point segment matching method by complementing their advantages. Also, we propose additional enhancements in order to reduce the number of false matches between the online point cloud and the target map, and to refine the position estimation error whenever a good match is detected. We demonstrate the utility of the proposed LOL system on several Kitti datasets of different lengths and environments, where the relocalization accuracy and the precision of the vehicle‚Äôs trajectory were significantly improved in every case, while still being able to maintain real-time performance.
keywords: {Three-dimensional displays;Laser radar;Sensors;Iterative closest point algorithm;Image color analysis;Trajectory;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197450&isnumber=9196508

L. Sun, D. Adolfsson, M. Magnusson, H. Andreasson, I. Posner and T. Duckett, "Localising Faster: Efficient and precise lidar-based robot localisation in large-scale environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4386-4392.
doi: 10.1109/ICRA40945.2020.9196708
Abstract: This paper proposes a novel approach for global localisation of mobile robots in large-scale environments. Our method leverages learning-based localisation and filtering-based localisation, to localise the robot efficiently and precisely through seeding Monte Carlo Localisation (MCL) with a deeplearned distribution. In particular, a fast localisation system rapidly estimates the 6-DOF pose through a deep-probabilistic model (Gaussian Process Regression with a deep kernel), then a precise recursive estimator refines the estimated robot pose according to the geometric alignment. More importantly, the Gaussian method (i.e. deep probabilistic localisation) and nonGaussian method (i.e. MCL) can be integrated naturally via importance sampling. Consequently, the two systems can be integrated seamlessly and mutually benefit from each other. To verify the proposed framework, we provide a case study in large-scale localisation with a 3D lidar sensor. Our experiments on the Michigan NCLT long-term dataset show that the proposed method is able to localise the robot in 1.94 s on average (median of 0.8 s) with precision 0.75 m in a largescale environment of approximately 0.5 km2.
keywords: {Robots;Neural networks;Three-dimensional displays;Gaussian processes;Laser radar;Monte Carlo methods;Kernel},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196708&isnumber=9196508

S. Rohou, B. Desrochers and L. Jaulin, "Set-membership state estimation by solving data association," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4393-4399.
doi: 10.1109/ICRA40945.2020.9197039
Abstract: This paper deals with the localization problem of a robot in an environment made of indistinguishable landmarks, and assuming the initial position of the vehicle is unknown. This scenario is typically encountered in underwater applications for which landmarks such as rocks all look alike. Furthermore, the position of the robot may be lost during a diving phase, which obliges us to consider unknown initial position. We propose a deterministic approach to solve simultaneously the problems of data association and state estimation, without combinatorial explosion. The efficiency of the method is shown on an actual experiment involving an underwater robot and sonar data.
keywords: {Sonar;State estimation;Rocks;Trajectory;Robot sensing systems;Reliability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197039&isnumber=9196508

Y. Huang and D. G. Caldwell, "A Linearly Constrained Nonparametric Framework for Imitation Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4400-4406.
doi: 10.1109/ICRA40945.2020.9196821
Abstract: In recent years, a myriad of advanced results have been reported in the community of imitation learning, ranging from parametric to non-parametric, probabilistic to non-probabilistic and Bayesian to frequentist approaches. Meanwhile, ample applications (e.g., grasping tasks and humanrobot collaborations) further show the applicability of imitation learning in a wide range of domains. While numerous literature is dedicated to the learning of human skills in unconstrained environments, the problem of learning constrained motor skills, however, has not received equal attention. In fact, constrained skills exist widely in robotic systems. For instance, when a robot is demanded to write letters on a board, its end-effector trajectory must comply with the plane constraint from the board. In this paper, we propose linearly constrained kernelized movement primitives (LC-KMP) to tackle the problem of imitation learning with linear constraints. Specifically, we propose to exploit the probabilistic properties of multiple demonstrations, and subsequently incorporate them into a linearly constrained optimization problem, which finally leads to a non-parametric solution. In addition, a connection between our framework and the classical model predictive control is provided. Several examples including simulated writing and locomotion tasks are presented to show the effectiveness of our framework.
keywords: {Trajectory;Probabilistic logic;Robots;Task analysis;Optimization;Kernel;Grasping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196821&isnumber=9196508

M. Saveriano, "An Energy-based Approach to Ensure the Stability of Learned Dynamical Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4407-4413.
doi: 10.1109/ICRA40945.2020.9196978
Abstract: Non-linear dynamical systems represent a compact, flexible, and robust tool for reactive motion generation. The effectiveness of dynamical systems relies on their ability to accurately represent stable motions. Several approaches have been proposed to learn stable and accurate motions from demonstration. Some approaches work by separating accuracy and stability into two learning problems, which increases the number of open parameters and the overall training time. Alternative solutions exploit single-step learning but restrict the applicability to one regression technique. This paper presents a single-step approach to learn stable and accurate motions that work with any regression technique. The approach makes energy considerations on the learned dynamics to stabilize the system at run-time while introducing small deviations from the demonstrated motion. Since the initial value of the energy injected into the system affects the reproduction accuracy, it is estimated from training data using an efficient procedure. Experiments on a real robot and a comparison on a public benchmark shows the effectiveness of the proposed approach.
keywords: {Lyapunov methods;Training data;Robots;Electrostatic discharges;Stability analysis;Trajectory;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196978&isnumber=9196508

A. Mandlekar et al., "IRIS: Implicit Reinforcement without Interaction at Scale for Learning Control from Offline Robot Manipulation Data," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4414-4420.
doi: 10.1109/ICRA40945.2020.9196935
Abstract: Learning from offline task demonstrations is a problem of great interest in robotics. For simple short-horizon manipulation tasks with modest variation in task instances, offline learning from a small set of demonstrations can produce controllers that successfully solve the task. However, leveraging a fixed batch of data can be problematic for larger datasets and longer-horizon tasks with greater variations. The data can exhibit substantial diversity and consist of suboptimal solution approaches. In this paper, we propose Implicit Reinforcement without Interaction at Scale (IRIS), a novel framework for learning from large-scale demonstration datasets. IRIS factorizes the control problem into a goal-conditioned low-level controller that imitates short demonstration sequences and a high-level goal selection mechanism that sets goals for the low-level and selectively combines parts of suboptimal solutions leading to more successful task completions. We evaluate IRIS across three datasets, including the RoboTurk Cans dataset collected by humans via crowdsourcing, and show that performant policies can be learned from purely offline learning. Additional results at https://sites.google.com/stanford.edu/iris/.
keywords: {Task analysis;Robots;Trajectory;Iris;Learning (artificial intelligence);Iris recognition;Grasping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196935&isnumber=9196508

F. J. Abu-Dakka and V. Kyrki, "Geometry-aware Dynamic Movement Primitives," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4421-4426.
doi: 10.1109/ICRA40945.2020.9196952
Abstract: In many robot control problems, factors such as stiffness and damping matrices and manipulability ellipsoids are naturally represented as symmetric positive definite (SPD) matrices, which capture the specific geometric characteristics of those factors. Typical learned skill models such as dynamic movement primitives (DMPs) can not, however, be directly employed with quantities expressed as SPD matrices as they are limited to data in Euclidean space. In this paper, we propose a novel and mathematically principled framework that uses Riemannian metrics to reformulate DMPs such that the resulting formulation can operate with SPD data in the SPD manifold. Evaluation of the approach demonstrates that beneficial properties of DMPs such as change of the goal during operation apply also to the proposed formulation.
keywords: {Manifolds;Robots;Symmetric matrices;Standards;Ellipsoids;Switches;Measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196952&isnumber=9196508

W. Yang, N. Strokina, N. Serbenyuk, R. Ghabcheloo and J. K√§m√§r√§inen, "Learning a Pile Loading Controller from Demonstrations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4427-4433.
doi: 10.1109/ICRA40945.2020.9196907
Abstract: This work introduces a learning-based pile loading controller for autonomous robotic wheel loaders. Controller parameters are learnt from a small number of demonstrations for which low level sensor (boom angle, bucket angle and hydrostatic driving pressure), egocentric video frames and control signals are recorded. Application specific deep visual features are learnt from demonstrations using a Siamese network architecture and a combination of cross-entropy and contrastive loss. The controller is based on a Random Forest (RF) regressor that provides robustness against changes in field conditions (loading distance, soil type, weather and illumination). The controller is deployed to a real autonomous robotic wheel loader and it outperforms prior art with a clear margin.
keywords: {Visualization;Loading;Robot sensing systems;Task analysis;Feature extraction;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196907&isnumber=9196508

T. Wang, V. Dhiman and N. Atanasov, "Learning Navigation Costs from Demonstration in Partially Observable Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4434-4440.
doi: 10.1109/ICRA40945.2020.9197199
Abstract: This paper focuses on inverse reinforcement learning (IRL) to enable safe and efficient autonomous navigation in unknown partially observable environments. The objective is to infer a cost function that explains expert-demonstrated navigation behavior while relying only on the observations and state-control trajectory used by the expert. We develop a cost function representation composed of two parts: a probabilistic occupancy encoder, with recurrent dependence on the observation sequence, and a cost encoder, defined over the occupancy features. The representation parameters are optimized by differentiating the error between demonstrated controls and a control policy computed from the cost encoder. Such differentiation is typically computed by dynamic programming through the value function over the whole state space. We observe that this is inefficient in large partially observable environments because most states are unexplored. Instead, we rely on a closed-form subgradient of the cost-to-go obtained only over a subset of promising states via an efficient motion-planning algorithm such as A* or RRT. Our experiments show that our model exceeds the accuracy of baseline IRL algorithms in robot navigation tasks, while substantially improving the efficiency of training and test-time inference.
keywords: {Robots;Cost function;Navigation;Planning;Feature extraction;Heuristic algorithms;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197199&isnumber=9196508

C. He et al., "Towards Bimanual Vein Cannulation: Preliminary Study of a Bimanual Robotic System With a Dual Force Constraint Controller," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4441-4447.
doi: 10.1109/ICRA40945.2020.9196889
Abstract: Retinal vein cannulation is a promising approach for treating retinal vein occlusion that involves injecting medicine into the occluded vessel to dissolve the clot. The approach remains largely unexploited clinically due to surgeon limitations in detecting interaction forces between surgical tools and retinal tissue. In this paper, a dual force constraint controller for robot-assisted retinal surgery was presented to keep the tool-to-vessel forces and tool-to-sclera forces below prescribed thresholds. A cannulation tool and forceps with dual force-sensing capability were developed and used to measure force information fed into the robot controller, which was implemented on existing Steady Hand Eye Robot platforms. The robotic system facilitates retinal vein cannulation by allowing a user to grasp the target vessel with the forceps and then enter the vessel with the cannula. The system was evaluated on an eye phantom. The results showed that, while the eyeball was subjected to rotational disturbances, the proposed controller actuates the robotic manipulators to maintain the average tool-to-vessel force at 10.9 mN and 13.1 mN and the average tool-to-sclera force at 38.1 mN and 41.2 mN for the cannula and the forcpes, respectively. Such small tool-to-tissue forces are acceptable to avoid retinal tissue injury. Additionally, two clinicians participated in a preliminary user study of the bimanual cannulation demonstrating that the operation time and tool-to-tissue forces are significantly decreased when using the bimanual robotic system as compared to freehand performance.
keywords: {Tools;Force;Robot sensing systems;Retina;Surgery;Veins},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196889&isnumber=9196508

S. Jeong and K. Tadano, "Evaluation of a combined grip of pinch and power grips in manipulating a master manipulator," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4448-4454.
doi: 10.1109/ICRA40945.2020.9196547
Abstract: In conventional robotic surgery, the manipulating methods exhibit limitations that are strongly related to the advantages and disadvantages of a pinch grip and power grip. The context of this study is focused on the introduction of a combined grip to compensate for such restraints. In particular, this study proposed the combined-grip-handle scheme on a master manipulator. In this framework, the position of fingertips was designed to be adjustable in distance and direction to allow for a pinch grip motion around the holding axis of a power grip motion. A ring-bar experiment applying the master-slave scheme was conducted with the master manipulator under several manipulating conditions of the combined grip and the conventional gripping types. Results for using the combined grip demonstrated that the combined grip showed better performance on the positioning operation, compared with the conventional gripping types.
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196547&isnumber=9196508

R. Hao, T. Greigarn and M. C. √áavu≈üoƒülu, "Contact Stability Analysis of Magnetically-Actuated Robotic Catheter Under Surface Motion," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4455-4462.
doi: 10.1109/ICRA40945.2020.9196951
Abstract: Contact force quality is one of the most critical factors for safe and effective lesion formation during cardiac ablation. The contact force and contact stability plays important roles in determining the lesion size and creating a gap-free lesion. In this paper, the contact stability of a novel magnetic resonance imaging (MRI)-actuated robotic catheter under tissue surface motion is studied. The robotic catheter is modeled using a pseudo-rigid-body model, and the contact model under surface constraint is provided. Two contact force control schemes to improve the contact stability of the catheter under heart surface motions are proposed and their performance are evaluated in simulation.
keywords: {Catheters;Force;Force control;Robots;Stability analysis;Magnetic resonance imaging;Friction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196951&isnumber=9196508

R. Chalard, D. Reversat, G. Morel and M. -A. Vitrani, "Fast and accurate intracorporeal targeting through an anatomical orifice exhibiting unknown behavior," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4463-4469.
doi: 10.1109/ICRA40945.2020.9196950
Abstract: Surgery may involve precise instrument tip positioning in a minimally invasive way. During these operations, the instrument is inserted in the body through an orifice. The movements of the instrument are constrained by interaction forces arising at the orifice level. The physical constraints may drastically vary depending on the patient‚Äôs anatomy. This introduces uncertainties that challenge the positioning task for a robot. Indeed, it raises an antagonism: On one side, the required precision appeals for a rigid behavior. On the other side, forces applied at the entry point should be limited, which requires softness. In this paper we choose to minimize forces at the orifice by using a passive ball joint wrist to manipulate the instrument. From a control perspective, this leads to consider the task as a 3 DOF wrist center positioning problem, whose softness can be achieved through conventional low impedance control. However, positioning the wrist center, even with a high static precision, does not allow to achieve a high precision of the instrument tip positioning when the orifice behavior is not known. To cope with this problem, we implement a controller that servos the tip position by commanding the wrist position. In order to deal with uncertainties, we exploit an adaptive control scheme that identifies in real-time the unknown mapping between the wrist velocity and the tip velocity. Both simulations and in vitro experimental results show the efficiency of the control law.
keywords: {Robots;Instruments;Wrist;Surgery;Force;Adaptation models;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196950&isnumber=9196508

M. Luo et al., "Robotic Swarm Control for Precise and On-Demand Embolization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4470-4476.
doi: 10.1109/ICRA40945.2020.9197009
Abstract: Existing approaches for robotic control of magnetic swarms are not capable of generating magnetic aggregates precisely in an arbitrarily specified target region in a fluidic flow environment. Such a swarm control capability is demanded by medical applications such as clinical embolization (i.e., localized clogging of blood vessels). This paper presents a new magnetic swarm control strategy to generate aggregates only in a specified target region under fluidic flow. Within the target region, the magnetic field generates sufficiently large magnetic forces among magnetic particles to maintain the aggregates' integrity at the junctions of blood vessels. In contrast, unintended aggregates outside the target region are disassembled by fluidic shear. The aggregation control approach achieved a mean absolute error of 0.15 mm in positioning a target region and a mean absolute error of 0.30 mm in controlling the target region's radius. With thrombin coating, 1 Œºm magnetic particles were controlled to perform embolization both in vitro (using microfluidic channel networks) and ex vivo (using porcine tissue). Experiments proved the effectiveness of the swarm control technique for on-demand, targeted embolization.
keywords: {Aggregates;Magnetic tunneling;Coils;Junctions;Magnetic particles;Blood vessels;Magnetic separation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197009&isnumber=9196508

H. Su, Y. Schmirander, Z. Li, X. Zhou, G. Ferrigno and E. De Momi, "Bilateral Teleoperation Control of a Redundant Manipulator with an RCM Kinematic Constraint," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4477-4482.
doi: 10.1109/ICRA40945.2020.9197267
Abstract: In this paper, a bilateral teleoperation control of a serial robot manipulator, which guarantees a Remote Center of Motion (RCM) constraint in its kinematic level, is developed. A two-layered approach based on the energy tank model is proposed to achieve haptic feedback on the end effector with a pedal switch. The redundancy of the manipulator is exploited to maintain the RCM constraint using the decoupled Cartesian Admittance Control. Transparency and stability of the proposed bilateral teleoperation are demonstrated using a KUKA LWR4+ serial robot and a Sigma 7 haptic manipulator with an RCM constraint in augmented reality. The results prove that the control can achieve not only the bilateral teleoperation but also maintain the RCM constraint.
keywords: {Manipulators;Surgery;Force;Frequency modulation;Kinematics;Haptic interfaces;Switches},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197267&isnumber=9196508

W. -L. Ma and A. D. Ames, "From Bipedal Walking to Quadrupedal Locomotion: Full-Body Dynamics Decomposition for Rapid Gait Generation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4491-4497.
doi: 10.1109/ICRA40945.2020.9196841
Abstract: This paper systematically decomposes a quadrupedal robot into bipeds to rapidly generate walking gaits and then recomposes these gaits to obtain quadrupedal locomotion. We begin by decomposing the full-order, nonlinear and hybrid dynamics of a three-dimensional quadrupedal robot, including its continuous and discrete dynamics, into two bipedal systems that are subject to external forces. Using the hybrid zero dynamics (HZD) framework, gaits for these bipedal robots can be rapidly generated (on the order of seconds) along with corresponding controllers. The decomposition is achieved in such a way that the bipedal walking gaits and controllers can be composed to yield dynamic walking gaits for the original quadrupedal robot - the result is the rapid generation of dynamic quadruped gaits utilizing the full-order dynamics. This methodology is demonstrated through the rapid generation (3.96 seconds on average) of four stepping-in-place gaits and one diagonally symmetric ambling gait at 0.35 m/s on a quadrupedal robot - the Vision 60, with 36 state variables and 12 control inputs - both in simulation and through outdoor experiments. This suggested a new approach for fast quadrupedal trajectory planning using full-body dynamics, without the need for empirical model simplification, wherein methods from dynamic bipedal walking can be directly applied to quadrupeds.
keywords: {Legged locomotion;Robot kinematics;Dynamics;Nonlinear dynamical systems;Jacobian matrices;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196841&isnumber=9196508

M. Tikam, D. Withey and N. J. Theron, "Posture Control for a Low-Cost Commercially-Available Hexapod Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4498-4504.
doi: 10.1109/ICRA40945.2020.9197147
Abstract: Posture control for legged robots has been widely developed on custom-designed robotic platforms, with little work being done on commercially-available robots despite their potential as low-cost research platforms. This paper presents the implementation of a Walking Posture Control system on a commercially-available hexapod robot which utilizes low-cost joint actuators without torque control capabilities. The hierarchical control system employs Virtual Model Control with simple foot force distribution and a novel, position-based Foot Force Controller that enables direct force control during the leg's stance phase and active compliance control during the swing phase. Ground truth measurements in experimental tests, obtained with a Vicon motion capture system, demonstrate the improvement to posture made by the control system on uneven terrain, with the results comparing favorably to those obtained in similar tests on more sophisticated, custom-designed platforms.
keywords: {Legged locomotion;Foot;Force;Robot sensing systems;Control systems;Engines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197147&isnumber=9196508

A. Wiktor and S. Rock, "Collaborative Multi-Robot Localization in Natural Terrain," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4529-4535.
doi: 10.1109/ICRA40945.2020.9197576
Abstract: This paper presents a novel filter architecture that allows a team of vehicles to collaboratively localize using Terrain Relative Navigation (TRN). The work explores several causes of measurement correlation that preclude the use of traditional estimators, and proposes an estimator structure that eliminates one source of measurement correlation while properly incorporating others through the use of Covariance Intersection. The result is a consistent estimator that is able to augment proven TRN techniques with multi-robot information, significantly improving localization for vehicles in uninformative terrain. The approach is demonstrated using field data from an Autonomous Underwater Vehicle (AUV) navigating with TRN in Monterey Bay and simulated inter-vehicle range measurements. In addition, a Monte Carlo simulation was used to quantify the algorithm's performance on one example mission. Monte Carlo results show that a vehicle operating in uninformative terrain has 62% lower localization error when fusing range measurements to two converged AUVs than it would using standard TRN.
keywords: {Robots;Correlation;Atmospheric measurements;Particle measurements;Extraterrestrial measurements;Collaboration;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197576&isnumber=9196508

X. Xu and Y. Diaz-Mercado, "Multi-Robot Control Using Coverage Over Time-Varying Non-Convex Domains," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4536-4542.
doi: 10.1109/ICRA40945.2020.9196630
Abstract: This paper addresses the problem of a domain becoming non-convex while using coverage control of a multirobot system over time-varying domains. When the domain moves around in the workspace, its motion and the presence of obstacles might cause it to deform into some non-convex shape, and the robot team should act in a coordinating manner to maintain coverage. The proposed solution is based on a framework for constructing a diffeomorphism to transform a non-convex coverage problem into a convex one. A control law is developed to capture the effects of time variations (e.g., from a time-varying density, time-varying convex hull of the domain and time-varying diffeomorphism) in the system. Analytic expressions of each term in the control law are found for uniform density case. A simulation and robotic implementation are used to validate the proposed algorithm.
keywords: {Robot kinematics;Multi-robot systems;Time-varying systems;Collision avoidance;Robot sensing systems;Transforms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196630&isnumber=9196508

S. Choudhury, K. Solovey, M. J. Kochenderfer and M. Pavone, "Efficient Large-Scale Multi-Drone Delivery Using Transit Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4543-4550.
doi: 10.1109/ICRA40945.2020.9197313
Abstract: We consider the problem of controlling a large fleet of drones to deliver packages simultaneously across broad urban areas. To conserve energy, drones hop between public transit vehicles (e.g., buses and trams). We design a comprehensive algorithmic framework that strives to minimize the maximum time to complete any delivery. We address the multifaceted complexity of the problem through a two-layer approach. First, the upper layer assigns drones to package delivery sequences with a near-optimal polynomial-time task allocation algorithm. Then, the lower layer executes the allocation by periodically routing the fleet over the transit network while employing efficient bounded-suboptimal multi-agent pathfinding techniques tailored to our setting. Experiments demonstrate the efficiency of our approach on settings with up to 200 drones, 5000 packages, and transit networks with up to 8000 stops in San Francisco and Washington DC. Our results show that the framework computes solutions within a few seconds (up to 2 minutes at most) on commodity hardware, and that drones travel up to 450% of their flight range with public transit.
keywords: {Drones;Task analysis;Resource management;Routing;Urban areas;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197313&isnumber=9196508

R. K. Ramachandran, N. Fronda and G. S. Sukhatme, "Resilience in multi-robot target tracking through reconfiguration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4551-4557.
doi: 10.1109/ICRA40945.2020.9196961
Abstract: We address the problem of maintaining resource availability in a networked multi-robot system performing distributed target tracking. In our model, robots are equipped with sensing and computational resources enabling them to track a target's position using a Distributed Kalman Filter (DKF). We use the trace of each robot's sensor measurement noise covariance matrix as a measure of sensing quality. When a robot's sensing quality deteriorates, the systems communication graph is modified by adding edges such that the robot with deteriorating sensor quality may share information with other robots to improve the team's target tracking ability. This computation is performed centrally and is designed to work without a large change in the number of active communication links. We propose two mixed integer semi-definite programming formulations (an `agent-centric' strategy and a `team-centric' strategy) to achieve this goal. We implement both formulations and a greedy strategy in simulation and show that the team-centric strategy outperforms the agent-centric and greedy strategies.
keywords: {Robot sensing systems;Target tracking;Covariance matrices;Kalman filters;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196961&isnumber=9196508

L. Sabattini, B. Capelli, C. Fantuzzi and C. Secchi, "Teleoperation of Multi-Robot Systems to Relax Topological Constraints," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4558-4564.
doi: 10.1109/ICRA40945.2020.9197254
Abstract: Multi-robot systems are able to achieve common objectives exchanging information among each other. This is possible exploiting a communication structure, usually modeled as a graph, whose topological properties (such as connectivity) are very relevant in the overall performance of the multirobot system. When considering mobile robots, such properties can change over time: robots are then controlled to preserve them, thus guaranteeing the possibility, for the overall system, to achieve its goals. This, however, implies limitations on the possible motion patterns of the robots, thus reducing the flexibility of the overall multi-robot system. In this paper we introduce teleoperation as a means to reduce these limitations, allowing temporary violations of topological properties, with the aim of increasing the flexibility of the multi-robot system.
keywords: {Multi-robot systems;Force;Mobile robots;Force feedback;Collision avoidance;Damping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197254&isnumber=9196508

M. Malley, B. Haghighat, L. Houel and R. Nagpal, "Eciton robotica: Design and Algorithms for an Adaptive Self-Assembling Soft Robot Collective," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4565-4571.
doi: 10.1109/ICRA40945.2020.9196565
Abstract: Social insects successfully create bridges, rafts, nests and other structures out of their own bodies and do so with no centralized control system, simply by following local rules. For example, while traversing rough terrain, army ants (genus Eciton) build bridges which grow and dissolve in response to local traffic. Because these self-assembled structures incorporate smart, flexible materials (i.e. ant bodies) and emerge from local behavior, the bridges are adaptive and dynamic. With the goal of realizing robotic collectives with similar features, we designed a hardware system, Eciton robotica, consisting of flexible robots that can climb over each other to assemble compliant structures and communicate locally using vibration. In simulation, we demonstrate self-assembly of structures: using only local rules and information, robots build and dissolve bridges in response to local traffic and varying terrain. Unlike previous self-assembling robotic systems that focused on latticebased structures and predetermined shapes, our system takes a new approach where soft robots attach to create amorphous structures whose final self-assembled shape can adapt to the needs of the group.
keywords: {Robot sensing systems;Bridges;Grippers;Vibrations;Self-assembly;Hardware},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196565&isnumber=9196508

K. Kawaharazuka et al., "Stable Tool-Use with Flexible Musculoskeletal Hands by Learning the Predictive Model of Sensor State Transition," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4572-4578.
doi: 10.1109/ICRA40945.2020.9197188
Abstract: The flexible under-actuated musculoskeletal hand is superior in its adaptability and impact resistance. On the other hand, since the relationship between sensors and actuators cannot be uniquely determined, almost all its controls are based on feedforward controls. When grasping and using a tool, the contact state of the hand gradually changes due to the inertia of the tool or impact of action, and the initial contact state is hardly kept. In this study, we propose a system that trains the predictive network of sensor state transition using the actual robot sensor information, and keeps the initial contact state by a feedback control using the network. We conduct experiments of hammer hitting, vacuuming, and brooming, and verify the effectiveness of this study.
keywords: {Grasping;Muscles;Robot sensing systems;Gold;Tools},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197188&isnumber=9196508

L. Schramm, A. Sintov and A. Boularias, "Learning to Transfer Dynamic Models of Underactuated Soft Robotic Hands," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4579-4585.
doi: 10.1109/ICRA40945.2020.9197300
Abstract: Transfer learning is a popular approach to bypassing data limitations in one domain by leveraging data from another domain. This is especially useful in robotics, as it allows practitioners to reduce data collection with physical robots, which can be time-consuming and cause wear and tear. The most common way of doing this with neural networks is to take an existing neural network, and simply train it more with new data. However, we show that in some situations this can lead to significantly worse performance than simply using the transferred model without adaptation. We find that a major cause of these problems is that models trained on small amounts of data can have chaotic or divergent behavior in some regions. We derive an upper bound on the Lyapunov exponent of a trained transition model, and demonstrate two approaches that make use of this insight. Both show significant improvement over traditional fine-tuning. Experiments performed on real underactuated soft robotic hands clearly demonstrate the capability to transfer a dynamic model from one hand to another.
keywords: {Adaptation models;Robots;Data models;Neural networks;Analytical models;Friction;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197300&isnumber=9196508

P. Oikonomou, M. Khamassi and C. S. Tzafestas, "Periodic movement learning in a soft-robotic arm," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4586-4592.
doi: 10.1109/ICRA40945.2020.9197035
Abstract: In this paper we introduce a novel technique that aims to dynamically control a modular bio-inspired soft-robotic arm in order to perform cyclic rhythmic patterns. Oscillatory signals are produced at the actuator's level by a central pattern generator (CPG), resulting in the generation of a periodic motion by the robot's end-effector. The proposed controller is based on a model-free neurodynamic scheme and is assigned with the task of training a policy that computes the parameters of the CPG model which generates a trajectory with desired features. The proposed methodology is first evaluated with a simulation model, which successfully reproduces the trained targets. Then experiments are also conducted using the real robot. Both procedures validate the efficiency of the learning architecture to successfully complete these tasks.
keywords: {Oscillators;Trajectory;Manipulators;Biological system modeling;Soft robotics;Mathematical model;Reinforcement learning;Central pattern generators;Soft Robotics;Rhythmic movements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197035&isnumber=9196508

O. Ogunmolu, X. Liu, N. Gans and R. D. Wiersma, "Mechanism and Model of a Soft Robot for Head Stabilization in Cancer Radiation Therapy," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4609-4615.
doi: 10.1109/ICRA40945.2020.9197007
Abstract: We present a parallel robot mechanism and the constitutive laws that govern the deformation of its constituent soft actuators. Our ultimate goal is the real-time motion-correction of a patient's head deviation from a target pose where the soft actuators control the position of the patient's cranial region on a treatment machine. We describe the mechanism, derive the stress-strain constitutive laws for the individual actuators and the inverse kinematics that prescribes a given deformation, and then present simulation results that validate our mathematical formulation. Our results demonstrate deformations consistent with our radially symmetric displacement formulation under a finite elastic deformation framework.
keywords: {Strain;Actuators;Adaptation models;Stress;Real-time systems;Robots;Cancer},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197007&isnumber=9196508

I. Akinola, J. Varley and D. Kalashnikov, "Learning Precise 3D Manipulation from Multiple Uncalibrated Cameras," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4616-4622.
doi: 10.1109/ICRA40945.2020.9197181
Abstract: In this work, we present an effective multi-view approach to closed-loop end-to-end learning of precise manipulation tasks that are 3D in nature. Our method learns to accomplish these tasks using multiple statically placed but uncalibrated RGB camera views without building an explicit 3D representation such as a pointcloud or voxel grid. This multi-camera approach achieves superior task performance on difficult stacking and insertion tasks compared to single-view baselines. Single view robotic agents struggle from occlusion and challenges in estimating relative poses between points of interest. While full 3D scene representations (voxels or pointclouds) are obtainable from registered output of multiple depth sensors, several challenges complicate operating off such explicit 3D representations. These challenges include imperfect camera calibration, poor depth maps due to object properties such as reflective surfaces, and slower inference speeds over 3D representations compared to 2D images. Our use of static but uncalibrated cameras does not require camera-robot or camera-camera calibration making the proposed approach easy to setup and our use of sensor dropout during training makes it resilient to the loss of camera-views after deployment.
keywords: {Task analysis;Cameras;Robot vision systems;Three-dimensional displays;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197181&isnumber=9196508

A. Strai≈æys, M. Burke and S. Ramamoorthy, "Surfing on an uncertain edge: Precision cutting of soft tissue using torque-based medium classification," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4623-4629.
doi: 10.1109/ICRA40945.2020.9196623
Abstract: Precision cutting of soft-tissue remains a challenging problem in robotics, due to the complex and unpredictable mechanical behaviour of tissue under manipulation. Here, we consider the challenge of cutting along the boundary between two soft mediums, a problem that is made extremely difficult due to visibility constraints, which means that the precise location of the cutting trajectory is typically unknown. This paper introduces a novel strategy to address this task, using a binary medium classifier trained using joint torque measurements, and a closed loop control law that relies on an error signal compactly encoded in the decision boundary of the classifier. We illustrate this on a grapefruit cutting task, successfully modulating a nominal trajectory t using dynamic movement primitives to follow the boundary between grapefruit pulp and peel using torque based medium classification. Results show that this control strategy is successful in 72 % of attempts in contrast to control using a nominal trajectory, which only succeeds in 50 % of attempts.
keywords: {Task analysis;Trajectory;Pipelines;Torque;Robot sensing systems;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196623&isnumber=9196508

R. Jangir, G. Aleny√† and C. Torras, "Dynamic Cloth Manipulation with Deep Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4630-4636.
doi: 10.1109/ICRA40945.2020.9196659
Abstract: In this paper we present a Deep Reinforcement Learning approach to solve dynamic cloth manipulation tasks. Differing from the case of rigid objects, we stress that the followed trajectory (including speed and acceleration) has a decisive influence on the final state of cloth, which can greatly vary even if the positions reached by the grasped points are the same. We explore how goal positions for non-grasped points can be attained through learning adequate trajectories for the grasped points. Our approach uses few demonstrations to improve control policy learning, and a sparse reward approach to avoid engineering complex reward functions. Since perception of textiles is challenging, we also study different state representations to assess the minimum observation space required for learning to succeed. Finally, we compare different combinations of control policy encodings, demonstrations, and sparse reward learning techniques, and show that our proposed approach can learn dynamic cloth manipulation in an efficient way, i.e., using a reduced observation space, a few demonstrations, and a sparse reward.
keywords: {Task analysis;Manipulator dynamics;Trajectory;Textiles;Deformable models;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196659&isnumber=9196508

R. Strudel, A. Pashevich, I. Kalevatykh, I. Laptev, J. Sivic and C. Schmid, "Learning to combine primitive skills: A step towards versatile robotic manipulation ¬ß," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4637-4643.
doi: 10.1109/ICRA40945.2020.9196619
Abstract: Manipulation tasks such as preparing a meal or assembling furniture remain highly challenging for robotics and vision. Traditional task and motion planning (TAMP) methods can solve complex tasks but require full state observability and are not adapted to dynamic scene changes. Recent learning methods can operate directly on visual inputs but typically require many demonstrations and/or task-specific reward engineering. In this work we aim to overcome previous limitations and propose a reinforcement learning (RL) approach to task planning that learns to combine primitive skills. First, compared to previous learning methods, our approach requires neither intermediate rewards nor complete task demonstrations during training. Second, we demonstrate the versatility of our vision-based task planning in challenging settings with temporary occlusions and dynamic scene changes. Third, we propose an efficient training of basic skills from few synthetic demonstrations by exploring recent CNN architectures and data augmentation. Notably, while all of our policies are learned on visual inputs in simulated environments, we demonstrate the successful transfer and high success rates when applying such policies to manipulation tasks on a real UR5 robotic arm.
keywords: {Task analysis;Robots;Planning;Learning (artificial intelligence);Training;Trajectory;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196619&isnumber=9196508

H. Wu, Z. Zhang, H. Cheng, K. Yang, J. Liu and Z. Guo, "Learning Affordance Space in Physical World for Vision-based Robotic Object Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4652-4658.
doi: 10.1109/ICRA40945.2020.9196783
Abstract: What is a proper representation for objects in manipulation? What would human try to perceive when manipulating a new object in a new environment? In fact, instead of focusing on the texture and illumination, human can infer the "affordance" [36] of the objects from vision. Here "affordance" describes the object's intrinsic property that affords a particular type of manipulation. In this work, we investigate whether such affordance can be learned by a deep neural network. In particular, we propose an Affordance Space Perception Network (ASPN) that takes an image as input and outputs an affordance map. Different from existing works that infer the pixel-wise probability affordance map in image space, our affordance is defined in the real world space, thus eliminates the need of hand-eye calibration. In addition, we extend the representation ability of affordance by defining it in a 3D affordance space and propose a novel training strategy to improve the performance. Trained purely with simulation data, ASPN can achieve significant performance in the real world. It is a task-agnostic framework and can handle different objects, scenes and viewpoints. Extensive real-world experiments demonstrate the accuracy and robustness of our approach. We achieve the success rates of 94.2% for singular-object pushing and 92.4% for multiple-object pushing. We also achieve the success rates of 97.2% for singular-object grasping and 95.4% for multiple-object grasping, which outperform current state-of-the-art methods.
keywords: {Robots;Task analysis;Robustness;Grasping;Data models;Calibration;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196783&isnumber=9196508

P. Huang, H. Meyr, M. D√∂rpinghaus and G. Fettweis, "Observability Analysis of Flight State Estimation for UAVs and Experimental Validation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4659-4665.
doi: 10.1109/ICRA40945.2020.9196635
Abstract: UAVs require reliable, cost-efficient onboard flight state estimation that achieves high accuracy and robustness to perturbation. We analyze a multi-sensor extended Kalman filter (EKF) based on the work by Leutenegger. The EKF uses measurements from a MEMS-based inertial system, static and dynamic pressure sensors as well as GPS. As opposed to other implementations we do not use a magnetic sensor because the weak magnetic field of the earth is subject to disturbances. Observability of the state is a necessary condition for the EKF to work. In this paper, we demonstrate that the system state is observable - which is in contrast to statements in the literature - if the random nature of the air mass is taken into account. Therefore, we carry out an in-depth observability analysis based on a singular value decomposition (SVD). The numerical SVD delivers a wealth of information regarding the observable (sub)spaces. We validated the theoretical findings based on sensor data recorded in test flights on a glider. Most importantly, we demonstrate that the EKF works. It is capable of absorbing large perturbations in the wind state variable converging to the undisturbed estimates.
keywords: {Observability;Mathematical model;Aerodynamics;State estimation;Global Positioning System;Magnetometers;Pressure measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196635&isnumber=9196508

P. Geneva, K. Eckenhoff, W. Lee, Y. Yang and G. Huang, "OpenVINS: A Research Platform for Visual-Inertial Estimation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4666-4672.
doi: 10.1109/ICRA40945.2020.9196524
Abstract: In this paper, we present an open platform, termed OpenVINS, for visual-inertial estimation research for both the academic community and practitioners from industry. The open sourced codebase provides a foundation for researchers and engineers to quickly start developing new capabilities for their visual-inertial systems. This codebase has out of the box support for commonly desired visual-inertial estimation features, which include: (i) on-manifold sliding window Kalman filter, (ii) online camera intrinsic and extrinsic calibration, (iii) camera to inertial sensor time offset calibration, (iv) SLAM landmarks with different representations and consistent First-Estimates Jacobian (FEJ) treatments, (v) modular type system for state management, (vi) extendable visual-inertial system simulator, and (vii) extensive toolbox for algorithm evaluation. Moreover, we have also focused on detailed documentation and theoretical derivations to support rapid development and research, which are greatly lacked in the current open sourced algorithms. Finally, we perform comprehensive validation of the proposed OpenVINS against state-of-the-art open sourced algorithms, showing its competing estimation performance.
keywords: {Cameras;Current measurement;Jacobian matrices;Calibration;Documentation;Estimation;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196524&isnumber=9196508

R. Jung, C. Brommer and S. Weiss, "Decentralized Collaborative State Estimation for Aided Inertial Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4673-4679.
doi: 10.1109/ICRA40945.2020.9197178
Abstract: In this paper, we present a Quaternion-based Error-State Extended Kalman Filter (Q-ESEKF) based on IMU propagation with an extension for Collaborative State Estimation (CSE) and a communication complexity of O(1) (in terms of required communication links). Our approach combines a versatile filter formulation with the concept of CSE, allowing independent state estimation on each of the agents and at the same time leveraging and statistically maintaining interdependencies between agents, after joint measurements and communication (i.e. relative position measurements) occur. We discuss the development of the overall framework and the probabilistic (re-)initialization of the agent's states upon initial or recurring joint observations. Our approach is evaluated in a simulation framework on two prominent benchmark datasets in 3D.
keywords: {Cameras;Sensors;Collaboration;State estimation;Three-dimensional displays;Calibration;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197178&isnumber=9196508

Y. Yang, B. P. Wisely Babu, C. Chen, G. Huang and L. Ren, "Analytic Combined IMU Integration (ACI2) For Visual Inertial Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4680-4686.
doi: 10.1109/ICRA40945.2020.9197280
Abstract: Batch optimization based inertial measurement unit (IMU) and visual sensor fusion enables high rate localization for many robotic tasks. However, it remains a challenge to ensure that the batch optimization is computationally efficient while being consistent for high rate IMU measurements without marginalization. In this paper, we derive inspiration from maximum likelihood estimation with partial-fixed estimates to provide a unified approach for handing both IMU preintegration and time-offset calibration. We present a modularized analytic combined IMU integrator (ACI2) with elegant derivations for IMU integrations, bias Jabcobians and related covariances. To simplify our derivation, we also prove that the right Jacobians for Hamilton quaterions and SO(3) are equivalent. Finally, we present a time offset calibrator that operates by fixing the linearization point for a given time offset. This reduces re-integration of the IMU measurements and thus improve efficiency. The proposed ACI2 and time-offset calibration is verified by intensive Monte-Carlo simulations generated from real world datasets. A proof-of-concept real world experiment is also conducted to verify the proposed ACI2 estimator.
keywords: {Optimization;Jacobian matrices;Maximum likelihood estimation;Time measurement;Cameras;Visualization;Calibration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197280&isnumber=9196508

Q. Leboutet, J. R. Guadarrama-Olvera, F. Bergner and G. Cheng, "Second-order Kinematics for Floating-base Robots using the Redundant Acceleration Feedback of an Artificial Sensory Skin," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4687-4694.
doi: 10.1109/ICRA40945.2020.9197169
Abstract: In this work, we propose a new estimation method for second-order kinematics for floating-base robots, based on highly redundant distributed inertial feedback. The linear acceleration of each robot link is measured at multiple points using a multimodal, self-configuring and self-calibrating artificial skin. The proposed algorithm is two-fold: i) the skin acceleration data is fused at the link level for state dimensionality reduction; ii) the estimated values are then fused limb-wise with data from the joint encoders and the main inertial measurement unit (IMU), using a Sigma-point Kalman filter. In this manner, it is possible to estimate the joint velocities and accelerations while avoiding the lag and noise amplification phenomena associated with conventional numerical derivation approaches. Experiments performed on the right arm and torso of a REEM-C humanoid robot, demonstrate the consistency of the proposed estimation method.
keywords: {Acceleration;Robot sensing systems;Skin;Gyroscopes;Accelerometers;Acceleration Feedback;Artificial Robot Skin;Sigma-point Kalman Filter},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197169&isnumber=9196508

V. Osadcuks, M. Pudzs, A. Zujevs, A. Pecka and A. Ardavs, "Clock-based time synchronization for an event-based camera dataset acquisition platform," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4695-4701.
doi: 10.1109/ICRA40945.2020.9197303
Abstract: The Dynamic Visual Sensor is considered to be a next-generation vision sensor. Since event-based vision is in its early stage of development, a small number of datasets has been created during the last decade. Dataset creation is motivated by the need for real data from one or many sensors. Temporal accuracy of data in such datasets is crucially important since the events have high temporal resolution measured in microseconds and, during an algorithm evaluation task, such type of visual data is usually fused with data from other types of sensors. The main aim of our research is to achieve the most accurate possible time synchronization between an event camera, LIDAR, and ambient environment sensors during a session of data acquisition. All the mentioned sensors as well as a stereo and a monocular camera were installed on a mobile robotic platform. In this work, a time synchronization architecture and algorithm are proposed for time synchronization with an implementation example on a PIC32 microcontroller. The overall time synchronization approach is scalable for other sensors where there is a need for accurate time synchronization between many nodes. The evaluation results of the proposed solution are reported and discussed in the paper.
keywords: {Synchronization;Robot sensing systems;Cameras;Laser radar;Clocks;Voltage control;Hardware},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197303&isnumber=9196508

M. Bednarczyk, H. Omran and B. Bayle, "Model Predictive Impedance Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4702-4708.
doi: 10.1109/ICRA40945.2020.9196969
Abstract: Robots are more and more often designed in order to perform tasks in synergy with human operators. In this context, a current research focus for collaborative robotics lies in the design of high-performance control solutions, which ensure security in spite of unmodeled external forces. The present work provides a method based on Model Predictive Control (MPC) to allow compliant behavior when interacting with an environment, while respecting practical robotic constraints. The study shows in particular how to define the impedance control problem as a MPC problem. The approach is validated with an experimental setup including a collaborative robot. The obtained results emphasize the ability of this control strategy to solve constraints like speed, energy or jerk limits, which have a direct impact on the operator's security during human-robot compliant interactions.
keywords: {Robots;Integrated circuit modeling;Impedance;Mathematical model;Task analysis;Collaboration;Impedance control;collaborative robotics;physical human-robot interaction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196969&isnumber=9196508

G. L. H. Johnston, A. L. Orekhov and N. Simaan, "Kinematic Modeling and Compliance Modulation of Redundant Manipulators Under Bracing Constraints," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4709-4716.
doi: 10.1109/ICRA40945.2020.9197387
Abstract: Collaborative robots should ideally use low torque actuators for passive safety reasons. However, some applications require these collaborative robots to reach deep into confined spaces while assisting a human operator in physically demanding tasks. In this paper, we consider the use of in-situ collaborative robots (ISCRs) that balance the conflicting demands of passive safety dictating low torque actuation and the need to reach into deep confined spaces. We consider the judicious use of bracing as a possible solution to these conflicting demands and present a modeling framework that takes into account the constrained kinematics and the effect of bracing on the endeffector compliance. We then define a redundancy resolution framework that minimizes the directional compliance of the end-effector while maximizing end-effector dexterity. Kinematic simulation results show that the redundancy resolution strategy successfully decreases compliance and improves kinematic conditioning while satisfying the constraints imposed by the bracing task. Applications of this modeling framework can support future research on the choice of bracing locations and support the formation of an admittance control framework for collaborative control of ISCRs under bracing constraints. Such robots can benefit workers in the future by reducing the physiological burdens that contribute to musculoskeletal injury.
keywords: {Kinematics;Robots;Redundancy;Task analysis;Collaboration;Torque;Safety;Bracing;redundancy resolution;stiffness modulation;compliance;collaborative robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197387&isnumber=9196508

C. Lee, D. -H. Kim, H. Singh and J. -H. Ryu, "Successive Stiffness Increment and Time Domain Passivity Approach for Stable and High Bandwidth Control of Series Elastic Actuator," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4717-4723.
doi: 10.1109/ICRA40945.2020.9196995
Abstract: For safe human-robot interaction, various type of flexible manipulators have been developed. Especially series elastic actuator (SEA) based manipulators have been getting huge attention since the elastic element of SEA prevents people from injury when undesirable collision happens. Moreover, it improves system durability by absorbing impact force, which could damage actuators. However, the elastic element inside SEA manipulator causes low system bandwidth which limits the speed performance of conventional impedance control approaches. To alleviate the low bandwidth issue of impedance controlled SEA while guaranteeing system stability, we implement Time Domain Passivity Approach (TDPA) and Successive Stiffness Increment (SSI) approach, which was invented in haptic and teleoperation domain. Impedance controlled SEA is reformulated as a two-port electrical circuit network for implementing TDPA. In addition, a pair of input and output power conjugate variable, dominating the system passivity is identified for implementing SSI approach. Experimental results showed that TDPA and SSI approach can render the stiffness of the impedance controller, which decides the bandwidth, upto 350 kN/m without any stability issue, while normal impedance controller only render upto 120 kN/m. Although both of the approaches significantly increased the bandwidth of the impedance controlled SEA, TDPA slightly outperformed in stability, and SSI outperformed in tracking.
keywords: {Impedance;Bandwidth;Force;Actuators;Torque;Manipulators;Springs},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196995&isnumber=9196508

M. Khoramshahi, G. Henriks, A. Naef, S. S. M. Salehian, J. Kim and A. Billard, "Arm-hand motion-force coordination for physical interactions with non-flat surfaces using dynamical systems: Toward compliant robotic massage," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4724-4730.
doi: 10.1109/ICRA40945.2020.9196593
Abstract: Many manipulation tasks require coordinated motions for arm and fingers. Complexity increases when the task requires to control for the force at contact against a non-flat surface; This becomes even more challenging when this contact is done on a human. All these challenges are regrouped when one, for instance, massages a human limb. When massaging, the robotic arm is required to continuously adapt its orientation and distance to the limb while the robot fingers exert desired patterns of forces and motion on the skin surface. To address these challenges, we adopt a Dynamical System (DS) approach that offers a unified motion-force control approach and enables to easily coordinate multiple degrees of freedom. As each human limb may slightly differ, we learn a model of the surface using support vector regression (SVR) which enable us to obtain a distance-to-surface mapping. The gradient of this mapping, along with the DS, generates the desired motions for the interaction with the surface. A DS-based impedance control for the robotic fingers allows to control separately for force along the normal direction of the surface while moving in the tangential plane. We validate our approach using the KUKA IIWA robotic arm and Allegro robotic hand for massaging a mannequin arm covered with a skin-like material. We show that our approach allows for 1) reactive motion planning to reach for an unknown surface, 2) following desired motion patterns on the surface, and 3) exerting desired interaction forces profiles. Our results show the effectiveness of our approach; especially the robustness toward uncertainties for shape and the given location of the surface.
keywords: {Surface impedance;Robot kinematics;Task analysis;Force;Manipulators;Thumb},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196593&isnumber=9196508

L. Xia, Y. Feng, F. Chen and X. Wu, "A Bio-Signal Enhanced Adaptive Impedance Controller for Lower Limb Exoskeleton," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4739-4744.
doi: 10.1109/ICRA40945.2020.9196774
Abstract: The problem of human-exoskeleton interaction with uncertain dynamical parameters remains an open-ended research area. It requires an elaborate control strategy design of the exoskeleton to accommodate complex and unpredictable human body movements. In this paper, we proposed a novel control approach for the lower limb exoskeleton to realize its task of assisting the human operator walking. The main challenge of this study was to determine the human lower extremity dynamics, such as the joint torque. For this purpose, we developed a neural network-based torque estimation method. It can predict the joint torques of humans with surface electromyogram signals (sEMG). Then an radial basis function neural network (RBF NN) enhanced adaptive impedance controller is employed to ensure exoskeleton track desired motion trajectory of a human operator. Algorithm performance is evaluated with two healthy subjects and the rehabilitation lower-limb exoskeleton developed by Shenzhen Institutes of Advanced Technology (SIAT).
keywords: {Exoskeletons;Torque;Estimation;Muscles;Impedance;Artificial neural networks;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196774&isnumber=9196508

P. Karkus, A. Angelova, V. Vanhoucke and R. Jonschkowski, "Differentiable Mapping Networks: Learning Structured Map Representations for Sparse Visual Localization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4753-4759.
doi: 10.1109/ICRA40945.2020.9197452
Abstract: Mapping and localization, preferably from a small number of observations, are fundamental tasks in robotics. We address these tasks by combining spatial structure (differentiable mapping) and end-to-end learning in a novel neural network architecture: the Differentiable Mapping Network (DMN). The DMN constructs a spatially structured view-embedding map and uses it for subsequent visual localization with a particle filter. Since the DMN architecture is end-to-end differentiable, we can jointly learn the map representation and localization using gradient descent. We apply the DMN to sparse visual localization, where a robot needs to localize in a new environment with respect to a small number of images from known viewpoints. We evaluate the DMN using simulated environments and a challenging real-world Street View dataset. We find that the DMN learns effective map representations for visual localization. The benefit of spatial structure increases with larger environments, more viewpoints for mapping, and when training data is scarce. Project website: https://sites.google.com/view/differentiable-mapping.
keywords: {Task analysis;Visualization;Feature extraction;Neural networks;Robot kinematics;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197452&isnumber=9196508

K. Ramachandruni, M. Babu V., A. Majumder, S. Dutta and S. Kumar, "Attentive Task-Net: Self Supervised Task-Attention Network for Imitation Learning using Video Demonstration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4760-4766.
doi: 10.1109/ICRA40945.2020.9197544
Abstract: This paper proposes an end-to-end self-supervised feature representation network named Attentive Task-Net or AT-Net for video-based task imitation. The proposed AT-Net incorporates a novel multi-level spatial attention module to highlight spatial features corresponding to the intended task demonstrated by the expert. The neural connections in AT-Net ensure the relevant information in the demonstration is amplified and the irrelevant information is suppressed while learning task-specific feature embeddings. This is achieved by a weighted combination of multiple intermediate feature maps of the input image at different stages of the CNN pipeline. The weights of the combination are given by the compatibility scores, predicted by the attention module for respective feature maps. The AT-Net is trained using a metric learning loss which aims to decrease the distance between the feature representations of concurrent frames from multiple view points and increase the distance between temporally consecutive frames. The AT-Net features are then used to formulate a reinforcement learning problem for task imitation. Through experiments on the publicly available Multi-view pouring dataset, it is demonstrated that the output of the attention module highlights the task-specific objects while suppressing the rest of the background. The efficacy of the proposed method is further validated by qualitative and quantitative comparison with a state-of-the-art technique along with intensive ablation studies. The proposed method is implemented to imitate a pouring task where an RL agent is learned with the AT-Net in Gazebo simulator. Our findings show that the AT-Net achieves 6.5% decrease in alignment error along with a reduction in the number of training iterations by almost 155k over the state-of-the-art while satisfactorily imitating the intended task.
keywords: {Task analysis;Measurement;Robots;Feature extraction;Training;Visualization;Pipelines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197544&isnumber=9196508

Q. She et al., "OpenLORIS-Object: A Robotic Vision Dataset and Benchmark for Lifelong Deep Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4767-4773.
doi: 10.1109/ICRA40945.2020.9196887
Abstract: The recent breakthroughs in computer vision have benefited from the availability of large representative datasets (e.g. ImageNet and COCO) for training. Yet, robotic vision poses unique challenges for applying visual algorithms developed from these standard computer vision datasets due to their implicit assumption over non-varying distributions for a fixed set of tasks. Fully retraining models each time a new task becomes available is infeasible due to computational, storage and sometimes privacy issues, while na√Øve incremental strategies have been shown to suffer from catastrophic forgetting. It is crucial for the robots to operate continuously under open-set and detrimental conditions with adaptive visual perceptual systems, where lifelong learning is a fundamental capability. However, very few datasets and benchmarks are available to evaluate and compare emerging techniques. To fill this gap, we provide a new lifelong robotic vision dataset ("OpenLORIS-Object") collected via RGB-D cameras. The dataset embeds the challenges faced by a robot in the real-life application and provides new benchmarks for validating lifelong object recognition algorithms. Moreover, we have provided a testbed of 9 state-of-the-art lifelong learning algorithms. Each of them involves 48 tasks with 4 evaluation metrics over the OpenLORIS-Object dataset. The results demonstrate that the object recognition task in the ever-changing difficulty environments is far from being solved and the bottlenecks are at the forward/backward transfer designs. Our dataset and benchmark are publicly available at https://lifelong-robotic-vision.github.io/dataset/object.
keywords: {Task analysis;Lighting;Object recognition;Cameras;Robot vision systems;Clutter},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196887&isnumber=9196508

K. Wang, Y. Chen, H. Guo, L. Wen and S. Shen, "Geometric Pretraining for Monocular Depth Estimation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4782-4788.
doi: 10.1109/ICRA40945.2020.9196847
Abstract: ImageNet-pretrained networks have been widely used in transfer learning for monocular depth estimation. These pretrained networks are trained with classification losses for which only semantic information is exploited while spatial information is ignored. However, both semantic and spatial information is important for per-pixel depth estimation. In this paper, we design a novel self-supervised geometric pretraining task that is tailored for monocular depth estimation using uncalibrated videos. The designed task decouples the structure information from input videos by a simple yet effective conditional autoencoder-decoder structure. Using almost unlimited videos from the internet, networks are pretrained to capture a variety of structures of the scene and can be easily transferred to depth estimation tasks using calibrated images. Extensive experiments are used to demonstrate that the proposed geometric-pretrained networks perform better than ImageNet-pretrained networks in terms of accuracy, few-shot learning and generalization ability. Using existing learning methods, geometric-transferred networks achieve new state-of-the-art results by a large margin. The pretrained networks will be open source soon1 .
keywords: {Task analysis;Estimation;Videos;Optical imaging;Adaptive optics;Training;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196847&isnumber=9196508

W. Lai, L. Cao, P. T. Phan, I. -W. Wu, S. C. Tjin and S. Jay Phee, "Joint Rotation Angle Sensing of Flexible Endoscopic Surgical Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4789-4795.
doi: 10.1109/ICRA40945.2020.9196549
Abstract: Accurate motion control of surgical robots is critical for the efficiency and safety of both state-of-the-art teleoperated robotic surgery and the ultimate autonomous robotic surgery. However, fine motion control for a flexible endoscopic surgical robot is highly challenging because of the shape-dependent and speed-dependent motion hysteresis of tendon-sheath mechanisms (TSMs) in the long, tortuous, and dynamically shape-changing robot body. Aiming to achieve precise closed-loop motion control, we propose a small and flexible sensor to directly sense the large and sharp rotations of the articulated joints of a flexible endoscopic surgical robot. The sensor-a Fiber Bragg Grating (FBG) eccentrically embedded in a thin and flexible epoxy substrate-can be significantly bent with a large bending angle range of [-62.9¬∞, 75.5¬∞] and small bending radius of 6.9 mm. Mounted in-between the two pivot-connected links of a joint, the sensor will bend once the joint is actuated, resulting in the wavelength shift of the FBG. In this study, the relationship between the wavelength shift and the rotation angle of the joint was theoretically modeled and then experimentally verified before and after the installation of the sensor in a robotic endoscopic grasper. The sensor, with the calibrated model, can track the rotation of the robotic joint with an RMSE of 3.34¬∞. This small and flexible sensor has good repeatability, high sensitivity (around 147.5 pm/degree), and low hysteresis (7.72%). It is suitable for surgical robots and manipulators whose articulated joints have a large rotation angle and small bending radius.
keywords: {Robot sensing systems;Optical fiber sensors;Substrates;Optical fiber theory;Medical robotics;Surgery;Flexible Robots;Surgical Robotics;Fiber Optics Sensor;Tendon Sheath Mechanism.},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196549&isnumber=9196508

B. Romero, F. Veiga and E. Adelson, "Soft, Round, High Resolution Tactile Fingertip Sensors for Dexterous Robotic Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4796-4802.
doi: 10.1109/ICRA40945.2020.9196909
Abstract: High resolution tactile sensors are often bulky and have shape profiles that make them awkward for use in manipulation. This becomes important when using such sensors as fingertips for dexterous multi-fingered hands, where boxy or planar fingertips limit the available set of smooth manipulation strategies. High resolution optical based sensors such as GelSight have until now been constrained to relatively flat geometries due to constraints on illumination geometry. Here, we show how to construct a rounded fingertip that utilizes a form of light piping for directional illumination. Our sensors can replace the standard rounded fingertips of the Allegro hand. They can capture high resolution maps of the contact surfaces, and can be used to support various dexterous manipulation tasks.
keywords: {Three-dimensional displays;Robot sensing systems;Plastics;Geometry;Light emitting diodes;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196909&isnumber=9196508

F. Ruppert and A. Badri-Spr√∂witz, "FootTile: a Rugged Foot Sensor for Force and Center of Pressure Sensing in Soft Terrain," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4810-4816.
doi: 10.1109/ICRA40945.2020.9197466
Abstract: In this paper, we present FootTile, a foot sensor for reaction force and center of pressure sensing in challenging terrain. We compare our sensor design to standard biomechanical devices, force plates and pressure plates. We show that FootTile can accurately estimate force and pressure distribution during legged locomotion. FootTile weighs 0.9 g, has a sampling rate of 330 Hz, a footprint of 10√ó10 mm and can easily be adapted in sensor range to the required load case. In three experiments, we validate: first, the performance of the individual sensor, second an array of FootTiles for center of pressure sensing and third the ground reaction force estimation during locomotion in granular substrate. We then go on to show the accurate sensing capabilities of the waterproof sensor in liquid mud, as a showcase for real world rough terrain use.
keywords: {Robot sensing systems;Force;Legged locomotion;Foot;Sensor arrays;Force sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197466&isnumber=9196508

V. C. V. Kumar, S. Ha, G. Sawicki and C. K. Liu, "Learning a Control Policy for Fall Prevention on an Assistive Walking Device," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4833-4840.
doi: 10.1109/ICRA40945.2020.9196798
Abstract: Fall prevention is one of the most important components in senior care. We present a technique to augment an assistive walking device with the ability to prevent falls. Given an existing walking device, our method develops a fall predictor and a recovery policy by utilizing the onboard sensors and actuators. The key component of our method is a robust human walking policy that models realistic human gait under a moderate level of perturbations. We use this human walking policy to provide training data for the fall predictor, as well as to teach the recovery policy how to best modify the person's gait when a fall is imminent. Our evaluation shows that the human walking policy generates walking sequences similar to those reported in biomechanics literature. Our experiments in simulation show that the augmented assistive device can indeed help recover balance from a variety of external perturbations. We also provide a quantitative method to evaluate the design choices for an assistive device.
keywords: {Legged locomotion;Perturbation methods;Assistive devices;Sensors;Adaptation models;Biological system modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196798&isnumber=9196508

S. Guo, Q. Xiang, K. Hashimoto and S. Jin, "Assistive Force of a Belt-type Hip Assist Suit for Lifting the Swing Leg during Walking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4841-4847.
doi: 10.1109/ICRA40945.2020.9196788
Abstract: This paper proposes a relatively simple function of assistive force for a belt-type hip assist suit developed by the authors' group. The function, which is inspired by the muscle force of the rectus femoris, contains only two parameters, the magnitude and a phase shift factor. Thus, it can reduce the amount of calculation in generating the desired assistive force during walking. Tests were performed on three healthy subjects to confirm its effect and to investigate its influence on the motions of hip, knee and ankle joints. It was demonstrated that the effect of the assist depended greatly on the phase shift factor, i.e., the location of the peak of the assistive force in a swing period. A large effect was observed when the peak of the assistive force came at mid-swing phase. The results of the tests showed that the proposed force function could help to increase walk ratio (the ratio of step length to the number of steps per minute) by an average value of 11.2% at a force magnitude of 35 N, which could produce an assistive torque of the same order as the magnitude of the muscle force of the rectus femoris around the hip joint.
keywords: {Force;Hip;Legged locomotion;Muscles;Belts;Torque;Windings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196788&isnumber=9196508

A. B. Ambrose and F. L. Hammond, "Soft Pneumatic System for Interface Pressure Regulation and Automated Hands-Free Donning in Robotic Prostheses," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4848-4854.
doi: 10.1109/ICRA40945.2020.9197405
Abstract: This paper discusses the design and preliminary evaluation of a soft pneumatic socket (SPS) with real-time pressure regulation and an automated underactuated donning mechanism (UDM). The ability to modulate the pressure at the human-socket interface of a prosthesis or wearable device to accommodate user's activities has the potential to make the user more comfortable. Furthermore, a hands-free, underactuated donning mechanism designed to reliably and safely don the socket onto the user may increase the convenience of prostheses and wearable devices. The pneumatic socket and donning mechanism are evaluated on synthetic forearm model designed to closely match the mechanical properties of the human forearm. The pneumatic socket was tested to determine the maximum loads it can withstand before slipping and the displacement of the socket after loading. The donning mechanism was able to successfully don the socket on to the replica forearm with a 100% success rate for the 30 trials that were tested. Both devices were also tested to determine the pressures they impart on the user. The highest pressures the socket can impart on the user is 4psi and the maximum pressure the donning mechanism imparts on the user is 0.83psi. These pressures were found to be lower than the reported pressures that cause pain and tissue damage.
keywords: {Sockets;Bladder;Valves;Fingers;Prosthetics;Laser beam cutting},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197405&isnumber=9196508

R. W. Nuckols, K. Swaminathan, S. Lee, L. Awad, C. J. Walsh and R. D. Howe, "Automated detection of soleus concentric contraction in variable gait conditions for improved exosuit control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4855-4862.
doi: 10.1109/ICRA40945.2020.9197428
Abstract: Exosuits can reduce metabolic demand and improve gait. Controllers explicitly derived from biological mechanisms that reflect the user's joint or muscle dynamics should in theory allow for individualized assistance and enable adaptation to changing gait. With the goal of developing an exosuit control strategy based on muscle power, we present an approach for estimating, at real time rates, when the soleus muscle begins to generate positive power. A low-profile ultrasound system recorded B-mode images of the soleus in walking individuals. An automated routine using optical flow segmented the data to a normalized gait cycle and estimated the onset of concentric contraction at real-time rates (~130Hz). Segmentation error was within 1% of the gait cycle compared to using ground reaction forces. Estimation of onset of concentric contraction had a high correlation (R2=0.92) and an RMSE of 2.6% gait cycle relative to manual estimation. We demonstrated the ability to estimate the onset of concentric contraction during fixed speed walking in healthy individuals that ranged from 39.3% to 45.8% of the gait cycle and feasibility in two persons post-stroke walking at comfortable walking speed. We also showed the ability to measure a shift in onset timing to 7% earlier when the biological system adapts from level to incline walking. Finally, we provided an initial evaluation for how the onset of concentric contraction might be used to inform exosuit control in level and incline walking.
keywords: {Muscles;Legged locomotion;Kinematics;Tendons;Real-time systems;Electromyography},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197428&isnumber=9196508

Y. Jin et al., "Soft Sensing Shirt for Shoulder Kinematics Estimation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4863-4869.
doi: 10.1109/ICRA40945.2020.9196586
Abstract: Soft strain sensors have been explored as an unobtrusive approach for wearable motion tracking. However, accurate tracking of multi degree-of-freedom (DOF) noncyclic joint movements remains a challenge. This paper presents a soft sensing shirt for tracking shoulder kinematics of both cyclic and random arm movements in 3 DOFs: adduction/abduction, horizontal flexion/extension, and internal/external rotation. The sensing shirt consists of 8 textile-based capacitive strain sensors sewn around the shoulder joint that communicate to a customized readout electronics board through sewn micro-coaxial cables. An optimized sensor design includes passive shielding and demonstrates high linearity and low hysteresis, making it suitable for wearable motion tracking. In a study with a single human subject, we evaluated the tracking capability of the integrated shirt in comparison with a ground truth optical motion capture system. An ensemble-based regression algorithm was implemented in post-processing to estimate joint angles and angular velocities from the strain sensor data. Results demonstrated root mean square errors (RMSEs) less than 4.5¬∞ for joint angle estimation and normalized root mean square errors (NRMSEs) less than 4% for joint velocity estimation. Furthermore, we applied a recursive feature elimination (RFE)-based sensor selection analysis to down select the number of sensors for future shirt designs. This sensor selection analysis found that 5 sensors out of 8 were sufficient to generate comparable accuracies.
keywords: {Tracking;Shoulder;Electrodes;Capacitive sensors;Robot sensing systems;Strain},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196586&isnumber=9196508

D. -A. Huang et al., "Motion Reasoning for Goal-Based Imitation Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4878-4884.
doi: 10.1109/ICRA40945.2020.9197172
Abstract: We address goal-based imitation learning, where the aim is to output the symbolic goal from a third-person video demonstration. This enables the robot to plan for execution and reproduce the same goal in a completely different environment. The key challenge is that the goal of a video demonstration is often ambiguous at the level of semantic actions. The human demonstrators might unintentionally achieve certain subgoals in the demonstrations with their actions. Our main contribution is to propose a motion reasoning framework that combines task and motion planning to disambiguate the true intention of the demonstrator in the video demonstration. This allows us to recognize the goals that cannot be disambiguated by previous action-based approaches. We evaluate our approach on a new dataset of 96 video demonstrations in a mockup kitchen environment. We show that our motion reasoning plays an important role in recognizing the actual goal of the demonstrator and improves the success rate by over 20%. We further show that by using the automatically inferred goal from the video demonstration, our robot is able to reproduce the same task in a real kitchen environment.
keywords: {Task analysis;Trajectory;Cognition;Planning;Motion segmentation;Human-robot interaction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197172&isnumber=9196508

S. K. Kim, E. Andrea Kirchner and F. Kirchner, "Flexible online adaptation of learning strategy using EEG-based reinforcement signals in real-world robotic applications," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4885-4891.
doi: 10.1109/ICRA40945.2020.9197538
Abstract: Flexible adaptation of learning strategy depending on online changes of the user's current intents have a high relevance in human-robot collaboration. In our previous study, we proposed an intrinsic interactive reinforcement learning approach for human-robot interaction, in which a robot learns his/her action strategy based on intrinsic human feedback that is generated in the human's brain as neural signature of the human's implicit evaluation of the robot's actions. Our approach has an inherent property that allows robots to adapt their behavior depending on online changes of the human's current intents. Such flexible adaptation is possible, since robot learning is updated in real time by human's online feedback. In this paper, the adaptivity of robot learning is tested on eight subjects who change their current control strategy by adding a new gesture to the previous used gestures. This paper evaluates the learning progress by analyzing learning phases (before and after adding a new gesture for control). The results show that the robot can adapt the previously learned policy depending on online changes of the user's intents. Especially, learning progress is interrelated with the classification performance of electroencephalograms (EEGs), which are used to measure the human's implicit evaluation of the robot's actions.
keywords: {Electroencephalography;Decoding;Electronic learning;Task analysis;Human-robot interaction;Robot learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197538&isnumber=9196508

J. Moon and B. -H. Lee, "Object-oriented Semantic Graph Based Natural Question Generation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4892-4898.
doi: 10.1109/ICRA40945.2020.9196563
Abstract: Generating a natural question can enable autonomous robots to propose problems according to their surroundings. However, recent studies on question generation rarely consider semantic graph mapping, which is widely used to understand environments. In this paper, we introduce a method to generate natural questions using object-oriented semantic graphs. First, a graph convolutional network extracts features from the graph. Then, a recurrent neural network generates the natural question from the extracted features. Using graphs, we can generate natural questions for both single and sequential scenes. The proposed method outperforms conventional methods on a publicly available dataset for single scenes and can generate questions for sequential scenes.
keywords: {Semantics;Feature extraction;Object oriented modeling;Neural networks;Convolution;Autonomous robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196563&isnumber=9196508

M. El-Shamouty, X. Wu, S. Yang, M. Albus and M. F. Huber, "Towards Safe Human-Robot Collaboration Using Deep Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4899-4905.
doi: 10.1109/ICRA40945.2020.9196924
Abstract: Safety in Human-Robot Collaboration (HRC) is a bottleneck to HRC-productivity in industry. With robots being the main source of hazards, safety engineers use over-emphasized safety measures, and carry out lengthy and expensive risk assessment processes on each HRC-layout reconfiguration. Recent advances in deep Reinforcement Learning (RL) offer solutions to add intelligence and comprehensibility of the environment to robots. In this paper, we propose a framework that uses deep RL as an enabling technology to enhance intelligence and safety of the robots in HRC scenarios and, thus, reduce hazards incurred by the robots. The framework offers a systematic methodology to encode the task and safety requirements and context of applicability into RL settings. The framework also considers core components, such as behavior explainer and verifier, which aim for transferring learned behaviors from research labs to industry. In the evaluations, the proposed framework shows the capability of deep RL agents learning collision-free point-to-point motion on different robots inside simulation, as shown in the supplementary video.
keywords: {Task analysis;Training;Hazards;Robot sensing systems;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196924&isnumber=9196508

Y. -L. Kuo, B. Katz and A. Barbu, "Deep compositional robotic planners that follow natural language commands," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4906-4912.
doi: 10.1109/ICRA40945.2020.9197464
Abstract: We demonstrate how a sampling-based robotic planner can be augmented to learn to understand a sequence of natural language commands in a continuous configuration space to move and manipulate objects. Our approach combines a deep network structured according to the parse of a complex command that includes objects, verbs, spatial relations, and attributes, with a sampling-based planner, RRT. A recurrent hierarchical deep network controls how the planner explores the environment, determines when a planned path is likely to achieve a goal, and estimates the confidence of each move to trade off exploitation and exploration between the network and the planner. Planners are designed to have near-optimal behavior when information about the task is missing, while networks learn to exploit observations which are available from the environment, making the two naturally complementary. Combining the two enables generalization to new maps, new kinds of obstacles, and more complex sentences that do not occur in the training set. Little data is required to train the model despite it jointly acquiring a CNN that extracts features from the environment as it learns the meanings of words. The model provides a level of interpretability through the use of attention maps allowing users to see its reasoning steps despite being an end-to-end model. This end-to-end model allows robots to learn to follow natural language commands in challenging continuous environments.
keywords: {Robots;Task analysis;Planning;Natural languages;Aerospace electronics;Cognition;Space exploration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197464&isnumber=9196508

N. Wilde, D. Kuliƒá and S. L. Smith, "Learning User Preferences from Corrections on State Lattices," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4913-4919.
doi: 10.1109/ICRA40945.2020.9197040
Abstract: Enabling a broader range of users to efficiently deploy autonomous mobile robots requires intuitive frameworks for specifying a robot's task and behaviour. We present a novel approach using learning from corrections (LfC), where a user is iteratively presented with a solution to a motion planning problem. Users might have preferences about parts of a robot's environment that are suitable for robot traffic or that should be avoided as well as preferences on the control actions a robot can take. The robot is initially unaware of these preferences; thus, we ask the user to provide a correction to the presented path. We assume that the user evaluates paths based on environment and motion features. From a sequence of corrections we learn weights for these features, which are then considered by the motion planner, resulting in future paths that better fit the user's preferences. We prove completeness of our algorithm and demonstrate its performance in simulations. Thereby, we show that the learned preferences yield good results not only for a set of training tasks but also for test tasks, as well as for different types of user behaviour.
keywords: {Task analysis;Lattices;Cost function;Mobile robots;Robot motion;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197040&isnumber=9196508

A. Ahmadi, L. Nardi, N. Chebrolu and C. Stachniss, "Visual Servoing-based Navigation for Monitoring Row-Crop Fields," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4920-4926.
doi: 10.1109/ICRA40945.2020.9197114
Abstract: Autonomous navigation is a pre-requisite for field robots to carry out precision agriculture tasks. Typically, a robot has to navigate along a crop field multiple times during a season for monitoring the plants, for applying agrochemicals, or for performing targeted interventions. In this paper, we propose a visual-based navigation framework tailored to row-crop fields that exploits the regular crop-row structure present in fields. Our approach uses only the images from on-board cameras without the need for performing explicit localization or maintaining a map of the field. Thus, it can operate without expensive RTK-GPS solutions often used in agricultural automation systems. Our navigation approach allows the robot to follow the crop rows accurately and handles the switch to the next row seamlessly within the same framework. We implemented our approach using C++ and ROS and thoroughly tested it in several simulated fields with different shapes and sizes. We also demonstrated the system running at frame-rate on an actual robot operating on a test row-crop field. The code and data have been published.
keywords: {Agriculture;Navigation;Cameras;Robot vision systems;Visualization;Monitoring},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197114&isnumber=9196508

F. Betti Sorbelli, S. Carpin, F. Cor√≤, A. Navarra and C. M. Pinotti, "Optimal Routing Schedules for Robots Operating in Aisle-Structures," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4927-4933.
doi: 10.1109/ICRA40945.2020.9197579
Abstract: In this paper, we consider the Constant-cost Orienteering Problem (COP) where a robot, constrained by a limited travel budget, aims at selecting a path with the largest reward in an aisle-graph. The aisle-graph consists of a set of loosely connected rows where the robot can change lane only at either end, but not in the middle. Even when considering this special type of graphs, the orienteering problem is known to be intractable. We optimally solve in polynomial time two special cases, COP-FR where the robot can only traverse full rows, and COP-SC where the robot can access the rows only from one side. To solve the general COP, we then apply our special case algorithms as well as a new heuristic that suitably combines them. Despite its light computational complexity and being confined into a very limited class of paths, the optimal solutions for COP-FR turn out to be competitive in terms of achieved rewards even for COP. This is shown by means of extended simulations performed on both real and synthetic scenarios. Furthermore, our new heuristic for the general case outperforms state-of-art algorithms, especially for input with highly unbalanced rewards.
keywords: {Robots;Optimized production technology;Routing;Heuristic algorithms;Task analysis;Irrigation;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197579&isnumber=9196508

J. Song and I. Sharf, "Time Optimal Motion Planning with ZMP Stability Constraint for Timber Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4934-4940.
doi: 10.1109/ICRA40945.2020.9196836
Abstract: This paper presents a dynamic stability-constrained optimal motion planning algorithm developed for a timber harvesting machine working on rough terrain. First, the kinematics model of the machine, and the Zero Moment Point (ZMP) stability measure is presented. Then, an approach to simplify the model to gain insight and achieve a fast solution of the optimization problem is introduced. The performance and computation time of the motion plan obtained with the simplified model is compared against that obtained with the full kinematics model of the machine with the help of MATLAB simulations. The results demonstrate feasibility of fast motion planning while satisfying the dynamic stability constraint.
keywords: {Planning;Kinematics;Manipulator dynamics;Acceleration;Stability analysis;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196836&isnumber=9196508

Y. Xiong, Y. Ge and P. J. From, "Push and Drag: An Active Obstacle Separation Method for Fruit Harvesting Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4957-4962.
doi: 10.1109/ICRA40945.2020.9197469
Abstract: Selectively picking a target fruit surrounded by obstacles is one of the major challenges for fruit harvesting robots. Different from traditional obstacle avoidance methods, this paper presents an active obstacle separation strategy that combines push and drag motions. The separation motion and trajectory are generated based on the 3D visual perception of the obstacle information around the target. A linear push is used to clear the obstacles from the area below the target, while a zig-zag push that contains several linear motions is proposed to push aside more dense obstacles. The zig-zag push can generate multi-directional pushes and the side-to-side motion can break the static contact force between the target and obstacles, thus helping the gripper to receive a target in more complex situations. Moreover, we propose a novel drag operation to address the issue of mis-capturing obstacles located above the target, in which the gripper drags the target to a place with fewer obstacles and then pushes back to move the obstacles aside for further detachment. Furthermore, an image processing pipeline consisting of color thresholding, object detection using deep learning and point cloud operation, is developed to implement the proposed method on a harvesting robot. Field tests show that the proposed method can improve the picking performance substantially. This method helps to enable complex clusters of fruits to be harvested with a higher success rate than conventional methods.
keywords: {Grippers;Robots;Three-dimensional displays;Drag;Trajectory;Force;Radio frequency},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197469&isnumber=9196508

S. Chen, J. Liu, X. Liang, S. Zhang, J. Hyypp√§ and R. Chen, "A Novel Calibration Method between a Camera and a 3D LiDAR with Infrared Images," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4963-4969.
doi: 10.1109/ICRA40945.2020.9196512
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196512&isnumber=9196508

Y. Zhu, C. Li and Y. Zhang, "Online Camera-LiDAR Calibration with Sensor Semantic Information," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4970-4976.
doi: 10.1109/ICRA40945.2020.9196627
keywords: {Calibration;Cameras;Laser radar;Image edge detection;Robot sensing systems;Semantics;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196627&isnumber=9196508

Z. Wang and M. Tomizuka, "Precise 3D Calibration of Wafer Handling Robot by Visual Detection and Tracking of Elliptic-shape Wafers," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4977-4982.
doi: 10.1109/ICRA40945.2020.9197150
keywords: {Three-dimensional displays;Image segmentation;Robots;Optimization;Image edge detection;Calibration;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197150&isnumber=9196508

K. Joo, H. Li, T. -H. Oh, Y. Bok and I. S. Kweon, "Globally Optimal Relative Pose Estimation for Camera on a Selfie Stick," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4983-4989.
doi: 10.1109/ICRA40945.2020.9196921
keywords: {Cameras;Calibration;Pose estimation;Robustness;Geometry;Transforms;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196921&isnumber=9196508

Z. Ouyang, L. Hu, Y. Lu, Z. Wang, X. Peng and L. Kneip, "Online calibration of exterior orientations of a vehicle-mounted surround-view camera system," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4990-4996.
doi: 10.1109/ICRA40945.2020.9197127
keywords: {Cameras;Calibration;Optimization;Motion estimation;Geometry;Automobiles;Mirrors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197127&isnumber=9196508

A. Cramariuc, A. Petrov, R. Suri, M. Mittal, R. Siegwart and C. Cadena, "Learning Camera Miscalibration Detection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 4997-5003.
doi: 10.1109/ICRA40945.2020.9197378
keywords: {Cameras;Calibration;Robots;Training;Sensor systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197378&isnumber=9196508

Y. Domae, A. Noda, T. Nagatani and W. Wan, "Robotic General Parts Feeder: Bin-picking, Regrasping, and Kitting," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5004-5010.
doi: 10.1109/ICRA40945.2020.9197056
keywords: {Pipelines;Robot sensing systems;Shape;Grippers;Service robots;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197056&isnumber=9196508

F. Islam, A. Vemula, S. -K. Kim, A. Dornbush, O. Salzman and M. Likhachev, "Planning, Learning and Reasoning Framework for Robot Truck Unloading," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5011-5017.
doi: 10.1109/ICRA40945.2020.9196604
keywords: {Planning;Robot sensing systems;Task analysis;Decision making;Collision avoidance;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196604&isnumber=9196508

A. Aalerud and G. Hovland, "Evaluation of Perception Latencies in a Human-Robot Collaborative Environment," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5018-5023.
doi: 10.1109/ICRA40945.2020.9197067
keywords: {Robot sensing systems;Measurement by laser beam;Delays;Position measurement;Collaboration;Sensor systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197067&isnumber=9196508

J. Zhao, X. Wang, S. Wang, X. Jiang and Y. Liu, "Assembly of randomly placed parts realized by using only one robot arm with a general parallel-jaw gripper," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5024-5030.
doi: 10.1109/ICRA40945.2020.9197396
keywords: {Grippers;Fasteners;Robotic assembly;Manipulators;Industries;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197396&isnumber=9196508

L. Calkins et al., "Bio-Inspired Distance Estimation using the Self-Induced Acoustic Signature of a Motor-Propeller System," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5047-5053.
doi: 10.1109/ICRA40945.2020.9197143
keywords: {Microphones;Acoustics;Robot sensing systems;Interference;Frequency-domain analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197143&isnumber=9196508

B. Fasquelle, M. Furet, P. Khanna, D. Chablat, C. Chevallereau and P. Wenger, "A bio-inspired 3-DOF light-weight manipulator with tensegrity X-joints," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5054-5060.
doi: 10.1109/ICRA40945.2020.9196589
keywords: {Bars;Springs;Birds;Neck;Manipulator dynamics;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196589&isnumber=9196508

Y. Chen, H. Chung, B. Chen, Y. Bao and Y. Sun, "The Lobster-inspired Antagonistic Actuation Mechanism Towards a Bending Module," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5061-5067.
doi: 10.1109/ICRA40945.2020.9196624
keywords: {Torque;Actuators;Legged locomotion;Hysteresis;Exoskeletons;Pneumatic systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196624&isnumber=9196508

S. M. Danforth et al., "Emulating duration and curvature of coral snake anti-predator thrashing behaviors using a soft-robotic platform," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5068-5074.
doi: 10.1109/ICRA40945.2020.9197549
keywords: {Soft robotics;MIMICs;Biology;Fabrication;Strain;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197549&isnumber=9196508

G. A. Ribeiro, L. N. Knop and M. Rastgaar, "Directional Mechanical Impedance of the Human Ankle During Standing with Active Muscles," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5075-5081.
doi: 10.1109/ICRA40945.2020.9196616
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196616&isnumber=9196508

H. -C. Lin and M. Mistry, "Contact Surface Estimation via Haptic Perception," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5087-5093.
doi: 10.1109/ICRA40945.2020.9196816
keywords: {Robot sensing systems;Estimation;Friction;Legged locomotion;Foot;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196816&isnumber=9196508

P. Kolaric et al., "Local Policy Optimization for Trajectory-Centric Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5094-5100.
doi: 10.1109/ICRA40945.2020.9197058
keywords: {Robustness;Trajectory optimization;Uncertainty;Learning (artificial intelligence);Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197058&isnumber=9196508

E. Hannigan, B. Song, G. Khandate, M. Haas-Heger, J. Yin and M. Ciocarlie, "Automatic Snake Gait Generation Using Model Predictive Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5101-5107.
doi: 10.1109/ICRA40945.2020.9196853
keywords: {Friction;Dynamics;Snake robots;Force;Adaptation models;Heuristic algorithms;Optimal control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196853&isnumber=9196508

V. Sadhu, S. Zonouz and D. Pompili, "On-board Deep-learning-based Unmanned Aerial Vehicle Fault Cause Detection and Identification," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5255-5261.
doi: 10.1109/ICRA40945.2020.9197071
keywords: {Drones;Computer crashes;Real-time systems;Robot sensing systems;Computer architecture;Neural networks;Data models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197071&isnumber=9196508

J. Ichnowski, M. Danielczuk, J. Xu, V. Satish and K. Goldberg, "GOMP: Grasp-Optimized Motion Planning for Bin Picking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5270-5277.
doi: 10.1109/ICRA40945.2020.9197548
keywords: {Trajectory;Grippers;Robot sensing systems;Planning;Manipulators;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197548&isnumber=9196508

K. C. Tan, M. Jung, I. Shyu, C. Wan and R. Dai, "Motion Planning and Task Allocation for a Jumping Rover Team," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5278-5283.
doi: 10.1109/ICRA40945.2020.9197268
keywords: {Planning;Task analysis;Smoothing methods;Resource management;Mobile robots;Wheels;Jumping Robots;Multiple Traveling Salesman Problem;Path Planning;Rapidly-exploring Random Tree;Mixed-Integer Linear Programming},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197268&isnumber=9196508

S. Song, D. Kim and S. Jo, "Active 3D Modeling via Online Multi-View Stereo," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5284-5291.
doi: 10.1109/ICRA40945.2020.9197089
keywords: {Three-dimensional displays;Image reconstruction;Surface reconstruction;Computational modeling;Solid modeling;Trajectory;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197089&isnumber=9196508

A. C. Holston and J. -H. Kim, "Reoriented Short-Cuts (RSC): An Adjustment Method for Locally Optimal Path Short-Cutting in High DoF Configuration Spaces," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5292-5298.
doi: 10.1109/ICRA40945.2020.9196532
keywords: {Convergence;Optimization;Robots;Planning;Complexity theory;Trajectory;Gaussian distribution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196532&isnumber=9196508

T. Fan, P. Long, W. Liu, J. Pan, R. Yang and D. Manocha, "Learning Resilient Behaviors for Navigation Under Uncertainty," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5299-5305.
doi: 10.1109/ICRA40945.2020.9196785
keywords: {Uncertainty;Navigation;Robots;Task analysis;Training;Estimation;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196785&isnumber=9196508

J. C. Hern√°ndez Ram√≠rez and M. Nahon, "Nonlinear Vector-Projection Control for Agile Fixed-Wing Unmanned Aerial Vehicles," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5314-5320.
doi: 10.1109/ICRA40945.2020.9196838
keywords: {Aircraft;Control systems;Attitude control;Aerodynamics;Position measurement;Aircraft propulsion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196838&isnumber=9196508

X. Shi, P. Spieler, E. Tang, E. -S. Lupu, P. Tokumaru and S. -J. Chung, "Adaptive Nonlinear Control of Fixed-Wing VTOL with Airflow Vector Sensing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5321-5327.
doi: 10.1109/ICRA40945.2020.9197344
keywords: {Force;Aerodynamics;Atmospheric modeling;Aircraft;Rotors;Propellers;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197344&isnumber=9196508

H. Nguyen, T. Dang and K. Alexis, "The Reconfigurable Aerial Robotic Chain: Modeling and Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5328-5334.
doi: 10.1109/ICRA40945.2020.9197184
keywords: {Robot sensing systems;Robot kinematics;Payloads;Shape;Prototypes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197184&isnumber=9196508

M. Hamandi, M. Tognon and A. Franchi, "Direct Acceleration Feedback Control of Quadrotor Aerial Vehicles," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5335-5341.
doi: 10.1109/ICRA40945.2020.9196557
keywords: {Acceleration;Accelerometers;Propellers;Robustness;Attitude control;Zirconium;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196557&isnumber=9196508

M. Brunner et al., "Trajectory Tracking Nonlinear Model Predictive Control for an Overactuated MAV," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5342-5348.
doi: 10.1109/ICRA40945.2020.9197005
keywords: {Rotors;Resource management;Actuators;Trajectory;Force;Quaternions;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197005&isnumber=9196508

Y. S. Sarkisov, M. Jun Kim, A. Coelho, D. Tsetserukou, C. Ott and K. Kondak, "Optimal Oscillation Damping Control of cable-Suspended Aerial Manipulator with a Single IMU Sensor," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5349-5355.
doi: 10.1109/ICRA40945.2020.9197055
keywords: {Oscillators;Damping;Manipulators;Robot sensing systems;Task analysis;Cranes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197055&isnumber=9196508

M. O‚ÄôKelly, H. Zheng, A. Jain, J. Auckley, K. Luong and R. Mangharam, "TUNERCAR: A Superoptimization Toolchain for Autonomous Racing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5356-5362.
doi: 10.1109/ICRA40945.2020.9197080
keywords: {Optimization;Sociology;Statistics;Vehicle dynamics;Hardware;Robots;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197080&isnumber=9196508

M. -Y. Yu, R. Vasudevan and M. Johnson-Roberson, "Risk Assessment and Planning with Bidirectional Reachability for Autonomous Driving," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5363-5369.
doi: 10.1109/ICRA40945.2020.9197491
keywords: {Risk management;Planning;Prediction algorithms;Autonomous vehicles;Robot sensing systems;Navigation;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197491&isnumber=9196508

M. Garz√≥n and A. Spalanzani, "Game theoretic decision making based on real sensor data for autonomous vehicles‚Äô maneuvers in high traffic," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5378-5384.
doi: 10.1109/ICRA40945.2020.9197430
keywords: {Games;Automobiles;Mathematical model;Game theory;Autonomous vehicles;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197430&isnumber=9196508

D. M. Saxena, S. Bae, A. Nakhaei, K. Fujimura and M. Likhachev, "Driving in Dense Traffic with Model-Free Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5385-5392.
doi: 10.1109/ICRA40945.2020.9197132
keywords: {Roads;Autonomous vehicles;Learning (artificial intelligence);Task analysis;Benchmark testing;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197132&isnumber=9196508

G. Notomista, M. Wang, M. Schwager and M. Egerstedt, "Enhancing Game-Theoretic Autonomous Car Racing Using Control Barrier Functions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5393-5399.
doi: 10.1109/ICRA40945.2020.9196757
keywords: {Collision avoidance;Trajectory;Robots;Acceleration;Safety;Bicycles;Automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196757&isnumber=9196508

Y. Latif, A. -D. Doan, T. -J. Chin and I. Reid, "SPRINT: Subgraph Place Recognition for INtelligent Transportation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5408-5414.
doi: 10.1109/ICRA40945.2020.9196522
keywords: {Image recognition;Hidden Markov models;Robots;Symmetric matrices;Cameras;Image retrieval},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196522&isnumber=9196508

S. Ratz, M. Dymczyk, R. Siegwart and R. Dub√©, "OneShot Global Localization: Instant LiDAR-Visual Pose Estimation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5415-5421.
doi: 10.1109/ICRA40945.2020.9197458
keywords: {Three-dimensional displays;Laser radar;Robots;Sensors;Image segmentation;Neural networks;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197458&isnumber=9196508

M. Lechner, R. Hasani, D. Rus and R. Grosu, "Gershgorin Loss Stabilizes the Recurrent Neural Network Compartment of an End-to-end Robot Learning Scheme," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5446-5452.
doi: 10.1109/ICRA40945.2020.9196608
keywords: {Stability analysis;Eigenvalues and eigenfunctions;Recurrent neural networks;Training;Robots;Heuristic algorithms;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196608&isnumber=9196508

H. Latifee, A. Pervez, J. -H. Ryu and D. Lee, "Mini-Batched Online Incremental Learning Through Supervisory Teleoperation with Kinesthetic Coupling," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5453-5459.
doi: 10.1109/ICRA40945.2020.9197444
keywords: {Task analysis;Couplings;Force;Trajectory;Robots;Education;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197444&isnumber=9196508

C. Gao, R. Gehlhar, A. D. Ames, S. -C. Liu and T. Delbruck, "Recurrent Neural Network Control of a Hybrid Dynamical Transfemoral Prosthesis with EdgeDRNN Accelerator," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5460-5466.
doi: 10.1109/ICRA40945.2020.9196984
keywords: {Prosthetics;Legged locomotion;PD control;Trajectory;Real-time systems;Knee},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196984&isnumber=9196508

S. Yang, W. Zhang, W. Lu, H. Wang and Y. Li, "Cross-context Visual Imitation Learning from Demonstrations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5467-5473.
doi: 10.1109/ICRA40945.2020.9196868
keywords: {Context modeling;Robots;Task analysis;Inverse problems;Visualization;Predictive models;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196868&isnumber=9196508

V. Schettino and Y. Demiris, "Improving Generalisation in Learning Assistance by Demonstration for Smart Wheelchairs," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5474-5480.
doi: 10.1109/ICRA40945.2020.9197490
keywords: {Wheelchairs;Training;Robots;Vehicles;Haptic interfaces;Sensors;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197490&isnumber=9196508

M. Naumann, L. Sun, W. Zhan and M. Tomizuka, "Analyzing the Suitability of Cost Functions for Explaining and Imitating Human Driving Behavior based on Inverse Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5481-5487.
doi: 10.1109/ICRA40945.2020.9196795
keywords: {Cost function;Trajectory;Vehicles;Roads;Learning (artificial intelligence);Safety;Planning;Automated vehicles;cost function;inverse reinforcement learning;imitation learning;cooperative motion planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196795&isnumber=9196508

J. Liu, H. Sugiyama, T. Nakayama and S. Miyashita, "Magnetic Sensor Based Topographic Localization for Automatic Dislocation of Ingested Button Battery," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5488-5494.
doi: 10.1109/ICRA40945.2020.9196546
keywords: {Batteries;Magnetic sensors;Magnetic resonance imaging;Magnetization;Magnetic separation;Stomach},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196546&isnumber=9196508

G. Li et al., "A Fully Actuated Body-Mounted Robotic Assistant for MRI-Guided Low Back Pain Injection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5495-5501.
doi: 10.1109/ICRA40945.2020.9197534
keywords: {Needles;Robots;Magnetic resonance imaging;Pain;Force;Back},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197534&isnumber=9196508

L. Balasubramanian, T. Wray and D. D. Damian, "Fault Tolerant Control in Shape-Changing Internal Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5502-5508.
doi: 10.1109/ICRA40945.2020.9196989
keywords: {Implants;Fault tolerance;Fault tolerant systems;Robot sensing systems;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196989&isnumber=9196508

A. Avinash, A. E. Abdelaal and S. E. Salcudean, "Evaluation of Increasing Camera Baseline on Depth Perception in Surgical Robotics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5509-5515.
doi: 10.1109/ICRA40945.2020.9197235
keywords: {Cameras;Robot vision systems;Surgery;Stereo image processing;Endoscopes;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197235&isnumber=9196508

Y. Tian et al., "Toward Autonomous Robotic Micro-Suturing using Optical Coherence Tomography Calibration and Path Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5516-5522.
doi: 10.1109/ICRA40945.2020.9196834
keywords: {Needles;Robots;Wounds;Calibration;Surgery;Imaging;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196834&isnumber=9196508

Y. Xu, K. Li, Z. Zhao and M. Q. . -H. Meng, "Improved Multiple Objects Tracking based Autonomous Simultaneous Magnetic Actuation & Localization for WCE," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5523-5529.
doi: 10.1109/ICRA40945.2020.9197142
keywords: {Magnetic moments;Magnetic separation;Object tracking;Magnetic resonance imaging;Interpolation;Actuators;Fitting;Simultaneous Magnetic Actuation and Localization;Multiple Objects Tracking;Wireless Capsule Endoscopy},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197142&isnumber=9196508

E. Tennakoon, T. Peynot, J. Roberts and N. Kottege, "Probe-before-step walking strategy for multi-legged robots on terrain with risk of collapse," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5530-5536.
doi: 10.1109/ICRA40945.2020.9197154
keywords: {Legged locomotion;Probes;Foot;Robot sensing systems;Force;Australia},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197154&isnumber=9196508

B. Reily, C. Reardon and H. Zhang, "Representing Multi-Robot Structure through Multimodal Graph Embedding for the Selection of Robot Teams," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5576-5582.
doi: 10.1109/ICRA40945.2020.9197389
keywords: {Robots;Task analysis;Multi-robot systems;Indexes;Organizations;Resource management;Biology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197389&isnumber=9196508

J. Lim and P. Tsiotras, "MAMS-A: Multi-Agent Multi-Scale A," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5583-5589.
doi: 10.1109/ICRA40945.2020.9197045
keywords: {Planning;Hypercubes;Search problems;Legged locomotion;Wavelet transforms;Aerospace engineering;Electronic mail},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197045&isnumber=9196508

B. Capelli and L. Sabattini, "Connectivity Maintenance: Global and Optimized approach through Control Barrier Functions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5590-5596.
doi: 10.1109/ICRA40945.2020.9197109
keywords: {Robots;Laplace equations;Multi-robot systems;Eigenvalues and eigenfunctions;Maintenance engineering;Task analysis;Control systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197109&isnumber=9196508

I. Buckley and M. Egerstedt, "Controller Synthesis for Infinitesimally Shape-Similar Formations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5597-5603.
doi: 10.1109/ICRA40945.2020.9196591
keywords: {Robot sensing systems;Robot kinematics;Lyapunov methods;Trajectory;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196591&isnumber=9196508

F. Rahbar and A. Martinoli, "A Distributed Source Term Estimation Algorithm for Multi-Robot Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5604-5610.
doi: 10.1109/ICRA40945.2020.9196959
keywords: {Robot kinematics;Robot sensing systems;Estimation;Navigation;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196959&isnumber=9196508

A. Pierson, W. Schwarting, S. Karaman and D. Rus, "Weighted Buffered Voronoi Cells for Distributed Semi-Cooperative Behavior," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5611-5617.
doi: 10.1109/ICRA40945.2020.9196686
keywords: {Navigation;Robot kinematics;Collision avoidance;Games;Planning;Safety},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196686&isnumber=9196508

A. Nicolai, G. Olson, Y. Meng√º√ß and G. A. Hollinger, "Learning to Control Reconfigurable Staged Soft Arms," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5618-5624.
doi: 10.1109/ICRA40945.2020.9197516
keywords: {Load modeling;Actuators;Soft robotics;Kinematics;Calibration;Training;Training data},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197516&isnumber=9196508

J. Jeong, C. Hoon Park and K. -U. Kyung, "Modeling and Analysis of SMA Actuator Embedded in Stretchable Coolant Vascular Pursuing Artificial Muscles," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5641-5646.
doi: 10.1109/ICRA40945.2020.9197090
keywords: {Springs;Coolants;Actuators;Mathematical model;Force;Wires},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197090&isnumber=9196508

O. -M. Pedersen, E. Misimi and F. Chaumette, "Grasping Unknown Objects by Coupling Deep Reinforcement Learning, Generative Adversarial Networks, and Visual Servoing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5655-5662.
doi: 10.1109/ICRA40945.2020.9197196
keywords: {Grasping;Robots;Grippers;Training;Task analysis;Gallium nitride;Image segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197196&isnumber=9196508

A. M. Kabir et al., "Incorporating Motion Planning Feasibility Considerations during Task-Agent Assignment to Perform Complex Tasks Using Mobile Manipulators," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5663-5670.
doi: 10.1109/ICRA40945.2020.9196667
keywords: {Task analysis;Planning;Manipulators;Robot kinematics;Containers;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196667&isnumber=9196508

L. Shao, T. Migimatsu and J. Bohg, "Learning to Scaffold the Development of Robotic Manipulation Skills," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5671-5677.
doi: 10.1109/ICRA40945.2020.9197134
keywords: {Task analysis;Tools;Uncertainty;Robot sensing systems;Robustness;Motor drives},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197134&isnumber=9196508

C. R. Garrett, C. Paxton, T. Lozano-P√©rez, L. P. Kaelbling and D. Fox, "Online Replanning in Belief Space for Partially Observable Task and Motion Problems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5678-5684.
doi: 10.1109/ICRA40945.2020.9196681
keywords: {Planning;Task analysis;Bayes methods;Manipulators;Aerospace electronics;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196681&isnumber=9196508

M. Brossard, A. Barrau and S. Bonnabel, "A Code for Unscented Kalman Filtering on Manifolds (UKF-M)," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5701-5708.
doi: 10.1109/ICRA40945.2020.9197489
keywords: {Manifolds;Kalman filters;Two dimensional displays;Dispersion;Robots;Covariance matrices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197489&isnumber=9196508

P. B√∂hmler, J. Dziedzitz, P. Hopfgarten, T. Specker and R. Lange, "Efficient and precise sensor fusion for non-linear systems with out-of-sequence measurements by example of mobile robotics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5709-5715.
doi: 10.1109/ICRA40945.2020.9197032
keywords: {Robot sensing systems;Delays;Current measurement;Sensor fusion;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197032&isnumber=9196508

J. Tian, W. Cheung, N. Glaser, Y. -C. Liu and Z. Kira, "UNO: Uncertainty-aware Noisy-Or Multimodal Fusion for Unanticipated Input Degradation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5716-5723.
doi: 10.1109/ICRA40945.2020.9197266
keywords: {Uncertainty;Degradation;Training;Noise measurement;Robot sensing systems;Entropy},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197266&isnumber=9196508

W. Lee, K. Eckenhoff, P. Geneva and G. Huang, "Intermittent GPS-aided VIO: Online Initialization and Calibration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5724-5731.
doi: 10.1109/ICRA40945.2020.9197029
keywords: {Global Positioning System;Robot sensing systems;Calibration;Cameras;Cloning;Robustness;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197029&isnumber=9196508

A. Barrau and S. Bonnabel, "A Mathematical Framework for IMU Error Propagation with Applications to Preintegration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5732-5738.
doi: 10.1109/ICRA40945.2020.9197492
keywords: {Earth;Mathematical model;Force;Robot kinematics;Sensors;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197492&isnumber=9196508

A. Kramer, C. Stahoviak, A. Santamaria-Navarro, A. -a. Agha-mohammadi and C. Heckman, "Radar-Inertial Ego-Velocity Estimation for Visually Degraded Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5739-5746.
doi: 10.1109/ICRA40945.2020.9196666
keywords: {Robot sensing systems;Radar measurements;Doppler radar;Doppler effect;Estimation;Velocity measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196666&isnumber=9196508

T. Kim, S. Yoo, H. S. Kim and T. Seo, "Position-based Impedance Control of a 2-DOF Compliant Manipulator for a Facade Cleaning Operation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5765-5770.
doi: 10.1109/ICRA40945.2020.9197478
keywords: {Manipulators;Force;Cleaning;Buildings;Force measurement;Sea measurements;Impedance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197478&isnumber=9196508

K. Nottensteiner, F. Stulp and A. Albu-Sch√§ffer, "Robust, Locally Guided Peg-in-Hole using Impedance-Controlled Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5771-5777.
doi: 10.1109/ICRA40945.2020.9196986
keywords: {Task analysis;Uncertainty;Geometry;Robot sensing systems;Robustness;State estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196986&isnumber=9196508

S. Huang and J. M. Schimmels, "Design of Spatial Admittance for Force-Guided Assembly of Polyhedral Parts in Single Point Frictional Contact," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5801-5807.
doi: 10.1109/ICRA40945.2020.9197075
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197075&isnumber=9196508

M. Taghavi, T. Helps and J. Rossiter, "Characterisation of Self-locking High-contraction Electro-ribbon Actuators," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5856-5861.
doi: 10.1109/ICRA40945.2020.9196849
keywords: {Actuators;Electrodes;Dielectric liquids;Force;Insulators;Dielectrics;Permittivity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196849&isnumber=9196508

T. Tsabedze, C. Mullen, R. Coulter, S. Wade and J. Zhang, "Helically Wrapped Supercoiled Polymer (HW-SCP) Artificial Muscles: Design, Characterization, and Modeling," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5862-5868.
doi: 10.1109/ICRA40945.2020.9197330
keywords: {Actuators;Strain;Force;Mathematical model;Muscles;Robots;Yarn},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197330&isnumber=9196508

Y. Li, T. Ren, Y. Chen and M. Z. Q. Chen, "A Variable Stiffness Soft Continuum Robot Based on Pre-charged Air, Particle Jamming, and Origami," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5869-5875.
doi: 10.1109/ICRA40945.2020.9196729
keywords: {Robots;Jamming;Force;Tendons;Electron tubes;Wires;Valves;Soft continuum robot;variable stiffness;pre-charged air;particle jamming;origami},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196729&isnumber=9196508

M. G√∂rner, F. Benedikt, F. Grimmel and T. Hulin, "SwarmRail: A Novel Overhead Robot System for Indoor Transport and Mobile Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5905-5911.
doi: 10.1109/ICRA40945.2020.9196972
keywords: {Rails;Wheels;Robot sensing systems;Manipulators;Layout},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196972&isnumber=9196508

T. Overbye and S. Saripalli, "Fast Local Planning and Mapping in Unknown Off-Road Terrain," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5912-5918.
doi: 10.1109/ICRA40945.2020.9196848
keywords: {Trajectory;Robots;Planning;Aerospace electronics;Microsoft Windows;Three-dimensional displays;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196848&isnumber=9196508

G. Swamy, S. Reddy, S. Levine and A. D. Dragan, "Scaled Autonomy: Enabling Human Operators to Control Robot Fleets," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5942-5948.
doi: 10.1109/ICRA40945.2020.9196792
keywords: {Task analysis;Mathematical model;Navigation;Autonomous robots;Hardware;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196792&isnumber=9196508

X. Zhao, T. Fan, D. Wang, Z. Hu, T. Han and J. Pan, "An Actor-Critic Approach for Legible Robot Motion Planner," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5949-5955.
doi: 10.1109/ICRA40945.2020.9197102
keywords: {Task analysis;Robot motion;Robot kinematics;Biological neural networks;Trajectory;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197102&isnumber=9196508

B. Gromov, J. Guzzi, L. M. Gambardella and A. Giusti, "Intuitive 3D Control of a Quadrotor in User Proximity with Pointing Gestures," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5964-5971.
doi: 10.1109/ICRA40945.2020.9196654
keywords: {Three-dimensional displays;Drones;Robot kinematics;Shape;Robot sensing systems;Aerospace electronics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196654&isnumber=9196508

T. Yuan et al., "Joint Inference of States, Robot Knowledge, and Human (False-)Beliefs," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5972-5978.
doi: 10.1109/ICRA40945.2020.9197355
keywords: {Robots;Cognition;Visualization;Graphical models;Psychology;Noise measurement;Object tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197355&isnumber=9196508

J. Gonzalez-Billandon, A. Sciutti, M. Tata, G. Sandini and F. Rea, "Audiovisual cognitive architecture for autonomous learning of face localisation by a Humanoid Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5979-5985.
doi: 10.1109/ICRA40945.2020.9196829
keywords: {Training;Learning systems;Deep learning;Pediatrics;Conferences;Humanoid robots;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196829&isnumber=9196508

A. Candela et al., "Planetary Rover Exploration Combining Remote and In Situ Measurements for Active Spectroscopic Mapping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5986-5993.
doi: 10.1109/ICRA40945.2020.9196973
keywords: {Feature extraction;Extraterrestrial measurements;Robot kinematics;Adaptation models;Productivity;Mars},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196973&isnumber=9196508

K. WATANABE, "Magnetic Docking Mechanism for Free-flying Space Robots with Spherical Surfaces," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 5994-5999.
doi: 10.1109/ICRA40945.2020.9197423
keywords: {Robots;Force;Magnetic levitation;Computer interfaces;Shape;Magnetoelasticity;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197423&isnumber=9196508

Y. Marchetti, J. Lightholder, E. Junkins, M. Cross, L. Mandrake and A. Fraeman, "Barefoot Rover: a Sensor-Embedded Rover Wheel Demonstrating In-Situ Engineering and Science Extractions using Machine Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6000-6006.
doi: 10.1109/ICRA40945.2020.9197500
keywords: {Wheels;Robot sensing systems;Rocks;Instruments;Measurement;Surface impedance;DC motors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197500&isnumber=9196508

P. F. Proen√ßa and Y. Gao, "Deep Learning for Spacecraft Pose Estimation from Photorealistic Rendering," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6007-6013.
doi: 10.1109/ICRA40945.2020.9197244
keywords: {Space vehicles;Quaternions;Pose estimation;Earth;Cameras;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197244&isnumber=9196508

O. -O. Christidi-Loumpasefski, G. Rekleitis and E. Papadopoulos, "Concurrent Parameter Identification and Control for Free-Floating Robotic Systems During On-Orbit Servicing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6014-6020.
doi: 10.1109/ICRA40945.2020.9197187
keywords: {Task analysis;Parameter estimation;Aerospace electronics;Manipulator dynamics;Adaptive control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197187&isnumber=9196508

M. Ekal and R. Ventura, "A Dual Quaternion-Based Discrete Variational Approach for Accurate and Online Inertial Parameter Estimation in Free-Flying obots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6021-6027.
doi: 10.1109/ICRA40945.2020.9196852
keywords: {Quaternions;Mathematical model;Parameter estimation;Robots;Linear matrix inequalities;Estimation;Programming},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196852&isnumber=9196508

J. K√ºmmerle and T. K√ºhner, "Unified Intrinsic and Extrinsic Camera and LiDAR Calibration under Uncertainties," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6028-6034.
doi: 10.1109/ICRA40945.2020.9197496
keywords: {Cameras;Calibration;Laser radar;Three-dimensional displays;Image edge detection;Detectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197496&isnumber=9196508

J. Rebello, A. Fung and S. L. Waslander, "AC/DCC : Accurate Calibration of Dynamic Camera Clusters for Visual SLAM," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6035-6041.
doi: 10.1109/ICRA40945.2020.9197217
keywords: {Cameras;Calibration;Robot vision systems;Simultaneous localization and mapping;Vehicle dynamics;Optimization;Measurement uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197217&isnumber=9196508

G. Koo, J. Kang, B. Jang and N. Doh, "Analytic Plane Covariances Construction for Precise Planarity-based Extrinsic Calibration of Camera and LiDAR," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6042-6048.
doi: 10.1109/ICRA40945.2020.9197149
keywords: {Three-dimensional displays;Calibration;Cameras;Laser radar;Linear programming;Solid modeling;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197149&isnumber=9196508

Y. -H. Chang, Y. -C. Liu and C. -C. Lan, "An End-Effector Wrist Module for the Kinematically Redundant Manipulation of Arm-Type Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6075-6080.
doi: 10.1109/ICRA40945.2020.9197258
keywords: {Wrist;Collision avoidance;Kinematics;Redundancy;Jacobian matrices;Service robots;Kinematically redundant manipulation;wrist module;roll-pitch-yaw;wrist singularity;inverse kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197258&isnumber=9196508

H. Zhao, W. Chen, S. Zhou, Z. Liu, F. Zheng and Y. -H. Liu, "Online Trajectory Planning for an Industrial Tractor Towing Multiple Full Trailers," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6089-6095.
doi: 10.1109/ICRA40945.2020.9196656
keywords: {Agricultural machinery;Vehicle dynamics;Planning;Trajectory;Dynamics;Wheels;Lead},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196656&isnumber=9196508

Q. Lu, G. M. Fricke, T. Tsuno and M. E. Moses, "A Bio-Inspired Transportation Network for Scalable Swarm Foraging," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6120-6126.
doi: 10.1109/ICRA40945.2020.9196762
keywords: {Robots;Transportation;Biology;Collision avoidance;Scalability;Task analysis;Explosions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196762&isnumber=9196508

G. Urbain, V. Barasuol, C. Semini, J. Dambre and F. wyffels, "Stance Control Inspired by Cerebellum Stabilizes Reflex-Based Locomotion on HyQ Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6127-6133.
doi: 10.1109/ICRA40945.2020.9196523
keywords: {Legged locomotion;Cerebellum;Foot;Stability analysis;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196523&isnumber=9196508

R. Kreiser, G. Waibel, N. Armengol, A. Renner and Y. Sandamirskaya, "Error estimation and correction in a spiking neural network for map formation in neuromorphic hardware," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6134-6140.
doi: 10.1109/ICRA40945.2020.9197498
keywords: {Neurons;Robots;Sociology;Statistics;Light emitting diodes;Neuromorphics;Synapses},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197498&isnumber=9196508

S. Tanaka, K. Koyama, T. Senoo and M. Ishikawa, "Adaptive Visual Shock Absorber with Visual-based Maxwell Model Using a Magnetic Gear," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6163-6168.
doi: 10.1109/ICRA40945.2020.9197504
keywords: {Strain;Visualization;Force;Shock absorbers;Magnetic gears;End effectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197504&isnumber=9196508

M. Xin, K. Zhang, D. Lackner and M. A. Minor, "Slip-Based Nonlinear Recursive Backstepping Path Following Controller for Autonomous Ground Vehicles," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6169-6175.
doi: 10.1109/ICRA40945.2020.9197165
keywords: {Kinematics;Vehicle dynamics;Backstepping;Tracking;Dynamics;Tires;Convergence},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197165&isnumber=9196508

Z. Li, √ñ. Arslan and N. Atanasov, "Fast and Safe Path-Following Control using a State-Dependent Directional Metric," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6176-6182.
doi: 10.1109/ICRA40945.2020.9197377
keywords: {Robots;Trajectory;Safety;Measurement;Navigation;Collision avoidance;Aerospace electronics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197377&isnumber=9196508

B. DeBoon, S. Nokleby and C. Rossa, "Backlash-Compensated Active Disturbance Rejection Control of Nonlinear Multi-Input Series Elastic Actuators," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6183-6189.
doi: 10.1109/ICRA40945.2020.9196657
keywords: {Actuators;Torque;Springs;Brakes;DC motors;Sea measurements;Hysteresis motors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196657&isnumber=9196508

S. Wang, A. Polyakov and G. Zheng, "On Generalized Homogenization of Linear Quadrotor Controller," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6190-6195.
doi: 10.1109/ICRA40945.2020.9197116
keywords: {Symmetric matrices;Generators;Linear matrix inequalities;Robustness;Closed loop systems;Lyapunov methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197116&isnumber=9196508

J. Liang, A. Handa, K. V. Wyk, V. Makoviychuk, O. Kroemer and D. Fox, "In-Hand Object Pose Tracking via Contact Feedback and GPU-Accelerated Robotic Simulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6203-6209.
doi: 10.1109/ICRA40945.2020.9197117
keywords: {Pose estimation;Robot sensing systems;Physics;Heuristic algorithms;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197117&isnumber=9196508

B. Wen, C. Mitash, S. Soorian, A. Kimmel, A. Sintov and K. E. Bekris, "Robust, Occlusion-aware Pose Estimation for Objects Grasped by Adaptive Hands," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6210-6217.
doi: 10.1109/ICRA40945.2020.9197350
keywords: {Three-dimensional displays;Pose estimation;Robot sensing systems;Robustness;Computational modeling;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197350&isnumber=9196508

M. Tian, L. Pan, M. H. Ang and G. Hee Lee, "Robust 6D Object Pose Estimation by Learning RGB-D Features," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6218-6224.
doi: 10.1109/ICRA40945.2020.9197555
keywords: {Feature extraction;Pose estimation;Three-dimensional displays;Robustness;Uncertainty;Image segmentation;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197555&isnumber=9196508

I. Sarantopoulos, M. Kiatos, Z. Doulgeri and S. Malassiotis, "Split Deep Q-Learning for Robust Object Singulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6225-6231.
doi: 10.1109/ICRA40945.2020.9196647
keywords: {Grasping;Task analysis;Clutter;Image segmentation;Robustness;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196647&isnumber=9196508

A. Murali, A. Mousavian, C. Eppner, C. Paxton and D. Fox, "6-DOF Grasping for Target-driven Object Manipulation in Clutter," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6232-6238.
doi: 10.1109/ICRA40945.2020.9197318
keywords: {Clutter;Three-dimensional displays;Grasping;Grippers;Robots;Collision avoidance;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197318&isnumber=9196508

K. Kleeberger and M. F. Huber, "Single Shot 6D Object Pose Estimation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6239-6245.
doi: 10.1109/ICRA40945.2020.9197207
keywords: {Three-dimensional displays;Solid modeling;Data models;Task analysis;Pose estimation;Image segmentation;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197207&isnumber=9196508

G. Kim, Y. S. Park, Y. Cho, J. Jeong and A. Kim, "MulRan: Multimodal Range Dataset for Urban Place Recognition," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6246-6253.
doi: 10.1109/ICRA40945.2020.9197298
keywords: {Laser radar;Radar imaging;Three-dimensional displays;Urban areas;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197298&isnumber=9196508

S. Du et al., "GPO: Global Plane Optimization for Fast and Accurate Monocular SLAM Initialization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6254-6260.
doi: 10.1109/ICRA40945.2020.9196970
keywords: {Cameras;Simultaneous localization and mapping;Optimization;Matrix decomposition;Transmission line matrix methods;Estimation;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196970&isnumber=9196508

T. K√ºhner and J. K√ºmmerle, "Large-Scale Volumetric Scene Reconstruction using LiDAR," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6261-6267.
doi: 10.1109/ICRA40945.2020.9197388
keywords: {Three-dimensional displays;Laser radar;Image reconstruction;Graphics processing units;Sensor fusion;Weight measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197388&isnumber=9196508

S. S. Puligilla, S. Tourani, T. Vaidya, U. S. Parihar, R. Kiran Sarvadevabhatla and K. M. Krishna, "Topological Mapping for Manhattan-like Repetitive Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6268-6274.
doi: 10.1109/ICRA40945.2020.9197520
keywords: {Topology;Network topology;Simultaneous localization and mapping;Neural networks;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197520&isnumber=9196508

K. M. Han and Y. J. Kim, "Robust RGB-D Camera Tracking using Optimal Key-frame Selection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6275-6281.
doi: 10.1109/ICRA40945.2020.9197021
keywords: {Cameras;Robustness;Optimization;Tracking;Iterative closest point algorithm;Robot vision systems;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197021&isnumber=9196508

S. Li, E. √ñzt√ºrk, C. De Wagter, G. C. H. E. de Croon and D. Izzo, "Aggressive Online Control of a Quadrotor via Deep Network Representations of Optimality Principles," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6282-6287.
doi: 10.1109/ICRA40945.2020.9197443
keywords: {Trajectory;Optimal control;Stability analysis;Neural networks;Delays;Training;Drones},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197443&isnumber=9196508

M. Kleinbort, E. Granados, K. Solovey, R. Bonalli, K. E. Bekris and D. Halperin, "Refined Analysis of Asymptotically-Optimal Kinodynamic Planning in the State-Cost Space," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6344-6350.
doi: 10.1109/ICRA40945.2020.9197236
keywords: {Trajectory;Planning;Aerospace electronics;Robots;Collision avoidance;Cost function;Space exploration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197236&isnumber=9196508

A. M. C. Rezende, V. M. Gon√ßalves, A. H. D. Nunes and L. C. A. Pimenta, "Robust quadcopter control with artificial vector fields," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6381-6387.
doi: 10.1109/ICRA40945.2020.9196605
keywords: {Robots;Vehicle dynamics;Robustness;Convergence;Level set;Mathematical model;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196605&isnumber=9196508

B. Osi≈Ñski et al., "Simulation-Based Reinforcement Learning for Real-World Autonomous Driving," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6411-6418.
doi: 10.1109/ICRA40945.2020.9196730
keywords: {Training;Visualization;Learning (artificial intelligence);Semantics;Robots;Image segmentation;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196730&isnumber=9196508

S. Rosbach, V. James, S. Gro√üjohann, S. Homoceanu, X. Li and S. Roth, "Driving Style Encoder: Situational Reward Adaptation for General-Purpose Planning in Automated Driving," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6419-6425.
doi: 10.1109/ICRA40945.2020.9196778
keywords: {Planning;Neural networks;Entropy;Kinematics;Machine learning;Tuning;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196778&isnumber=9196508

S. K. Jayaraman, D. M. Tilbury, X. Jessie Yang, A. K. Pradhan and L. P. Robert, "Analysis and Prediction of Pedestrian Crosswalk Behavior during Automated Vehicle Interactions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6426-6432.
doi: 10.1109/ICRA40945.2020.9197347
keywords: {Predictive models;Trajectory;Legged locomotion;Vehicle dynamics;Virtual environments;Planning;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197347&isnumber=9196508

D. Barnes, M. Gadd, P. Murcutt, P. Newman and I. Posner, "The Oxford Radar RobotCar Dataset: A Radar Extension to the Oxford RobotCar Dataset," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6433-6438.
doi: 10.1109/ICRA40945.2020.9196884
keywords: {Robot sensing systems;Laser radar;Three-dimensional displays;Azimuth;Calibration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196884&isnumber=9196508

S. Fang and A. Choromanska, "Multi-modal Experts Network for Autonomous Driving," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6439-6445.
doi: 10.1109/ICRA40945.2020.9197459
keywords: {Laser radar;Feature extraction;Cameras;Training;Autonomous vehicles;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197459&isnumber=9196508

M. Jayasuriya, J. Arukgoda, R. Ranasinghe and G. Dissanayake, "Localising PMDs through CNN Based Perception of Urban Streets," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6454-6460.
doi: 10.1109/ICRA40945.2020.9196639
keywords: {Feature extraction;Transforms;Cameras;Semantics;Two dimensional displays;Data mining;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196639&isnumber=9196508

N. Akai, T. Hirayama and H. Murase, "Hybrid Localization using Model- and Learning-Based Methods: Fusion of Monte Carlo and E2E Localizations via Importance Sampling," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6469-6475.
doi: 10.1109/ICRA40945.2020.9196568
keywords: {Atmospheric measurements;Particle measurements;Proposals;Predictive models;Fuses;Learning systems;Monte Carlo methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196568&isnumber=9196508

B. Patel, T. D. Barfoot and A. P. Schoellig, "Visual Localization with Google Earth Images for Robust Global Pose Estimation of UAVs," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6491-6497.
doi: 10.1109/ICRA40945.2020.9196606
keywords: {Cameras;Image registration;Three-dimensional displays;Visualization;Earth;Robustness;Google},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196606&isnumber=9196508

L. Hermann, M. Argus, A. Eitel, A. Amiranashvili, W. Burgard and T. Brox, "Adaptive Curriculum Generation from Demonstrations for Sim-to-Real Visuomotor Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6498-6505.
doi: 10.1109/ICRA40945.2020.9197108
keywords: {Task analysis;Training;Robots;Trajectory;Learning (artificial intelligence);Adaptation models;Stacking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197108&isnumber=9196508

P. Abolghasemi and L. B√∂l√∂ni, "Accept Synthetic Objects as Real: End-to-End Training of Attentive Deep Visuomotor Policies for Manipulation in Clutter," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6506-6512.
doi: 10.1109/ICRA40945.2020.9197552
keywords: {Clutter;Robots;Training data;Task analysis;Training;Encoding;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197552&isnumber=9196508

B. Nemec, M. Simoniƒç and A. Ude, "Learning of Exception Strategies in Assembly Tasks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6521-6527.
doi: 10.1109/ICRA40945.2020.9197480
keywords: {Robot sensing systems;Task analysis;Trajectory;Robot kinematics;Databases;Statistical learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197480&isnumber=9196508

A. Munawar, N. Srishankar and G. S. Fischer, "An Open-Source Framework for Rapid Development of Interactive Soft-Body Simulations for Real-Time Training," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6544-6550.
doi: 10.1109/ICRA40945.2020.9197573
keywords: {Visualization;Computational modeling;Real-time systems;Training;Robots;Faces;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197573&isnumber=9196508

O. Erin, D. Antonelli, M. E. Tiryaki and M. Sitti, "Towards 5-DoF Control of an Untethered Magnetic Millirobot via MRI Gradient Coils," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6551-6557.
doi: 10.1109/ICRA40945.2020.9196692
keywords: {Magnetic resonance imaging;Robots;Magnetic devices;Coils;Three-dimensional displays;Force;Medical robotics;miniature robots;magnetic actuation;magnetic resonance imaging;optimal control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196692&isnumber=9196508

S. Samadi, S. Caron, A. Tanguy and A. Kheddar, "Balance of Humanoid Robots in a Mix of Fixed and Sliding Multi-Contact Scenarios," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6590-6596.
doi: 10.1109/ICRA40945.2020.9197253
keywords: {Humanoid robots;Mathematical model;Friction;Task analysis;Gravity;Humanoid and multi-legged robots;balance;multi-contacts;sliding contacts},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197253&isnumber=9196508

G. Ficht and S. Behnke, "Fast Whole-Body Motion Control of Humanoid Robots with Inertia Constraints," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6597-6603.
doi: 10.1109/ICRA40945.2020.9197322
keywords: {Legged locomotion;Foot;Kinematics;Humanoid robots;Hip;Computational modeling;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197322&isnumber=9196508

S. Tonneau, D. Song, P. Fernbach, N. Mansard, M. Ta√Øx and A. Del Prete, "SL1M: Sparse L1-norm Minimization for contact planning on uneven terrain," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6604-6610.
doi: 10.1109/ICRA40945.2020.9197371
keywords: {Silicon;Planning;Foot;Minimization;Kinematics;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197371&isnumber=9196508

S. J. Jorgensen, M. Vedantam, R. Gupta, H. Cappel and L. Sentis, "Finding Locomanipulation Plans Quickly in the Locomotion Constrained Manifold," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6611-6617.
doi: 10.1109/ICRA40945.2020.9197533
keywords: {Trajectory;Task analysis;Foot;Manifolds;Pelvis;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197533&isnumber=9196508

J. White, D. Swart and C. Hubicki, "Force-based Control of Bipedal Balancing on Dynamic Terrain with the "Tallahassee Cassie" Robotic Platform," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6618-6624.
doi: 10.1109/ICRA40945.2020.9196725
keywords: {Pelvis;Legged locomotion;Foot;Dynamics;Vehicle dynamics;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196725&isnumber=9196508

L. Guerrero-Bonilla, D. Salda√±a and V. Kumar, "Dense r-robust formations on lattices," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6633-6639.
doi: 10.1109/ICRA40945.2020.9196683
keywords: {Lattices;Robot kinematics;Communication networks;Robustness;Robot sensing systems;Energy consumption},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196683&isnumber=9196508

R. Wehbe and R. K. Williams, "Optimizing Topologies for Probabilistically Secure Multi-Robot Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6640-6646.
doi: 10.1109/ICRA40945.2020.9197249
keywords: {Robots;Probabilistic logic;Security;Optimization;Topology;Observers;Multi-robot systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197249&isnumber=9196508

A. Dutta, A. Ghosh, S. Sisley and O. P. Kreidl, "Efficient Communication in Large Multi-robot Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6647-6653.
doi: 10.1109/ICRA40945.2020.9196672
keywords: {Robot kinematics;Routing;Multi-robot systems;Complexity theory;Relays;Communication networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196672&isnumber=9196508

R. Ghosh et al., "CyPhyHouse: A programming, simulation, and deployment toolchain for heterogeneous distributed coordination," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6654-6660.
doi: 10.1109/ICRA40945.2020.9196513
keywords: {Robot kinematics;Task analysis;Middleware;Collision avoidance;Python},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196513&isnumber=9196508

F. Yang and N. Chakraborty, "Chance Constrained Simultaneous Path Planning and Task Assignment for Multiple Robots with Stochastic Path Costs," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6661-6667.
doi: 10.1109/ICRA40945.2020.9197354
keywords: {Robots;Task analysis;Collision avoidance;Path planning;Resource management;Random variables;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197354&isnumber=9196508

P. Mukherjee, M. Santilli, A. Gasparri and R. K. Williams, "Optimal Topology Selection for Stable Coordination of Asymmetrically Interacting Multi-Robot Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6668-6674.
doi: 10.1109/ICRA40945.2020.9196822
keywords: {Robot kinematics;Topology;Robot sensing systems;Multi-robot systems;Symmetric matrices;Laplace equations},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196822&isnumber=9196508

R. Papallas and M. R. Dogar, "Non-Prehensile Manipulation in Clutter with Human-In-The-Loop," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6723-6729.
doi: 10.1109/ICRA40945.2020.9196689
keywords: {Robots;Planning;Clutter;Aerospace electronics;1/f noise;Task analysis;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196689&isnumber=9196508

S. Lensgraf et al., "PuzzleFlex: kinematic motion of chains with loose joints," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6730-6737.
doi: 10.1109/ICRA40945.2020.9196854
keywords: {Robots;Kinematics;Analytical models;Shape;Jacobian matrices;Aerospace electronics;Linear programming},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196854&isnumber=9196508

A. Kloss, M. Bauza, J. Wu, J. B. Tenenbaum, A. Rodriguez and J. Bohg, "Accurate Vision-based Manipulation through Contact Reasoning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6738-6744.
doi: 10.1109/ICRA40945.2020.9197409
keywords: {Shape;Predictive models;Planning;Analytical models;Robots;Computational modeling;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197409&isnumber=9196508

J. -S. Ha, D. Driess and M. Toussaint, "A Probabilistic Framework for Constrained Manipulations and Task and Motion Planning under Uncertainty," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6745-6751.
doi: 10.1109/ICRA40945.2020.9196840
keywords: {Robots;Planning;Trajectory optimization;Skeleton;Programming},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196840&isnumber=9196508

M. Suhail Saleem and M. Likhachev, "Planning with Selective Physics-based Simulation for Manipulation Among Movable Objects," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6752-6758.
doi: 10.1109/ICRA40945.2020.9197451
keywords: {Planning;Collision avoidance;Manipulators;Physics;Computational modeling;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197451&isnumber=9196508

N. Doshi, F. R. Hogan and A. Rodriguez, "Hybrid Differential Dynamic Programming for Planar Manipulation Primitives," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6759-6765.
doi: 10.1109/ICRA40945.2020.9197414
keywords: {Trajectory;Planning;Contacts;Heuristic algorithms;Force;Convergence;Friction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197414&isnumber=9196508

C. -Y. Chai, Y. -P. Wu and S. -L. Tsao, "Deep Depth Fusion for Black, Transparent, Reflective and Texture-Less Objects," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6766-6772.
doi: 10.1109/ICRA40945.2020.9196894
keywords: {Cameras;Robot vision systems;Three-dimensional displays;Color;Image color analysis;Prediction algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196894&isnumber=9196508

W. Zhen, Y. Hu, H. Yu and S. Scherer, "LiDAR-enhanced Structure-from-Motion," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6773-6779.
doi: 10.1109/ICRA40945.2020.9197030
keywords: {Laser radar;Cameras;Pipelines;Three-dimensional displays;Visualization;Robustness;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197030&isnumber=9196508

M. Pollach, F. Schiegg and A. Knoll, "Low Latency And Low-Level Sensor Fusion For Automotive Use-Cases," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6780-6786.
doi: 10.1109/ICRA40945.2020.9196717
keywords: {Cameras;Three-dimensional displays;Object detection;Sensor fusion;Robot sensing systems;Two dimensional displays;Radar;sensor fusion;object detection;Bayesian networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196717&isnumber=9196508

H. Zhang, Z. Chen, D. Zanotto and Y. Guo, "Robot-Assisted and Wearable Sensor-Mediated Autonomous Gait Analysis¬ß," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6795-6802.
doi: 10.1109/ICRA40945.2020.9197571
keywords: {Robot sensing systems;Legged locomotion;Task analysis;Instruments;Robot kinematics;Wearable Technology;Instrumented Footwear;Gait Analysis;Assistive Robotics;SportSole},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197571&isnumber=9196508

L. Roveda, N. Castaman, P. Franceschi, S. Ghidoni and N. Pedrocchi, "A Control Framework Definition to Overcome Position/Interaction Dynamics Uncertainties in Force-Controlled Tasks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6819-6825.
doi: 10.1109/ICRA40945.2020.9197141
keywords: {Force;Pose estimation;Impedance;Task analysis;Three-dimensional displays;Robots;Damping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197141&isnumber=9196508

L. Wijayarathne and F. L. Hammond, "Identification of Compliant Contact Parameters and Admittance Force Modulation on a Non-stationary Compliant Surface," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6826-6832.
doi: 10.1109/ICRA40945.2020.9196897
keywords: {Force;Impedance;Force control;Probes;Surface impedance;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196897&isnumber=9196508

W. Amanhoud, M. Khoramshahi, M. Bonnesoeur and A. Billard, "Force Adaptation in Contact Tasks with Dynamical Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6841-6847.
doi: 10.1109/ICRA40945.2020.9197509
keywords: {Force;Robots;Task analysis;Surface impedance;Dynamics;Impedance;Tracking;Force Control;Compliance and Impedance Control;Physical Human-Robot Interaction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197509&isnumber=9196508

K. Sakurada, M. Shibuya and W. Wang, "Weakly Supervised Silhouette-based Semantic Scene Change Detection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6861-6867.
doi: 10.1109/ICRA40945.2020.9196985
keywords: {Semantics;Image segmentation;Cameras;Training;Task analysis;Satellites;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196985&isnumber=9196508

L. Du et al., "3DCFS: Fast and Robust Joint 3D Semantic-Instance Segmentation via Coupled Feature Selection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6868-6875.
doi: 10.1109/ICRA40945.2020.9197242
keywords: {Semantics;Task analysis;Three-dimensional displays;Feature extraction;Logic gates;Training;Euclidean distance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197242&isnumber=9196508

Y. -C. Liu, J. Tian, C. -Y. Ma, N. Glaser, C. -W. Kuo and Z. Kira, "Who2com: Collaborative Perception via Learnable Handshake Communication," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6876-6883.
doi: 10.1109/ICRA40945.2020.9197364
keywords: {Task analysis;Bandwidth;Semantics;Training;Collaboration;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197364&isnumber=9196508

Z. Landgraf, F. Falck, M. Bloesch, S. Leutenegger and A. J. Davison, "Comparing View-Based and Map-Based Semantic Labelling in Real-Time SLAM," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6884-6890.
doi: 10.1109/ICRA40945.2020.9196843
keywords: {Labeling;Semantics;Three-dimensional displays;Simultaneous localization and mapping;Cameras;Image reconstruction;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196843&isnumber=9196508

G. Izatt and R. Tedrake, "Generative Modeling of Environments with Scene Grammars and Variational Inference," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6891-6897.
doi: 10.1109/ICRA40945.2020.9196910
keywords: {Grammar;Robots;Production;Testing;Training;Random variables;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196910&isnumber=9196508

M. Nazarczuk and K. Mikolajczyk, "SHOP-VRB: A Visual Reasoning Benchmark for Object Perception," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6898-6904.
doi: 10.1109/ICRA40945.2020.9197332
keywords: {Visualization;Cognition;Benchmark testing;Robots;Image color analysis;Task analysis;Plastics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197332&isnumber=9196508

J. Hughes, S. Li and D. Rus, "Sensorization of a Continuum Body Gripper for High Force and Delicate Object Grasping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6913-6919.
doi: 10.1109/ICRA40945.2020.9196603
keywords: {Grippers;Force;Robot sensing systems;Strain;Bladder;Mechanical sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196603&isnumber=9196508

S. Jain, T. Stalin, V. Subramaniam, J. Agarwal and P. V. y Alvarado, "A Soft Gripper with Retractable Nails for Advanced Grasping and Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6928-6934.
doi: 10.1109/ICRA40945.2020.9197259
keywords: {Nails;Grippers;Grasping;Three-dimensional displays;Actuators;Payloads;Fingers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197259&isnumber=9196508

X. Hu, H. Zeng, D. Chen, J. Zhu and A. Song, "Real-time Continuous Hand Motion Myoelectric Decoding by Automated Data Labeling," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6951-6957.
doi: 10.1109/ICRA40945.2020.9197286
keywords: {Muscles;Neurons;Wrist;Training;Feature extraction;Neural networks;Principal component analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197286&isnumber=9196508

M. Kabtoul, A. Spalanzani and P. Martinet, "Towards Proactive Navigation: A Pedestrian-Vehicle Cooperation Based Behavioral Model," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6958-6964.
doi: 10.1109/ICRA40945.2020.9196669
keywords: {Navigation;Space vehicles;Predictive models;Strain;Task analysis;Trajectory;Autonomous vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196669&isnumber=9196508

P. Scales, O. Aycard and V. Auberg√©, "Studying Navigation as a Form of Interaction: a Design Approach for Social Robot Navigation Methods," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6965-6972.
doi: 10.1109/ICRA40945.2020.9197037
keywords: {Navigation;Biological system modeling;Robot sensing systems;Mobile robots;Design methodology;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197037&isnumber=9196508

K. -M. Yang, K. -H. Seo, S. H. Kang and Y. Lim, "Robot Plan Model Generation and Execution with Natural Language Interface," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6973-6978.
doi: 10.1109/ICRA40945.2020.9196987
keywords: {Task analysis;Service robots;Natural languages;Human-robot interaction;Robot sensing systems;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196987&isnumber=9196508

J. Jin, N. M. Nguyen, N. Sakib, D. Graves, H. Yao and M. Jagersand, "Mapless Navigation among Dynamics with Social-safety-awareness: a reinforcement learning approach from 2D laser scans," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6979-6985.
doi: 10.1109/ICRA40945.2020.9197148
keywords: {Collision avoidance;Navigation;Training;Robot sensing systems;Lasers;Path planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197148&isnumber=9196508

H. O. Caldag and S. Yesilyurt, "Steering Control of Magnetic Helical Swimmers in Swirling Flows due to Confinement," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 6994-7000.
doi: 10.1109/ICRA40945.2020.9196521
keywords: {Magnetic fields;Magnetosphere;Magnetic confinement;Magnetohydrodynamics;Propulsion;Navigation;microswimmers;helical swimming;low Reynolds number;steering;control;stability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196521&isnumber=9196508

K. Rosser, J. Kok, J. Chahl and J. Bongard, "Sim2real gap is non-monotonic with robot complexity for morphology-in-the-loop flapping wing design," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7001-7007.
doi: 10.1109/ICRA40945.2020.9196539
keywords: {Morphology;Robots;Shape;Finite element analysis;Complexity theory;Computational modeling;Machine learning;morphology;simulation to reality;evolution;bio-inspired},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196539&isnumber=9196508

R. Lopez-Lopez et al., "A Linearized Model for an Ornithopter in Gliding Flight: Experiments and Simulations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7008-7014.
doi: 10.1109/ICRA40945.2020.9196929
keywords: {Numerical models;Force;Mathematical model;Hardware;Steady-state;Computed tomography;Aerodynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196929&isnumber=9196508

A. Ramezani, "Towards biomimicry of a bat-style perching maneuver on structures: the manipulation of inertial dynamics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7015-7021.
doi: 10.1109/ICRA40945.2020.9197376
keywords: {Aerodynamics;Manipulator dynamics;Mathematical model;Robot sensing systems;Birds},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197376&isnumber=9196508

R. Zhou and H. -T. Lin, "Bioinspired object motion filters as the basis of obstacle negotiation in micro aerial systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7022-7028.
doi: 10.1109/ICRA40945.2020.9196752
keywords: {Visualization;Kernel;Optical filters;Drones;Band-pass filters;Biological system modeling;Insects;motion vision;obstacle avoidance;visual guidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196752&isnumber=9196508

D. A. Schreiber et al., "ARCSnake: An Archimedes‚Äô Screw-Propelled, Reconfigurable Serpentine Robot for Complex Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7029-7034.
doi: 10.1109/ICRA40945.2020.9196968
keywords: {Robots;Fasteners;Brushless motors;Skin;Propulsion;Torque;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196968&isnumber=9196508

J. Feng, L. Yang, H. Wang, Y. Song and J. Xiao, "GPR-based Subsurface Object Detection and Reconstruction Using Random Motion and DepthNet," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7035-7041.
doi: 10.1109/ICRA40945.2020.9197043
keywords: {Ground penetrating radar;Three-dimensional displays;Image reconstruction;Dielectrics;Feature extraction;Object detection;Inspection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197043&isnumber=9196508

H. Cuevas-Velasquez et al., "Real-time Stereo Visual Servoing for Rose Pruning with Robotic Arm," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7050-7056.
doi: 10.1109/ICRA40945.2020.9197272
keywords: {Cameras;Robot vision systems;Manipulators;Real-time systems;Pipelines;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197272&isnumber=9196508

P. Hamelin et al., "Slip-Limiting Controller for Redundant Line-Suspended Robots: Application to LineRanger," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7081-7087.
doi: 10.1109/ICRA40945.2020.9196832
keywords: {Wheels;Mobile robots;Angular velocity;Robot sensing systems;Resource management;Velocity measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196832&isnumber=9196508

D. Wu, W. Zhang, M. Qin and B. Xie, "Interval Search Genetic Algorithm Based on Trajectory to Solve Inverse Kinematics of Redundant Manipulators and Its Application," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7088-7094.
doi: 10.1109/ICRA40945.2020.9196890
keywords: {Manipulators;Kinematics;Sociology;Statistics;Trajectory;Genetic algorithms;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196890&isnumber=9196508

Z. Fu, E. Spyrakos-Papastavridis, Y. -h. Lin and J. S. Dai, "Analytical Expressions of Serial Manipulator Jacobians and their High-Order Derivatives based on Lie Theory," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7095-7100.
doi: 10.1109/ICRA40945.2020.9197131
keywords: {Jacobian matrices;Manipulators;Kinematics;Acceleration;Fasteners},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197131&isnumber=9196508

F. Mariƒá, M. Giamou, S. Khoubyarian, I. Petroviƒá and J. Kelly, "Inverse Kinematics for Serial Kinematic Chains via Sum of Squares Optimization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7101-7107.
doi: 10.1109/ICRA40945.2020.9196704
keywords: {Kinematics;Optimization;Conferences;Automation;Robots;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196704&isnumber=9196508

J. Marti-Saumell, A. Santamaria-Navarro, C. Ocampo-Martinez and J. Andrade-Cetto, "Multi-task closed-loop inverse kinematics stability through semidefinite programming," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7108-7114.
doi: 10.1109/ICRA40945.2020.9196750
keywords: {Task analysis;Stability analysis;Robots;Kinematics;Thermal stability;Numerical stability;Asymptotic stability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196750&isnumber=9196508

N. Benhabib, V. Padois and D. Daney, "Securing Industrial Operators with Collaborative Robots: Simulation and Experimental Validation for a Carpentry task," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7128-7134.
doi: 10.1109/ICRA40945.2020.9197161
keywords: {Task analysis;Cutting tools;Milling;Force;Service robots;Safety},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197161&isnumber=9196508

H. -G. Jeon, S. Im, J. Oh and M. Hebert, "Learning Shape-based Representation for Visual Localization in Extremely Changing Conditions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7135-7141.
doi: 10.1109/ICRA40945.2020.9196842
keywords: {Visualization;Shape;Cameras;Semantics;Robustness;Geometry;Buildings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196842&isnumber=9196508

H. Seo, C. Youngdong Son, D. Lee and H. Jin Kim, "Trajectory Planning with Safety Guaranty for a Multirotor based on the Forward and Backward Reachability Analysis," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7142-7148.
doi: 10.1109/ICRA40945.2020.9196760
keywords: {Trajectory;Planning;Safety;Reachability analysis;Robustness;Optimization;Aerospace engineering},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196760&isnumber=9196508

S. Bansal, A. Bajcsy, E. Ratner, A. D. Dragan and C. J. Tomlin, "A Hamilton-Jacobi Reachability-Based Framework for Predicting and Analyzing Human Motion for Safe Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7149-7155.
doi: 10.1109/ICRA40945.2020.9197257
keywords: {Predictive models;Robots;Stochastic processes;Planning;Data models;Computational modeling;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197257&isnumber=9196508

S. Eick and A. I. Ant√≥n, "Enhancing Privacy in Robotics via Judicious Sensor Selection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7156-7165.
doi: 10.1109/ICRA40945.2020.9196983
keywords: {Robot sensing systems;Privacy;Data privacy;Cameras;Task analysis;Law;privacy;privacy by design;robotics;robot design;sensor selection;compliance;privacy impact assessments},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196983&isnumber=9196508

S. Li and O. Bastani, "Robust Model Predictive Shielding for Safe Reinforcement Learning with Stochastic Dynamics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7166-7172.
doi: 10.1109/ICRA40945.2020.9196867
keywords: {Safety;Robustness;Stochastic processes;Robots;Trajectory;Nonlinear dynamical systems;Heuristic algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196867&isnumber=9196508

E. B. Ferreira Filho and L. C. A. Pimenta, "Segregation of Heterogeneous Swarms of Robots in Curves," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7173-7179.
doi: 10.1109/ICRA40945.2020.9196851
keywords: {Collision avoidance;Robot kinematics;Heuristic algorithms;Topology;Convergence;Damping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196851&isnumber=9196508

H. Wang and M. Rubenstein, "A Fast, Accurate, and Scalable Probabilistic Sample-Based Approach for Counting Swarm Size," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7180-7185.
doi: 10.1109/ICRA40945.2020.9196529
keywords: {Robots;Estimation;Shape;Task analysis;Heuristic algorithms;Random variables;Clocks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196529&isnumber=9196508

J. T. Ebert, M. Gauci, F. Mallmann-Trenn and R. Nagpal, "Bayes Bots: Collective Bayesian Decision-Making in Decentralized Robot Swarms," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7186-7192.
doi: 10.1109/ICRA40945.2020.9196584
keywords: {Robot sensing systems;Bayes methods;Decision making;Classification algorithms;Task analysis;Color},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196584&isnumber=9196508

Y. K. Lopes, S. M. Trenkwalder, A. B. Leal, T. J. Dodd and R. Gro√ü, "Supervisory Control of Robot Swarms Using Public Events," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7193-7199.
doi: 10.1109/ICRA40945.2020.9197418
keywords: {Collision avoidance;Robot sensing systems;Mobile robots;Generators;Supervisory control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197418&isnumber=9196508

B. Abbyasov, R. Lavrenov, A. Zakiev, K. Yakovlev, M. Svinin and E. Magid, "Automatic tool for Gazebo world construction: from a grayscale image to a 3D solid model," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7226-7232.
doi: 10.1109/ICRA40945.2020.9196621
keywords: {Tools;Solid modeling;Three-dimensional displays;Robot sensing systems;Gray-scale;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196621&isnumber=9196508

J. Cacace, N. Mimmo and L. Marconi, "A ROS Gazebo plugin to simulate ARVA sensors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7233-7239.
doi: 10.1109/ICRA40945.2020.9196914
keywords: {Receivers;Transmitters;Sensors;Electromagnetics;Antennas;Robots;Unmanned aerial vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196914&isnumber=9196508

H. Wu, D. Misra and G. S. Chirikjian, "Is That a Chair? Imagining Affordances Using Simulations of an Articulated Human Body," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7240-7246.
doi: 10.1109/ICRA40945.2020.9197384
keywords: {Robots;Solid modeling;Cognition;Physics;Three-dimensional displays;Data models;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197384&isnumber=9196508

S. Iqbal et al., "Toward Sim-to-Real Directional Semantic Grasping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7247-7253.
doi: 10.1109/ICRA40945.2020.9197310
keywords: {Grippers;Grasping;Cameras;Training;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197310&isnumber=9196508

C. Matl, Y. Narang, R. Bajcsy, F. Ramos and D. Fox, "Inferring the Material Properties of Granular Media for Robotic Tasks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 2770-2777.
doi: 10.1109/ICRA40945.2020.9197063
keywords: {Robots;Friction;Numerical models;Bayes methods;Material properties;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197063&isnumber=9196508

Z. Qin, K. Fang, Y. Zhu, L. Fei-Fei and S. Savarese, "KETO: Learning Keypoint Representations for Tool Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7278-7285.
doi: 10.1109/ICRA40945.2020.9196971
keywords: {Tools;Task analysis;Robots;Visualization;Force;Three-dimensional displays;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196971&isnumber=9196508

L. Yen-Chen, A. Zeng, S. Song, P. Isola and T. -Y. Lin, "Learning to See before Learning to Act: Visual Pre-training for Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7286-7293.
doi: 10.1109/ICRA40945.2020.9197331
keywords: {Task analysis;Robots;Visualization;Predictive models;Grasping;Head;Data models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197331&isnumber=9196508

F. von Drigalski et al., "Contact-based in-hand pose estimation using Bayesian state estimation and particle filtering," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7294-7299.
doi: 10.1109/ICRA40945.2020.9196640
keywords: {Pose estimation;Grippers;Collision avoidance;Robot kinematics;Tactile sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196640&isnumber=9196508

D. Park, Y. Seo, D. Shin, J. Choi and S. Y. Chun, "A Single Multi-Task Deep Neural Network with Post-Processing for Object Detection with Reasoning and Robotic Grasp Detection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7300-7306.
doi: 10.1109/ICRA40945.2020.9197179
keywords: {Robots;Grasping;Cognition;Task analysis;Neural networks;Grippers;Object detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197179&isnumber=9196508

Z. Hashemifar and K. Dantu, "Practical Persistence Reasoning in Visual SLAM," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7307-7313.
doi: 10.1109/ICRA40945.2020.9196913
keywords: {Simultaneous localization and mapping;Visualization;Estimation;Cognition;Probability;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196913&isnumber=9196508

T. Zhang, H. Zhang, Y. Li, Y. Nakamura and L. Zhang, "FlowFusion: Dynamic Dense RGB-D SLAM Based on Optical Flow," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7322-7328.
doi: 10.1109/ICRA40945.2020.9197349
keywords: {Cameras;Dynamics;Optical imaging;Simultaneous localization and mapping;Three-dimensional displays;Two dimensional displays;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197349&isnumber=9196508

R. Michelmore, M. Wicker, L. Laurenti, L. Cardelli, Y. Gal and M. Kwiatkowska, "Uncertainty Quantification with Statistical Guarantees in End-to-End Autonomous Driving Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7344-7350.
doi: 10.1109/ICRA40945.2020.9196844
keywords: {Uncertainty;Safety;Autonomous vehicles;Neural networks;Automobiles;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196844&isnumber=9196508

J. W. Kim et al., "Autonomously Navigating a Surgical Tool Inside the Eye by Learning from Demonstration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7351-7357.
doi: 10.1109/ICRA40945.2020.9196537
keywords: {Tools;Retina;Surgery;Navigation;Task analysis;Trajectory;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196537&isnumber=9196508

F. Fei, Z. Tu, D. Xu and X. Deng, "Learn-to-Recover: Retrofitting UAVs with Reinforcement Learning-Assisted Flight Control Under Cyber-Physical Attacks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7358-7364.
doi: 10.1109/ICRA40945.2020.9196611
keywords: {Actuators;Fault tolerance;Fault tolerant systems;Vehicle dynamics;Learning (artificial intelligence);Training;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196611&isnumber=9196508

T. Laidlow, J. Czarnowski, A. Nicastro, R. Clark and S. Leutenegger, "Towards the Probabilistic Fusion of Learned Priors into Standard Pipelines for 3D Reconstruction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7373-7379.
doi: 10.1109/ICRA40945.2020.9197001
keywords: {Standards;Probability distribution;Fuses;Image reconstruction;Three-dimensional displays;Uncertainty;Probability density function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197001&isnumber=9196508

T. Maki, M. Zhao, F. Shi, K. Okada and M. Inaba, "Model Reference Adaptive Control of Multirotor for Missions with Dynamic Change of Payloads During Flight," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7433-7439.
doi: 10.1109/ICRA40945.2020.9196861
keywords: {Attitude control;Adaptation models;Payloads;MIMO communication;Unmanned aerial vehicles;Adaptive control;Gravity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196861&isnumber=9196508

Y. Mulgaonkar, W. Liu, D. Thakur, K. Daniilidis, C. J. Taylor and V. Kumar, "The Tiercel: A novel autonomous micro aerial vehicle that can map the environment by flying into obstacles," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7448-7454.
doi: 10.1109/ICRA40945.2020.9197269
keywords: {Collision avoidance;Cameras;Robot vision systems;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197269&isnumber=9196508

T. Henderson and N. Papanikolopoulos, "Adaptive Control of Variable-Pitch Propellers: Pursuing Minimum-Effort Operation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7470-7476.
doi: 10.1109/ICRA40945.2020.9197208
keywords: {Propellers;Mathematical model;Servomotors;Geometry;Brushless DC motors;Blades},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197208&isnumber=9196508

A. Pore and G. Aragon-Camarasa, "On Simple Reactive Neural Networks for Behaviour-Based Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7477-7483.
doi: 10.1109/ICRA40945.2020.9197262
keywords: {Robots;Task analysis;Training;Computer architecture;Learning (artificial intelligence);Grasping;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197262&isnumber=9196508

A. Kusari and J. P. How, "Predicting optimal value functions by interpolating reward functions in scalarized multi-objective reinforcement learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7484-7490.
doi: 10.1109/ICRA40945.2020.9197456
keywords: {Interpolation;Training;Learning (artificial intelligence);Gaussian processes;Mathematical model;Random variables;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197456&isnumber=9196508

L. He, N. Aouf, J. F. Whidborne and B. Song, "Integrated moment-based LGMD and deep reinforcement learning for UAV obstacle avoidance," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7491-7497.
doi: 10.1109/ICRA40945.2020.9197152
keywords: {Navigation;Collision avoidance;Robustness;Lighting;Robots;Optical imaging;Machine learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197152&isnumber=9196508

T. A. Kessler Faulkner, E. Schaertl Short and A. L. Thomaz, "Interactive Reinforcement Learning with Inaccurate Feedback," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7498-7504.
doi: 10.1109/ICRA40945.2020.9197219
keywords: {Maintenance engineering;Robot sensing systems;Estimation;Task analysis;Learning (artificial intelligence);Computer science},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197219&isnumber=9196508

M. A. Lee et al., "Guided Uncertainty-Aware Policy Optimization: Combining Learning and Model-Based Strategies for Sample-Efficient Policy Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7505-7512.
doi: 10.1109/ICRA40945.2020.9197125
keywords: {Task analysis;Uncertainty;Robot sensing systems;Learning (artificial intelligence);Cameras;Switches},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197125&isnumber=9196508

M. A. Rana, D. Chen, J. Williams, V. Chu, S. R. Ahmadzadeh and S. Chernova, "Benchmark for Skill Learning from Demonstration: Impact of User Experience, Task Complexity, and Start Configuration on Performance," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7561-7567.
doi: 10.1109/ICRA40945.2020.9197470
keywords: {Task analysis;Robots;Trajectory;Videos;Pressing;Benchmark testing;Complexity theory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197470&isnumber=9196508

G. Lentini, G. Grioli, M. G. Catalano and A. Bicchi, "Robot Programming without Coding," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7576-7582.
doi: 10.1109/ICRA40945.2020.9196904
keywords: {Robots;Task analysis;Education;Trajectory;Programming;Three-dimensional displays;Impedance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196904&isnumber=9196508

G. Clark, J. Campbell, S. M. Rezayat Sorkhabadi, W. Zhang and H. B. Amor, "Predictive Modeling of Periodic Behavior for Human-Robot Symbiotic Walking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7599-7605.
doi: 10.1109/ICRA40945.2020.9196676
keywords: {Legged locomotion;Robot sensing systems;Biomechanics;Predictive models;Prosthetics;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196676&isnumber=9196508

J. Leclerc, H. Zhao, D. Z. Bao, A. T. Becker, M. Ghosn and D. J. Shah, "Agile 3D-Navigation of a Helical Magnetic Swimmer," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7638-7644.
doi: 10.1109/ICRA40945.2020.9197323
keywords: {Navigation;Trajectory;Heart;Blood;Valves;Frequency measurement;Turning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197323&isnumber=9196508

C. Cai, Y. S. Liang, N. Somani and W. Yan, "Inferring the Geometric Nullspace of Robot Skills from Human Demonstrations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7668-7675.
doi: 10.1109/ICRA40945.2020.9197174
keywords: {Task analysis;Manifolds;Adaptation models;Service robots;Grasping;Data models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197174&isnumber=9196508

N. Figueroa, S. Faraji, M. Koptev and A. Billard, "A Dynamical System Approach for Adaptive Grasping, Navigation and Co-Manipulation with Humanoid Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7676-7682.
doi: 10.1109/ICRA40945.2020.9197038
keywords: {Robot kinematics;Legged locomotion;Grasping;Task analysis;Humanoid robots;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197038&isnumber=9196508

F. Morbidi, "Subspace Projectors for State-Constrained Multi-Robot Consensus," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7705-7711.
doi: 10.1109/ICRA40945.2020.9196758
keywords: {Symmetric matrices;Eigenvalues and eigenfunctions;Protocols;Matrix decomposition;Laplace equations;Two dimensional displays;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196758&isnumber=9196508

C. Banks, S. Wilson, S. Coogan and M. Egerstedt, "Multi-Agent Task Allocation using Cross-Entropy Temporal Logic Optimization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7712-7718.
doi: 10.1109/ICRA40945.2020.9197066
keywords: {Task analysis;Automata;Cost function;Planning;Resource management;Switches},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197066&isnumber=9196508

Y. Emam, S. Mayya, G. Notomista, A. Bohannon and M. Egerstedt, "Adaptive Task Allocation for Heterogeneous Multi-Robot Teams with Evolving and Unknown Robot Capabilities," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7719-7725.
doi: 10.1109/ICRA40945.2020.9197283
keywords: {Task analysis;Resource management;Cost function;Mobile robots;Real-time systems;Minimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197283&isnumber=9196508

D. Mox, M. Calvo-Fullana, M. Gerasimenko, J. Fink, V. Kumar and A. Ribeiro, "Mobile Wireless Network Infrastructure on Demand," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7726-7732.
doi: 10.1109/ICRA40945.2020.9197460
keywords: {Task analysis;Ad hoc networks;Routing;Wireless networks;Hardware;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197460&isnumber=9196508

J. Liu and R. K. Williams, "Monitoring Over the Long Term: Intermittent Deployment and Sensing Strategies for Multi-Robot Teams," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7733-7739.
doi: 10.1109/ICRA40945.2020.9196826
keywords: {Robot sensing systems;Monitoring;Mutual information;Spatiotemporal phenomena;Kernel},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196826&isnumber=9196508

A. Benevento, M. Santos, G. Notarstefano, K. Paynabar, M. Bloch and M. Egerstedt, "Multi-Robot Coordination for Estimation and Coverage of Unknown Spatial Fields," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7740-7746.
doi: 10.1109/ICRA40945.2020.9197487
keywords: {Density functional theory;Estimation;Gaussian processes;Robot sensing systems;Prediction algorithms;Bayes methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197487&isnumber=9196508

M. Hamaya et al., "Learning Robotic Assembly Tasks with Lower Dimensional Systems by Leveraging Physical Softness and Environmental Constraints," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7747-7753.
doi: 10.1109/ICRA40945.2020.9197327
keywords: {Task analysis;Soft robotics;Aerospace electronics;Force;Robotic assembly;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197327&isnumber=9196508

J. Austin, R. Corrales-Fatou, S. Wyetzner and H. Lipson, "Titan: A Parallel Asynchronous Library for Multi-Agent and Soft-Body Robotics using NVIDIA CUDA," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7754-7760.
doi: 10.1109/ICRA40945.2020.9196808
keywords: {Graphics processing units;Robots;Libraries;Springs;Computational modeling;Kernel;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196808&isnumber=9196508

A. Sintov, A. Kimmel, K. E. Bekris and A. Boularias, "Motion Planning with Competency-Aware Transition Models for Underactuated Adaptive Hands," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7761-7767.
doi: 10.1109/ICRA40945.2020.9196564
keywords: {Data models;Planning;Predictive models;Adaptation models;Trajectory;Training;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196564&isnumber=9196508

M. Hasan et al., "Human-like Planning for Reaching in Cluttered Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7784-7790.
doi: 10.1109/ICRA40945.2020.9196665
keywords: {Task analysis;Planning;Robots;Testing;Feature extraction;Trajectory;Standards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196665&isnumber=9196508

S. Hun Cheong, B. Y. Cho, J. Lee, C. Kim and C. Nam, "Where to relocate?: Object rearrangement inside cluttered and confined environments for robotic manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7791-7797.
doi: 10.1109/ICRA40945.2020.9197485
keywords: {Planning;Manipulators;Collision avoidance;Task analysis;Clutter;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197485&isnumber=9196508

V. Thangavelu, M. S. da Silva, J. Choi and N. Napp, "Autonomous Modification of Unstructured Environments with Found Material," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7798-7804.
doi: 10.1109/ICRA40945.2020.9197372
keywords: {Uncertainty;Robot sensing systems;Physics;Shape;Buildings;physics simulation;autonomous construction;robotics;irregular building materials.},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197372&isnumber=9196508

J. Zhang, M. S. Ramanagopal, R. Vasudevan and M. Johnson-Roberson, "LiStereo: Generate Dense Depth Maps from LIDAR and Stereo Imagery," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7829-7836.
doi: 10.1109/ICRA40945.2020.9196628
keywords: {Laser radar;Task analysis;Training;Feature extraction;Estimation;Convolution;Correlation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196628&isnumber=9196508

A. Hardt-Stremayr and S. Weiss, "Monocular Visual-Inertial Odometry in Low-Textured Environments with Smooth Gradients: A Fully Dense Direct Filtering Approach," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7837-7843.
doi: 10.1109/ICRA40945.2020.9196881
keywords: {Cameras;Uncertainty;Estimation;Mathematical model;Motion estimation;Integrated circuits;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196881&isnumber=9196508

Y. Huang and Q. Huang, "Interaction Stability Analysis from the Input-Output Viewpoints," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7878-7884.
doi: 10.1109/ICRA40945.2020.9196643
keywords: {Impedance;Admittance;Robots;Force;Kinematics;Stability criteria},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196643&isnumber=9196508

D. Feliu-Talegon, R. Cortez-Vega and V. Feliu-Batlle, "Improving the contact instant detection of sensing antennae using a Super-Twisting algorithm," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7885-7890.
doi: 10.1109/ICRA40945.2020.9197107
keywords: {Antennas;Estimation;Vibrations;Robot sensing systems;Antenna measurements;Delays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197107&isnumber=9196508

J. Xu, M. Danielczuk, E. Steinbach and K. Goldberg, "6DFC: Efficiently Planning Soft Non-Planar Area Contact Grasps using 6D Friction Cones," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7891-7897.
doi: 10.1109/ICRA40945.2020.9197293
keywords: {Friction;Grippers;Three-dimensional displays;Force;Solid modeling;Computational modeling;Ellipsoids},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197293&isnumber=9196508

N. Fazeli, A. Ajay and A. Rodriguez, "Long-Horizon Prediction and Uncertainty Propagation with Residual Point Contact Learners," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7898-7904.
doi: 10.1109/ICRA40945.2020.9196511
keywords: {Predictive models;Analytical models;Uncertainty;Computational modeling;Trajectory;Dynamics;Stochastic processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196511&isnumber=9196508

G. Bellegarda and K. Byl, "Versatile Trajectory Optimization Using a LCP Wheel Model for Dynamic Vehicle Maneuvers," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7905-7911.
doi: 10.1109/ICRA40945.2020.9197541
keywords: {Vehicle dynamics;Wheels;Friction;Planning;Dynamics;Trajectory optimization;Tires},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197541&isnumber=9196508

H. M√∂ls, K. Li and U. D. Hanebeck, "Highly Parallelizable Plane Extraction for Organized Point Clouds Using Spherical Convex Hulls," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7920-7926.
doi: 10.1109/ICRA40945.2020.9197139
keywords: {Three-dimensional displays;Feature extraction;Robot sensing systems;Clustering algorithms;Real-time systems;Data mining},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197139&isnumber=9196508

J. Li, K. Koreitem, D. Meger and G. Dudek, "View-Invariant Loop Closure with Oriented Semantic Landmarks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7943-7949.
doi: 10.1109/ICRA40945.2020.9196886
keywords: {Cameras;Simultaneous localization and mapping;Semantics;Trajectory;Layout;Robustness;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196886&isnumber=9196508

G. Z√∂ller, V. Wall and O. Brock, "Active Acoustic Contact Sensing for Soft Pneumatic Actuators," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7966-7972.
doi: 10.1109/ICRA40945.2020.9196916
keywords: {Actuators;Robot sensing systems;Acoustics;Microphones;Acoustic measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196916&isnumber=9196508

J. H. Low, J. Y. Goh, N. Cheng, P. M. Khin, Q. Q. Han and C. H. Yeow, "A Bidirectional 3D-printed Soft Pneumatic Actuator and Graphite-based Flex Sensor for Versatile Grasping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 7979-7985.
doi: 10.1109/ICRA40945.2020.9196837
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196837&isnumber=9196508

B. Reily, Q. Zhu, C. Reardon and H. Zhang, "Simultaneous Learning from Human Pose and Object Cues for Real-Time Activity Recognition," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8006-8012.
doi: 10.1109/ICRA40945.2020.9196632
keywords: {Activity recognition;Real-time systems;Optimization;Object recognition;Feature extraction;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196632&isnumber=9196508

E. J. Hwang, B. Kyu Ahn, B. A. Macdonald and H. Seok Ahn, "Demonstration of Hospital Receptionist Robot with Extended Hybrid Code Network to Select Responses and Gestures," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8013-8018.
doi: 10.1109/ICRA40945.2020.9197160
keywords: {Task analysis;Robot sensing systems;Pipelines;Face detection;Recurrent neural networks;Speech recognition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197160&isnumber=9196508

C. Birmingham, Z. Hu, K. Mahajan, E. Reber and M. J. Matariƒá, "Can I Trust You? A User Study of Robot Mediation of a Support Group," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8019-8026.
doi: 10.1109/ICRA40945.2020.9196875
keywords: {Educational robots;Mediation;Sensitivity;Robot sensing systems;Atmospheric measurements;Particle measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196875&isnumber=9196508

J. D. Caporale, B. W. McInroe, C. Ning, T. Libby, R. J. Full and D. E. Koditschek, "Coronal Plane Spine Twisting Composes Shape To Adjust the Energy Landscape for Grounded Reorientation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8052-8058.
doi: 10.1109/ICRA40945.2020.9197026
keywords: {Shape;Kinematics;Potential energy;Hip;Torso;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197026&isnumber=9196508

M. Inazawa, T. Takemori, M. Tanaka and F. Matsuno, "Motion Design for a Snake Robot Negotiating Complicated Pipe Structures of a Constant Diameter," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8073-8079.
doi: 10.1109/ICRA40945.2020.9197224
keywords: {Snake robots;Windings;Shape;Robots;Junctions;Modeling;Pins},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197224&isnumber=9196508

J. De la Fuente, R. Shor and S. Larter, "Single Actuator Peristaltic Robot for Subsurface Exploration and Device Emplacement," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8096-8102.
doi: 10.1109/ICRA40945.2020.9196823
keywords: {Robots;Hydrocarbons;Soil;Reservoirs;Actuators;Oils;Asphalt},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196823&isnumber=9196508

S. A. Zimmermann, T. F. C. Berninger, J. Derkx and D. J. Rixen, "Dynamic modeling of robotic manipulators for accuracy evaluation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8144-8150.
doi: 10.1109/ICRA40945.2020.9197304
keywords: {Solid modeling;Manipulator dynamics;Mathematical model;Service robots;Finite element analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197304&isnumber=9196508

D. Agudelo-Espa√±a et al., "A Real-Robot Dataset for Assessing Transferability of Learned Dynamics Models," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8151-8157.
doi: 10.1109/ICRA40945.2020.9197392
keywords: {Trajectory;Robots;Artificial neural networks;Heuristic algorithms;Mathematical model;Torque measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197392&isnumber=9196508

P. Saha, A. Ali, B. A. Mudassar, Y. Long and S. Mukhopadhyay, "MagNet: Discovering Multi-agent Interaction Dynamics using Neural Network," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8158-8164.
doi: 10.1109/ICRA40945.2020.9196846
keywords: {Mathematical model;Magnetic cores;Multi-agent systems;Force;Training;Springs;Oscillators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196846&isnumber=9196508

H. Nguyen, N. Adrian, J. L. Xin Yan, J. M. Salfity, W. Allen and Q. -C. Pham, "Development of a Robotic System for Automated Decaking of 3D-Printed Parts," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8202-8208.
doi: 10.1109/ICRA40945.2020.9197110
keywords: {Powders;Cleaning;Service robots;Three-dimensional displays;Task analysis;Force control;deep learning;manipulation;system design;3D-printing;decaking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197110&isnumber=9196508

R. Xu, H. Liu, C. Liu, Z. Sun, T. L. Lam and H. Qian, "A Novel Solar Tracker Driven by Waves: From Idea to Implementation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8209-8214.
doi: 10.1109/ICRA40945.2020.9196998
keywords: {Solar panels;Brakes;Oceans;DC motors;Sun;Solar energy;Attitude control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196998&isnumber=9196508

J. Kim, J. Seo, S. Park, S. Han and J. Cho, "Design and Implementation of Hydraulic-Cable driven Manipulator for Disaster Response Operation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8215-8221.
doi: 10.1109/ICRA40945.2020.9196554
keywords: {Manipulators;Blades;Actuators;Hydraulic systems;Torque;Wires},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196554&isnumber=9196508

J. P. Yepez Placencia, D. A. Carnegie and J. W. Murphy, "Designs for an Expressive Mechatronic Chordophone," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8222-8228.
doi: 10.1109/ICRA40945.2020.9197255
keywords: {Mechatronics;Instruments;Music;Actuators;Robots;Prototypes;Solenoids},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197255&isnumber=9196508

J. Shen and D. Hong, "OmBURo: A Novel Unicycle Robot with Active Omnidirectional Wheel," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8237-8243.
doi: 10.1109/ICRA40945.2020.9196927
keywords: {Wheels;Mobile robots;Gears;Friction;Mathematical model;Energy loss},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196927&isnumber=9196508

E. Niehs et al., "Recognition and Reconfiguration of Lattice-Based Cellular Structures by Simple Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8252-8259.
doi: 10.1109/ICRA40945.2020.9196700
keywords: {Tiles;Robot sensing systems;Lattices;Shape;Autonomous robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196700&isnumber=9196508

C. Liu, S. Yu and M. Yim, "A Fast Configuration Space Algorithm for Variable Topology Truss Modular Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8260-8266.
doi: 10.1109/ICRA40945.2020.9196880
keywords: {Topology;Robots;Planning;Geometry;Shape;Kinematics;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196880&isnumber=9196508

B. Gabrich, G. Li and M. Yim, "ModQuad-DoF: A Novel Yaw Actuation for Modular Quadrotors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8267-8273.
doi: 10.1109/ICRA40945.2020.9196735
keywords: {Automation;Propellers;Attitude control;Conferences;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196735&isnumber=9196508

M. Yao, X. Xiao, Y. Tian, H. Cui and J. Paik, "An Actuation Fault Tolerance Approach to Reconfiguration Planning of Modular Self-folding Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8274-8280.
doi: 10.1109/ICRA40945.2020.9196574
keywords: {Fault tolerance;Fault tolerant systems;Robots;Three-dimensional displays;Circuit faults;Shape;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196574&isnumber=9196508

H. Kawano, "Parallel Permutation for Linear Full-resolution Reconfiguration of Heterogeneous Sliding-only Cubic Modular Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8281-8287.
doi: 10.1109/ICRA40945.2020.9197033
keywords: {Navigation;Hardware;Robot kinematics;Shape;Cameras;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197033&isnumber=9196508

J. Kallwies, B. Forkel and H. -J. Wuensche, "Determining and Improving the Localization Accuracy of AprilTag Detection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8288-8294.
doi: 10.1109/ICRA40945.2020.9197427
keywords: {Cameras;C++ languages;Libraries;Robot vision systems;Calibration;Image edge detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197427&isnumber=9196508

F. Bai, "Change of Optimal Values: A Pre-calculated Metric," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8295-8301.
doi: 10.1109/ICRA40945.2020.9197163
keywords: {Optimization;Measurement;Manifolds;Mathematical model;Robots;Covariance matrices;Gaussian distribution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197163&isnumber=9196508

S. Scheideman, N. Ray and H. Zhang, "A Flexible Method for Performance Evaluation of Robot Localization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8302-8308.
doi: 10.1109/ICRA40945.2020.9197275
keywords: {Simultaneous localization and mapping;Navigation;Cameras;Performance evaluation;Robot localization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197275&isnumber=9196508

P. Stankiewicz, M. Heistand and M. Kobilarov, "Quantifying Good Seamanship For Autonomous Surface Vessel Performance Evaluation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8309-8315.
doi: 10.1109/ICRA40945.2020.9197572
keywords: {Marine vehicles;Safety;Geometry;Decision making;Navigation;Risk management;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197572&isnumber=9196508

M. S. Nunes, A. Dehban, P. Moreno and J. Santos-Victor, "Action-conditioned Benchmarking of Robotic Video Prediction Models: a Comparative Study," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8316-8322.
doi: 10.1109/ICRA40945.2020.9196839
keywords: {Predictive models;Measurement;Visualization;Stochastic processes;Planning;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196839&isnumber=9196508

Z. Zhuang, X. Yu and R. Mahony, "LyRN (Lyapunov Reaching Network): A Real-Time Closed Loop approach from Monocular Vision," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8331-8337.
doi: 10.1109/ICRA40945.2020.9196781
keywords: {Lyapunov methods;Grasping;Feature extraction;Computer architecture;Task analysis;Pose estimation;Velocity control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196781&isnumber=9196508

T. Novkovic, R. Pautrat, F. Furrer, M. Breyer, R. Siegwart and J. Nieto, "Object Finding in Cluttered Scenes Using Interactive Perception," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8338-8344.
doi: 10.1109/ICRA40945.2020.9197101
keywords: {Cameras;Task analysis;Robot sensing systems;Search problems;Clutter;Detectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197101&isnumber=9196508

J. Cai, X. Tao, H. Cheng and Z. Zhang, "CCAN: Constraint Co-Attention Network for Instance Grasping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8353-8359.
doi: 10.1109/ICRA40945.2020.9197182
keywords: {Feature extraction;Grasping;Training;Task analysis;Robots;Data mining;Correlation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197182&isnumber=9196508

X. Guo et al., "3D Object Detection and Tracking Based on Streaming Data," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8376-8382.
doi: 10.1109/ICRA40945.2020.9197183
keywords: {Three-dimensional displays;Feature extraction;Proposals;Object detection;Prediction algorithms;Correlation;Agriculture},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197183&isnumber=9196508

A. D. Pon, J. Ku, C. Li and S. L. Waslander, "Object-Centric Stereo Matching for 3D Object Detection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8383-8389.
doi: 10.1109/ICRA40945.2020.9196660
keywords: {Three-dimensional displays;Object detection;Two dimensional displays;Laser radar;Detectors;Cameras;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196660&isnumber=9196508

A. Balasch, M. Beinhofer and G. Zauner, "The Relative Confusion Matrix, a Tool to Assess Classifiablility in Large Scale Picking Applications," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8390-8396.
doi: 10.1109/ICRA40945.2020.9197540
keywords: {Robots;Measurement;Task analysis;Reliability;Tools;Logistics;Workstations},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197540&isnumber=9196508

Z. Li and X. Ji, "Pose-guided Auto-Encoder and Feature-Based Refinement for 6-DoF Object Pose Regression," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8397-8403.
doi: 10.1109/ICRA40945.2020.9196953
keywords: {Feature extraction;Pose estimation;Three-dimensional displays;Training;Rendering (computer graphics);Image reconstruction;Decoding},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196953&isnumber=9196508

C. Sommer, Y. Sun, E. Bylow and D. Cremers, "PrimiTect: Fast Continuous Hough Voting for Primitive Detection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8404-8410.
doi: 10.1109/ICRA40945.2020.9196988
keywords: {Three-dimensional displays;Feature extraction;Interpolation;Two dimensional displays;Transforms;Computational modeling;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196988&isnumber=9196508

Z. Zhang and K. Zhang, "FarSee-Net: Real-Time Semantic Segmentation by Efficient Multi-scale Context Aggregation and Feature Space Super-resolution," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8411-8417.
doi: 10.1109/ICRA40945.2020.9196599
keywords: {Semantics;Convolution;Image segmentation;Feature extraction;Real-time systems;Spatial resolution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196599&isnumber=9196508

C. Li, Y. Meng, S. H. Chan and Y. -T. Chen, "Learning 3D-aware Egocentric Spatial-Temporal Interaction via Graph Convolutional Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8418-8424.
doi: 10.1109/ICRA40945.2020.9197057
keywords: {Feature extraction;Three-dimensional displays;Roads;Hidden Markov models;Vehicles;Two dimensional displays;Convolution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197057&isnumber=9196508

T. Kim and J. -H. Lee, "C-3PO: Cyclic-Three-Phase Optimization for Human-Robot Motion Retargeting based on Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8425-8432.
doi: 10.1109/ICRA40945.2020.9196948
keywords: {Skeleton;Robot motion;Robot kinematics;Kinematics;Zirconium;Torso},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196948&isnumber=9196508

M. Islam, V. S. Vibashan and H. Ren, "AP-MTL: Attention Pruned Multi-task Learning Model for Real-time Instrument Detection and Segmentation in Robot-assisted Surgery," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8433-8439.
doi: 10.1109/ICRA40945.2020.9196905
keywords: {Task analysis;Instruments;Decoding;Real-time systems;Computational modeling;Optimization;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196905&isnumber=9196508

X. Gao, Y. Jin, Q. Dou and P. -A. Heng, "Automatic Gesture Recognition in Robot-assisted Surgery with Reinforcement Learning and Tree Search," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8440-8446.
doi: 10.1109/ICRA40945.2020.9196674
keywords: {Surgery;Gesture recognition;Robots;Hidden Markov models;Learning (artificial intelligence);Feature extraction;Task analysis;Surgical gesture recognition;Deep reinforcement learning in robotics;Tree search;Robotic surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196674&isnumber=9196508

X. -Y. Zhou, J. -Q. Zheng, P. Li and G. -Z. Yang, "ACNN: a Full Resolution DCNN for Medical Image Segmentation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8455-8461.
doi: 10.1109/ICRA40945.2020.9197328
keywords: {Image segmentation;Convolution;Biomedical imaging;Image resolution;Convolutional neural networks;Three-dimensional displays;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197328&isnumber=9196508

Y. Wang, S. Nalluri and M. Pajic, "Hyperproperties for Robotics: Planning via HyperLTL," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8462-8468.
doi: 10.1109/ICRA40945.2020.9196874
keywords: {Planning;Robustness;Privacy;Automata;Model checking;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196874&isnumber=9196508

Y. Zhang and D. A. Shell, "Abstractions for computing all robotic sensors that suffice to solve a planning problem," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8469-8475.
doi: 10.1109/ICRA40945.2020.9196812
keywords: {Robot sensing systems;Planning;Sensor phenomena and characterization;Uncertainty;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196812&isnumber=9196508

D. Khalidi, D. Gujarathi and I. Saha, "T: A Heuristic Search Based Path Planning Algorithm for Temporal Logic Specifications," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8476-8482.
doi: 10.1109/ICRA40945.2020.9196928
keywords: {Automata;Heuristic algorithms;Trajectory;Task analysis;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196928&isnumber=9196508

N. Sayols et al., "Global/local motion planning based on Dynamic Trajectory Reconfiguration and Dynamical Systems for Autonomous Surgical Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8483-8489.
doi: 10.1109/ICRA40945.2020.9197525
keywords: {Trajectory;Tools;Robots;Collision avoidance;Task analysis;Surgery;Splines (mathematics)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197525&isnumber=9196508

Q. Gao, M. Pajic and M. M. Zavlanos, "Deep Imitative Reinforcement Learning for Temporal Logic Robot Motion Planning with Noisy Semantic Observations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8490-8496.
doi: 10.1109/ICRA40945.2020.9197297
keywords: {Robot sensing systems;Labeling;Uncertainty;Semantics;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197297&isnumber=9196508

P. V√°≈àa, A. Alves Neto, J. Faigl and D. G. Macharet, "Minimal 3D Dubins Path with Bounded Curvature and Pitch Angle," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8497-8503.
doi: 10.1109/ICRA40945.2020.9197084
keywords: {Three-dimensional displays;Two dimensional displays;Turning;Path planning;Atmospheric modeling;Space vehicles;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197084&isnumber=9196508

I. Bozcan and E. Kayacan, "AU-AIR: A Multi-modal Unmanned Aerial Vehicle Dataset for Low Altitude Traffic Surveillance," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8504-8510.
doi: 10.1109/ICRA40945.2020.9196845
keywords: {Object detection;Videos;Visualization;Cameras;Detectors;Surveillance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196845&isnumber=9196508

A. Bouman et al., "Design and Autonomous Stabilization of a Ballistically-Launched Multirotor," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8511-8517.
doi: 10.1109/ICRA40945.2020.9197542
keywords: {SQUIDs;Electron tubes;Aerodynamics;Drones;Prototypes;Thermal stability;Aircraft},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197542&isnumber=9196508

J. P. Rodr√≠guez-Gomez, A. G. Egu√≠luz, J. R. Mart√≠nez-de Dios and A. Ollero, "Asynchronous event-based clustering and tracking for intrusion monitoring in UAS," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8518-8524.
doi: 10.1109/ICRA40945.2020.9197341
keywords: {Cameras;Robot vision systems;Tracking;Surveillance;Robustness;event camera;asynchronous;intrusion monitoring;surveillance;UAS;clustering;feature tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197341&isnumber=9196508

M. Ng, E. Tang, G. S. Soh and S. Foong, "SHIFT: Selective Heading Image for Translation An onboard monocular optical flow estimator for fast constantly rotating UAVs," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8525-8531.
doi: 10.1109/ICRA40945.2020.9197073
keywords: {Cameras;Optical imaging;Optical sensors;Adaptive optics;Optical filters;Tracking;Integrated optics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197073&isnumber=9196508

C. H. Tan, D. Sufiyan bin Shaiful, E. Tang, J. -Y. Khaw, G. S. Soh and S. Foong, "Flydar: Magnetometer-based High Angular Rate Estimation during Gyro Saturation for SLAM," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8532-8537.
doi: 10.1109/ICRA40945.2020.9197486
keywords: {Robots;Magnetometers;Sensors;Estimation;Frequency measurement;Saturation magnetization;Angular velocity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197486&isnumber=9196508

D. Tzoumanikas, Q. Yan and S. Leutenegger, "Nonlinear MPC with Motor Failure Identification and Recovery for Safe and Aggressive Multicopter Flight," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8538-8544.
doi: 10.1109/ICRA40945.2020.9196690
keywords: {Actuators;Resource management;Propellers;Aerodynamics;Quaternions;Angular velocity;Vehicle dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196690&isnumber=9196508

G. Guarino, T. Chateau, C. Teuli√®re and V. Antoine, "Temporal information integration for video semantic segmentation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8545-8551.
doi: 10.1109/ICRA40945.2020.9197204
keywords: {Optical imaging;Image segmentation;Semantics;Adaptive optics;Optical filters;Bayes methods;Optical fiber networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197204&isnumber=9196508

A. Elhafsi, B. Ivanovic, L. Janson and M. Pavone, "Map-Predictive Motion Planning in Unknown Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8552-8558.
doi: 10.1109/ICRA40945.2020.9197522
keywords: {Robots;Trajectory;Planning;Navigation;Collision avoidance;Safety;Cognition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197522&isnumber=9196508

X. Wu and M. W. Mueller, "Using multiple short hops for multicopter navigation with only inertial sensors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8559-8565.
doi: 10.1109/ICRA40945.2020.9196610
keywords: {State estimation;Gyroscopes;Sensors;Inertial navigation;Accelerometers;Measurement uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196610&isnumber=9196508

T. Henderson, V. Sze and S. Karaman, "An Efficient and Continuous Approach to Information-Theoretic Exploration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8566-8572.
doi: 10.1109/ICRA40945.2020.9196592
keywords: {Robot sensing systems;Mutual information;Distortion measurement;Gain measurement;Time measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196592&isnumber=9196508

D. Cagara, M. Dunbabin and P. Rigby, "A Feature-Based Underwater Path Planning Approach using Multiple Perspective Prior Maps," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8573-8579.
doi: 10.1109/ICRA40945.2020.9196680
keywords: {Navigation;Cameras;Sensors;Uncertainty;Image segmentation;Feature extraction;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196680&isnumber=9196508

T. T√≥th, Z. Pusztai and L. Hajder, "Automatic LiDAR-Camera Calibration of Extrinsic Parameters Using a Spherical Target," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8580-8586.
doi: 10.1109/ICRA40945.2020.9197316
keywords: {Cameras;Calibration;Laser radar;Three-dimensional displays;Estimation;Mathematical model;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197316&isnumber=9196508

M. Schreiber, V. Belagiannis, C. Gl√§ser and K. Dietmayer, "Motion Estimation in Occupancy Grid Maps in Stationary Settings Using Recurrent Neural Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8587-8593.
doi: 10.1109/ICRA40945.2020.9196702
keywords: {Computer architecture;Microprocessors;Vehicle dynamics;Measurement by laser beam;Time measurement;Recurrent neural networks;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196702&isnumber=9196508

H. B√ºlow, C. A. Mueller, A. Gomez Chavez, F. Buda and A. Birk, "A Divide and Conquer Method for 3D Registration of Inhomogeneous, Partially Overlapping Scans with Fourier Mellin SOFT (FMS)," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8594-8601.
doi: 10.1109/ICRA40945.2020.9197453
keywords: {Three-dimensional displays;Frequency modulation;Robustness;Underwater vehicles;Two dimensional displays;Cultural differences;Nonhomogeneous media},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197453&isnumber=9196508

F. A. Maken, F. Ramos and L. Ott, "Estimating Motion Uncertainty with Bayesian ICP," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8602-8608.
doi: 10.1109/ICRA40945.2020.9197085
keywords: {Iterative closest point algorithm;Uncertainty;Bayes methods;Three-dimensional displays;Robot sensing systems;Standards;Stochastic processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197085&isnumber=9196508

Y. Wang, M. Ramezani and M. Fallon, "Actively Mapping Industrial Structures with Information Gain-Based Planning on a Quadruped Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8609-8615.
doi: 10.1109/ICRA40945.2020.9197153
keywords: {Robot sensing systems;Service robots;Solid modeling;Planning;Laser radar},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197153&isnumber=9196508

Z. Ye, G. Zhang and H. Bao, "Efficient Covisibility-based Image Matching for Large-Scale SfM," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8616-8622.
doi: 10.1109/ICRA40945.2020.9197383
keywords: {Three-dimensional displays;Vocabulary;Image reconstruction;Image retrieval;Feature extraction;Robustness;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197383&isnumber=9196508

H. Kim and B. Lee, "Probabilistic TSDF Fusion Using Bayesian Deep Learning for Dense 3D Reconstruction with a Single RGB Camera," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8623-8629.
doi: 10.1109/ICRA40945.2020.9196663
keywords: {Uncertainty;Three-dimensional displays;Probabilistic logic;Bayes methods;Predictive models;Cameras;Machine learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196663&isnumber=9196508

P. -H. Chen, Z. -X. Luo, Z. -K. Huang, C. Yang and K. -W. Chen, "IF-Net: An Illumination-invariant Feature Network," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8630-8636.
doi: 10.1109/ICRA40945.2020.9196893
keywords: {Lighting;Training;Measurement;Benchmark testing;Training data;Schedules;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196893&isnumber=9196508

Y. Hu, W. Zhen and S. Scherer, "Deep-Learning Assisted High-Resolution Binocular Stereo Depth Reconstruction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8637-8643.
doi: 10.1109/ICRA40945.2020.9196655
keywords: {Uncertainty;Predictive models;Image reconstruction;Proposals;Computational modeling;Image resolution;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196655&isnumber=9196508

L. Hajder and D. Barath, "Least-squares Optimal Relative Planar Motion for Vehicle-mounted Cameras," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8644-8650.
doi: 10.1109/ICRA40945.2020.9196755
keywords: {Cameras;Transmission line matrix methods;Robot vision systems;Estimation;Automobiles;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196755&isnumber=9196508

L. Hajder and D. Barath, "Relative planar motion for vehicle-mounted cameras from a single affine correspondence," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8651-8657.
doi: 10.1109/ICRA40945.2020.9197438
keywords: {Cameras;Transmission line matrix methods;Mathematical model;Estimation;Geometry;Robot vision systems;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197438&isnumber=9196508

H. Kim, P. Kim and H. J. Kim, "Moving object detection for visual odometry in a dynamic environment based on occlusion accumulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8658-8664.
doi: 10.1109/ICRA40945.2020.9196767
keywords: {Cameras;Heuristic algorithms;Object detection;Robustness;Trajectory;Visual odometry;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196767&isnumber=9196508

S. Leonardos, X. Zhou and K. Daniilidis, "A Low-Rank Matrix Approximation Approach to Multiway Matching with Applications in Multi-Sensory Data Association," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8665-8671.
doi: 10.1109/ICRA40945.2020.9196583
keywords: {Convex functions;Optimization;Manifolds;Xenon;Approximation algorithms;Clustering algorithms;Noise measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196583&isnumber=9196508

A. Munawar, N. Srishankar, L. Fichera and G. S. Fischer, "A Parametric Grasping Methodology for Multi-Manual Interactions in Real-Time Dynamic Simulations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8712-8718.
doi: 10.1109/ICRA40945.2020.9197099
keywords: {Friction;Grasping;Force;Sensors;Computational modeling;Mathematical model;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197099&isnumber=9196508

A. Smyrli and E. Papadopoulos, "A methodology for the incorporation of arbitrarily-shaped feet in passive bipedal walking dynamics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8719-8725.
doi: 10.1109/ICRA40945.2020.9196617
keywords: {Foot;Legged locomotion;Shape;Geometry;Mathematical model;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196617&isnumber=9196508

T. F. C. Berninger, F. Sygulla, S. Fuderer and D. J. Rixen, "Experimental Analysis of Structural Vibration Problems of a Biped Walking Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8726-8731.
doi: 10.1109/ICRA40945.2020.9197282
keywords: {Legged locomotion;Robot sensing systems;Foot;Gears;Harmonic analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197282&isnumber=9196508

M. Fevre and J. P. Schmiedeler, "Dynamic Coupling as an Indicator of Gait Robustness for Underactuated Biped Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8732-8738.
doi: 10.1109/ICRA40945.2020.9197203
keywords: {Couplings;Mathematical model;Legged locomotion;Aerodynamics;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197203&isnumber=9196508

F. M. Smaldone, N. Scianca, V. Modugno, L. Lanari and G. Oriolo, "ZMP Constraint Restriction for Robust Gait Generation in Humanoids," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8739-8745.
doi: 10.1109/ICRA40945.2020.9197171
keywords: {Humanoid robots;Lips;Robustness;Stability criteria;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197171&isnumber=9196508

G. A. Castillo, B. Weng, W. Zhang and A. Hereid, "Hybrid Zero Dynamics Inspired Feedback Control Policy Design for 3D Bipedal Locomotion using Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8746-8752.
doi: 10.1109/ICRA40945.2020.9197175
keywords: {Legged locomotion;Three-dimensional displays;Trajectory;Robustness;Torso;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197175&isnumber=9196508

Y. -M. Chen and M. Posa, "Optimal Reduced-order Modeling of Bipedal Locomotion," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8753-8760.
doi: 10.1109/ICRA40945.2020.9197004
keywords: {Task analysis;Legged locomotion;Reduced order systems;Lips;Trajectory optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197004&isnumber=9196508

B. Ramtoula, R. de Azambuja and G. Beltrame, "CAPRICORN: Communication Aware Place Recognition using Interpretable Constellations of Objects in Robot Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8761-8768.
doi: 10.1109/ICRA40945.2020.9197270
keywords: {Semantics;Three-dimensional displays;Simultaneous localization and mapping;Robustness;Visualization;Bandwidth},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197270&isnumber=9196508

A. Desai and N. Michael, "Online Planning for Quadrotor Teams in 3-D Workspaces via Reachability Analysis On Invariant Geometric Trees," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8769-8775.
doi: 10.1109/ICRA40945.2020.9197195
keywords: {Collision avoidance;Planning;Robot kinematics;Vegetation;Trajectory;Reachability analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197195&isnumber=9196508

H. Xu, L. Wang, Y. Zhang, K. Qiu and S. Shen, "Decentralized Visual-Inertial-UWB Fusion for Relative State Estimation of Aerial Swarm," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8776-8782.
doi: 10.1109/ICRA40945.2020.9196944
keywords: {Drones;State estimation;Cameras;Sensors;Global Positioning System;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196944&isnumber=9196508

M. Whitzer, D. Shishika, D. Thakur, V. Kumar and A. Prorok, "DC-CAPT: Concurrent Assignment and Planning of Trajectories for Dubins Cars," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8791-8797.
doi: 10.1109/ICRA40945.2020.9196799
keywords: {Automobiles;Collision avoidance;Robots;Trajectory;Planning;Turning;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196799&isnumber=9196508

M. Beglini, L. Lanari and G. Oriolo, "Anti-Jackknifing Control of Tractor-Trailer Vehicles via Intrinsically Stable MPC," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8806-8812.
doi: 10.1109/ICRA40945.2020.9197012
keywords: {Trajectory;Agricultural machinery;Computational modeling;Vehicle dynamics;Tracking;Dynamics;Linear approximation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197012&isnumber=9196508

O. Ljungqvist, D. Axehill and H. Pettersson, "On sensing-aware model predictive path-following control for a reversing general 2-trailer with a car-like tractor," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8813-8819.
doi: 10.1109/ICRA40945.2020.9197346
keywords: {Agricultural machinery;Axles;Sensors;Kinematics;Reliability;Estimation;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197346&isnumber=9196508

L. Cheng, J. Huang, L. Liu, Z. Jian, Y. Huang and K. Huang, "Offline Practising and Runtime Training Framework for Autonomous Motion Control of Snake Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8820-8826.
doi: 10.1109/ICRA40945.2020.9196637
keywords: {Robots;Snake robots;Runtime;Training;Entropy;Motion control;Linear regression},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196637&isnumber=9196508

D. Pazderski and K. Koz≈Çowski, "Control of a differentially driven nonholonomic robot subject to a restricted wheels rotation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8827-8832.
doi: 10.1109/ICRA40945.2020.9196519
keywords: {Wheels;Mobile robots;Kinematics;Task analysis;Manifolds;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196519&isnumber=9196508

N. D. Kent, R. M. Bhirangi, M. Travers and T. M. Howard, "Inferring Task-Space Central Pattern Generator Parameters for Closed-loop Control of Underactuated Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8833-8839.
doi: 10.1109/ICRA40945.2020.9196957
keywords: {Mathematical model;Robot kinematics;Adaptation models;Probability distribution;Oscillators;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196957&isnumber=9196508

S. Cruciani, H. Yin and D. Kragic, "In-Hand Manipulation of Objects with Unknown Shapes," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8848-8854.
doi: 10.1109/ICRA40945.2020.9197273
keywords: {Shape;Grippers;Three-dimensional displays;Task analysis;Planning;Robots;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197273&isnumber=9196508

T. Li, K. Srinivasan, M. Q. -H. Meng, W. Yuan and J. Bohg, "Learning Hierarchical Control for Robust In-Hand Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8855-8862.
doi: 10.1109/ICRA40945.2020.9197343
keywords: {Robustness;Task analysis;Force;Robot kinematics;Torque;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197343&isnumber=9196508

F. R. Hogan, J. Ballester, S. Dong and A. Rodriguez, "Tactile Dexterity: Manipulation Primitives with Tactile Feedback," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8863-8869.
doi: 10.1109/ICRA40945.2020.9196976
keywords: {Tactile sensors;Trajectory;Force;Friction;Perturbation methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196976&isnumber=9196508

S. Yuan, A. D. Epps, J. B. Nowak and J. K. Salisbury, "Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8870-8876.
doi: 10.1109/ICRA40945.2020.9197146
keywords: {Grasping;Prototypes;Kinematics;Task analysis;Robot sensing systems;Thumb},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197146&isnumber=9196508

F. Monet et al., "High-Resolution Optical Fiber Shape Sensing of Continuum Robots: A Comparative Study," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8877-8883.
doi: 10.1109/ICRA40945.2020.9197454
keywords: {Shape;Fiber gratings;Optical sensors;Robot sensing systems;Spatial resolution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197454&isnumber=9196508

W. Han and R. Tedrake, "Local Trajectory Stabilization for Dexterous Manipulation via Piecewise Affine Approximations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8884-8891.
doi: 10.1109/ICRA40945.2020.9196824
keywords: {Trajectory optimization;Manipulator dynamics;Task analysis;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196824&isnumber=9196508

H. Ye, H. Huang and M. Liu, "Monocular Direct Sparse Localization in a Prior 3D Surfel Map," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8892-8898.
doi: 10.1109/ICRA40945.2020.9197022
keywords: {Cameras;Laser radar;Three-dimensional displays;Visualization;Rendering (computer graphics);Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197022&isnumber=9196508

C. Qin, H. Ye, C. E. Pranata, J. Han, S. Zhang and M. Liu, "LINS: A Lidar-Inertial State Estimator for Robust and Efficient Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8899-8906.
doi: 10.1109/ICRA40945.2020.9197567
keywords: {Feature extraction;Laser radar;Three-dimensional displays;Kalman filters;Real-time systems;Optimization;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197567&isnumber=9196508

H. Madhusudanan et al., "Automated Eye-in-Hand Robot-3D Scanner Calibration for Low Stitching Errors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8906-8912.
doi: 10.1109/ICRA40945.2020.9196748
keywords: {Calibration;DH-HEMTs;Robot kinematics;Three-dimensional displays;Kinematics;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196748&isnumber=9196508

H. Huang, H. Ye, Y. Sun and M. Liu, "Monocular Visual Odometry using Learned Repeatability and Description," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8913-8919.
doi: 10.1109/ICRA40945.2020.9197406
keywords: {Cameras;Feature extraction;Two dimensional displays;Robustness;Pose estimation;Three-dimensional displays;Visual odometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197406&isnumber=9196508

Z. Zhang, A. Tawari, S. Martin and D. Crandall, "Interaction Graphs for Object Importance Estimation in On-road Driving Videos," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8920-8927.
doi: 10.1109/ICRA40945.2020.9197104
keywords: {Feature extraction;Automobiles;Videos;Convolution;Estimation;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197104&isnumber=9196508

S. Akhtar, A. Tandiya, M. Moussa and C. Tarry, "A Robotics Inspection System for Detecting Defects on Semi-specular Painted Automotive Surfaces," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8928-8934.
doi: 10.1109/ICRA40945.2020.9196980
keywords: {Inspection;Surface treatment;Cameras;Surface topography;Robots;Automobiles;Surface reconstruction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196980&isnumber=9196508

C. Mucchiani and M. Yim, "A Novel Underactuated End-Effector for Planar Sequential Grasping of Multiple Objects," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8935-8941.
doi: 10.1109/ICRA40945.2020.9197380
keywords: {Force;Grasping;Sensors;Estimation;Shape;Fasteners;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197380&isnumber=9196508

W. Chen, Z. Xiao, J. Lu, Z. Zhao and Y. Wang, "Design and Analysis of a Synergy-Inspired Three-Fingered Hand," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8942-8948.
doi: 10.1109/ICRA40945.2020.9196901
keywords: {Thumb;Robots;Joints;Muscles;Grasping;Electronics packaging},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196901&isnumber=9196508

L. Chin, F. Barscevicius, J. Lipton and D. Rus, "Multiplexed Manipulation: Versatile Multimodal Grasping via a Hybrid Soft Gripper," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8949-8955.
doi: 10.1109/ICRA40945.2020.9196626
keywords: {Grasping;Grippers;Multiplexing;Force;Belts;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196626&isnumber=9196508

D. Hirano, N. Tanishima, A. Bylard and T. G. Chen, "Underactuated Gecko Adhesive Gripper for Simple and Versatile Grasp," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8964-8969.
doi: 10.1109/ICRA40945.2020.9196806
keywords: {Grippers;Force;Grasping;Pulleys;Adhesives;Actuators;Tendons},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196806&isnumber=9196508

R. Lagneau, A. Krupa and M. Marchal, "Active Deformation through Visual Servoing of Soft Objects," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8978-8984.
doi: 10.1109/ICRA40945.2020.9197506
keywords: {Strain;Jacobian matrices;Deformable models;Shape;Task analysis;Adaptation models;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197506&isnumber=9196508

J. Jin, L. Petrich, Z. Zhang, M. Dehghan and M. Jagersand, "Visual Geometric Skill Inference by Watching Human Demonstration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 8985-8991.
doi: 10.1109/ICRA40945.2020.9196570
keywords: {Task analysis;Kernel;Robustness;Feature extraction;Robot kinematics;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196570&isnumber=9196508

Y. V. S. Harish, H. Pandya, A. Gaud, S. Terupally, S. Shankar and K. M. Krishna, "DFVS: Deep Flow Guided Scene Agnostic Image Based Visual Servoing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9000-9006.
doi: 10.1109/ICRA40945.2020.9196753
keywords: {Visual servoing;Cameras;Convergence;Visualization;Adaptive optics;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196753&isnumber=9196508

E. A. Rodr√≠guez Mart√≠nez, G. Caron, C. P√©gard and D. L. Alabazares, "Photometric Path Planning for Vision-Based Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9007-9013.
doi: 10.1109/ICRA40945.2020.9197091
keywords: {Visualization;Navigation;Cameras;Visual servoing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197091&isnumber=9196508

A. Paolillo, T. S. Lembono and S. Calinon, "A memory of motion for visual predictive control tasks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9014-9020.
doi: 10.1109/ICRA40945.2020.9197216
keywords: {Visualization;Microsoft Windows;Trajectory;Optimization;Task analysis;Computational modeling;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197216&isnumber=9196508

A. B. Clark and N. Rojas, "Design and Workspace Characterisation of Malleable Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9021-9027.
doi: 10.1109/ICRA40945.2020.9197439
keywords: {End effectors;Robot kinematics;Task analysis;Mathematical model;Topology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197439&isnumber=9196508

A. K. Nguyen et al., "A Tri-Stable Soft Robotic Finger Capable of Pinch and Wrap Grasps," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9028-9034.
doi: 10.1109/ICRA40945.2020.9196818
keywords: {Grippers;Springs;Shape;Soft robotics;Grasping;Force;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196818&isnumber=9196508

S. Wang, R. Zhang, D. A. Haggerty, N. D. Naclerio and E. W. Hawkes, "A Dexterous Tip-extending Robot with Variable-length Shape-locking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9035-9041.
doi: 10.1109/ICRA40945.2020.9197311
keywords: {Electron tubes;Tendons;Shape;Educational robots;Manipulators;Pneumatic systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197311&isnumber=9196508

N. Kohls, B. Dias, Y. Mensah, B. P. Ruddy and Y. C. Mazumdar, "Compliant Electromagnetic Actuator Architecture for Soft Robotics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9042-9049.
doi: 10.1109/ICRA40945.2020.9197442
keywords: {Iron;Actuators;Magnetic cores;Powders;Electromagnetics;Magnetic liquids},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197442&isnumber=9196508

B. H. Do, V. Banashek and A. M. Okamura, "Dynamically Reconfigurable Discrete Distributed Stiffness for Inflated Beam Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9050-9056.
doi: 10.1109/ICRA40945.2020.9197237
keywords: {Valves;Jamming;Actuators;Laser beams;Soft robotics;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197237&isnumber=9196508

Z. Peng et al., "Data-Driven Reinforcement Learning for Walking Assistance Control of a Lower Limb Exoskeleton with Hemiplegic Patients," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9065-9071.
doi: 10.1109/ICRA40945.2020.9197229
keywords: {Legged locomotion;Exoskeletons;Adaptation models;Learning (artificial intelligence);Trajectory;Extremities;Optimal control;Data-driven Control;Reinforcement Learning;Leader-Follower Multi-Agent System;Lower Limb Exoskeleton;Hemiplegic Patients;Actor-Critic Neural Network},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197229&isnumber=9196508

M. Drolet, E. Q. Yumbla, B. Hobbs and P. Artemiadis, "On the Effects of Visual Anticipation of Floor Compliance Changes on Human Gait: Towards Model-based Robot-Assisted Rehabilitation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9072-9078.
doi: 10.1109/ICRA40945.2020.9197536
keywords: {Legged locomotion;Visualization;Muscles;Robot sensing systems;Perturbation methods;Electromyography},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197536&isnumber=9196508

H. Zhang and C. Ye, "A Visual Positioning System for Indoor Blind Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9079-9085.
doi: 10.1109/ICRA40945.2020.9196782
keywords: {Cameras;RNA;Feature extraction;Visualization;Pose estimation;Navigation;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196782&isnumber=9196508

T. T. H. Duong, D. R. Whittaker and D. Zanotto, "An Outsole-Embedded Optoelectronic Sensor to Measure Shear Ground Reaction Forces During Locomotion," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9086-9092.
doi: 10.1109/ICRA40945.2020.9196962
keywords: {Robot sensing systems;Footwear;Force;Force measurement;Instruments;Legged locomotion;wearable technology;optoelectronics;shear force sensor;instrumented footwear},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196962&isnumber=9196508

G. R. Tan, M. Raitor and S. H. Collins, "Bump‚Äôem: an Open-Source, Bump-Emulation System for Studying Human Balance and Gait," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9093-9099.
doi: 10.1109/ICRA40945.2020.9197105
keywords: {Brushless motors;Perturbation methods;Force;Force sensors;Shafts;Force control;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197105&isnumber=9196508

L. Gerez, A. Dwivedi and M. Liarokapis, "A Hybrid, Soft Exoskeleton Glove Equipped with a Telescopic Extra Thumb and Abduction Capabilities," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9100-9106.
doi: 10.1109/ICRA40945.2020.9197473
keywords: {Actuators;Thumb;Exoskeletons;Tendons;Robots;Pneumatic systems;Grasping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197473&isnumber=9196508

B. Treussart, F. Geffard, N. Vignais and F. Marin, "Controlling an upper-limb exoskeleton by EMG signal while carrying unknown load," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9107-9113.
doi: 10.1109/ICRA40945.2020.9197087
keywords: {Exoskeletons;Electromyography;Torque;Robots;Muscles;Gravity;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197087&isnumber=9196508

F. Zhang and Y. Demiris, "Learning Grasping Points for Garment Manipulation in Robot-Assisted Dressing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9114-9120.
doi: 10.1109/ICRA40945.2020.9196994
keywords: {Clothing;Robots;Grasping;Collision avoidance;Rails;Neural networks;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196994&isnumber=9196508

A. E. H. Martin, E. Dean-Leon and G. Cheng, "TACTO-Selector: Enhanced Hierarchical Fusion of PBVS with Reactive Skin Control for Physical Human-Robot Interaction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9121-9127.
doi: 10.1109/ICRA40945.2020.9196979
keywords: {Task analysis;Collision avoidance;Skin;Robot sensing systems;Safety},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196979&isnumber=9196508

E. Lamon, M. Leonori, W. Kim and A. Ajoudani, "Towards an Intelligent Collaborative Robotic System for Mixed Case Palletizing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9128-9134.
doi: 10.1109/ICRA40945.2020.9196850
keywords: {Pallets;Task analysis;Collaboration;Robots;Impedance;Torque;Resource management},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196850&isnumber=9196508

N. G. Luttmer, T. E. Truong, A. M. Boynton, D. Carrier and M. A. Minor, "Treadmill Based Three Tether Parallel Robot for Evaluating Auditory Warnings While Running," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9135-9142.
doi: 10.1109/ICRA40945.2020.9196600
keywords: {Perturbation methods;Force;Legged locomotion;Muscles;Pulleys;Tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196600&isnumber=9196508

M. Mujica, M. Benoussaad and J. -Y. Fourquet, "Evaluation of Human-Robot Object Co-manipulation Under Robot Impedance Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9143-9149.
doi: 10.1109/ICRA40945.2020.9197329
keywords: {Collaboration;Task analysis;Impedance;Manipulators;Service robots;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197329&isnumber=9196508

A. Coelho, H. Singh, K. Kondak and C. Ott, "Whole-Body Bilateral Teleoperation of a Redundant Aerial Manipulator," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9150-9156.
doi: 10.1109/ICRA40945.2020.9197028
keywords: {Task analysis;Manipulators;Haptic interfaces;Cameras;Null space;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197028&isnumber=9196508

T. -C. Lin, A. Unni Krishnan and Z. Li, "Shared Autonomous Interface for Reducing Physical Effort in Robot Teleoperation via Human Motion Mapping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9157-9163.
doi: 10.1109/ICRA40945.2020.9197220
keywords: {Task analysis;Fatigue;Muscles;Grasping;Cameras;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197220&isnumber=9196508

A. Handa et al., "DexPilot: Vision-Based Teleoperation of Dexterous Robotic Hand-Arm System," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9164-9170.
doi: 10.1109/ICRA40945.2020.9197124
keywords: {Tracking;Three-dimensional displays;Task analysis;Robot sensing systems;Cameras;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197124&isnumber=9196508

Y. Yang, D. Constantinescu and Y. Shi, "Distributed Winner-Take-All Teleoperation of A Multi-Robot System," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9171-9177.
doi: 10.1109/ICRA40945.2020.9197535
keywords: {Robots;Decision making;Protocols;Heuristic algorithms;Indexes;Force;Multi-robot systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197535&isnumber=9196508

M. K. Zein, A. Sidaoui, D. Asmar and I. H. Elhajj, "Enhanced Teleoperation Using Autocomplete," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9178-9184.
doi: 10.1109/ICRA40945.2020.9197140
keywords: {Task analysis;Trajectory;Robots;Training;Support vector machines;Manuals;Drones},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197140&isnumber=9196508

E. Shellshear, Y. Li, R. Bohlin and J. S. Carlson, "Contact-based Bounding Volume Hierarchy for Assembly Tasks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9185-9190.
doi: 10.1109/ICRA40945.2020.9196573
keywords: {Path planning;Task analysis;Geometry;Buildings;Planning;Measurement;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196573&isnumber=9196508

Y. Li, E. Shellshear, R. Bohlin and J. S. Carlson, "Construction of Bounding Volume Hierarchies for Triangle Meshes with Mixed Face Sizes," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9191-9195.
doi: 10.1109/ICRA40945.2020.9197113
keywords: {IP networks;Covariance matrices;Three-dimensional displays;Tensile stress;Cost function;Path planning;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197113&isnumber=9196508

P. Polack, L. -M. Dallen and A. Cord, "Strategy for automated dense parking: how to navigate in narrow lanes," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9196-9202.
doi: 10.1109/ICRA40945.2020.9197088
keywords: {Robots;Collision avoidance;Aerospace electronics;Navigation;Mathematical model;Kinematics;Automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197088&isnumber=9196508

A. Kawasaki and A. Seki, "Multimodal Trajectory Predictions for Urban Environments Using Geometric Relationships between a Vehicle and Lanes," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9203-9209.
doi: 10.1109/ICRA40945.2020.9196738
keywords: {Trajectory;Predictive models;Hidden Markov models;Acceleration;Geometry;Shape;Urban areas},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196738&isnumber=9196508

P. Zheng, P. -B. Wieber and O. Aycard, "Online optimal motion generation with guaranteed safety in shared workspace," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9210-9215.
doi: 10.1109/ICRA40945.2020.9197018
keywords: {Collision avoidance;Trajectory;Safety;Manipulators;Robot sensing systems;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197018&isnumber=9196508

C. Folkestad, D. Pastor and J. W. Burdick, "Episodic Koopman Learning of Nonlinear Robot Dynamics with Application to Fast Multirotor Landing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9216-9222.
doi: 10.1109/ICRA40945.2020.9197510
keywords: {Eigenvalues and eigenfunctions;Nonlinear dynamical systems;Robots;Aerospace electronics;Heuristic algorithms;Vehicle dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197510&isnumber=9196508

Z. Yang, L. Yang and L. Zhang, "Eye-in-Hand 3D Visual Servoing of Helical Swimmers Using Parallel Mobile Coils," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9223-9229.
doi: 10.1109/ICRA40945.2020.9197276
keywords: {Coils;Magnetic resonance imaging;Three-dimensional displays;Cameras;Magnetic devices;Visual servoing;Magnetic separation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197276&isnumber=9196508

L. Yang, J. Yu and L. Zhang, "A Mobile Paramagnetic Nanoparticle Swarm with Automatic Shape Deformation Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9230-9236.
doi: 10.1109/ICRA40945.2020.9197010
keywords: {Shape;Strain;Magnetic resonance imaging;Nanoparticles;Virtual private networks;Micromagnetics;Magnetic anisotropy},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197010&isnumber=9196508

J. Quispe and S. R√©gnier, "Magnetic miniature swimmers with multiple rigid flagella," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9237-9243.
doi: 10.1109/ICRA40945.2020.9196531
keywords: {Robots;Propulsion;Magnetosphere;Prototypes;Microorganisms;Force;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196531&isnumber=9196508

J. Cailliez, A. Weill-Duflos, M. Boudaoud, S. R√©gnier and S. Haliyo, "Design and Control of a Large-Range Nil-Stiffness Electro-Magnetic Active Force Sensor," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9244-9250.
doi: 10.1109/ICRA40945.2020.9197096
keywords: {Probes;Force;Force measurement;Optical sensors;Force sensors;Sensor phenomena and characterization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197096&isnumber=9196508

R. Yu et al., "Modeling Electromagnetic Navigation Systems for Medical Applications using Random Forests and Artificial Neural Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9251-9256.
doi: 10.1109/ICRA40945.2020.9197212
keywords: {Saturation magnetization;Electromagnets;Current measurement;Magnetic cores;Magnetostatics;Magnetic resonance imaging;Magnetic separation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197212&isnumber=9196508

S. Dong et al., "Automated Tracking System with Head and Tail Recognition for Time-Lapse Observation of Free-Moving C. elegans," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9257-9262.
doi: 10.1109/ICRA40945.2020.9197546
keywords: {Fitting;Tracking;Head;Microscopy;Mathematical model;Real-time systems;Curve fitting},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197546&isnumber=9196508

J. Shields, O. Pizarro and S. B. Williams, "Towards Adaptive Benthic Habitat Mapping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9263-9270.
doi: 10.1109/ICRA40945.2020.9196811
keywords: {Feature extraction;Uncertainty;Biological system modeling;Bayes methods;Data models;Neural networks;Backscatter},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196811&isnumber=9196508

D. Han, Y. Hwang, N. Kim and Y. Choi, "Multispectral Domain Invariant Image for Retrieval-based Place Recognition," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9271-9277.
doi: 10.1109/ICRA40945.2020.9197514
keywords: {Image recognition;Robot sensing systems;Task analysis;Semantics;Thermal sensors;Feature extraction;Imaging},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197514&isnumber=9196508

A. S. Bauer, P. Schmaus, F. Stulp and D. Leidner, "Probabilistic Effect Prediction through Semantic Augmentation and Physical Simulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9278-9284.
doi: 10.1109/ICRA40945.2020.9197477
keywords: {Robots;Planning;Probabilistic logic;Cognition;Semantics;Task analysis;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197477&isnumber=9196508

N. Shah, D. Kala Vasudevan, K. Kumar, P. Kamojjhala and S. Srivastava, "Anytime Integrated Task and Motion Policies for Stochastic Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9285-9291.
doi: 10.1109/ICRA40945.2020.9197574
keywords: {Robots;Planning;Task analysis;Computational modeling;Collision avoidance;Stochastic processes;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197574&isnumber=9196508

N. Ding, Z. Zheng, J. Song, Z. Sun, T. L. Lam and H. Qian, "CCRobot-III: a Split-type Wire-driven Cable Climbing Robot for Cable-stayed Bridge Inspection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9308-9314.
doi: 10.1109/ICRA40945.2020.9196772
keywords: {Bridges;Payloads;Force;Wheels;Winches;Robots;Inspection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196772&isnumber=9196508

K. Suryavanshi, R. Vadapalli, R. Vucha, A. Sarkar and K. M. Krishna, "Omnidirectional Tractable Three Module Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9316-9321.
doi: 10.1109/ICRA40945.2020.9197210
keywords: {Robots;Angular velocity;Turning;Shafts;Elbow;Crawlers;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197210&isnumber=9196508

S. T. Nguyen, A. Q. Pham, C. Motley and H. M. La, "A Practical Climbing Robot for Steel Bridge Inspection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9322-9328.
doi: 10.1109/ICRA40945.2020.9196892
keywords: {Bridges;Steel;Mobile robots;Inspection;Adhesives;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196892&isnumber=9196508

H. Eto and H. H. Asada, "Development of a Wheeled Wall-Climbing Robot with a Shape-Adaptive Magnetic Adhesion Mechanism," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9329-9335.
doi: 10.1109/ICRA40945.2020.9196919
keywords: {Wheels;Mobile robots;Magnetic levitation;Magnetic forces;Welding;Adhesives},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196919&isnumber=9196508

A. Lomakin and J. Deutscher, "Algebraic Fault Detection and Identification for Rigid Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9352-9358.
doi: 10.1109/ICRA40945.2020.9197561
keywords: {Fault detection;Jacobian matrices;Mathematical model;Kernel;Time measurement;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197561&isnumber=9196508

C. Pose, J. Giribet and I. Mas, "Fault tolerance analysis of a hexarotor with reconfigurable tilted rotors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9359-9365.
doi: 10.1109/ICRA40945.2020.9196552
keywords: {Rotors;Torque;Force;Servomotors;Fault tolerance;Fault tolerant systems;Attitude control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196552&isnumber=9196508

D. S. Katz, C. Hutchison, M. Zizyte and C. L. Goues, "Detecting Execution Anomalies As an Oracle for Autonomy Software Robustness," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9366-9373.
doi: 10.1109/ICRA40945.2020.9197060
keywords: {Testing;Tools;Instruments;Clustering algorithms;Service robots;Safety},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197060&isnumber=9196508

Y. Sun, Y. Zhou, S. Maskell, J. Sharp and X. Huang, "Reliability Validation of Learning Enabled Vehicle Tracking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9390-9396.
doi: 10.1109/ICRA40945.2020.9196932
keywords: {Testing;Tools;Tracking;Neurons;Cameras;Feature extraction;Reliability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196932&isnumber=9196508

D. Park, Y. Seo and S. Y. Chun, "Real-Time, Highly Accurate Robotic Grasp Detection using Fully Convolutional Neural Network with Rotation Ensemble Module," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9397-9403.
doi: 10.1109/ICRA40945.2020.9197002
keywords: {Proposals;Grasping;Task analysis;Robot sensing systems;Feature extraction;Kernel},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197002&isnumber=9196508

K. Zakka, A. Zeng, J. Lee and S. Song, "Form2Fit: Learning Shape Priors for Generalizable Assembly from Disassembly," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9404-9410.
doi: 10.1109/ICRA40945.2020.9196733
keywords: {Task analysis;Shape;Visualization;Training data;Three-dimensional displays;Solid modeling;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196733&isnumber=9196508

P. Sundaresan et al., "Learning Rope Manipulation Policies Using Dense Object Descriptors Trained on Synthetic Depth Data," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9411-9418.
doi: 10.1109/ICRA40945.2020.9197121
keywords: {Task analysis;Visualization;Robots;Strain;Training;Videos;Data models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197121&isnumber=9196508

J. Song, F. Bai, L. Zhao, S. Huang and R. Xiong, "Efficient two step optimization for large embedded deformation graph based SLAM," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9419-9425.
doi: 10.1109/ICRA40945.2020.9196930
keywords: {Simultaneous localization and mapping;Strain;Jacobian matrices;Optimization;Cameras;Deformable models;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196930&isnumber=9196508

T. E. Lee et al., "Camera-to-Robot Pose Estimation from a Single Image," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9426-9432.
doi: 10.1109/ICRA40945.2020.9196596
keywords: {Cameras;Robot vision systems;Robot kinematics;Calibration;Two dimensional displays;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196596&isnumber=9196508

S. S. Shivakumar, N. Rodrigues, A. Zhou, I. D. Miller, V. Kumar and C. J. Taylor, "PST900: RGB-Thermal Calibration, Dataset and Segmentation Network," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9441-9447.
doi: 10.1109/ICRA40945.2020.9196831
keywords: {Cameras;Calibration;Image segmentation;Semantics;Heating systems;Aluminum;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196831&isnumber=9196508

F. Zhang et al., "Instance Segmentation of LiDAR Point Clouds," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9448-9455.
doi: 10.1109/ICRA40945.2020.9196622
keywords: {Three-dimensional displays;Laser radar;Image segmentation;Two dimensional displays;Encoding;Semantics;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196622&isnumber=9196508

D. Patar and H. I. Bozma, "Generation of Object Candidates Through Simply Looking Around," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9456-9462.
doi: 10.1109/ICRA40945.2020.9197482
keywords: {Cameras;Robot vision systems;Image segmentation;Visualization;Coherence;Tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197482&isnumber=9196508

F. Engelmann, T. Kontogianni and B. Leibe, "Dilated Point Convolutions: On the Receptive Field Size of Point Convolutions on 3D Point Clouds," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9463-9469.
doi: 10.1109/ICRA40945.2020.9197503
keywords: {Three-dimensional displays;Task analysis;Semantics;Network architecture;Image segmentation;Two dimensional displays;Conferences},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197503&isnumber=9196508

B. Bovcon and M. Kristan, "A water-obstacle separation and refinement network for unmanned surface vehicles," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9470-9476.
doi: 10.1109/ICRA40945.2020.9197194
keywords: {Decoding;Visualization;Feature extraction;Image segmentation;Semantics;Image edge detection;Task analysis;obstacle detection;semantic segmentation;sensor fusion;unmanned surface vehicles;separation function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197194&isnumber=9196508

P. Shyam, K. -J. Yoon and K. -S. Kim, "Dynamic Anchor Selection for Improving Object Localization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9477-9483.
doi: 10.1109/ICRA40945.2020.9197076
keywords: {Feature extraction;Detectors;Computer architecture;Task analysis;Spatial resolution;Head;Object detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197076&isnumber=9196508

D. Barnes and I. Posner, "Under the Radar: Learning to Predict Robust Keypoints for Odometry Estimation and Metric Localisation in Radar," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9484-9490.
doi: 10.1109/ICRA40945.2020.9196835
keywords: {Radar;Measurement;Task analysis;Estimation;Robot sensing systems;Computer architecture},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196835&isnumber=9196508

S. Casas, C. Gulino, R. Liao and R. Urtasun, "SpAGNN: Spatially-Aware Graph Neural Networks for Relational Behavior Forecasting from Sensor Data," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9491-9497.
doi: 10.1109/ICRA40945.2020.9196697
keywords: {Forecasting;Laser radar;Three-dimensional displays;Neural networks;Object detection;Predictive models;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196697&isnumber=9196508

A. Filatov, A. Rykov and V. Murashkin, "Any Motion Detector: Learning Class-agnostic Scene Dynamics from a Sequence of LiDAR Point Clouds," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9498-9504.
doi: 10.1109/ICRA40945.2020.9196716
keywords: {Three-dimensional displays;Tensile stress;Vehicle dynamics;Transforms;Laser radar;Estimation;Object detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196716&isnumber=9196508

M. Monforte, A. Arriandiaga, A. Glover and C. Bartolozzi, "Where and When: Event-Based Spatiotemporal Trajectory Prediction from the iCub‚Äôs Point-Of-View," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9521-9527.
doi: 10.1109/ICRA40945.2020.9197373
keywords: {Trajectory;Robots;Predictive models;Cameras;Target tracking;Data models;Pipelines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197373&isnumber=9196508

A. S. Vempati, R. Siegwart and J. Nieto, "A Data-driven Planning Framework for Robotic Texture Painting on 3D Surfaces," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9528-9534.
doi: 10.1109/ICRA40945.2020.9196693
keywords: {Painting;Paints;Robots;Three-dimensional displays;Solid modeling;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196693&isnumber=9196508

B. Ichter, E. Schmerling, T. -W. E. Lee and A. Faust, "Learned Critical Probabilistic Roadmaps for Robotic Motion Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9535-9541.
doi: 10.1109/ICRA40945.2020.9197106
keywords: {Planning;Robots;Trajectory;Probabilistic logic;Training;Complexity theory;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197106&isnumber=9196508

S. Kim and B. An, "Learning Heuristic A: Efficient Graph Search using Neural Network," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9542-9547.
doi: 10.1109/ICRA40945.2020.9197015
keywords: {Heuristic algorithms;Training;Path planning;Biological neural networks;Robots;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197015&isnumber=9196508

R. Terasawa, Y. Ariki, T. Narihira, T. Tsuboi and K. Nagasaka, "3D-CNN Based Heuristic Guided Task-Space Planner for Faster Motion Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9548-9554.
doi: 10.1109/ICRA40945.2020.9196883
keywords: {Planning;Task analysis;Robots;Collision avoidance;Heuristic algorithms;Feature extraction;Convolution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196883&isnumber=9196508

K. Liu, M. Stadler and N. Roy, "Learned Sampling Distributions for Efficient Planning in Hybrid Geometric and Object-Level Representations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9555-9562.
doi: 10.1109/ICRA40945.2020.9196771
keywords: {Navigation;Planning;Semantics;Trajectory;Mathematical model;Optimization;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196771&isnumber=9196508

D. Driess, O. Oguz, J. -S. Ha and M. Toussaint, "Deep Visual Heuristics: Learning Feasibility of Mixed-Integer Programs for Manipulation Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9563-9569.
doi: 10.1109/ICRA40945.2020.9197291
keywords: {Planning;Task analysis;Robot sensing systems;Neural networks;Grasping;Search problems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197291&isnumber=9196508

A. Dai, S. Papatheodorou, N. Funk, D. Tzoumanikas and S. Leutenegger, "Fast Frontier-based Information-driven Autonomous Exploration with an MAV," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9570-9576.
doi: 10.1109/ICRA40945.2020.9196707
keywords: {Planning;Octrees;Entropy;Robot sensing systems;Measurement;Task analysis;Aerial Systems: Perception and Autonomy;Visual-Based Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196707&isnumber=9196508

A. Paris, B. T. Lopez and J. P. How, "Dynamic Landing of an Autonomous Quadrotor on a Moving Platform in Turbulent Wind Conditions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9577-9583.
doi: 10.1109/ICRA40945.2020.9197081
keywords: {Trajectory;Cameras;Vehicle dynamics;Planning;Global Positioning System;Visualization;Acceleration;Unmanned aerial vehicles;autonomous vehicles;landing on a moving platform;disturbance compensation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197081&isnumber=9196508

M. Basescu and J. Moore, "Direct NMPC for Post-Stall Motion Planning with Fixed-Wing UAVs," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9592-9598.
doi: 10.1109/ICRA40945.2020.9196724
keywords: {Aerodynamics;Trajectory;Atmospheric modeling;Real-time systems;Computational modeling;Planning;Splines (mathematics)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196724&isnumber=9196508

G. Zogopoulos-Papaliakos and K. J. Kyriakopoulos, "A Flight Envelope Determination and Protection System for Fixed-Wing UAVs," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9599-9605.
doi: 10.1109/ICRA40945.2020.9197433
keywords: {Iron;Aircraft;Numerical models;Atmospheric modeling;Approximation algorithms;Mathematical model;Aerospace control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197433&isnumber=9196508

J. Mercat, T. Gilles, N. El Zoghby, G. Sandou, D. Beauvois and G. P. Gil, "Multi-Head Attention for Multi-Modal Joint Vehicle Motion Forecasting," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9638-9644.
doi: 10.1109/ICRA40945.2020.9197340
keywords: {Forecasting;Predictive models;Roads;Uncertainty;Computer architecture;Tensile stress;Probability density function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197340&isnumber=9196508

E. Westman, I. Gkioulekas and M. Kaess, "A Volumetric Albedo Framework for 3D Imaging Sonar Reconstruction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9645-9651.
doi: 10.1109/ICRA40945.2020.9197042
keywords: {Sonar;Image reconstruction;Imaging;Three-dimensional displays;Sensors;Nonlinear optics;Surface reconstruction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197042&isnumber=9196508

S. F. G. Ehlers, M. Stuede, K. Nuelle and T. Ortmaier, "Map Management Approach for SLAM in Large-Scale Indoor and Outdoor Areas," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9652-9658.
doi: 10.1109/ICRA40945.2020.9196997
keywords: {Simultaneous localization and mapping;Lasers;Navigation;Feature extraction;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196997&isnumber=9196508

Y. Yue et al., "A Hierarchical Framework for Collaborative Probabilistic Semantic Mapping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9659-9665.
doi: 10.1109/ICRA40945.2020.9197261
keywords: {Semantics;Collaboration;Three-dimensional displays;Robot sensing systems;Geometry;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197261&isnumber=9196508

T. Duong, N. Das, M. Yip and N. Atanasov, "Autonomous Navigation in Unknown Environments using Sparse Kernel-based Occupancy Mapping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9666-9672.
doi: 10.1109/ICRA40945.2020.9197412
keywords: {Support vector machines;Kernel;Training;Robot sensing systems;Collision avoidance;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197412&isnumber=9196508

C. Gomez et al., "Hybrid Topological and 3D Dense Mapping through Autonomous Exploration for Large Indoor Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9673-9679.
doi: 10.1109/ICRA40945.2020.9197226
keywords: {Three-dimensional displays;Measurement;Robots;Semantics;Two dimensional displays;Indoor environments;Path planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197226&isnumber=9196508

S. -F. Ch‚Äông, N. Sogi, P. Purkait, T. -J. Chin and K. Fukui, "Resolving Marker Pose Ambiguity by Robust Rotation Averaging with Clique Constraints," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9680-9686.
doi: 10.1109/ICRA40945.2020.9196902
keywords: {Cameras;Pipelines;Machine-to-machine communications;Image edge detection;Pose estimation;Simultaneous localization and mapping;Histograms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196902&isnumber=9196508

K. Ito, Q. Kong, S. Horiguchi, T. Sumiyoshi and K. Nagamatsu, "Anticipating the Start of User Interaction for Service Robot in the Wild," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9687-9693.
doi: 10.1109/ICRA40945.2020.9196548
keywords: {Training;Embedded systems;Costs;Service robots;Computational modeling;Conferences;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196548&isnumber=9196508

J. Tebbe, L. Klamt, Y. Gao and A. Zell, "Spin Detection in Robotic Table Tennis," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9694-9700.
doi: 10.1109/ICRA40945.2020.9196536
keywords: {Three-dimensional displays;Cameras;Robot vision systems;Trajectory;Quaternions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196536&isnumber=9196508

C. Gan, Y. Zhang, J. Wu, B. Gong and J. B. Tenenbaum, "Look, Listen, and Act: Towards Audio-Visual Embodied Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9701-9707.
doi: 10.1109/ICRA40945.2020.9197008
keywords: {Navigation;Visualization;Task analysis;Robot sensing systems;Visual perception;Acoustics;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197008&isnumber=9196508

C. Yang, X. Lan, H. Zhang and N. Zheng, "Autonomous Tool Construction with Gated Graph Neural Network," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9708-9714.
doi: 10.1109/ICRA40945.2020.9197285
keywords: {Tools;Data models;Robots;Task analysis;Training;Solid modeling;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197285&isnumber=9196508

F. Li, C. Fu, F. Lin, Y. Li and P. Lu, "Training-Set Distillation for Real-Time UAV Object Tracking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9715-9721.
doi: 10.1109/ICRA40945.2020.9197252
keywords: {Training;Unmanned aerial vehicles;Correlation;Reliability;Real-time systems;Optimization;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197252&isnumber=9196508

B. -U. Lee, K. Lee, J. Oh and I. S. Kweon, "CNN-Based Simultaneous Dehazing and Depth Estimation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9722-9728.
doi: 10.1109/ICRA40945.2020.9197358
keywords: {Decoding;Propagation losses;Estimation;Training;Image reconstruction;Task analysis;Scattering},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197358&isnumber=9196508

H. Su et al., "Internet of Things (IoT)-based Collaborative Control of a Redundant Manipulator for Teleoperated Minimally Invasive Surgeries," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9737-9742.
doi: 10.1109/ICRA40945.2020.9197321
keywords: {Collision avoidance;Manipulators;Surgery;Task analysis;Force;Tools},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197321&isnumber=9196508

J. Reher, N. Csomay-Shanklin, D. L. Christensen, B. Bristow, A. D. Ames and L. Smoot, "Passive Dynamic Balancing and Walking in Actuated Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9775-9781.
doi: 10.1109/ICRA40945.2020.9197400
keywords: {Legged locomotion;Dynamics;Nonlinear dynamical systems;Robot sensing systems;Hardware},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197400&isnumber=9196508

S. Caron, "Biped Stabilization by Linear Feedback of the Variable-Height Inverted Pendulum Model," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9782-9788.
doi: 10.1109/ICRA40945.2020.9196715
keywords: {Mathematical model;Lips;Three-dimensional displays;Feedback control;Legged locomotion;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196715&isnumber=9196508

W. Z. Peng, C. Mummolo and J. H. Kim, "Stability Criteria of Balanced and Steppable Unbalanced States for Full-Body Systems with Implications in Robotic and Human Gait," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9789-9795.
doi: 10.1109/ICRA40945.2020.9196820
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196820&isnumber=9196508

J. C. Vaz and P. Oh, "Material Handling by Humanoid Robot While Pushing Carts Using a Walking Pattern Based on Capture Point," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9796-9801.
doi: 10.1109/ICRA40945.2020.9196872
keywords: {Humanoid robots;Legged locomotion;Friction;Robot sensing systems;Wrist;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196872&isnumber=9196508

P. Arpenti, F. Ruggiero and V. Lippiello, "Interconnection and Damping Assignment Passivity-Based Control for Gait Generation in Underactuated Compass-Like Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9802-9808.
doi: 10.1109/ICRA40945.2020.9196598
keywords: {Legged locomotion;Potential energy;Damping;Transmission line matrix methods;Mathematical model;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196598&isnumber=9196508

W. Wu, S. Bhattacharya and A. Prorok, "Multi-Robot Path Deconfliction through Prioritization by Path Prospects," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9809-9815.
doi: 10.1109/ICRA40945.2020.9196813
keywords: {Robot kinematics;Collision avoidance;Planning;Trajectory;Heuristic algorithms;Couplings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196813&isnumber=9196508

L. Zhang, Z. Zhang, R. Siegwart and J. J. Chung, "A Connectivity-Prediction Algorithm and its Application in Active Cooperative Localization for Multi-Robot Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9824-9830.
doi: 10.1109/ICRA40945.2020.9197083
keywords: {Prediction algorithms;Robot sensing systems;Planning;Uncertainty;Computational modeling;Gaussian distribution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197083&isnumber=9196508

W. Luo, S. Yi and K. Sycara, "Behavior Mixing with Minimum Global and Subgroup Connectivity Maintenance for Large-Scale Multi-Robot Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9845-9851.
doi: 10.1109/ICRA40945.2020.9197429
keywords: {Collision avoidance;Robot kinematics;Task analysis;Safety;Multi-robot systems;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197429&isnumber=9196508

C. K. Verginis and D. V. Dimarogonas, "Energy-Optimal Cooperative Manipulation via Provable Internal-Force Regulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9859-9865.
doi: 10.1109/ICRA40945.2020.9196696
keywords: {Grasping;Force;Robots;Dynamics;Acceleration;Jacobian matrices;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196696&isnumber=9196508

J. H. Lee, Y. Kim, S. -G. An and S. -H. Bae, "Robot Telekinesis: Application of a Unimanual and Bimanual Object Manipulation Technique to Robot Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9866-9872.
doi: 10.1109/ICRA40945.2020.9197517
keywords: {Robot sensing systems;End effectors;Task analysis;Education;Service robots;Collaboration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197517&isnumber=9196508

G. Notomista, S. Mayya, M. Selvaggio, M. Santos and C. Secchi, "A Set-Theoretic Approach to Multi-Task Execution and Prioritization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9873-9879.
doi: 10.1109/ICRA40945.2020.9196741
keywords: {Task analysis;Robot kinematics;Jacobian matrices;Aerospace electronics;Manipulators;Safety},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196741&isnumber=9196508

D. Parent, A. Colom√© and C. Torras, "Variable Impedance Control in Cartesian Latent Space while Avoiding Obstacles in Null Space," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9888-9894.
doi: 10.1109/ICRA40945.2020.9197192
keywords: {Aerospace electronics;Task analysis;Trajectory;Jacobian matrices;Manipulators;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197192&isnumber=9196508

H. Li, J. Tan and H. He, "MagicHand: Context-Aware Dexterous Grasping Using an Anthropomorphic Robotic Hand," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9895-9901.
doi: 10.1109/ICRA40945.2020.9196538
keywords: {Grasping;Three-dimensional displays;Neurons;Cameras;Robot vision systems;Dexterous Grasping;Characteristics of Objects Recognition;NIR Spectrum;RGB-D Images},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196538&isnumber=9196508

Z. Sun, K. Yuan, W. Hu, C. Yang and Z. Li, "Learning Pregrasp Manipulation of Objects from Ungraspable Poses," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9917-9923.
doi: 10.1109/ICRA40945.2020.9196982
keywords: {Grasping;Robustness;Training;Grippers;Sensors;End effectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196982&isnumber=9196508

Z. Tong, T. He, C. H. Kim, Y. Hin Ng, Q. Xu and J. Seo, "Picking Thin Objects by Tilt-and-Pivot Manipulation and Its Application to Bin Picking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9932-9938.
doi: 10.1109/ICRA40945.2020.9197493
keywords: {Grippers;Shape;Solids;Surface treatment;Hardware;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197493&isnumber=9196508

Z. -L. Ni, G. -B. Bian, Z. -G. Hou, X. -H. Zhou, X. -L. Xie and Z. Li, "Attention-Guided Lightweight Network for Real-Time Segmentation of Robotic Surgical Instruments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9939-9945.
doi: 10.1109/ICRA40945.2020.9197425
keywords: {Instruments;Convolution;Semantics;Computational efficiency;Decoding;Surgery;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197425&isnumber=9196508

M. K. Welleweerd, A. G. de Groot, S. O. H. de Looijer, F. J. Siepel and S. Stramigioli, "Automated robotic breast ultrasound acquisition using ultrasound feedback," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9946-9952.
doi: 10.1109/ICRA40945.2020.9196736
keywords: {Breast;Probes;Trajectory;Safety;Robot kinematics;Skin},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196736&isnumber=9196508

Z. Min, D. Zhu and M. Q. . -H. Meng, "Robust and Accurate 3D Curve to Surface Registration with Tangent and Normal Vectors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9953-9959.
doi: 10.1109/ICRA40945.2020.9196923
keywords: {Three-dimensional displays;Surgery;Robustness;Probes;Probabilistic logic;Robots;Biomedical imaging},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196923&isnumber=9196508

M. Yoshimura, M. M. Marinho, K. Harada and M. Mitsuishi, "Single-Shot Pose Estimation of Surgical Robot Instruments‚Äô Shafts from Monocular Endoscopic Images," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9960-9966.
doi: 10.1109/ICRA40945.2020.9196779
keywords: {Instruments;Robots;Pose estimation;Surgery;Shafts;Endoscopes;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196779&isnumber=9196508

A. Nguyen et al., "End-to-End Real-time Catheter Segmentation with Optical Flow-Guided Warping during Endovascular Intervention," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9967-9973.
doi: 10.1109/ICRA40945.2020.9197307
keywords: {Catheters;Image segmentation;X-ray imaging;Real-time systems;Machine learning;Motion segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197307&isnumber=9196508

H. Zhang, M. Shen, P. L. Shah and G. -Z. Yang, "Pathological Airway Segmentation with Cascaded Neural Networks for Bronchoscopic Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9974-9980.
doi: 10.1109/ICRA40945.2020.9196756
keywords: {Three-dimensional displays;Atmospheric modeling;Training;Two dimensional displays;Computed tomography;Image segmentation;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196756&isnumber=9196508

A. Katsumaru and R. Ozawa, "Design of 3D-printed assembly mechanisms based on special wooden joinery techniques and its application to a robotic hand," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9981-9987.
doi: 10.1109/ICRA40945.2020.9197475
keywords: {Gears;Robots;Pins;Shape;Three-dimensional displays;Thumb;Printers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197475&isnumber=9196508

J. Tanaka and A. Sugahara, "Parallel gripper with displacement-magnification mechanism and extendable finger mechanism," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 9988-9993.
doi: 10.1109/ICRA40945.2020.9196746
keywords: {Grippers;Gears;Nails;Thumb;Force;Piezoelectric transducers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196746&isnumber=9196508

C. Son and S. Kim, "A Shape Memory Polymer Adhesive Gripper For Pick-and-Place Applications," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10010-10016.
doi: 10.1109/ICRA40945.2020.9197511
keywords: {Switched mode power supplies;Grippers;Adhesives;Heating systems;Shape;Rough surfaces;Surface roughness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197511&isnumber=9196508

M. Okada, S. Takenaka and T. Taniguchi, "Multi-person Pose Tracking using Sequential Monte Carlo with Probabilistic Neural Pose Predictor," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10024-10030.
doi: 10.1109/ICRA40945.2020.9196509
keywords: {Uncertainty;Probabilistic logic;Adaptive optics;Optical imaging;Pose estimation;Optical sensors;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196509&isnumber=9196508

A. O≈°ep, P. Voigtlaender, M. Weber, J. Luiten and B. Leibe, "4D Generic Video Object Proposals," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10031-10037.
doi: 10.1109/ICRA40945.2020.9196949
keywords: {Proposals;Electron tubes;Three-dimensional displays;Image segmentation;Video sequences;Motion segmentation;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196949&isnumber=9196508

A. Sengupta, R. Lagneau, A. Krupa, E. Marchand and M. Marchal, "Simultaneous Tracking and Elasticity Parameter Estimation of Deformable Objects," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10038-10044.
doi: 10.1109/ICRA40945.2020.9196770
keywords: {Strain;Elasticity;Estimation;Deformable models;Force measurement;Force;Force sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196770&isnumber=9196508

J. Wilson and M. C. Lin, "AVOT: Audio-Visual Object Tracking of Multiple Objects for Robotics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10045-10051.
doi: 10.1109/ICRA40945.2020.9197528
keywords: {Object tracking;Object detection;Visualization;Neural networks;Machine learning;Feature extraction;Streaming media},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197528&isnumber=9196508

G. Chen, S. Shen, L. Wen, S. Luo and L. Bo, "Efficient Pig Counting in Crowds with Keypoints Tracking and Spatial-aware Temporal Response Filtering," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10052-10058.
doi: 10.1109/ICRA40945.2020.9197211
keywords: {Cameras;Tracking;Robot vision systems;Inspection;Skeleton;Pipelines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197211&isnumber=9196508

C. Wang et al., "6-PACK: Category-level 6D Pose Tracker with Anchor-Based Keypoints," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10059-10066.
doi: 10.1109/ICRA40945.2020.9196679
keywords: {Three-dimensional displays;Pose estimation;Robustness;Robots;Real-time systems;Tracking;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196679&isnumber=9196508

J. Tian, X. Zhao, X. D. Gu and S. Chen, "Designing Ferromagnetic Soft Robots (FerroSoRo) with Level-Set-Based Multiphysics Topology Optimization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10067-10074.
doi: 10.1109/ICRA40945.2020.9197457
keywords: {Soft magnetic materials;Optimization;Topology;Magnetic domains;Magnetoacoustic effects;Level set;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197457&isnumber=9196508

Y. She, S. Q. Liu, P. Yu and E. Adelson, "Exoskeleton-covered soft finger with vision-based proprioception and tactile sensing," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10075-10081.
doi: 10.1109/ICRA40945.2020.9197369
keywords: {Soft robotics;Cameras;Robot vision systems;Ink},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197369&isnumber=9196508

J. Sun, B. Tighe and J. Zhao, "Tuning the Energy Landscape of Soft Robots for Fast and Strong Motion," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10082-10088.
doi: 10.1109/ICRA40945.2020.9196737
keywords: {Soft robotics;Springs;Potential energy;Shape;Actuators;Plastics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196737&isnumber=9196508

J. Carlson, J. Friedman, C. Kim and C. Sung, "REBOund: Untethered Origami Jumping Robot with Controllable Jump Height," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10089-10095.
doi: 10.1109/ICRA40945.2020.9196534
keywords: {Potential energy;Computational modeling;Energy measurement;Springs;Servomotors;Robots;Faces},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196534&isnumber=9196508

M. Kim, W. K. Chung and K. Kim, "Motion Intensity Extraction Scheme for Simultaneous Recognition of Wrist/Hand Motions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10112-10117.
doi: 10.1109/ICRA40945.2020.9197467
keywords: {Muscles;Crosstalk;Feature extraction;Wrist;Pattern recognition;Microsoft Windows;Electrodes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197467&isnumber=9196508

F. M. Ramos and M. Hayashibe, "Simultaneous Online Motion Discrimination and Evaluation of Whole-body Exercise by Synergy Probes for Home Rehabilitation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10118-10124.
doi: 10.1109/ICRA40945.2020.9197232
keywords: {Task analysis;Probes;Training data;Hidden Markov models;Torso;Real-time systems;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197232&isnumber=9196508

D. M. Stramel and S. K. Agrawal, "Validation of a Forward Kinematics Based Controller for a mobile Tethered Pelvic Assist Device to Augment Pelvic Forces during Walking," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10133-10139.
doi: 10.1109/ICRA40945.2020.9196585
keywords: {Belts;Legged locomotion;Pelvis;Kinematics;Training;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196585&isnumber=9196508

D. N. Wolf, Z. A. Hall and E. M. Schearer, "Model Learning for Control of a Paralyzed Human Arm with Functional Electrical Stimulation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10148-10154.
doi: 10.1109/ICRA40945.2020.9196992
keywords: {Muscles;Wrist;Iron;Force;Robots;Ground penetrating radar;Data models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196992&isnumber=9196508

R. Nayeem, S. Bazzi, N. Hogan and D. Sternad, "Transient Behavior and Predictability in Manipulating Complex Objects," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10155-10161.
doi: 10.1109/ICRA40945.2020.9196977
keywords: {Transient analysis;Robots;Steady-state;Task analysis;Dynamics;Force;Haptic interfaces},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196977&isnumber=9196508

D. Sirintuna, Y. Aydin, O. Caldiran, O. Tokatli, V. Patoglu and C. Basdogan, "A Variable-Fractional Order Admittance Controller for pHRI," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10162-10168.
doi: 10.1109/ICRA40945.2020.9197288
keywords: {Admittance;Task analysis;Robot sensing systems;Collaboration;Stability criteria},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197288&isnumber=9196508

Z. Erickson, V. Gangaram, A. Kapusta, C. K. Liu and C. C. Kemp, "Assistive Gym: A Physics Simulation Framework for Assistive Robotics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10169-10176.
doi: 10.1109/ICRA40945.2020.9197411
keywords: {Task analysis;Manipulators;Physics;Tools;Human-robot interaction;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197411&isnumber=9196508

J. Campbell and K. Yamane, "Learning Whole-Body Human-Robot Haptic Interaction in Social Contexts," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10177-10183.
doi: 10.1109/ICRA40945.2020.9196933
keywords: {Robot sensing systems;Haptic interfaces;Force;Spatiotemporal phenomena;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196933&isnumber=9196508

M. G. Carmichael, R. Khonasty, S. Aldini and D. Liu, "Human Preferences in Using Damping to Manage Singularities During Physical Human-Robot Collaboration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10184-10190.
doi: 10.1109/ICRA40945.2020.9197093
keywords: {Damping;Manipulators;Collaboration;Jacobian matrices;Kinematics;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197093&isnumber=9196508

W. Kim, P. Balatti, E. Lamon and A. Ajoudani, "MOCA-MAN: A MObile and reconfigurable Collaborative Robot Assistant for conjoined huMAN-robot actions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10191-10197.
doi: 10.1109/ICRA40945.2020.9197115
keywords: {Admittance;Task analysis;Collaboration;Robot sensing systems;Clamps;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197115&isnumber=9196508

R. Balachandran, J. -H. Ryu, M. Jorda, C. Ott and A. Albu-Schaeffer, "Closing the Force Loop to Enhance Transparency in Time-delayed Teleoperation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10198-10204.
doi: 10.1109/ICRA40945.2020.9197420
keywords: {Force;Iron;Force measurement;Robots;Stability analysis;Delays;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197420&isnumber=9196508

F. Porcini, D. Chiaradia, S. Marcheschi, M. Solazzi and A. Frisoli, "Evaluation of an Exoskeleton-based Bimanual Teleoperation Architecture with Independently Passivated Slave Devices," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10205-10211.
doi: 10.1109/ICRA40945.2020.9197079
keywords: {Exoskeletons;Task analysis;Computer architecture;Stability analysis;Robots;Delays;Haptic interfaces},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197079&isnumber=9196508

M. Macchini, T. Havy, A. Weber, F. Schiano and D. Floreano, "Hand-worn Haptic Interface for Drone Teleoperation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10212-10218.
doi: 10.1109/ICRA40945.2020.9196664
keywords: {Haptic interfaces;Drones;Task analysis;Robot sensing systems;Hardware},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196664&isnumber=9196508

A. Bushman, M. Asselmeier, J. Won and A. LaViers, "Toward Human-like Teleoperated Robot Motion: Performance and Perception of a Choreography-inspired Method in Static and Dynamic Tasks for Rapid Pose Selection of Articulated Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10219-10225.
doi: 10.1109/ICRA40945.2020.9196742
keywords: {Task analysis;Training;Dynamics;Joints;Robot motion;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196742&isnumber=9196508

J. DelPreto et al., "Helping Robots Learn: A Human-Robot Master-Apprentice Model Using Demonstrations via Virtual Reality Teleoperation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10226-10233.
doi: 10.1109/ICRA40945.2020.9196754
keywords: {Robots;Grasping;Task analysis;Three-dimensional displays;Solid modeling;Virtual reality;Pipelines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196754&isnumber=9196508

V. Pruks and J. -H. Ryu, "A Framework for Interactive Virtual Fixture Generation for Shared Teleoperation in Unstructured Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10234-10241.
doi: 10.1109/ICRA40945.2020.9196579
keywords: {Tools;Feature extraction;Task analysis;Robots;Detectors;Three-dimensional displays;Haptic interfaces},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196579&isnumber=9196508

M. Fnadi, W. Du, R. Gomes da Silva, F. Plumet and F. Benamar, "Local Obstacle-Skirting Path Planning for a Fast Bi-steerable Rover using B√©zier Curves," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10242-10248.
doi: 10.1109/ICRA40945.2020.9197563
keywords: {Safety;Collision avoidance;Mobile robots;Lead;Path planning;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197563&isnumber=9196508

Y. Ding and U. Thomas, "Collision Avoidance with Proximity Servoing for Redundant Serial Robot Manipulators," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10249-10255.
doi: 10.1109/ICRA40945.2020.9196759
keywords: {Collision avoidance;Robot sensing systems;Task analysis;Manipulators;Skin},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196759&isnumber=9196508

M. Kollmitz, D. B√ºscher and W. Burgard, "Predicting Obstacle Footprints from 2D Occupancy Maps by Learning from Physical Interactions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10256-10262.
doi: 10.1109/ICRA40945.2020.9197474
keywords: {Two dimensional displays;Collision avoidance;Image segmentation;Training;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197474&isnumber=9196508

S. Eiffert, H. Kong, N. Pirmarzdashti and S. Sukkarieh, "Path Planning in Dynamic Environments using Generative RNNs and Monte Carlo Tree Search," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10263-10269.
doi: 10.1109/ICRA40945.2020.9196631
keywords: {Robots;Predictive models;Path planning;Decoding;Collision avoidance;Training;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196631&isnumber=9196508

A. Singletary, T. Gurriet, P. Nilsson and A. D. Ames, "Safety-Critical Rapid Aerial Exploration of Unknown Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10270-10276.
doi: 10.1109/ICRA40945.2020.9197416
keywords: {Safety;Collision avoidance;Three-dimensional displays;Drones;Trajectory;Vehicle dynamics;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197416&isnumber=9196508

Q. Wang, B. Wang, J. Yu, K. Schweizer, B. J. Nelson and L. Zhang, "Reconfigurable Magnetic Microswarm for Thrombolysis under Ultrasound Imaging," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10285-10291.
doi: 10.1109/ICRA40945.2020.9197432
keywords: {Ultrasonic imaging;Magnetic resonance imaging;Convection;Coagulation;Coils;Micro/nanorobot;magnetic control;collective behavior;thrombolysis;ultrasound imaging},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197432&isnumber=9196508

E. Gerena, F. Legendre, Y. Vitry, S. R√©gnier and S. Haliyo, "Improving Optical Micromanipulation with Force-Feedback Bilateral Coupling," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10292-10298.
doi: 10.1109/ICRA40945.2020.9197424
keywords: {Optical feedback;Optical sensors;Force;Haptic interfaces;Optical imaging;Three-dimensional displays;High-speed optical techniques},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197424&isnumber=9196508

Z. Hao, D. Kim, A. R. Mohazab and A. Ansari, "Maneuver at Micro Scale: Steering by Actuation Frequency Control in Micro Bristle Robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10299-10304.
doi: 10.1109/ICRA40945.2020.9196694
keywords: {Robots;Resonant frequency;Actuators;Vibrations;Steady-state;Wires;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196694&isnumber=9196508

K. Jayaram, J. Shum, S. Castellanos, E. F. Helbling and R. J. Wood, "Scaling down an insect-size microrobot, HAMR-VI into HAMR-Jr," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10305-10311.
doi: 10.1109/ICRA40945.2020.9197436
keywords: {Legged locomotion;Actuators;Resonant frequency;Heat-assisted magnetic recording;Fabrication;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197436&isnumber=9196508

D. A. Shell and J. M. O‚ÄôKane, "Reality as a simulation of reality: robot illusions, fundamental limits, and a physical demonstration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10327-10334.
doi: 10.1109/ICRA40945.2020.9196761
keywords: {Robot sensing systems;Software;Sensor systems;Mobile robots;Emulation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196761&isnumber=9196508

A. Pacheck, S. Moarref and H. Kress-Gazit, "Finding Missing Skills for High-Level Behaviors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10335-10341.
doi: 10.1109/ICRA40945.2020.9197223
keywords: {Task analysis;Maintenance engineering;Games;Robot control;Manipulators;Safety},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197223&isnumber=9196508

S. Bharadwaj, A. P. Vinod, R. Dimitrova and U. Topcu, "Near-Optimal Reactive Synthesis Incorporating Runtime Information," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10342-10348.
doi: 10.1109/ICRA40945.2020.9196581
keywords: {Runtime;Switches;Games;Robots;Measurement;Safety;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196581&isnumber=9196508

A. K. Bozkurt, Y. Wang, M. M. Zavlanos and M. Pajic, "Control Synthesis from Linear Temporal Logic Specifications using Model-Free Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10349-10355.
doi: 10.1109/ICRA40945.2020.9196796
keywords: {Learning (artificial intelligence);Automata;Planning;Markov processes;Computational modeling;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196796&isnumber=9196508

G. Jeanneau, V. B√©goc, S. Briot and A. Goldsztejn, "R-Min: a Fast Collaborative Underactuated Parallel Robot for Pick-and-Place Operations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10365-10371.
doi: 10.1109/ICRA40945.2020.9196990
keywords: {Collision avoidance;Collaboration;Prototypes;Parallel robots;Robot sensing systems;Springs},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196990&isnumber=9196508

K. Xu, S. Wang, X. Wang, J. Wang, Z. Chen and D. Liu, "High-Flexibility Locomotion and Whole-Torso Control for a Wheel-Legged Robot on Challenging Terrain," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10372-10377.
doi: 10.1109/ICRA40945.2020.9197526
keywords: {Legged locomotion;Wheels;Torso;Force;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197526&isnumber=9196508

J. -P. Merlet, Y. Papegay and A. -V. Gasc, "The Prince‚Äôs tears, a large cable-driven parallel robot for an artistic exhibition," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10378-10383.
doi: 10.1109/ICRA40945.2020.9197011
keywords: {Meters;Length measurement;Winches;Powders;Kinematics;Robot kinematics;cable-driven parallel robot;kinematics;art},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197011&isnumber=9196508

C. Bouzgarrou, A. Koessler and N. Bouton, "Singularity analysis and reconfiguration mode of the 3-CRS parallel manipulator," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10384-10390.
doi: 10.1109/ICRA40945.2020.9197337
keywords: {Manipulators;Kinematics;Transmission line matrix methods;Force;Geometry;Prototypes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197337&isnumber=9196508

N. Kumar and S. Coros, "Trajectory optimization for a class of robots belonging to Constrained Collaborative Mobile Agents (CCMA) family," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10391-10397.
doi: 10.1109/ICRA40945.2020.9197048
keywords: {Kinematics;Mobile robots;Trajectory optimization;Mobile agents;Task analysis;Parallel Robots;Optimization and Optimal Control;Multi-Robot Systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197048&isnumber=9196508

B. -S. Sim, K. -J. Kim and K. -H. Yu, "Development of Body Rotational Wheeled Robot and its Verification of Effectiveness," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10405-10411.
doi: 10.1109/ICRA40945.2020.9197047
keywords: {Mobile robots;Wheels;Force;Gears;Friction;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197047&isnumber=9196508

C. Stetco, B. Ubezio, S. M√ºhlbacher-Karrer and H. Zangl, "Radar Sensors in Collaborative Robotics: Fast Simulation and Experimental Validation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10452-10458.
doi: 10.1109/ICRA40945.2020.9197180
keywords: {Radar;Robot sensing systems;Radar antennas;Chirp;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197180&isnumber=9196508

K. Kase, C. Paxton, H. Mazhar, T. Ogata and D. Fox, "Transferable Task Execution from Pixels through Deep Planning Domain Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10459-10465.
doi: 10.1109/ICRA40945.2020.9196597
keywords: {Task analysis;Planning;Robot sensing systems;Grounding;Robustness;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196597&isnumber=9196508

B. Goodrich, A. Kuefler and W. D. Richards, "Depth by Poking: Learning to Estimate Depth from Self-Supervised Grasping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10466-10472.
doi: 10.1109/ICRA40945.2020.9196797
keywords: {Estimation;Uncertainty;Robot sensing systems;Training;Grasping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196797&isnumber=9196508

S. Pirk, M. Khansari, Y. Bai, C. Lynch and P. Sermanet, "Online Learning of Object Representations by Appearance Space Feature Alignment," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10473-10479.
doi: 10.1109/ICRA40945.2020.9196567
keywords: {Videos;Robots;Training;Measurement;Object recognition;Video sequences;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196567&isnumber=9196508

C. Moses, M. Noseworthy, L. P. Kaelbling, T. Lozano-P√©rez and N. Roy, "Visual Prediction of Priors for Articulated Object Interaction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10480-10486.
doi: 10.1109/ICRA40945.2020.9196541
keywords: {Robots;Visualization;Training;Kinematics;Gaussian processes;Optimization;Kernel},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196541&isnumber=9196508

R. Araki, T. Onishi, T. Hirakawa, T. Yamashita and H. Fujiyoshi, "MT-DSSD: Deconvolutional Single Shot Detector Using Multi Task Learning for Object Detection, Segmentation, and Grasping Detection," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10487-10493.
doi: 10.1109/ICRA40945.2020.9197251
keywords: {Grasping;Robots;Object detection;Semantics;Task analysis;Deconvolution;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197251&isnumber=9196508

Y. Lin, C. Tang, F. -J. Chu and P. A. Vela, "Using Synthetic Data and Deep Networks to Recognize Primitive Shapes for Object Grasping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10494-10501.
doi: 10.1109/ICRA40945.2020.9197256
keywords: {Shape;Grasping;Image segmentation;Three-dimensional displays;Task analysis;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197256&isnumber=9196508

M. Schwarz and S. Behnke, "Stillleben: Realistic Scene Synthesis for Deep Learning in Robotics," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10502-10508.
doi: 10.1109/ICRA40945.2020.9197309
keywords: {Training;Rendering (computer graphics);Robots;Engines;Pipelines;Task analysis;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197309&isnumber=9196508

J. Hong, M. Fulton and J. Sattar, "A Generative Approach Towards Improved Robotic Detection of Marine Litter," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10525-10531.
doi: 10.1109/ICRA40945.2020.9197575
keywords: {Training;Image color analysis;Plastics;Gallium nitride;Task analysis;Shape;Decoding},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197575&isnumber=9196508

Y. Fu, S. Sen, J. Reimann and C. Theurer, "Spatiotemporal Representation Learning with GAN Trained LSTM-LSTM Networks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10548-10555.
doi: 10.1109/ICRA40945.2020.9196858
keywords: {Spatiotemporal phenomena;Gallium nitride;Task analysis;Training;Generative adversarial networks;Robots;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196858&isnumber=9196508

A. E. Tekden, A. Erdem, E. Erdem, M. Imre, M. Y. Seker and E. Ugur, "Belief Regulated Dual Propagation Nets for Learning Action Effects on Groups of Articulated Objects," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10556-10562.
doi: 10.1109/ICRA40945.2020.9196878
keywords: {Robots;Physics;Engines;Predictive models;History;Neural networks;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196878&isnumber=9196508

H. Cui et al., "Deep Kinematic Models for Kinematically Feasible Vehicle Trajectory Predictions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10563-10569.
doi: 10.1109/ICRA40945.2020.9197560
keywords: {Predictive models;Kinematics;Trajectory;Hidden Markov models;Radar tracking;Data models;Interpolation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197560&isnumber=9196508

Z. Qiao et al., "Human Driver Behavior Prediction based on UrbanFlow," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10570-10576.
doi: 10.1109/ICRA40945.2020.9196918
keywords: {Trajectory;Autonomous vehicles;Data collection;Automobiles;Roads;Drones},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196918&isnumber=9196508

J. A. Caley and G. A. Hollinger, "Environment Prediction from Sparse Samples for Robotic Information Gathering," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10577-10583.
doi: 10.1109/ICRA40945.2020.9197263
keywords: {Robots;Data models;Oceans;Neural networks;Convolution;Network architecture;Logic gates},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197263&isnumber=9196508

F. Paus, T. Huang and T. Asfour, "Predicting Pushing Action Effects on Spatial Object Relations by Learning Internal Prediction Models," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10584-10590.
doi: 10.1109/ICRA40945.2020.9197295
keywords: {Predictive models;Two dimensional displays;Robots;Data models;Physics;Three-dimensional displays;Analytical models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197295&isnumber=9196508

S. Noda et al., "Learning of Key Pose Evaluation for Efficient Multi-contact Motion Planner," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10591-10597.
doi: 10.1109/ICRA40945.2020.9197189
keywords: {Planning;Trajectory;Torque;Legged locomotion;Jacobian matrices;Knee;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197189&isnumber=9196508

M. Bhardwaj, B. Boots and M. Mukadam, "Differentiable Gaussian Process Motion Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10598-10604.
doi: 10.1109/ICRA40945.2020.9197260
keywords: {Planning;Conferences;Automation;Gaussian processes;Artificial intelligence;Trajectory optimization;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197260&isnumber=9196508

D. Molina, K. Kumar and S. Srivastava, "Learn and Link: Learning Critical Regions for Efficient Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10605-10611.
doi: 10.1109/ICRA40945.2020.9196833
keywords: {Planning;Probabilistic logic;Robots;Density measurement;Task analysis;Buildings;Convolutional neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196833&isnumber=9196508

D. R. McArthur, Z. An and D. J. Cappelleri, "Pose-Estimate-Based Target Tracking for Human-Guided Remote Sensor Mounting with a UAV," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10636-10642.
doi: 10.1109/ICRA40945.2020.9196514
keywords: {Target tracking;Cameras;Unmanned aerial vehicles;Visualization;Task analysis;Surface cleaning;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196514&isnumber=9196508

N. J. Sanket et al., "EVDodgeNet: Deep Dynamic Obstacle Dodging with Event Cameras," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10651-10657.
doi: 10.1109/ICRA40945.2020.9196877
keywords: {Cameras;Collision avoidance;Motion segmentation;Machine learning;Optical imaging;Robot vision systems;Image segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196877&isnumber=9196508

V. Walter, M. Vrba and M. Saska, "On training datasets for machine learning-based visual relative localization of micro-scale UAVs," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10674-10680.
doi: 10.1109/ICRA40945.2020.9196947
keywords: {Cameras;Training;Observers;Visualization;Image color analysis;Global navigation satellite system;Position measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196947&isnumber=9196508

L. Zhu, Y. Cui and T. Matsubara, "Dynamic Actor-Advisor Programming for Scalable Safe Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10681-10687.
doi: 10.1109/ICRA40945.2020.9197200
keywords: {Dynamic programming;Programming;Robots;Learning (artificial intelligence);Heuristic algorithms;Task analysis;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197200&isnumber=9196508

E. Marchesini and A. Farinelli, "Discrete Deep Reinforcement Learning for Mapless Navigation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10688-10694.
doi: 10.1109/ICRA40945.2020.9196739
keywords: {Training;Navigation;Robot kinematics;Robot sensing systems;Optimization;Machine learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196739&isnumber=9196508

Y. Xiao, J. Hoffman, T. Xia and C. Amato, "Learning Multi-Robot Decentralized Macro-Action-Based Policies via a Centralized Q-Net," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10695-10701.
doi: 10.1109/ICRA40945.2020.9196684
keywords: {Robot kinematics;Training;Tools;Task analysis;Machine learning;History},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196684&isnumber=9196508

M. Turchetta, A. Krause and S. Trimpe, "Robust Model-free Reinforcement Learning with Multi-objective Bayesian Optimization," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10702-10708.
doi: 10.1109/ICRA40945.2020.9197000
keywords: {Robustness;Optimization;Training;Control theory;Computational modeling;Learning (artificial intelligence);Bayes methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197000&isnumber=9196508

Y. Di, H. Morimitsu, Z. Lou and X. Ji, "A Unified Framework for Piecewise Semantic Reconstruction in Dynamic Scenes via Exploiting Superpixel Relations," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10737-10743.
doi: 10.1109/ICRA40945.2020.9197240
keywords: {Semantics;Motion segmentation;Image reconstruction;Motion estimation;Pipelines;Silicon;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197240&isnumber=9196508

K. Zieli≈Ñski and D. Belter, "Keyframe-based Dense Mapping with the Graph of View-Dependent Local Maps," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10744-10750.
doi: 10.1109/ICRA40945.2020.9196865
keywords: {Ellipsoids;Three-dimensional displays;Robot sensing systems;Cameras;Two dimensional displays;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196865&isnumber=9196508

M. Popoviƒá, T. Vidal-Calleja, J. J. Chung, J. Nieto and R. Siegwart, "Informative Path Planning for Active Field Mapping under Localization Uncertainty," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10751-10757.
doi: 10.1109/ICRA40945.2020.9197034
keywords: {Uncertainty;Planning;Robot sensing systems;Trajectory;Manuals;Robot localization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197034&isnumber=9196508

J. A. Stork and T. Stoyanov, "Ensemble of Sparse Gaussian Process Experts for Implicit Surface Mapping with Streaming Data," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10758-10764.
doi: 10.1109/ICRA40945.2020.9196620
keywords: {Surface treatment;Data models;Predictive models;Covariance matrices;Gaussian processes;Computational modeling;Measurement uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196620&isnumber=9196508

S. Pagad, D. Agarwal, S. Narayanan, K. Rangan, H. Kim and G. Yalla, "Robust Method for Removing Dynamic Objects from Point Clouds," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10765-10771.
doi: 10.1109/ICRA40945.2020.9197168
keywords: {Three-dimensional displays;Vehicle dynamics;Octrees;Object detection;Laser modes;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197168&isnumber=9196508

P. L. Dovesi et al., "Real-Time Semantic Stereo Matching," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10780-10787.
doi: 10.1109/ICRA40945.2020.9196784
keywords: {Semantics;Feature extraction;Task analysis;Estimation;Three-dimensional displays;Image segmentation;Computer architecture},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196784&isnumber=9196508

Y. Lu, M. Sarkis and G. Lu, "Multi-Task Learning for Single Image Depth Estimation and Segmentation Based on Unsupervised Network," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10788-10794.
doi: 10.1109/ICRA40945.2020.9196723
keywords: {Image segmentation;Estimation;Task analysis;Training;Feature extraction;Neural networks;Image reconstruction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196723&isnumber=9196508

J. Liu, P. Zhao, Z. Gan, M. Johnson-Roberson and R. Vasudevan, "Leveraging the Template and Anchor Framework for Safe, Online Robotic Gait Design," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10869-10875.
doi: 10.1109/ICRA40945.2020.9197017
keywords: {Legged locomotion;Rabbits;Safety;Foot;Predictive models;Control systems;Bipeds;underactuated system;safety guarantee},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197017&isnumber=9196508

C. McGreavy et al., "Unified Push Recovery Fundamentals: Inspiration from Human Study," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10876-10882.
doi: 10.1109/ICRA40945.2020.9196911
keywords: {Modulation;Robots;Hip;Stability criteria;Foot;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196911&isnumber=9196508

L. Barcelos, R. Oliveira, R. Possas, L. Ott and F. Ramos, "DISCO: Double Likelihood-free Inference Stochastic Control," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10969-10975.
doi: 10.1109/ICRA40945.2020.9196931
keywords: {Uncertainty;Trajectory;Mathematical model;Computational modeling;Numerical models;Stochastic processes;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196931&isnumber=9196508

C. Zhang, A. Khan, S. Paternain and A. Ribeiro, "Sufficiently Accurate Model Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 10991-10997.
doi: 10.1109/ICRA40945.2020.9197502
keywords: {Task analysis;Optimization;Data models;Adaptation models;Heuristic algorithms;Neural networks;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197502&isnumber=9196508

G. Kazhoyan, A. Niedzwiecki and M. Beetz, "Towards Plan Transformations for Real-World Mobile Fetch and Place," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11011-11017.
doi: 10.1109/ICRA40945.2020.9197446
keywords: {Task analysis;Planning;Runtime;Manipulators;Transforms;Complexity theory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197446&isnumber=9196508

J. Xu, K. Harada, W. Wan, T. Ueshiba and Y. Domae, "Planning an Efficient and Robust Base Sequence for a Mobile Manipulator Performing Multiple Pick-and-place Tasks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11018-11024.
doi: 10.1109/ICRA40945.2020.9196999
keywords: {Manipulators;Databases;Task analysis;Robustness;Grasping;Uncertainty;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196999&isnumber=9196508

Z. Han et al., "Towards Mobile Multi-Task Manipulation in a Confined and Integrated Environment with Irregular Objects," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11025-11031.
doi: 10.1109/ICRA40945.2020.9197395
keywords: {Gears;Navigation;Task analysis;Manipulators;Three-dimensional displays;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197395&isnumber=9196508

F. Bertoncelli, F. Ruggiero and L. Sabattini, "Linear Time-Varying MPC for Nonprehensile Object Manipulation with a Nonholonomic Mobile Robot," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11032-11038.
doi: 10.1109/ICRA40945.2020.9197173
keywords: {Mobile robots;Friction;Task analysis;Dynamics;Mathematical model;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197173&isnumber=9196508

M. Bajracharya et al., "A Mobile Manipulation System for One-Shot Teaching of Complex Tasks in Homes," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11039-11045.
doi: 10.1109/ICRA40945.2020.9196677
keywords: {Task analysis;Robot kinematics;Robustness;Visualization;Aerospace electronics;Education},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196677&isnumber=9196508

S. A. Parkison, J. M. Walls, R. W. Wolcott, M. Saad and R. M. Eustice, "2D to 3D Line-Based Registration with Unknown Associations via Mixed-Integer Programming," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11046-11052.
doi: 10.1109/ICRA40945.2020.9196718
keywords: {Three-dimensional displays;Two dimensional displays;Cameras;Cost function;Robot sensing systems;Transforms;Symmetric matrices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196718&isnumber=9196508

Y. Ding, J. Yang and H. Kong, "An efficient solution to the relative pose estimation with a common direction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11053-11059.
doi: 10.1109/ICRA40945.2020.9196636
keywords: {Cameras;Eigenvalues and eigenfunctions;Gravity;Pose estimation;Transmission line matrix methods;Symmetric matrices;Motion estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196636&isnumber=9196508

V. Chen, M. -K. Yoon and Z. Shao, "Task-Aware Novelty Detection for Visual-based Deep Learning in Autonomous Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11060-11066.
doi: 10.1109/ICRA40945.2020.9196720
keywords: {Training;Task analysis;Predictive models;Roads;Data models;Autonomous systems;Decision making},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196720&isnumber=9196508

R. Wang, N. Yang, J. St√ºckler and D. Cremers, "DirectShape: Direct Photometric Alignment of Shape Priors for Visual Vehicle Pose and Shape Estimation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11067-11073.
doi: 10.1109/ICRA40945.2020.9197095
keywords: {Shape;Three-dimensional displays;Two dimensional displays;Automobiles;Current measurement;Solid modeling;Image reconstruction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197095&isnumber=9196508

S. Reddy, M. Mathew, L. Gomez, M. Rusinol, D. Karatzas and C. V. Jawahar, "RoadText-1K: Text Detection & Recognition Dataset for Driving Videos," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11074-11080.
doi: 10.1109/ICRA40945.2020.9196577
keywords: {Videos;Text recognition;Vehicles;Image recognition;Task analysis;Roads;Semantics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196577&isnumber=9196508

Z. Song, J. Lu, T. Zhang and H. Li, "End-to-end Learning for Inter-Vehicle Distance and Relative Velocity Estimation in ADAS with a Monocular Camera," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11081-11087.
doi: 10.1109/ICRA40945.2020.9197557
keywords: {Estimation;Three-dimensional displays;Cameras;Optical imaging;Two dimensional displays;Feature extraction;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197557&isnumber=9196508

N. Heravi, W. Yuan, A. M. Okamura and J. Bohg, "Learning an Action-Conditional Model for Haptic Texture Generation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11088-11095.
doi: 10.1109/ICRA40945.2020.9197447
keywords: {Haptic interfaces;Autoregressive processes;Force;Acceleration;Predictive models;Solid modeling;Discrete Fourier transforms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197447&isnumber=9196508

H. Kim, H. H. Guo and A. T. Asbeck, "Just Noticeable Differences for Joint Torque Feedback During Static Poses," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11096-11102.
doi: 10.1109/ICRA40945.2020.9197537
keywords: {Torque;Muscles;Exoskeletons;Elbow;Skin;Force;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197537&isnumber=9196508

S. -m. Hur, J. Park, J. Park and Y. Oh, "Design of a Parallel Haptic Device with Gravity Compensation by using its System Weight," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11103-11108.
doi: 10.1109/ICRA40945.2020.9197065
keywords: {Gravity;Haptic interfaces;Jacobian matrices;Torque;Manipulators;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197065&isnumber=9196508

A. Beauvisage, K. Ahiska and N. Aouf, "Multimodal tracking framework for visual odometry in challenging illumination conditions," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11133-11139.
doi: 10.1109/ICRA40945.2020.9196891
keywords: {Cameras;Feature extraction;Bundle adjustment;Visual odometry;Lighting;Tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196891&isnumber=9196508

K. de Langis and J. Sattar, "Realtime Multi-Diver Tracking and Re-identification for Underwater Human-Robot Collaboration," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11140-11146.
doi: 10.1109/ICRA40945.2020.9197308
keywords: {Robots;Tracking;Feature extraction;Collaboration;Unmanned underwater vehicles;Task analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197308&isnumber=9196508

J. Zhan, J. Cartucho and S. Giannarou, "Autonomous Tissue Scanning under Free-Form Motion for Intraoperative Tissue Characterisation," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11147-11154.
doi: 10.1109/ICRA40945.2020.9197294
keywords: {Three-dimensional displays;Probes;Tracking;Robots;Cameras;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197294&isnumber=9196508

N. Bira, Y. Meng√º√ß and J. R. Davidson, "3D-Printed Electroactive Hydraulic Valves for Use in Soft Robotic Applications," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11200-11206.
doi: 10.1109/ICRA40945.2020.9196993
keywords: {Valves;Erbium;Three-dimensional displays;Soft robotics;Electrodes;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196993&isnumber=9196508

T. Bitz, F. Zahedi and H. Lee, "Variable Damping Control of a Robotic Arm to Improve Trade-off between Agility and Stability and Reduce User Effort," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11259-11265.
doi: 10.1109/ICRA40945.2020.9196572
keywords: {Damping;Stability analysis;Service robots;Acceleration;Safety;Impedance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196572&isnumber=9196508

H. F. Chame and J. Tani, "Cognitive and motor compliance in intentional human-robot interaction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11291-11297.
doi: 10.1109/ICRA40945.2020.9196896
keywords: {Torque;Joints;Neural networks;Predictive models;Robot sensing systems;Stochastic processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196896&isnumber=9196508

R. Balachandran et al., "Adaptive Authority Allocation in Shared Control of Robots Using Bayesian Filters," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11298-11304.
doi: 10.1109/ICRA40945.2020.9196941
keywords: {Bayes methods;Robots;Uncertainty;Task analysis;Measurement uncertainty;Resource management;Noise measurement;Adaptive authority allocation;shared control;teleoperation;Kalman filter;Bayesian filters},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196941&isnumber=9196508

J. A. Fishel et al., "Tactile Telerobots for Dull, Dirty, Dangerous, and Inaccessible Tasks," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11305-11310.
doi: 10.1109/ICRA40945.2020.9196888
keywords: {Robot sensing systems;Haptic interfaces;Task analysis;Force;Manipulators;Electrodes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196888&isnumber=9196508

G. Li, E. Del Bianco, F. Caponetto, V. Katsageorgiou, N. G. Tsagarakis and I. Sarakoglou, "A Novel Orientability Index and the Kinematic Design of the RemoT-ARM: A Haptic Master with Large and Dexterous Workspace," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11319-11325.
doi: 10.1109/ICRA40945.2020.9196710
keywords: {Manipulators;Indexes;Haptic interfaces;Kinematics;Performance evaluation;Force;Phantoms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196710&isnumber=9196508

A. Lewis, D. Drajeske, J. Raiti, A. Berens, J. Rosen and B. Hannaford, "RAVEN-S: Design and Simulation of a Robot for Teleoperated Microgravity Rodent Dissection Under Time Delay," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11332-11337.
doi: 10.1109/ICRA40945.2020.9196691
keywords: {Tools;Task analysis;Rodents;Delay effects;Delays;Force;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196691&isnumber=9196508

G. Ye, Q. Lin, T. -H. Juang and H. Liu, "Collision-free Navigation of Human-centered Robots via Markov Games," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11338-11344.
doi: 10.1109/ICRA40945.2020.9196810
keywords: {Collision avoidance;Robots;Markov processes;Navigation;Games;Robustness;Training;Collision-free navigation;human-centered robotics;deep reinforcement learning;multi-agent system;adversarial training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196810&isnumber=9196508

A. J. Sathyamoorthy, J. Liang, U. Patel, T. Guan, R. Chandra and D. Manocha, "DenseCAvoid: Real-time Navigation in Dense Crowds using Anticipatory Behaviors," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11345-11352.
doi: 10.1109/ICRA40945.2020.9197379
keywords: {Collision avoidance;Navigation;Trajectory;Robot sensing systems;Robustness;Tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197379&isnumber=9196508

S. K. Bashetty, H. Ben Amor and G. Fainekos, "DeepCrashTest: Turning Dashcam Videos into Virtual Crash Tests for Automated Driving Systems," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11353-11360.
doi: 10.1109/ICRA40945.2020.9197053
keywords: {Three-dimensional displays;Trajectory;Cameras;Videos;Tracking;Vehicle crash testing;Data mining},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197053&isnumber=9196508

X. Wang et al., "Robotic Control of a Magnetic Swarm for On-Demand Intracellular Measurement," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11385-11391.
doi: 10.1109/ICRA40945.2020.9197532
keywords: {Coils;Magnetic devices;Magnetic separation;Magnetic resonance imaging;Magnetic particles;Signal to noise ratio;Magnetic nanoparticles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197532&isnumber=9196508

X. Guo et al., "Acoustofluidic Tweezers for the 3D Manipulation of Microparticles," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11392-11397.
doi: 10.1109/ICRA40945.2020.9197265
keywords: {Transducers;Acoustics;Force;Fluids;Three-dimensional displays;Streaming media;Hydrodynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197265&isnumber=9196508

R. Maderna, M. Poggiali, A. M. Zanchettin and P. Rocco, "An online scheduling algorithm for human-robot collaborative kitting," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11430-11435.
doi: 10.1109/ICRA40945.2020.9197431
keywords: {Task analysis;Ergonomics;Robot kinematics;Strain;Collaboration;Scheduling algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197431&isnumber=9196508

J. Svegliato, P. Sharma and S. Zilberstein, "A Model-Free Approach to Meta-Level Control of Anytime Algorithms," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11436-11442.
doi: 10.1109/ICRA40945.2020.9196898
keywords: {Learning (artificial intelligence);Autonomous systems;Planning;Heuristic algorithms;Computational modeling;Real-time systems;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196898&isnumber=9196508

J. K. Behrens, K. Stepanova and R. Babuska, "Simultaneous task allocation and motion scheduling for complex tasks executed by multiple robots," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11443-11449.
doi: 10.1109/ICRA40945.2020.9197103
keywords: {Task analysis;Robot kinematics;Planning;Collision avoidance;Job shop scheduling;Resource management;task scheduling;dual-arm manipulation;motion planning;multi-robot systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197103&isnumber=9196508

M. Collins and N. Michael, "Efficient Planning for High-Speed MAV Flight in Unknown Environments Using Online Sparse Topological Graphs," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11450-11456.
doi: 10.1109/ICRA40945.2020.9197167
keywords: {Planning;Collision avoidance;Robot sensing systems;Libraries;Safety;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197167&isnumber=9196508

N. Van Stolen, S. Hyun Kim, H. T. Tran and G. Chowdhary, "Evaluating Adaptation Performance of Hierarchical Deep Reinforcement Learning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11457-11463.
doi: 10.1109/ICRA40945.2020.9197052
keywords: {Training;Adaptation models;Trajectory;Games;Learning (artificial intelligence);Robots;Switches},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197052&isnumber=9196508

S. A. Zudaire, M. Garrett and S. Uchite, "Iterator-Based Temporal Logic Task Planning," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11472-11478.
doi: 10.1109/ICRA40945.2020.9197274
keywords: {Task analysis;Robot sensing systems;Planning;Fires;Unmanned aerial vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197274&isnumber=9196508

Y. Kantaros, M. Malencia, V. Kumar and G. J. Pappas, "Reactive Temporal Logic Planning for Multiple Robots in Unknown Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11479-11485.
doi: 10.1109/ICRA40945.2020.9197570
keywords: {Robot sensing systems;Planning;Task analysis;Heuristic algorithms;Automata},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197570&isnumber=9196508

S. Engin, E. Mitchell, D. Lee, V. Isler and D. D. Lee, "Higher Order Function Networks for View Planning and Multi-View Reconstruction," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11486-11492.
doi: 10.1109/ICRA40945.2020.9197435
keywords: {Three-dimensional displays;Image reconstruction;Planning;Cameras;Surface reconstruction;Inspection;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197435&isnumber=9196508

K. Rana, B. Talbot, V. Dasagi, M. Milford and N. S√ºnderhauf, "Residual Reactive Navigation: Combining Classical and Learned Navigation Strategies For Deployment in Unknown Environments," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11493-11499.
doi: 10.1109/ICRA40945.2020.9197386
keywords: {Navigation;Robots;Uncertainty;Training;Task analysis;Learning (artificial intelligence);Machine learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197386&isnumber=9196508

R. K. Malhan, R. Jomy Joseph, A. V. Shembekar, A. M. Kabir, P. M. Bhatt and S. K. Gupta, "Online Grasp Plan Refinement for Reducing Defects During Robotic Layup of Composite Prepreg Sheets," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11500-11507.
doi: 10.1109/ICRA40945.2020.9196876
keywords: {Trajectory;Grasping;Grippers;Robot sensing systems;Computational modeling;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196876&isnumber=9196508

M. Van der Merwe, Q. Lu, B. Sundaralingam, M. Matak and T. Hermans, "Learning Continuous 3D Reconstructions for Geometrically Aware Grasping," 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 2020, pp. 11516-11522.
doi: 10.1109/ICRA40945.2020.9196981
keywords: {Three-dimensional displays;Optimization;Collision avoidance;Grasping;Geometry;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9196981&isnumber=9196508

