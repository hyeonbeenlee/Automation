"[Front cover]," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1-2.
doi: 10.1109/ICRA.2017.7988678
Abstract: Presents the front cover or splash screen of the proceedings record.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988678&isnumber=7988677

"Welcome," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1-2.
doi: 10.1109/ICRA.2017.7988679
Abstract: Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988679&isnumber=7988677

"Organizing Committee," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1-101.
doi: 10.1109/ICRA.2017.7988680
Abstract: Provides a listing of current committee members and society officers.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988680&isnumber=7988677

"Plenary and keynote talks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 26-34.
doi: 10.1109/ICRA.2017.7988681
Abstract: These plenaries discuss the following: Modeling the possibilities: From the Chalkboard to the Race Track to the World Beyond; Nobel Turing Challenge: Grand Challenge of AI, Robotics, and Systems Biology; Framing the International Discussion on the Weaponization of Increasingly Autonomous Technologies; EndoMaster: A Surgical Robot's Journey from the Research Lab to the Operating Theatre; Capturing Vivid 3D Models of the World from Video;Industry 4.0 - Automation and Robotics; Research at the Intersection Between Robots and Play: Designing Robots for Children's Healthcare; An Operational Platform of Cloud Robotics;and Model-based Optimization for Humanoid and Wearable Robots.
keywords: {Artificial intelligence;Chemicals;Biology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988681&isnumber=7988677

"Special sessions on emerging robotics technology," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 35-90.
doi: 10.1109/ICRA.2017.7988682
Abstract: Provides an abstract for each of the presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.
keywords: {Robots;IEEE transactions;Mechatronics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988682&isnumber=7988677

"Workshop and Tutorials," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 102-124.
doi: 10.1109/ICRA.2017.7988683
Abstract: Provides an abstract for each of the presentations and a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.
keywords: {Informatics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988683&isnumber=7988677

"Program at a glance," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 125-132.
doi: 10.1109/ICRA.2017.7988684
Abstract: Provides a schedule of conference events and a listing of which papers were presented in each session.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988684&isnumber=7988677

"Index of papers presented at ICRA 2017 and published in the IEEE Robotics and Automation Letters," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1-25.
doi: 10.1109/ICRA.2017.7988685
Abstract: The following topics are dealt with: robotics; path planning; and automation.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988685&isnumber=7988677

S. Sakai, "A structure preserving nondimensionalization of hydraulic rotational joints," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 26-32.
doi: 10.1109/ICRA.2017.7988686
Abstract: This paper proposes a non-dimensional representation for hydraulic arms whose original representation is complex in terms of the nonlinear dynamics and many physical parameters. Unlike the usual nondimensional representations, the proposed nondimensional representation preserves a parametric structure in the original representation. Without loss of generality, only by changing the damping constant, the rod area, the source pressure, and the cylinder allocation, and also assuming that all the other parameters are unit, any numerical property such as the numerical existence is investigated efficiently.
keywords: {Hydraulic systems;Mathematical model;Robots;Nonlinear dynamical systems;Damping;Numerical models;Resource management},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988686&isnumber=7988677

J. Sun, Y. Zhang, C. Zhang, Z. Guo and X. Xiao, "Mechanical design of a compact Serial Variable Stiffness Actuator (SVSA) based on lever mechanism," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 33-38.
doi: 10.1109/ICRA.2017.7988687
Abstract: Compliant actuator is widely accepted for physical human-robot interaction due to its safety aspect, dynamic performance improvements and energy saving abilities. In this paper, based on the variable ratio lever mechanism, a new kind of Serial Variable Stiffness Actuator (SVSA) is proposed by using an Archimedean Spiral Relocation Mechanism (ASRM) to change the position of the pivot, implementing large range of adjustable stiffness. The ASRM introduced here makes the SVSA design has continuous stiffness adjustment ability and simply mechanical structure. Within the Variable Stiffness Mechanism (VSM), two linear springs are assembled antagonistically on a spring shaft. Their displacements are perpendicular to the output link to transmit the spring force more efficiently. Stiffness modeling and analysis of the SVSA are carried out to cover large deflection angle. The physical implementation of the SVSA shows that the output stiffness of the VSM is changed from 1.72 to 150.56 Nm/rad using a linear spring with stiffness 1882 N/m, working range covered from 0 to 360°. Control experiments also proved the wide range of stiffness adjustment ability of the SVSA.
keywords: {Springs;Force;Actuators;Spirals;Torque;Synchronous motors;Shafts},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988687&isnumber=7988677

S. Hyon, S. Tanimoto and S. Asao, "Toward compliant, fast, high-precision, and low-cost manipulator with hydraulic hybrid servo booster," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 39-44.
doi: 10.1109/ICRA.2017.7988688
Abstract: We propose a novel hydraulic hybrid servo drive for robotic applications. This method embeds a small servo-controlled pump into a hydraulic metering circuit. The circuit is compactly integrated into a servo-unit, then replicated for each joint, and connected to one common low-pressure line. Thanks to the boosting effect, one can simultaneously achieve high-load and high-precision servo control performance with low-cost components. The paper describes the principle of the new circuit and two realizations: one for a slider testbed with a single-rod cylinder, the other for a three-joint manipulator prototype. The slider experiments show that the proposed circuit can not only achieve the high piston velocity, but also exclusively generate large piston force with a small positional error up to the resolution of the servo-pump. Moreover, experiments on the manipulator demonstrate that the robot can compliantly respond to external perturbations, thanks to the high backdrivability of the servo-pump.
keywords: {Servomotors;Valves;Service robots;Pistons;Pumps},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988688&isnumber=7988677

X. Li, W. Chen and W. Lin, "Design of a structure-controlled variable stiffness actuator based on rotary flexure hinges," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 45-50.
doi: 10.1109/ICRA.2017.7988689
Abstract: This paper presents a new variable stiffness actuator (VSA) based on a structure-controlled method: controlling the mechanical structure of the actuator by rotating four flexure hinges. The VSA possesses a property that the output position and stiffness are independently controlled. This is realized by a serial arrangement of a principle driving motor, a small stiffness variation motor and a novel variable stiffness mechanism (VSM). The VSM consists of four combined notch flexure hinge frames, each of which contains an inner rotary flexure shaft and outer stationary hinge housing. The stiffness is adjusted by rotating the inner flexure shaft to change the second moment of area. Its value is independent to the VSA output angle when the flexure rotational angle is fixed. The working principle of this VSA is elaborated and the optimization mechanical design of the VSM is presented. A prototype has been implemented and its primary characteristic test results validate the design features.
keywords: {Shafts;Torque;Layout;Springs;Gears;Radio frequency;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988689&isnumber=7988677

S. Yoo, W. Lee and W. K. Chung, "Intrinsically backdrivable hydraulic servovalve for interactive robot control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 51-57.
doi: 10.1109/ICRA.2017.7988690
Abstract: There has been consistent trials to make a hydraulic actuator to be effective in interactive robot applications that require high power and durability. However, conventional strategies to obtain this goal, such as force/torque servo control or adding elastic components, suffer from complexity, sensor problems, and reduced system robustness. In this paper, we show that introducing backdrivability to hydraulic system may be an ultimate solution to constructing interactive hydraulic robot systems, by analyzing the advantages of backdrivability for this application. Moreover, we show that the backdrivability of valve-controlled hydraulic system can be achieved by adding a load pressure feedback mechanism on the spool of the servovalve, using the similarity of its dynamics structure to that of a flexible joint robot. Finally, we show that the derived backdrivable servovalve dynamics is actually the dynamics of the pressure control valve, and we report experiments that verify the analyzed advantages of backdrivability.
keywords: {Actuators;Robots;Hydraulic systems;Torque;Dynamics;Impedance;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988690&isnumber=7988677

Y. Chen, S. Le, Q. Chu Tan, O. Lau, F. Wan and C. Song, "A reconfigurable hybrid actuator with rigid and soft components," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 58-63.
doi: 10.1109/ICRA.2017.7988691
Abstract: Classical rigid-bodied robotic systems are presented with proven success in theoretical development and industrial applications, are recently challenged by the emergence of soft robotics due to a growing need in physical human-robot interactions (pHRI), such as wearable devices, medical robots, personal robots, etc. In this paper, we present the design and fabrication of a robust, hybrid bending actuator build from both rigid and soft components inspired by crustaceans, where its bending radius and axis can be mechanically programmed through the selective activation of the rigid exterior joints, actuated by the soft actuators inside. The hybrid actuator was experimentally measured in terms of bending and force tests to demonstrate the utility of this design. Finally, a case study was presented to demonstrate its capacity to adapt to specific objects geometry, anticipating its potential application in situations where compliance is the priority.
keywords: {Actuators;Force;Fabrication;Soft robotics;Robustness;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988691&isnumber=7988677

A. Spröwitz et al., "Scalable pneumatic and tendon driven robotic joint inspired by jumping spiders," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 64-70.
doi: 10.1109/ICRA.2017.7988692
Abstract: Fluidic actuators allow versatile, agile, and powerful motions and are commonly applied in robotics and automation. Likewise, many biological systems use fluidic actuators implemented with tissue for a wealth of tasks and performances. Spiders for example apply a hybrid mechanism of hydraulically actuated joint extension and muscle-based joint flexion to produce movement in two of their seven leg joints. Here, we present a novel spider-inspired joint mechanism employing both pneumatics and electrically-actuated tendons capable of strong, dynamic, and rapid joint movement. The implementation of the joint is closely inspired by those seen in real spiders, with a foldable structured membrane that effectively transfers all the energy from pressure to torque as the leg unfolds. To evaluate the mechanism we derived static joint models and a simple jumping model, and conducted equivalent experimental tests with a prototype of a single jumping leg robot. Besides applications in robot locomotion, the implementation and modeling of the spider-inspired joint mechanism can be utilized to further explore dynamics and functional biomechanics in spiders. In the future, we hope to use this platform to answer questions related to the impressive jumping and locomotion performances of real arachnids, and explore what morphological traits lie behind efficient spider locomotion at different size scales.
keywords: {Legged locomotion;Torque;Force;Muscles;Actuators;Tendons},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988692&isnumber=7988677

W. Lee and W. K. Chung, "Position-based PD control design for hydraulic robots using passive subsystems in multi-time scales," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 71-78.
doi: 10.1109/ICRA.2017.7988693
Abstract: A position-based proportional-derivative (PD) controller with inner torque feedback loops can be used as a simple controller to render compliant behaviors to hydraulic robots. However, using this control framework involves a tradeoff between the stability and performance of the closed-loop system (which includes the external environment) because the joint position sensors and control units (i.e., electrohydraulic servovalves) used in the control are separated (non-collocated) from the robot by their joint flexibility. To effectively overcome this limitation, this paper proposes a joint position-based PD control strategy for constructing an inherently stable and compliant hydraulic robot system. To this end, we use virtual internal leakage to separate the system by frequency into subsystems that include control units (i.e., servovalve), flexible joints, and robot manipulator, respectively. This architecture allows the hydraulic robot to behave as a passive system within its operating frequency region under the guidance of controllers designed to guarantee the stability of the passive subsystems within the respective frequency regions. The proposed approach was verified experimentally.
keywords: {Hydraulic systems;Torque;PD control;Impedance;Robot sensing systems;Frequency control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7988693&isnumber=7988677

K. Zhong, P. Jain and A. Kapoor, "Fast second-order cone programming for safe mission planning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 79-86.
doi: 10.1109/ICRA.2017.7989014
Abstract: This paper considers the problem of safe mission planning of dynamic systems operating under uncertain environments. Much of the prior work on achieving robust and safe control requires solving second-order cone programs (SOCP). Unfortunately, existing general purpose SOCP methods are often infeasible for real-time robotic tasks due to high memory and computational requirements imposed by existing general optimization methods. The key contribution of this paper is a fast and memory-efficient algorithm for SOCP that would enable robust and safe mission planning on-board robots in realtime. Our algorithm does not have any external dependency, can efficiently utilize warm start provided in safe planning settings, and in fact leads to significant speed up over standard optimization packages (like SDPT3) for even standard SOCP problems. For example, for a standard quadrotor problem, our method leads to speedup of 1000× over SDPT3 without any deterioration in the solution quality. Our method is based on two insights: a) SOCPs can be interpreted as optimizing a function over a polytope with infinite sides, b) a linear function can be efficiently optimized over this polytope. We combine the above observations with a novel utilization of Wolfe's algorithm [1] to obtain an efficient optimization method that can be easily implemented on small embedded devices. In addition to the above mentioned algorithm, we also design a two-level sensing method based on Gaussian Process for complex obstacles with non-linear boundaries such as a cylinder.
keywords: {Planning;Robots;Uncertainty;Optimization;Probabilistic logic;Minimization;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989014&isnumber=7988677

M. Chen, S. Herbert and C. J. Tomlin, "Exact and efficient Hamilton-Jacobi guaranteed safety analysis via system decomposition," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 87-92.
doi: 10.1109/ICRA.2017.7989015
Abstract: Hamilton-Jacobi (HJ) reachability is a method that provides rigorous analyses of the safety properties of dynamical systems. These guarantees can be provided by the computation of a backward reachable set (BRS), which represents the set of states from which the system may be driven into violating safety properties despite the system's best effort to remain safe. Unfortunately, the complexity of the BRS computation scales exponentially with the number of state dimensions. Although numerous approximation techniques are able to tractably provide conservative estimates of the BRS, they often require restrictive assumptions about system dynamics without providing an exact solution. In this paper we propose a general method for decomposing dynamical systems. Even when the resulting subsystems are coupled, relatively high-dimensional BRSs that were previously intractable or expensive to compute can now be quickly and exactly computed in lower-dimensional subspaces. As a result, the curse of dimensionality is alleviated to a large degree without sacrificing optimality. We demonstrate our theoretical results through a 3D Dubins Car model and a 6D Acrobatic Quadrotor model.
keywords: {Trajectory;Safety;System dynamics;Optimal control;Heuristic algorithms;Complexity theory;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989015&isnumber=7988677

F. Farshidian, M. Neunert, A. W. Winkler, G. Rey and J. Buchli, "An efficient optimal planning and control framework for quadrupedal locomotion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 93-100.
doi: 10.1109/ICRA.2017.7989016
Abstract: In this paper, we present an efficient Dynamic Programing framework for optimal planning and control of legged robots. First we formulate this problem as an optimal control problem for switched systems. Then we propose a multi-level optimization approach to find the optimal switching times and the optimal continuous control inputs. Through this scheme, the decomposed optimization can potentially be done more efficiently than the combined approach. Finally, we present a continuous-time constrained LQR algorithm which simultaneously optimizes the feedforward and feedback controller with O(n) time-complexity. In order to validate our approach, we show the performance of our framework on a quadrupedal robot. We choose the Center of Mass dynamics and the full kinematic formulation as the switched system model where the switching times as well as the contact forces and the joint velocities are optimized for different locomotion tasks such as gap crossing, walking and trotting.
keywords: {Optimization;Switches;Legged locomotion;Optimal control;Switched systems;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989016&isnumber=7988677

V. Dugar, S. Choudhury and S. Scherer, "A κITE in the wind: Smooth trajectory optimization in a moving reference frame," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 109-116.
doi: 10.1109/ICRA.2017.7989017
Abstract: A significant challenge for unmanned aerial vehicles capable of flying long distances is planning in a wind field. Although there has been a plethora of work on the individual topics of planning long routes, smooth trajectory optimization and planning in a wind field, it is difficult for these methods to scale to solve the combined problem. In this paper, we address the problem of planning long, dynamically feasible, time-optimal trajectories in the presence of wind (which creates a moving reference frame). We present an algorithm, κITE, that elegantly decouples the joint trajectory optimization problem into individual path optimization in a fixed ground frame and a velocity profile optimization in a moving reference frame. The key idea is to derive a decoupling framework that guarantees feasibility of the final fused trajectory. Our results show that κITE is able to produce high-quality solutions for planning with a helicopter flying at speeds of 50 m/s, handling winds up to 20 m/s and missions over 200 km. We validate our approach with real-world experiments on a full-scale helicopter with a pilot in the loop. Our approach paves the way forward for autonomous systems to exhibit pilot-like behavior when flying missions in winds aloft.
keywords: {Planning;Trajectory optimization;Helicopters;Vehicle dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989017&isnumber=7988677

L. Liu, Y. Zhou and L. Shao, "DAP3D-Net: Where, what and how actions occur in videos?," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 138-145.
doi: 10.1109/ICRA.2017.7989018
Abstract: Action parsing in videos with complex scenes is an interesting but challenging task in computer vision. In this paper, we propose a novel deep model based on 3D CNN (convolutional neural network) and LSTM (long short-term memory) module with a multi-task learning manner for effective Deep Action Parsing (DAP3D-Net) in videos. Particularly in the training phase, each action clip, sliced to several short consecutive segments, is fed into 3D CNN followed by LSTM to model the whole action dynamic information, so that action localization, classification and attributes learning can be jointly optimized via our deep model. Once the DAP3D-Net is trained, for an upcoming test video, we can describe each individual action in the video simultaneously as: Where the action occurs; What the action is and How the action is performed. To well demonstrate the effectiveness of the proposed DAP3D-Net, we also contribute a new Numerous-category Aligned Synthetic Action dataset, i.e., NASA, which consists of 200,000 action clips of 300 categories and with 33 pre-defined action attributes in two hierarchical levels (i.e., low-level attributes of basic body part movements and high-level attributes related to action motion). We learn DAP3D-Net using the NASA dataset and then evaluate it on our collected Human Action Understanding (HAU) dataset and the public THUMOS dataset. Experimental results show that our approach can accurately localize, categorize and describe multiple actions in realistic videos.
keywords: {Videos;NASA;Three-dimensional displays;Solid modeling;Data models;YouTube;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989018&isnumber=7988677

R. A. Jellal, M. Lange, B. Wassermann, A. Schilling and A. Zell, "LS-ELAS: Line segment based efficient large scale stereo matching," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 146-152.
doi: 10.1109/ICRA.2017.7989019
Abstract: We present LS-ELAS, a line segment extension to the ELAS algorithm, which increases the performance and robustness. LS-ELAS is a binocular dense stereo matching algorithm, which computes the disparities in constant time for most of the pixels in the image and in linear time for a small subset of the pixels (support points). Our approach is based on line segments to determine the support points instead of uniformly selecting them over the image range. This way we find very informative support points which preserve the depth discontinuity. The prior of our Bayesian stereo matching method is based on a set of line segments and a set of support points. Both sets are given to a constrained Delaunay triangulation to generate a triangulation mesh which is aware of possible depth discontinuities. We further increased the accuracy by using an adaptive method to sample candidate points along edge segments. We evaluated our algorithm on the Middlebury benchmark.
keywords: {Image edge detection;Image segmentation;Complexity theory;Feature extraction;Correlation;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989019&isnumber=7988677

R. Fukui, J. Schneider, T. Nishioka, S. Warisawa and I. Yamada, "Growth measurement of Tomato fruit based on whole image processing," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 153-158.
doi: 10.1109/ICRA.2017.7989020
Abstract: Crop grow measurement technologies are important to increase the farm productivity. Detection and measurement of fruit volume are useful for forecasting and harvesting applications. Some environmental challenges such as lighting conditions or occlusions make the fruit detection difficult. Our approach is based on features extraction from images through a sub-image clustering technique. Then images being described as a number of pixel in various labels are used in a regression model to estimate the fruit volume. The validity of the proposed method in experimental condition is successfully verified. The method is evaluated also in a field condition but results were inferior to the expectation. This paper tries to elucidate the reasons of the insufficient performance and tries to improve the proposed method in terms of illumination condition, precision and calculation time.
keywords: {Image color analysis;Robots;Volume measurement;Feature extraction;Sensors;Cameras;Agriculture;Field Robotics Growth measurement;Image processing;Tomato volume;Regression},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989020&isnumber=7988677

D. Su and Y. F. Li, "Development of precise mobile gaze tracking system based on online sparse Gaussian process regression and smooth-pursuit identification," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 159-164.
doi: 10.1109/ICRA.2017.7989021
Abstract: In this paper, we aim to address two challenges in the implementation of mobile gaze tracking systems, i.e., the parallax error and the inflexible calibration procedure. Our proposed method mainly involves two steps and all the calibration process can be completed without needs to receive user's commands. At first, instead of fixating at calibration points successively, users are required to fixate at one calibration point while smoothly and persistently varying the head position. In this case, the eye movements will compensate for head movements due to the activation of the smooth pursuit system. Then the PCA analysis is applied for distinguishing the smooth pursuits from other kinds of eye movements to get reliable training data. Meanwhile, a online sparse Gaussian Process using the FITC approximation is proposed to model the relationship between image pupil centers and gaze points. The next step aims to compensate the parallax error by recovering the epipolar geometry of gaze tracking systems and eyeballs. Users are asked to fixate at the points with different distances and detected parallax errors can be applied to estimate the epipolar geometry of mobile gaze trackers by solving a nonlinear optimization problem. Thus the real image gaze point with different depths can be straightforwardly estimated as the intersection point of two epipolar lines derived from binocular data. The simulation and experimental results demonstrate the effectiveness of our proposed method.
keywords: {Calibration;Head;Gaze tracking;Training data;Cameras;Mobile communication;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989021&isnumber=7988677

M. K. Paul, K. Wu, J. A. Hesch, E. D. Nerurkar and S. I. Roumeliotis, "A comparative analysis of tightly-coupled monocular, binocular, and stereo VINS," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 165-172.
doi: 10.1109/ICRA.2017.7989022
Abstract: In this paper, a sliding-window two-camera vision-aided inertial navigation system (VINS) is presented in the square-root inverse domain. The performance of the system is assessed for the cases where feature matches across the two-camera images are processed with or without any stereo constraints (i.e., stereo vs. binocular). To support the comparison results, a theoretical analysis on the information gain when transitioning from binocular to stereo is also presented. Additionally, the advantage of using a two-camera (both stereo and binocular) system over a monocular VINS is assessed. Furthermore, the impact on the achieved accuracy of different image-processing frontends and estimator design choices is quantified. Finally, a thorough evaluation of the algorithm's processing requirements, which runs in real-time on a mobile processor, as well as its achieved accuracy as compared to alternative approaches is provided, for various scenes and motion profiles.
keywords: {Cameras;Visualization;Feature extraction;Mathematical model;Simultaneous localization and mapping;Noise measurement;Time measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989022&isnumber=7988677

A. Byravan and D. Fox, "SE3-nets: Learning rigid body motion using deep neural networks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 173-180.
doi: 10.1109/ICRA.2017.7989023
Abstract: We introduce SE3-Nets which are deep neural networks designed to model and learn rigid body motion from raw point cloud data. Based only on sequences of depth images along with action vectors and point wise data associations, SE3-Nets learn to segment effected object parts and predict their motion resulting from the applied force. Rather than learning point wise flow vectors, SE3-Nets predict SE(3) transformations for different parts of the scene. Using simulated depth data of a table top scene and a robot manipulator, we show that the structure underlying SE3-Nets enables them to generate a far more consistent prediction of object motion than traditional flow based networks. Additional experiments with a depth camera observing a Baxter robot pushing objects on a table show that SE3-Nets also work well on real data.
keywords: {Three-dimensional displays;Transforms;Predictive models;Decoding;Motion segmentation;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989023&isnumber=7988677

Z. Huang, D. Zhao, H. Lam, D. J. LeBlanc and H. Peng, "Evaluation of automated vehicles in the frontal cut-in scenario — An enhanced approach using piecewise mixture models," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 197-202.
doi: 10.1109/ICRA.2017.7989024
Abstract: Evaluation and testing are critical for the development of Automated Vehicles (AVs). Currently, companies test AVs on public roads, which is very time-consuming and inefficient. We proposed the Accelerated Evaluation concept which uses a modified statistics of the surrounding vehicles and the Importance Sampling theory to reduce the evaluation time by several orders of magnitude, while ensuring the final evaluation results are accurate. In this paper, we further extend this idea by using Piecewise Mixture Distribution models instead of Single Distribution models. We demonstrate this idea to evaluate vehicle safety in lane change scenarios. The behavior of the cut-in vehicles was modeled based on more than 400,000 naturalistic driving lane changes collected by the University of Michigan Safety Pilot Model Deployment Program. Simulation results confirm that the accuracy and efficiency of the Piecewise Mixture Distribution method are better than the single distribution.
keywords: {Acceleration;Maximum likelihood estimation;Monte Carlo methods;Safety;Gaussian distribution;Probability density function;Exponential distribution;Automated vehicle;active safety;lane change;cut-in;evaluation;test},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989024&isnumber=7988677

D. Barnes, W. Maddern and I. Posner, "Find your own way: Weakly-supervised segmentation of path proposals for urban autonomy," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 203-210.
doi: 10.1109/ICRA.2017.7989025
Abstract: We present a weakly-supervised approach to segmenting proposed drivable paths in images with the goal of autonomous driving in complex urban environments. Using recorded routes from a data collection vehicle, our proposed method generates vast quantities of labelled images containing proposed paths and obstacles without requiring manual annotation, which we then use to train a deep semantic segmentation network. With the trained network we can segment proposed paths and obstacles at run-time using a vehicle equipped with only a monocular camera without relying on explicit modelling of road or lane markings. We evaluate our method on the large-scale KITTI and Oxford RobotCar datasets and demonstrate reliable path proposal and obstacle segmentation in a wide variety of environments under a range of lighting, weather and traffic conditions. We illustrate how the method can generalise to multiple path proposals at intersections and outline plans to incorporate the system into a framework for autonomous urban driving.
keywords: {Image segmentation;Cameras;Roads;Sensors;Semantics;Data collection;Laser radar},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989025&isnumber=7988677

D. Xu et al., "Ego-centric traffic behavior understanding through multi-level vehicle trajectory analysis," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 211-218.
doi: 10.1109/ICRA.2017.7989026
Abstract: This study proposes a multi-level trajectory analysis method for modeling traffic behavior from an ego-centric view, where on-road vehicle trajectories are collected based on the authors' previous studies of an on-board system consisting of multiple 2D lidar sensors. From an input set of trajectories, a set of hot regions (topics) that trajectory points most frequently present are first discovered using a sticky HDP-HMM; then, the major paths of the trajectories' transitions across different hot regions are extracted by recursively mining frequent subsequences of topics; and finally, paths are modeled using a hierarchical hidden Markov model (HHMM), where the intra-path dynamics is represented using an HMM, in which each state corresponds to a hot region, while the inter-path transition is assumed to be Markovian. The model could be used for behavior prediction, i.e. whenever a vehicle is detected in a scene, predicting which route it will probably follow and how its trajectory will probably develop over time, which is essential to interpreting the potential risks for longer time horizons. Experiments are conducted using a large set of vehicle trajectories collected from motorways in Beijing, and promising results are presented.
keywords: {Trajectory;Hidden Markov models;Analytical models;Vehicle dynamics;Predictive models;Videos;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989026&isnumber=7988677

J. Gao, Q. Wang and Y. Yuan, "Embedding structured contour and location prior in siamesed fully convolutional networks for road detection," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 219-224.
doi: 10.1109/ICRA.2017.7989027
Abstract: Road detection from the perspective of moving vehicles is a challenging issue in autonomous driving. Recently, many deep learning methods spring up for this task because they can extract high-level local features to find road regions from raw RGB data, such as Convolutional Neural Networks (CNN) and Fully Convolutional Networks (FCN). However, how to detect the boundary of road accurately is still an intractable problem. In this paper, we propose a siamesed fully convolutional network (named as “s-FCN-loc”) based on VGG-net architecture, which is able to consider RGB-channel, semantic contour and location prior simultaneously to segment road region elaborately. To be specific, the s-FCN-loc has two streams to process original RGB images and contour maps respectively. At the same time, the location prior is directly appended to the last feature map to promote the final detection performance. Experiments demonstrate that the proposed s-FCN-loc can learn more discriminative features of road boundaries and converge 30% faster than the original FCN during the training stage. Finally, the proposed approach is evaluated on KITTI road detection benchmark, and achieves a competitive result.
keywords: {Roads;Semantics;Feature extraction;Streaming media;Image segmentation;Training;Image edge detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989027&isnumber=7988677

V. Cardoso et al., "A Model-Predictive Motion Planner for the IARA autonomous car," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 225-230.
doi: 10.1109/ICRA.2017.7989028
Abstract: We present the Model-Predictive Motion Planner (MPMP) of the Intelligent Autonomous Robotic Automobile (IARA). IARA is a fully autonomous car that uses a path planner to compute a path from its current position to the desired destination. Using this path, the current position, a goal in the path and a map, IARA's MPMP is able to compute smooth trajectories from its current position to the goal in less than 50 ms. MPMP computes the poses of these trajectories so that they follow the path closely and, at the same time, are at a safe distance of occasional obstacles. Our experiments have shown that MPMP is able to compute trajectories that precisely follow a path produced by a Human driver (distance of 0.15 m in average) while smoothly driving IARA at speeds of up to 32.4 km/h (9 m/s).
keywords: {Trajectory;Automobiles;Computational modeling;Mathematical model;Hardware;Planning;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989028&isnumber=7988677

A. Scheel, S. Reuter and K. Dietmayer, "Vehicle tracking using extended object methods: An approach for fusing radar and laser," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 231-238.
doi: 10.1109/ICRA.2017.7989029
Abstract: Combining data from heterogeneous sensors allows to enhance tracking systems by increasing the field of view, incorporating redundancy, and improving the performance by exploiting complementary sensor characteristics. This paper proposes a new vehicle tracking approach for vehicle environment perception that fuses radar and laser data. A Random-Finite-Set-based tracking filter, which permits a clear mathematical formulation of the multi-object problem, is used as fusion center. In combination with extended object measurement models that work on the raw sensor data directly, the filter uses all available information without the need for further preprocessing routines, considers object interdependencies, and works in ambiguous situations. The results are evaluated using experimental data from a test vehicle.
keywords: {Radar tracking;Laser radar;Sensors;Measurement by laser beam;Laser fusion;Laser modes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989029&isnumber=7988677

A. L. Ballardini, D. Cattaneo, S. Fontana and D. G. Sorrenti, "An online probabilistic road intersection detector," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 239-246.
doi: 10.1109/ICRA.2017.7989030
Abstract: In this paper we propose a probabilistic approach for detecting and classifying urban road intersections from a moving vehicle. The approach is based on images from an onboard stereo rig; it relies on the detection of the road ground plane on one side, and on a pixel-level classification of the road on the other. The two processing pipelines are then integrated and the parameters of the road components, i.e., the intersection geometry, are inferred. As opposed to other state-of-the-art offline methods, which require processing of the whole video sequence, our approach integrates the image data by means of an online procedure. The experiments have been performed on well-known KITTI datasets, allowing for future comparisons.
keywords: {Roads;Three-dimensional displays;Image reconstruction;Pipelines;Probabilistic logic;Detectors;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989030&isnumber=7988677

S. Noh and K. An, "Risk assessment for automatic lane change maneuvers on highways," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 247-254.
doi: 10.1109/ICRA.2017.7989031
Abstract: This paper presents a risk assessment algorithm for automatic lane change maneuvers on highways. It is capable of reliably assessing a given highway situation in terms of the possibility of collisions and robustly giving a recommendation for lane changes. The algorithm infers potential collision risks of observed vehicles based on Bayesian networks considering uncertainties of its input data. It utilizes two complementary risk metrics (time-to-collision and minimal safety margin) in temporal and spatial aspects to cover all risky situations that can occur for lane changes. In addition, it provides a robust recommendation for lane changes by filtering out uncertain noise data pertaining to vehicle tracking. The validity of the algorithm is tested and evaluated on public highways in real traffic as well as a closed high-speed test track in simulated traffic through in-vehicle testing based on overtaking and overtaken scenarios in order to demonstrate the feasibility of the risk assessment for automatic lane change maneuvers on highways.
keywords: {Measurement;Risk management;Road transportation;Uncertainty;Safety;Cognition;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989031&isnumber=7988677

S. H. Turlapati, A. Srivastava, K. M. Krishna and S. V. Shah, "Detachable modular robot capable of cooperative climbing and multi agent exploration," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 255-260.
doi: 10.1109/ICRA.2017.7989032
Abstract: At the cross section of the fields of Uneven Terrain Navigation and Multi Agent Systems (MAS), in this work, a Detachable Compliant Modular Robot (DCMR) which can perform concurrent scene exploration by detaching into numerous parts, while preserving its ability to climb stairs is proposed and built. A spring is designed and used in the modular robot taking the worst-case-scenario of stairs encountered in an urban setting. In addition to the actuators at the wheels, an additional set of actuators per module are introduced to enable the detachment and re-attachment. The design additions and their trade-offs are discussed. Potential applications are presented with special focus on improving coverage of a map with obstacles/slabs large enough to merit exploration by climbing them. The problem of turning in crammed spaces is solved using the ability to detach of DCMR. The detaching & re-attaching capability, and stair climbing of the composite modular robot are demonstrated through experimentation using the prototype.
keywords: {Robot kinematics;Wheels;Springs;Servomotors;Stability analysis;Fasteners},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989032&isnumber=7988677

G. López-Nicolás, M. Aranda and Y. Mezouar, "Formation of differential-drive vehicles with field-of-view constraints for enclosing a moving target," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 261-266.
doi: 10.1109/ICRA.2017.7989033
Abstract: An emerging application of multirobot systems is the monitoring of a dynamic event. Here, the goal is to enclose and track a moving target by attaining a desired geometric formation around it. By considering a circular pattern configuration for the target enclosing, the multirobot system is able to perform full perception of the target along its motion. In the proposed system, the robots rely only on their onboard vision sensor without external input to complete the task. The key problem resides in overcoming the motion and visual constraints of the agents. In particular, differential-drive robots with limited sensing, that must maintain visibility of the moving target as it navigates in the environment, are considered. A novel approach to characterize the motion of the robots in the formation that allows to enclose and track the target while overcoming their limited field of view (FOV) is presented. The proposed approach is illustrated through simulations.
keywords: {Robot kinematics;Cameras;Robot vision systems;Target tracking;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989033&isnumber=7988677

C. Vrohidis, C. P. Bechlioulis and K. J. Kyriakopoulos, "Safe decentralized and reconfigurable multi-agent control with guaranteed convergence," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 267-272.
doi: 10.1109/ICRA.2017.7989034
Abstract: In this paper, we consider a networked multi-robot system operating in an obstacle populated planar workspace under a single leader-multiple followers architecture. We propose a decentralized reconfiguration strategy of the set of connectivity and formation specifications that assures convergence to the desired point, while guaranteeing global connectivity. In particular, we construct a low-level Decentralized Navigation Functions based controller that encodes the goals and safety requirements of the system. However, owing to topological obstructions, stable critical points other than the desired one may appear. In such case, we employ a high-level distributed discrete procedure which attempts to solve a Distributed Constraint Satisfaction Problem on a local Voronoi partition, providing the necessary reconfiguration for the system to progress towards its goal. Eventually, we show that the system either converges to the desired point or attains a tree configuration with respect to the formation topology, in which case the system switches to a novel controller based on the Prescribed Performance technique, that eventually guarantees convergence. Finally, a simulation study clarifies and verifies the approach.
keywords: {Convergence;Navigation;Safety;Robot sensing systems;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989034&isnumber=7988677

A. Jahn, R. J. Alitappeh, D. Saldaña, L. C. A. Pimenta, A. G. Santos and M. F. M. Campos, "Distributed multi-robot coordination for dynamic perimeter surveillance in uncertain environments," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 273-278.
doi: 10.1109/ICRA.2017.7989035
Abstract: In this work, multiple robots circulate around the boundary of a desired region in order to create a virtual fence. The aim of the this fence is to avoid internal or external agents crossing through the delimited area. In this paper, we propose a distributed technique that allows a team of robots to plan the deformation of the boundary shape in order to escort the safe region from one place to a goal. Our proposal is composed of two parts. First, we present a distributed planning method for the dynamic boundary. We model the resulting plan as a twice differentiable function. Second, we use the obtained function to guide the robot team, where every member uses only local information for the controller. The robots distribute themselves along the time-varying perimeter and patrol around it. We show in simulation how the robots behave in partially/totally unknown environments with static obstacles.
keywords: {Shape;Robot kinematics;Trajectory;Planning;Robot sensing systems;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989035&isnumber=7988677

M. Guo and M. M. Zavlanos, "Distributed data gathering with buffer constraints and intermittent communication," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 279-284.
doi: 10.1109/ICRA.2017.7989036
Abstract: We consider a team of multiple dynamical and heterogeneous robots which are deployed for gathering different types of data within a common workspace. The robots have different roles due to different capabilities: some gather data from the workspace (Type-A robots) and others receive data from Type-A robots and upload them to a data center (Type-B robots). The data-gathering tasks are specified locally to each Type-A robot as high-level Linear Temporal Logic (LTL) formulas. All robots have a limited buffer to store the data. Thus the data gathered by Type-A robots should be transferred to Type-B robots before the buffers overflow, respecting at the same time limited communication range for all robots. The main contribution of this work is a distributed task coordination and intermittent meeting scheme that guarantees the satisfaction of all local tasks while obeying the above constraints. We present numerical simulations to demonstrate the advantages of the proposed method over most existing approaches that require all-time network connectivity.
keywords: {Robot kinematics;Buffer storage;Collision avoidance;Data transfer;Temperature sensors;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989036&isnumber=7988677

Y. F. Chen, M. Liu, M. Everett and J. P. How, "Decentralized non-communicating multiagent collision avoidance with deep reinforcement learning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 285-292.
doi: 10.1109/ICRA.2017.7989037
Abstract: Finding feasible, collision-free paths for multiagent systems can be challenging, particularly in non-communicating scenarios where each agent's intent (e.g. goal) is unobservable to the others. In particular, finding time efficient paths often requires anticipating interaction with neighboring agents, the process of which can be computationally prohibitive. This work presents a decentralized multiagent collision avoidance algorithm based on a novel application of deep reinforcement learning, which effectively offloads the online computation (for predicting interaction patterns) to an offline learning procedure. Specifically, the proposed approach develops a value network that encodes the estimated time to the goal given an agent's joint configuration (positions and velocities) with its neighbors. Use of the value network not only admits efficient (i.e., real-time implementable) queries for finding a collision-free velocity vector, but also considers the uncertainty in the other agents' motion. Simulation results show more than 26% improvement in paths quality (i.e., time to reach the goal) when compared with optimal reciprocal collision avoidance (ORCA), a state-of-the-art collision avoidance strategy.
keywords: {Collision avoidance;Learning (artificial intelligence);Kinematics;Decision making;Real-time systems;Navigation;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989037&isnumber=7988677

R. K. Williams, A. Gasparri and G. Ulivi, "Decentralized matroid optimization for topology constraints in multi-robot allocation problems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 293-300.
doi: 10.1109/ICRA.2017.7989038
Abstract: In this paper, we demonstrate how topological constraints, as well as other abstract constraints, can be integrated into task allocation by applying the combinatorial theory of matroids. By modeling problems as an intersection of matroid constraints, arbitrary combinatorial relationships can be achieved in the task allocation space. To illustrate the expressiveness of the framework, we model a novel task allocation problem that couples abstract per-robot constraints with a communication spanning tree constraint. As our problem is cast as a matroid intersection, provable optimality bounds with simple greedy algorithms follows immediately from theory. Next, we present a decentralized algorithm that applies auction methods to task allocation with matroid intersections. Simulations of task allocation for surveillance in urban environments demonstrate our results. Finally, Monte Carlo results are provided that indicate greedy task allocations can be highly competitive even with near-optimal solutions in practice.
keywords: {Resource management;Greedy algorithms;Optimization;Robot sensing systems;Surveillance;Multi-robot systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989038&isnumber=7988677

H. Lin, P. Ray and M. Howard, "Learning task constraints in operational space formulation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 309-315.
doi: 10.1109/ICRA.2017.7989039
Abstract: Many human skills can be described in terms of performing a set of prioritised tasks. While a number of tools have become available that recover the underlying control policy from constrained movements, few have explicitly considered learning how constraints should be imposed in order to perform the control policy. In this paper, a method for learning the self-imposed constraints present in movement observations is proposed. The problem is formulated into the operational space control framework, where the goal is to estimate the constraint matrix and its null space projection that decompose the task space and any redundant degrees of freedom. The proposed method requires no prior knowledge about either the dimensionality of the constraints nor the underlying control policies. The techniques are evaluated on a simulated three degree-of-freedom arm and on the AR10 humanoid hand.
keywords: {Aerospace electronics;Null space;Pressing;Glass;Linear programming;Redundancy;Jacobian matrices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989039&isnumber=7988677

M. Karlsson, A. Robertsson and R. Johansson, "Autonomous interpretation of demonstrations for modification of dynamical movement primitives," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 316-321.
doi: 10.1109/ICRA.2017.7989040
Abstract: The concept of dynamical movement primitives (DMPs) has become popular for modeling of motion, commonly applied to robots. This paper presents a framework that allows a robot operator to adjust DMPs in an intuitive way. Given a generated trajectory with a faulty last part, the operator can use lead-through programming to demonstrate a corrective trajectory. A modified DMP is formed, based on the first part of the faulty trajectory and the last part of the corrective one. A real-time application is presented and verified experimentally.
keywords: {Trajectory;Manipulators;Learning (artificial intelligence);Education;Collision avoidance;Niobium},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989040&isnumber=7988677

C. D. McKinnon and A. P. Schoellig, "Learning multimodal models for robot dynamics online with a mixture of Gaussian process experts," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 322-328.
doi: 10.1109/ICRA.2017.7989041
Abstract: For decades, robots have been essential allies alongside humans in controlled industrial environments like heavy manufacturing facilities. However, without the guidance of a trusted human operator to shepherd a robot safely through a wide range of conditions, they have been barred from the complex, ever changing environments that we live in from day to day. Safe learning control has emerged as a promising way to start bridging algorithms based on first principles to complex real-world scenarios by using data to adapt, and improve performance over time. Safe learning methods rely on a good estimate of the robot dynamics and of the bounds on modelling error in order to be effective. Current methods focus on either a single adaptive model, or a fixed, known set of models for the robot dynamics. This limits them to static or slowly changing environments. This paper presents a method using Gaussian Processes in a Dirichlet Process mixture model to learn an increasing number of non-linear models for the robot dynamics. We show that this approach enables a robot to re-use past experience from an arbitrary number of previously visited operating conditions, and to automatically learn a new model when a new and distinct operating condition is encountered. This approach improves the robustness of existing Gaussian Process-based models to large changes in dynamics that do not have to be specified ahead of time.
keywords: {Robots;Data models;Heuristic algorithms;Aerodynamics;System dynamics;Gaussian processes;Safety},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989041&isnumber=7988677

F. Abi-Farraj, T. Osa, N. P. J. Peters, G. Neumann and P. R. Giordano, "A learning-based shared control architecture for interactive task execution," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 329-335.
doi: 10.1109/ICRA.2017.7989042
Abstract: Shared control is a key technology for various robotic applications in which a robotic system and a human operator are meant to collaborate efficiently. In order to achieve efficient task execution in shared control, it is essential to predict the desired behavior for a given situation or context in order to simplify the control task for the human operator. This prediction is obtained by exploiting Learning from Demonstration (LfD), which is a popular approach for transferring human skills to robots. We encode the demonstrated behavior as trajectory distributions and generalize the learned distributions to new situations. The goal of this paper is to present a shared control framework that uses learned expert distributions to gain more autonomy. Our approach controls the balance between the controller's autonomy and the human preference based on the distributions of the demonstrated trajectories. Moreover, the learned distributions are autonomously refined from collaborative task executions, resulting in a master-slave system with increasing autonomy that requires less user input with an increasing number of task executions. We experimentally validated that our shared control approach enables efficient task executions. Moreover, the conducted experiments demonstrated that the developed system improves its performances through interactive task executions with our shared control.
keywords: {Trajectory;Manipulators;Force feedback;Adaptation models;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989042&isnumber=7988677

A. Tamar, G. Thomas, T. Zhang, S. Levine and P. Abbeel, "Learning from the hindsight plan — Episodic MPC improvement," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 336-343.
doi: 10.1109/ICRA.2017.7989043
Abstract: Model predictive control (MPC) is a popular control method that has proved effective for robotics, among other fields. MPC performs re-planning at every time step. Re-planning is done with a limited horizon per computational and real-time constraints and often also for robustness to potential model errors. However, the limited horizon leads to suboptimal performance. In this work, we consider the iterative learning setting, where the same task can be repeated several times, and propose a policy improvement scheme for MPC. The main idea is that between executions we can, offline, run MPC with a longer horizon, resulting in a hindsight plan. To bring the next real-world execution closer to the hindsight plan, our approach learns to re-shape the original cost function with the goal of satisfying the following property: short horizon planning (as realistic during real executions) with respect to the shaped cost should result in mimicking the hindsight plan. This effectively consolidates long-term reasoning into the short-horizon planning. We empirically evaluate our approach in contact-rich manipulation tasks both in simulated and real environments, such as peg insertion by a real PR2 robot.
keywords: {Planning;Robots;Trajectory;Heuristic algorithms;System dynamics;Optimal control;Standards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989043&isnumber=7988677

K. Pereida, R. R. P. R. Duivenvoorden and A. P. Schoellig, "High-precision trajectory tracking in changing environments through L1 adaptive feedback and iterative learning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 344-350.
doi: 10.1109/ICRA.2017.7989044
Abstract: As robots and other automated systems are introduced to unknown and dynamic environments, robust and adaptive control strategies are required to cope with disturbances, unmodeled dynamics and parametric uncertainties. In this paper, we propose and provide theoretical proofs of a combined L1 adaptive feedback and iterative learning control (ILC) framework to improve trajectory tracking of a system subject to unknown and changing disturbances. The L1 adaptive controller forces the system to behave in a repeatable, predefined way, even in the presence of unknown and changing disturbances; however, this does not imply that perfect trajectory tracking is achieved. ILC improves the tracking performance based on experience from previous executions. The performance of ILC is limited by the robustness and repeatability of the underlying system, which, in this approach, is handled by the L1 adaptive controller. In particular, we are able to generalize learned trajectories across different system configurations because the L1 adaptive controller handles the underlying changes in the system. We demonstrate the improved trajectory tracking performance and generalization capabilities of the combined method compared to pure ILC in experiments with a quadrotor subject to unknown, dynamic disturbances. This is the first work to show L1 adaptive control combined with ILC in experiment.
keywords: {Adaptive control;Trajectory tracking;Aerodynamics;Output feedback;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989044&isnumber=7988677

A. M. Kabir, J. D. Langsfeld, C. Zhuang, K. N. Kaipa and S. K. Gupta, "A systematic approach for minimizing physical experiments to identify optimal trajectory parameters for robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 351-357.
doi: 10.1109/ICRA.2017.7989045
Abstract: Use of robots is rising in process applications where robots need to interact with parts using tools. Representative examples can be cleaning, polishing, grinding, etc. These tasks can be non-repetitive in nature and the physics-based models of the task performances are unknown for new materials and tools. In order to reduce operation cost and time, the robot needs to identify and optimize the trajectory parameters. The trajectory parameters that influence the performance can be speed, force, torque, stiffness, etc. Building physics-based models may not be feasible for every new task, material, and tool profile as it will require conducting a large number of experiments. We have developed a method that identifies the right set of parameters to optimize the task objective and meet performance constraints. The algorithm makes decisions based on uncertainty in the surrogate model of the task performance. It intelligently samples the parameter space and selects a point for experimentation from the sampled set by determining its probability to be optimum among the set. The iterative process leads to rapid convergence to the optimal point with a small number of experiments. We benchmarked our method against other optimization methods on synthetic problems. The method has been validated by conducting physical experiments on a robotic cleaning problem. The algorithm is general enough to be applied to any optimization problem involving black box constraints.
keywords: {Robots;Optimization;Trajectory;Tools;Force;Cleaning;Buildings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989045&isnumber=7988677

M. Laskey et al., "Comparing human-centric and robot-centric sampling for robot deep learning from demonstrations," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 358-365.
doi: 10.1109/ICRA.2017.7989046
Abstract: Motivated by recent advances in Deep Learning for robot control, this paper considers two learning algorithms in terms of how they acquire demonstrations from fallible human supervisors. Human-Centric (HC) sampling is a standard supervised learning algorithm, where a human supervisor demonstrates the task by teleoperating the robot to provide trajectories consisting of state-control pairs. Robot-Centric (RC) sampling is an increasingly popular alternative used in algorithms such as DAgger, where a human supervisor observes the robot execute a learned policy and provides corrective control labels for each state visited. We suggest RC sampling can be challenging for human supervisors and prone to mislabeling. RC sampling can also induce error in policy performance because it repeatedly visits areas of the state space that are harder to learn. Although policies learned with RC sampling can be superior to HC sampling for standard learning models such as linear SVMs, policies learned with HC sampling may be comparable to RC when applied to expressive learning models such as deep learning and hyper-parametric decision trees, which can achieve very low training error provided there is enough data. We compare HC and RC using a grid world environment and a physical robot singulation task. In the latter the input is a binary image of objects on a planar worksurface and the policy generates a motion in the gripper to separate one object from the rest. We observe in simulation that for linear SVMs, policies learned with RC outperformed those learned with HC but that using deep models this advantage disappears. We also find that with RC, the corrective control labels provided by humans can be highly inconsistent. We prove there exists a class of examples in which at the limit, HC is guaranteed to converge to an optimal policy while RC may fail to converge. These results suggest a form of HC sampling may be preferable for highly-expressive learning models and human supervisors.
keywords: {Trajectory;Training;Robot sensing systems;Loss measurement;Aerospace electronics;Standards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989046&isnumber=7988677

H. Liu, Y. Wu, F. Sun, D. Guo and B. Fang, "Multi-label tactile property analysis," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 366-371.
doi: 10.1109/ICRA.2017.7989047
Abstract: In this paper, we exploit the intrinsic relation between different adjective labels and develop a novel multilabel dictionary learning and sparse coding method which is improved by introducing the structured output association information. Such a method makes use of the label correlation information and is more suitable for the multi-label tactile understanding task. In addition, we develop a globally-convergent iterative algorithms to solve the dictionary learning problem. Finally, we perform extensive experimental validations on the public available tactile sequence dataset PHAC-2 and show the advantages of the proposed method.
keywords: {Dictionaries;Kernel;Optimization;Encoding;Correlation;Training;Silicon},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989047&isnumber=7988677

A. G. Eguíluz, I. Rañó, S. A. Coleman and T. M. McGinnity, "Reliable object handover through tactile force sensing and effort control in the Shadow Robot hand," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 372-377.
doi: 10.1109/ICRA.2017.7989048
Abstract: A fundamental problem in cooperative HumanRobot Interaction is object handover. Existing works in this area assume the human can reliably grasp the object from the robot hand. However, in some situations the human can produce perturbing forces in the object that are not meant to end in a handover. These perturbations can result in the object being dropped or the robot hand being damaged. This paper addresses this problem and presents a mechanism for reliable robot to human object handover implemented in a Shadow Robot hand endowed with tactile sensing. Given a stable grasping configuration, using BioTAC sensors we are able to estimate the contact forces applied to the object, and provide a feedback signal to a joint effort controller to maintain grasp forces despite perturbations. Our system is able to identify between object pulling forces which should result in an object handover, and other disturbances. Experimental results show that the hand releases the object only when the object is pulled, validating the proposed algorithm.
keywords: {Force;Handover;Robot sensing systems;Grasping;Reliability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989048&isnumber=7988677

B. Saund, S. Chen and R. Simmons, "Touch based localization of parts for high precision manufacturing," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 378-385.
doi: 10.1109/ICRA.2017.7989049
Abstract: Performing detailed work on objects requires precise localization. Currently humans aid machines in localization either by direct operation, or implicitly by designing a sequence of actions a robot follows. Our approach to automate localization is to reason over many potential actions, perform the best information gathering action, and then use the measurement obtained to update a non-Gaussian belief. We propose a method for autonomous localization of objects with initial 6DOF uncertainty capable of reasoning about and performing measurements with low uncertainty and arbitrary error models. Surprisingly, common methods capable of modeling arbitrary belief distributions perform poorly as measurement uncertainty decreases, so we modify a particle filter to handle these accurate measurements produced by tactile or laser sensors. We then show how the expected information gain of the proposed measurement can be calculated efficiently from these particles. We present experiments, both in simulation and on hardware, that show our method is both fast and accurate.
keywords: {Atmospheric measurements;Particle measurements;Robot sensing systems;Measurement uncertainty;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989049&isnumber=7988677

R. Balachandran, M. Jorda, J. Artigas, J. Ryu and O. Khatib, "Passivity-based stability in explicit force control of robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 386-393.
doi: 10.1109/ICRA.2017.7989050
Abstract: Direct force control of robots is challenging, particularly since the interaction with the environment can render the robot unstable. This paper presents the results of novel approaches for passivity-based stability for a particular direct force control method, namely explicit force control. A step-by-step procedure to passivate and stabilise the control loop is presented and it explains how Time Domain Passivity Approach, a passivity-based tool widely used in teleoperation and haptics has been extended and applied in explicit force control. The electrical circuit and network-port representations derived in the process allows the analytical evaluation of the system and can be applied in other control architectures as well. The stability methods are presented both qualitatively and quantitatively with simulations and hardware experiments. A discussion about the results obtained and the energy behavior is also provided. Results are promising and suggest that these methods can be used for stable and high-bandwidth force control of robotic manipulators.
keywords: {Force;Force control;Robots;Iron;Stability criteria;Ports (Computers)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989050&isnumber=7988677

F. Bergner, E. Dean-Leon and G. Cheng, "Efficient event-driven reactive control for large scale robot skin," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 394-400.
doi: 10.1109/ICRA.2017.7989051
Abstract: In this work we present a novel efficient event-driven reactive skin controller for large scale robot skin. The novel event-driven controller derives from a standard Jacobian torque controller and fully takes advantage of our multi-modal event-driven robot skin. Event-driven systems only sample, transmit and process information when the novelty of the information is guaranteed. This increases their efficiency in comparison to synchronous systems. We also use the new event-driven controller formulation to design a new synchronous reactive skin controller. We compare both controllers in a comprehensive performance evaluation with our robot TOMM. TOMM has two UR5 robot arms, each covered with 253 multi-modal skin cells. Each skin cell samples 4 different modalities and supports data mode and event mode. The results show that the event-driven reactive skin controller always outperforms the synchronous reference controller while both controllers show exactly the same response. When the robot is not moving then the event-driven controller reduces the CPU usage by 78% in comparison to the synchronous reference controller. When the robot is responding to contacts then the CPU usage reduces by 66%.
keywords: {Skin;Robot sensing systems;Torque;Robot kinematics;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989051&isnumber=7988677

J. Kangro, S. Traversaro, D. Pucci and F. Nori, "Skin normal force calibration using vacuum bags," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 401-406.
doi: 10.1109/ICRA.2017.7989052
Abstract: This paper presents a proof of concept to calibrate iCub's skin using vacuum bags. The main idea of the method consists of inserting the skin, made of distributed capacitive sensors, in a vacuum bag and then decreasing the pressure in the bag to create a uniform pressure distribution on the skin surface. The capacitance changes of each sensor were then related to the applied differential pressure using a least square fitting with a fifth order polynomial model. After calibration, integration of the pressure distribution over the skin geometry provides us with the net normal force applied to the skin. Experiments were conducted using the forearm skin of the iCub humanoid robot and the calibration results were validated using standard weights. The validation results indicate acceptable average errors in force prediction.
keywords: {Skin;Force;Calibration;Capacitance;Dielectrics;Tactile sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989052&isnumber=7988677

T. -H. -L. Le, A. Maslyczyk, J. -P. Roberge and V. Duchaine, "A highly sensitive multimodal capacitive tactile sensor," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 407-412.
doi: 10.1109/ICRA.2017.7989053
Abstract: As technology develops, manufacture process becomes more and more automated using robots. There is demand for high performance tactile sensor which can support robotic grippers in manipulation tasks especially for unstructured flexible objects. Despite the efforts that have been spent, the fabrication process of those functional sensor remains complicated due to their requirement of specialized materials and equipment. The proposed multimodal sensor overcomes the difficulty by enhancing the electrical and mechanical design therefore simplifying the manufacture steps. In this version, static and dynamic sensing are integrated in the same layer of capacitive sensor with direct written microstructured dielectric. This structure allows it to have large range of force sensing as well as the ability of detecting contact events such as slippage or losing of contact.
keywords: {Dielectrics;Robot sensing systems;Capacitance;Dynamics;Capacitive sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989053&isnumber=7988677

D. P. Losey and M. K. O'Malley, "Effects of discretization on the K-width of series elastic actuators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 421-426.
doi: 10.1109/ICRA.2017.7989054
Abstract: Rigid haptic devices enable humans to physically interact with virtual environments, and the range of impedances that can be safely rendered using these rigid devices is quantified by the Z-Width metric. Series elastic actuators (SEAs) similarly modulate the impedance felt by the human operator when interacting with a robotic device, and, in particular, the robot's perceived stiffness can be controlled by changing the elastic element's equilibrium position. In this paper, we explore the K-Width of SEAs, while specifically focusing on how discretization inherent in the computer-control architecture affects the system's passivity. We first propose a hybrid model for a single degree-of-freedom (DoF) SEA based on prior hybrid models for rigid haptic systems. Next, we derive a closed-form bound on the K-Width of SEAs that is a generalization of known constraints for both rigid haptic systems and continuous time SEA models. This bound is first derived under a continuous time approximation, and is then numerically supported with discrete time analysis. Finally, experimental results validate our finding that large pure masses are the most destabilizing operator in human-SEA interactions, and demonstrate the accuracy of our theoretical K-Width bound.
keywords: {Haptic interfaces;Actuators;Robots;Force;Numerical models;Impedance;Springs},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989054&isnumber=7988677

M. Raitor, J. M. Walker, A. M. Okamura and H. Culbertson, "WRAP: Wearable, restricted-aperture pneumatics for haptic guidance," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 427-432.
doi: 10.1109/ICRA.2017.7989055
Abstract: Wearable haptic feedback devices for virtual reality, human-robot interaction, and motion guidance require lightweight actuators that display clearly discernible cues to the user. These goals motivate the design of WRAP, a wearable, pneumatically actuated haptic feedback device. WRAP displays a variety of tactile sensations to the user by inflating a thermoplastic pneumatic actuator in direct contact with the skin. This paper describes the design and construction of WRAP, shows its effectiveness in indicating direction cues to users, and demonstrates two other appUcations for WRAP in image-guided medical interventions and human-computer interaction. Users were able to identify translation and rotation cues from WRAP with 99.4% accuracy. Our results suggest that WRAP is suitable for a variety of wearable and portable applications in which direction cues are beneficial.
keywords: {Haptic interfaces;Pneumatic actuators;Skin;Wrist;Vibrations;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989055&isnumber=7988677

A. Hagengruber, H. Höppner and J. Vogel, "Blindfolded robotic teleoperation using spatial force feedback to the toe," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 433-438.
doi: 10.1109/ICRA.2017.7989056
Abstract: This paper examines the capability to incorporate spatial force feedback to the human toe when teleoperating a robotic arm in a force task. Due to the growing complexity of teleoperated systems new means of feedback get increasingly important. To investigate the viability of spatial toe-feedback, experiments with 12 subjects were conducted. The participants had to teleoperate a DLR Light-Weight Robot (LWR) via optical tracking of one finger in order to push a toy train. The orientation of the rail was unknown to the subject and had to be explored using the haptic feedback - a three-dimensional spatial force to the toe, reflecting the contact forces at the robotic end-effector - in absence of visual feedback. The rail was mounted in one of four possible orientations (differences of 45°). The main task of the experiment was to identify the present orientation. In our study subjects could successfully identify the orientation of the rail in more than two thirds of all trials (68%). In almost half of the trials (44%) the subjects were able to move the train along the rails long enough to reach the bumpers at the end and identify them as such. Assuming no feedback would be provided at all, the first metric has a chance level of 25%, and reaching the bumper can be considered impossible. Thus, we can conclude that humans can incorporate spatial force feedback to the toe into their sensorimotor loop.
keywords: {Rails;Force;Robot sensing systems;Force feedback;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989056&isnumber=7988677

A. Burka, A. Rajvanshi, S. Allen and K. J. Kuchenbecker, "Proton 2: Increasing the sensitivity and portability of a visuo-haptic surface interaction recorder," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 439-445.
doi: 10.1109/ICRA.2017.7989057
Abstract: The Portable Robotic Optical/Tactile ObservatioN PACKage (PROTONPACK, or Proton for short) is a new handheld visuo-haptic sensing system that records surface interactions. We previously demonstrated system calibration and a classification task using external motion tracking. This paper details improvements in surface classification performance and removal of the dependence on external motion tracking, necessary before embarking on our goal of gathering a vast surface interaction dataset. Two experiments were performed to refine data collection parameters. After adjusting the placement and filtering of the Proton's high-bandwidth accelerometers, we recorded interactions between two differently-sized steel tooling ball end-effectors (diameter 6.35 and 9.525 mm) and five surfaces. Using features based on normal force, tangential force, end-effector speed, and contact vibration, we trained multi-class SVMs to classify the surfaces using 50 ms chunks of data from each end-effector. Classification accuracies of 84.5% and 91.5% respectively were achieved on unseen test data, an improvement over prior results. In parallel, we pursued on-board motion tracking, using the Proton's camera and fiducial markers. Motion tracks from the external and onboard trackers agree within 2 mm and 0.01 rad RMS, and the accuracy decreases only slightly to 87.7% when using onboard tracking for the 9.525 mm end-effector. These experiments indicate that the Proton 2 is ready for portable data collection.
keywords: {Protons;Robot sensing systems;Accelerometers;Tracking;Force;Vibrations;Plastics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989057&isnumber=7988677

M. Kim, J. Kim, Y. Lee and D. Lee, "On the passivity of mechanical integrators in haptic rendering," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 446-452.
doi: 10.1109/ICRA.2017.7989058
Abstract: We propose a novel haptic rendering scheme based on passive midpoint integrator (PMI), which is an extension of our prior non-iterative passive mechanical integrator (NPMI) to maximal coordinates for simulation of complex articulated rigid bodies and to multi-point intermittent contact with the linear complementarity problem (LCP) formulation incorporated. The proposed PMI-based haptic rendering then can stably simulate mechanical systems with wide-range of parameters/updaterates (in contrast to semi-implicit Euler integrator), while maintaining losslessness of simple harmonic oscillation (in contrast to implicit Euler integrator), as compared in this paper. Application of this PMI-based haptic rendering is also presented for multi-user virtual co-manipulation of shared rigid object in SE(3) using hand/fingers with multi-point contact over the Internet.
keywords: {Rendering (computer graphics);Haptic interfaces;Mechanical systems;Springs;Stability analysis;Harmonic analysis;Oscillators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989058&isnumber=7988677

D. Gongora, H. Nagano, Y. Suzuki, M. Konyo and S. Tadokoro, "Collision representation using vibrotactile cues to bimanual impact localization for mobile robot operations," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 461-468.
doi: 10.1109/ICRA.2017.7989059
Abstract: Unnoticed collisions compromise the success of remote exploratory tasks with mobile robots. We propose a vibrotactile stimulation method to represent frontal collisions that is based on the way people perceive impacts on a bar held with both hands. We observed that to estimate the impact point in a bimanual impact localization task people relied on amplitude and duration differences of the impact vibrations delivered to their hands. Then, to apply these results, we obtained a psychophysical function that relates impact points and vibration parameters. Finally, we used a differential drive mobile robot equipped with a high speed tactile sensor on the front bumper to evaluate our method in a simplified teleoperation task. We observed that participants required less time to complete the task when vibrotactile feedback was available.
keywords: {Vibrations;Bars;Aluminum;Mobile robots;Correlation;Delays;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989059&isnumber=7988677

W. Choi, J. Won, H. Cho and J. Park, "A rehabilitation exercise robot for treating low back pain," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 482-489.
doi: 10.1109/ICRA.2017.7989060
Abstract: Low back pain is one of the world's most serious health problems. Conservative methods are recommended for back pain, and stabilization exercise as one of these methods has been proven to be effective. The “big 3” exercises are proven stabilization exercises, and it is able to train most of the muscles associated with low back stability. However, they are hard to be performed by some patients because the big 3 require sufficient strength in the upper and lower limbs as well as in the low back to maintain their postures. In this paper, we propose a rehabilitation robot SERA (Stabilization Exercise Robot Assistance system) to compensate for this shortcoming, and we describe the robot's developments and experiments. The proposed robot is designed to achieve effects similar to the big 3. The robot also ensures active exercises by voluntary control of the exerciser and provides anti-gravity force generated by series elastic actuators (SEAs) in order to adjust the exercise load. Experiments using surface electromyograph (sEMG) sensors with three subjects show the results for these features.
keywords: {Robots;Muscles;Force;Back;Stability analysis;Torque;Pain},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989060&isnumber=7988677

P. Agarwal and A. D. Deshpande, "A novel framework for optimizing motor (Re)-learning with a robotic exoskeleton," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 490-497.
doi: 10.1109/ICRA.2017.7989061
Abstract: A critical question to be answered to improve robotic rehabilitation is what is the optimal rehabilitation environment for a subject that will facilitate maximum recovery during therapy? Studies suggest that task variability, nature and degree of assistance or error-augmentation and type of feedback play a critical role in motor (re)-learning. In this work, we present a framework for robot-assisted motor (re)-learning that provides subject-specific training by allowing for simultaneous adaptation of task, assistance and feedback based on the performance of the subject on the task. We model a continuous and coordinated multi-joint task using a learning-from-demonstration approach, which allows the task to be modeled in a generative manner such that the challenge-level of the task could be modulated in an online manner. To train the subjects for dexterous manipulation, we present a torque-based task that requires the subject to dynamically regulate their joint torques. Finally, we carry out a pilot study with healthy human subjects using our previously developed hand exoskeleton to test a hypothesis and the results suggest that training under simultaneous adaptation of task, assistance and feedback positively affects motor learning.
keywords: {Training;Robot kinematics;Medical treatment;Adaptation models;Neuromuscular;Performance evaluation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989061&isnumber=7988677

P. Sabetian and J. M. Hollerbach, "A 3 wire body weight support system for a large treadmill," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 498-503.
doi: 10.1109/ICRA.2017.7989062
Abstract: A 3 DoF parallel cable driven body weight support (BWS) system has been developed for the University of Utah's Treadport Locomotion Interface, for purposes of rehabilitation, simulation of steep slopes, and display of reduced gravity environments. The Treadport's large belt (6 by 10 feet) requires a multi-cable support system to ensure that the unloading forces are close to vertical. This paper presents the design and experimental validation, including the system model and force control.
keywords: {Winches;Legged locomotion;Belts;Gravity;Force control;Tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989062&isnumber=7988677

H. Zhu, J. Doan, C. Stence, G. Lv, T. Elery and R. Gregg, "Design and validation of a torque dense, highly backdrivable powered knee-ankle orthosis," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 504-510.
doi: 10.1109/ICRA.2017.7989063
Abstract: This paper presents the mechatronic design and experimental validation of a novel powered knee-ankle orthosis for testing torque-driven rehabilitation control strategies. The modular actuator of the orthosis is designed with a torque dense motor and a custom low-ratio transmission (24:1) to provide mechanical transparency to the user, allowing them to actively contribute to their joint kinematics during gait training. The 4.88 kg orthosis utilizes frameless components and light materials, such as aluminum alloy and carbon fiber, to reduce its mass. A human subject experiment demonstrates accurate torque control with high output torque during stance and low backdrive torque during swing at fast walking speeds. This work shows that backdrivability, precise torque control, high torque output, and light weight can be achieved in a powered orthosis without the high cost and complexity of variable transmissions, clutches, and/or series elastic components.
keywords: {Torque;Actuators;Legged locomotion;Torque control;Knee;Gears;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989063&isnumber=7988677

V. Nalam and H. Lee, "Design and validation of a multi-axis robotic platform for the characterization of ankle neuromechanics," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 511-516.
doi: 10.1109/ICRA.2017.7989064
Abstract: This paper presents a novel multi-axis robotic platform for the characterization of two important neuromuscular properties of the human ankle: mechanical impedance and reflex responses. The platform is capable of producing highly accurate position perturbations up to an angular speed of 200°/s and emulating a wide range of haptic environments in two degree-of-freedom (DOF) of the ankle: dorsiflexion-plantarflexion (in the sagittal plane) and inversion-eversion (in the frontal plane). This unique feature allows us to seamlessly simulate realistic mechanical environments and to transiently perturb the ankle for the characterization of its neuromuscular properties. The position controller achieved the accuracy of 0.05° even under the loading condition (a subject of 95 kg standing on the platform). The haptic controller could successfully emulate a wide range of mechanical environments, from compliant to rigid (50-1000 Nm/rad), with an error of 2% of the commanded values. We further validated that the proposed platform could reliably estimate the stiffness of a mockup (17.8-171.0 Nm/rad) that resembles the human ankle within an error of 1.6%. Finally we demonstrated that the platform could be successfully utilized to elicit medium-latency and long-latency reflex responses of the ankle muscles. Implications for future ankle studies are discussed.
keywords: {Impedance;Actuators;Haptic interfaces;Robots;Muscles;Torque;Servomotors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989064&isnumber=7988677

J. Park et al., "A robotic orthosis with a cable-differential mechanism," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 517-521.
doi: 10.1109/ICRA.2017.7989065
Abstract: Robotic orthoses have potential to assist people having difficulty in walking due to their neurological disorders. However, it is important to design lighter orthoses since additional weight and inertia from the device cause discomfort to the wearer and even instability during walking in some extreme cases. To address this problem, a robotic orthosis with a cable differential mechanism is proposed in this paper. It is designed to assist stroke patients with hemiplegia. It has 2 active degrees of freedom at the hip and knee joints and one passive degree of freedom at the ankle. A cable differential mechanism is used to transmit the torques generated by the actuators, which are located near the pelvis of the wearer to reduce the inertial effect. The cable differential mechanism allows for the actuators to share the load with each other, which results in decrease of the maximum required torques by the actuators. Therefore, smaller actuators are possible to be used for further reduction of the weight. The proposed robotic orthosis with a cable differential mechanism, which is called “COWALK-Mobile 2,” is implemented and evaluated.
keywords: {Actuators;Pulleys;Legged locomotion;Torque;Hip;Knee},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989065&isnumber=7988677

H. Hanzlick, H. Murphy and H. Lee, "Stability of the human ankle in relation to environmental mechanics," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 522-527.
doi: 10.1109/ICRA.2017.7989066
Abstract: This paper presents quantification of multidimensional ankle stability in relation to mechanical environments having different levels of stability. This study, for the first time, explores the range of stiffness-defined haptic environments over which young healthy individuals can maintain stability despite aggressive perturbation. Ankle stability was quantified in 2 degree-of-freedom (DOF) of the ankle, in both the sagittal and frontal planes. Importantly, the magnitude of negative environmental stiffness that the subjects could maintain stability is 4 times as great in the sagittal plane as in the frontal plane. In addition to managing a wider range of unstable environments in the sagittal plane, subjects were also more efficient at regaining stability after perturbation and less sensitive to changes in the environmental stiffness. Outcomes of this study would be beneficial to the design and control of robots physically interacting with human lower extremities, such as lower-limb exoskeletons and powered ankle-foot orthoses.
keywords: {Robots;Haptic interfaces;Stability criteria;Impedance;Extremities;Damping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989066&isnumber=7988677

C. Chen, H. Hu and Y. Liu, "Static and dynamic partitions of inequalities and their application in supervisor simplification," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 536-542.
doi: 10.1109/ICRA.2017.7989067
Abstract: Although supervisor simplification in the framework of automated manufacturing systems has been studied in many literatures, there is still an intense demand for essential and general techniques. Basically, supervisors can be synthesized by specifications which are expressed by generalized mutual exclusion constraints (GMECs). In this paper, we propose static and dynamic partitions on GMECs to remove redundant ones while retain necessary ones. These two partitions are distinctly different in the utilization of system information. Static partition separates inequalities into independent and dependent ones without doing any structure analysis. While dynamic partition divides inequalities into active and inactive ones necessarily with the aid of system information. Nevertheless, mathematical analysis shows that statically dependent inequalities are essentially dynamically inactive while dynamically active ones are substantially statically independent. Thus, these partitions are contradictory in theory whereas compatible in practice. Since static partition is more general while its dynamic counterpart is more precise, they together complementarily explain many simplification principles. Furthermore, they are applicable to both ordinary and general systems. Experimental results show the effectiveness and efficiency of supervisor simplification based on static and dynamic inequality partitions.
keywords: {Manganese;Tools;Concrete;Manufacturing systems;Complexity theory;Computer science;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989067&isnumber=7988677

Q. Zhu, M. Zhou, Y. Qiao and N. Wu, "Close-down process scheduling of wafer residence time-constrained multi-cluster tools," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 543-548.
doi: 10.1109/ICRA.2017.7989068
Abstract: Semiconductor manufacturing industry has adopted multi-cluster tools as wafer fabrication equipment that is extraordinarily pricey but highly attractive owing to their higher productivity than single cluster tools can achieve. A challenging issue is how to schedule these tools. It is especially difficult to schedule their frequently occurring close-down processes subject to wafer residency constraints. Such processes appear frequently as caused by wafer lot switches and preventive and emergency maintenances. They are dynamical and non-cyclic. We analyze the synchronization conditions for multiple robots to perform concurrent activities. Upon these conditions, for the situations that an optimal schedule can be found in the steady state, a linear program model is proposed to find a feasible and optimal schedule for close-down processes. An example shows the application and efficiency of our proposed method.
keywords: {Tools;Robots;Optimal scheduling;Schedules;Steady-state;Job shop scheduling;Cluster tools;robotic manufacturing cells;semiconductor manufacturing automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989068&isnumber=7988677

K. Nottensteiner and K. Hertkorn, "Constraint-based sample propagation for improved state estimation in robotic assembly," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 549-556.
doi: 10.1109/ICRA.2017.7989069
Abstract: In fast changing assembly scenarios, it is required to adapt the task execution to the current state of the setup without extensive calibration routines. Therefore, it is important to estimate the geometric uncertainties and contact states during the assembly execution. We use a sequential Monte Carlo (SMC) method to track the relative poses between workpieces during a robotic assembly based on joint torque and position measurements only. In contrast to existing approaches, we focus on assembly tasks where the workpiece is not fixed in the workcell, but can, for example, slide on a table surface. We propose a new constraint-based propagation model for the SMC approach: a compensation motion for the samples dependent on the violation of contact constraints is derived. This allows us to track the motion of the workpieces in cases where a common random diffusion model fails. The method is evaluated with experiments using an assembly scenario with two KUKA LBR iiwa robot arms and shows accurate tracking performance.
keywords: {Uncertainty;Manipulators;Computational modeling;Kinematics;Solid modeling;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989069&isnumber=7988677

C. Paxton, A. Hundt, F. Jonathan, K. Guerin and G. D. Hager, "CoSTAR: Instructing collaborative robots with behavior trees and vision," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 564-571.
doi: 10.1109/ICRA.2017.7989070
Abstract: For collaborative robots to become useful, end users who are not robotics experts must be able to instruct them to perform a variety of tasks. With this goal in mind, we developed a system for end-user creation of robust task plans with a broad range of capabilities. CoSTAR: the Collaborative System for Task Automation and Recognition is our winning entry in the 2016 KUKA Innovation Award competition at the Hannover Messe trade show, which this year focused on Flexible Manufacturing. CoSTAR is unique in how it creates natural abstractions that use perception to represent the world in a way users can both understand and utilize to author capable and robust task plans. Our Behavior Tree-based task editor integrates high-level information from known object segmentation and pose estimation with spatial reasoning and robot actions to create robust task plans. We describe the cross-platform design and implementation of this system on multiple industrial robots and evaluate its suitability for a wide variety of use cases.
keywords: {Service robots;Robustness;Grippers;Collaboration;Ontologies;User interfaces},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989070&isnumber=7988677

J. I. Lipton, Z. Manchester and D. Rus, "Planning cuts for mobile robots with bladed tools," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 572-579.
doi: 10.1109/ICRA.2017.7989071
Abstract: Linear bladed cutting tools, such as jigsaws and reciprocating saws are vital manufacturing tools for humans. They enable people to cut structures that are much larger than themselves. Robots currently lack a generic path planner for linear bladed cutting tools. We developed a model for bladed tools based on Reeds-Shepp cars, and used the model to make a generic path planning algorithm for closed curves. We built an autonomous mobile robot which can implement the algorithm to cut arbitrarily large shapes in a 2D plane. We tested the robots performance and demonstrated the algorithm on several test cases.
keywords: {Blades;Tools;Trajectory;Shape;Turning;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989071&isnumber=7988677

C. Sung, R. Lin, S. Miyashita, S. Yim, S. Kim and D. Rus, "Self-folded soft robotic structures with controllable joints," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 580-587.
doi: 10.1109/ICRA.2017.7989072
Abstract: This paper describes additive self-folding, an origami-inspired rapid fabrication approach for creating actuatable compliant structures. Recent work in 3-D printing and other rapid fabrication processes have mostly focused on rigid objects or objects that can achieve small deformations. In contrast, soft robots often require elastic materials and large amounts of movement. Additive self-folding is a process that involves cutting slices of a 3-D object in a long strip and then pleat folding them into a likeness of the original model. The zigzag pattern for folding enables large bending movements that can be actuated and controlled. Gaps between slices in the folded model can be designed to provide larger deformations or higher shape accuracy. We advance existing planar fabrication and self-folding techniques to automate the fabrication process, enabling highly compliant structures with complex 3-D geometries to be designed and fabricated within a few hours. We describe this process in this paper and provide algorithms for converting 3-D meshes into additive self-folding designs. The designs can be rapidly instrumented for global control using magnetic fields or tendon-driven for local bending. We also describe how the resulting structures can be modeled and their responses to tendon-driven control predicted. We test our design and fabrication methods on three models (a bunny, a tuna fish, and a starfish) and demonstrate the method's potential for actuation by actuating the tuna fish and starfish models using tendons and magnetic control.
keywords: {Fabrication;Additives;Geometry;Algorithm design and analysis;Robots;Strips;Tendons},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989072&isnumber=7988677

M. Bucak, A. F. Bozkurt, K. Erkan and H. Üvet, "A new design concept of magnetically levitated 4 pole hybrid mover driven by linear motor," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 596-601.
doi: 10.1109/ICRA.2017.7989073
Abstract: This paper reports a new design topology of 4 pole hybrid electromagnetic levitation system in conjunction with linear synchronous motor. The mover, 4 pole hybrid electromagnet, is levitated underneath of the linear motor with zero power control algorithm. Propulsion and one-dimensional planar motion of the hybrid electromagnet is provided by the vector controlled linear motor. The new design of 4 pole hybrid electromagnet has several improvements over older systems, such as weight reduction and less material usage. Diagonal drive integration of mover and linear motor is proposed and experimental results are presented.
keywords: {Permanent magnet motors;Induction motors;Synchronous motors;Coils;Magnetic levitation;Magnetic cores},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989073&isnumber=7988677

M. Watanabe and H. Tsukagoshi, "Soft sheet actuator generating traveling waves inspired by gastropod's locomotion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 602-607.
doi: 10.1109/ICRA.2017.7989074
Abstract: In this paper, we propose an epoch-making soft sheet actuator called “Wavy-sheet”. Inspired by gastropod's locomotion, Wavy-sheet can generate continuous traveling waves on the whole soft body. It aims to be applied to a mobile soft mat capable of moving and transporting without damaging the object and the ground. The actuator, driven by pneumatics, is mainly composed of a couple of flexible rubber tubes and fabrics. The advantages are: i) many traveling waves can be generated by just three tubes, ii) the whole structure can adapt its own shape to the outer environment passively, and iii) only 10 mm in thickness and can generate waves with larger than 10mm in amplitude. In this paper, first, we describe the basic concept of Wavy-sheet, and then show the configuration and the principle of wave propagation. Next, fabrication methods are illustrated and the design methods are addressed. By using a prototype actuator, several experiments are conducted. Finally, we verify the effectiveness of the proposed actuator and its design methods.
keywords: {Actuators;Electron tubes;Rubber;Robots;Shape;Fabrics;Surface waves},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989074&isnumber=7988677

Y. Hong, S. Kim and K. Kim, "Modified nonlinear pressure estimator of pneumatic actuator for force controller design," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 608-613.
doi: 10.1109/ICRA.2017.7989075
Abstract: This paper presents a modified nonlinear pneumatic model for pneumatic force servo systems. The modified model is proposed in order to estimate pressures accurately for both chambers of a pneumatic cylinder by adopting flow coefficient maps, which is different from a conventional model whose flow coefficient is constant. The simulated data from the model is also compared to the experiment result and shows its accuracy compared to a widely used conventional model. The modified model and the experimental procedure are described and verified in this paper as well. Finally, the applicability of the proposed model to model-based controller design is also shown through the experiment of force servo controls based on a force sensor.
keywords: {Force;Valves;Mathematical model;Pneumatic systems;Servomotors;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989075&isnumber=7988677

A. Wilson, "Design and development of a Magneto-Rheological linear clutch for force controlled human safe robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 614-619.
doi: 10.1109/ICRA.2017.7989076
Abstract: This paper proposes a Magneto Rheological linear clutch for use in human safe robotic applications. The force transmitted to the links of the robot must be precisely controlled for any manipulator if it has to be operated safely alongside humans. The traditional approaches to this problem is using various compliant actuating schemes like Series Elastic Actuators, Joint Torque Control etc. Research on the usage of smart materials that change their properties on application of electrical or magnetic fields for human safe robots have gained momentum recently. Studies on the feasibility of Magneto-Rheological actuators has been done already. This paper introduces a MR clutch which can control the force transmitted by a linear actuator. The electromechanical model of the linear clutch has been developed, implemented in hardware, and tested using a prototype one Degree of Freedom arm. The design of the clutch is detailed and the performance is characterized thorough a series of experiments. The results suggest that the linear clutch serves well for the precise force control of a linear actuator.
keywords: {Robots;Fluids;Actuators;Magnetic fields;Force;Shafts;Coils},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989076&isnumber=7988677

T. Ko, H. Kaminaga and Y. Nakamura, "Underactuated four-fingered hand with five electro hydrostatic actuators in cluster," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 620-625.
doi: 10.1109/ICRA.2017.7989077
Abstract: For heavy duty tasks which are needed in field or rough terrain, we developed a hydrostatically actuated anthropomorphic hand. The hand is specifically designed for the humanoid robot HYDRA, whose 40 joints are driven by back-drivable electro-hydrostatic actuators (EHA). Each designed hand has four fingers with a total of five DOF. Each finger has three joints underactuated by one tendon. Opposition/reposition of the thumb joint is also driven by one tendon. The five tendons are pulled by a miniature linear cluster EHA mounted in the forearm. The cluster EHA consists of a light weight tie-rod cylinder cluster with five pistons, and five low friction trochoid pumps with a crescent separator. Its 300 N nominal tension generates 1.5 Nm joint torque on each of the finger joints. Design of the cylinder and pump, with results of evaluation experiments is shown in this paper. Forearm structure with a mechanism to measure the tendon tension, low friction tendon routing in the forearm, low friction wire guiding link for the wrist, and parallel link wrist driving mechanism with two EHAs are also described.
keywords: {Pistons;Force;Hydraulic systems;Robots;Rotors;Actuators;Particle separators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989077&isnumber=7988677

Z. M. Hammond, N. S. Usevitch, E. W. Hawkes and S. Follmer, "Pneumatic Reel Actuator: Design, modeling, and implementation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 626-633.
doi: 10.1109/ICRA.2017.7989078
Abstract: We present the design, modeling, and implementation of a novel pneumatic actuator, the Pneumatic Reel Actuator (PRA). The PRA is highly extensible, lightweight, capable of operating in compression and tension, compliant, and inexpensive. An initial prototype of the PRA can reach extension ratios greater than 16:1, has a force-to-weight ratio over 28:1, reach speeds of 0.87 meters per second, and can be constructed with parts totaling less than $4 USD. We have developed a model describing the actuator and have conducted experiments characterizing the actuator's performance in regards to force, extension, pressure, and speed. We have implemented two parallel robotic applications in the form of a three degree of freedom robot arm and a tetrahedral robot.
keywords: {Actuators;Springs;Spirals;Force;Shape;Robots;Plastics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989078&isnumber=7988677

M. Zhang et al., "Deep reinforcement learning for tensegrity robot locomotion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 634-641.
doi: 10.1109/ICRA.2017.7989079
Abstract: Tensegrity robots, composed of rigid rods connected by elastic cables, have a number of unique properties that make them appealing for use as planetary exploration rovers. However, control of tensegrity robots remains a difficult problem due to their unusual structures and complex dynamics. In this work, we show how locomotion gaits can be learned automatically using a novel extension of mirror descent guided policy search (MDGPS) applied to periodic locomotion movements, and we demonstrate the effectiveness of our approach on tensegrity robot locomotion. We evaluate our method with real-world and simulated experiments on the SUPERball tensegrity robot, showing that the learned policies generalize to changes in system parameters, unreliable sensor measurements, and variation in environmental conditions, including varied terrains and a range of different gravities. Our experiments demonstrate that our method not only learns fast, power-efficient feedback policies for rolling gaits, but that these policies can succeed with only the limited onboard sensing provided by SUPERball's accelerometers. We compare the learned feedback policies to learned open-loop policies and hand-engineered controllers, and demonstrate that the learned policy enables the first continuous, reliable locomotion gait for the real SUPERball robot. Our code and supplementary material is available from http://rll.berkeley.edu/drl_tensegrity.
keywords: {Robot sensing systems;Mirrors;Neural networks;Training;Gravity;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989079&isnumber=7988677

M. Rafieisakhaei, S. Chakravorty and P. R. Kumar, "T-LQG: Closed-loop belief space planning via trajectory-optimized LQG," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 649-656.
doi: 10.1109/ICRA.2017.7989080
Abstract: Planning under motion and observation uncertainties requires the solution of a stochastic control problem in the space of feedback policies. In this paper, by restricting the policy class to the linear feedback polices, we reduce the general (n2 + n)-dimensional belief space planning problem to an (n)-dimensional problem. As opposed to the previous literature that search in the space of open-loop optimal control policies, we obtain this reduction in the space of closed-loop policies by obtaining a Linear Quadratic Gaussian (LQG) design with the best nominal performance. Then, by taking the entire underlying trajectory of the LQG controller as the decision variable, we pose a coupled design of the trajectory and estimator (while keeping the design of the controller separate) as a NonLinear Program (NLP) that can be solved by a general NLP solver. We prove that under a first-order approximation and a careful usage of the separation principle, our approximations are valid. We provide an analysis on the existing major belief space planning methods and show that our algorithm keeps the lowest computational burden while searching in the policy space. Finally, we extend our solution to contain general state and control constraints. Our simulation results support our design.
keywords: {Trajectory;Aerospace electronics;Planning;Mathematical model;Estimation;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989080&isnumber=7988677

J. M. Mendes Filho, E. Lucet and D. Filliat, "Real-time distributed receding horizon motion planning and control for mobile multi-robot dynamic systems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 657-663.
doi: 10.1109/ICRA.2017.7989081
Abstract: This paper proposes an improvement of a motion planning approach and a modified model predictive control (MPC) for solving the navigation problem of a team of dynamical wheeled mobile robots in the presence of obstacles in a realistic environment. Planning is performed by a distributed receding horizon algorithm where constrained optimization problems are numerically solved for each prediction time-horizon. This approach allows distributed motion planning for a multi-robot system with asynchronous communication while avoiding collisions and minimizing the travel time of each robot. However, the robots dynamics prevents the planned motion to be applied directly to the robots. Using unicycle-like vehicles in a dynamic simulation, we show that deviations from the planned motion caused by the robots dynamics can be overcome by modifying the optimization problem underlying the planning algorithm and by adding an MPC for trajectory tracking. Results also indicate that this approach can be used in systems subjected to real-time constraint.
keywords: {Robots;Collision avoidance;Planning;Trajectory;Dynamics;Optimization;Vehicle dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989081&isnumber=7988677

M. Mukadam, C. -A. Cheng, X. Yan and B. Boots, "Approximately optimal continuous-time motion planning and control via Probabilistic Inference," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 664-671.
doi: 10.1109/ICRA.2017.7989082
Abstract: The problem of optimal motion planing and control is fundamental in robotics. However, this problem is intractable for continuous-time stochastic systems in general and the solution is difficult to approximate if non-instantaneous nonlinear performance indices are present. In this work, we provide an efficient algorithm, PIPC (Probabilistic Inference for Planning and Control), that yields approximately optimal policies with arbitrary higher-order nonlinear performance indices. Using probabilistic inference and a Gaussian process representation of trajectories, PIPC exploits the underlying sparsity of the problem such that its complexity scales linearly in the number of nonlinear factors. We demonstrate the capabilities of our algorithm in a receding horizon setting with multiple systems in simulation.
keywords: {Planning;Gaussian processes;Heuristic algorithms;Probabilistic logic;Approximation algorithms;Trajectory;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989082&isnumber=7988677

P. Salaris, R. Spica, P. R. Giordano and P. Rives, "Online optimal active sensing control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 672-678.
doi: 10.1109/ICRA.2017.7989083
Abstract: This paper deals with the problem of active sensing control for nonlinear differentially flat systems. The objective is to improve the estimation accuracy of an observer by determining the inputs of the system that maximise the amount of information gathered by the outputs over a time horizon. In particular, we use the Observability Gramian (OG) to quantify the richness of the acquired information. First, we define a trajectory for the flat outputs of the system by using B-Spline curves. Then, we exploit an online gradient descent strategy to move the control points of the B-Spline in order to actively maximise the smallest eigenvalue of the OG over the whole planning horizon. While the system travels along its planned (optimized) trajectory, an Extended Kalman Filter (EKF) is used to estimate the system state. In order to keep memory of the past acquired sensory data for online re-planning, the OG is also computed on the past estimated state trajectories. This is then used for an online replanning of the optimal trajectory during the robot motion which is continuously refined by exploiting the state estimation obtained by the EKF. In order to show the effectiveness of our method we consider a simple but significant case of a planar robot with a single range measurement. The simulation results show that, along the optimal path, the EKF converges faster and provides a more accurate estimate than along other possible (non-optimal) paths.
keywords: {Robot sensing systems;Trajectory;Observability;Estimation;Eigenvalues and eigenfunctions;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989083&isnumber=7988677

H. Pham and Q. Pham, "On the structure of the time-optimal path parameterization problem with third-order constraints," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 679-686.
doi: 10.1109/ICRA.2017.7989084
Abstract: Finding the Time-Optimal Parameterization of a Path (TOPP) subject to second-order constraints (e.g. acceleration, torque, contact stability, etc.) is an important and well-studied problem in robotics. In comparison, TOPP subject to third-order constraints (e.g. jerk, torque rate, etc.) has received far less attention and remains largely open. In this paper, we investigate the structure of the TOPP problem with third-order constraints. In particular, we identify two major difficulties: (i) how to smoothly connect optimal profiles, and (ii) how to address singularities, which stop profile integration prematurely. We propose a new algorithm, TOPP3, which addresses these two difficulties and thereby constitutes an important milestone towards an efficient computational solution to TOPP with third-order constraints.
keywords: {Acceleration;Torque;Robots;Joining processes;Periodic structures;Force;Convex functions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989084&isnumber=7988677

J. Ha and H. Choi, "Multiscale abstraction, planning and control using diffusion wavelets for stochastic optimal control problems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 687-694.
doi: 10.1109/ICRA.2017.7989085
Abstract: This work presents a multiscale framework to solve a class of stochastic optimal control problems in the context of robot motion planning and control in a complex environment. In order to handle complications resulting from a large decision space and complex environmental geometry, two key concepts are adopted: (a) a diffusion wavelet representation of the Markov chain for hierarchical abstraction of the state space; and (b) a desirability function-based representation of the Markov decision process (MDP) to efficiently calculate the optimal policy. In the proposed framework, a global plan that compressively takes into account the long time/length-scale state transition is first obtained by approximately solving an MDP whose desirability function is represented by coarse scale bases in the hierarchical abstraction. Then, a detailed local plan is computed by solving an MDP that considers wavelet bases associated with a focused region of the state space, guided by the global plan. The resulting multiscale plan is utilized to finally compute a continuous-time optimal control policy within a receding horizon implementation. Two numerical examples are presented to demonstrate the applicability and validity of the proposed approach.
keywords: {Markov processes;Multiresolution analysis;Optimal control;Aerospace electronics;Planning;Robots;Discrete wavelet transforms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989085&isnumber=7988677

Z. Xie, C. K. Liu and K. Hauser, "Differential dynamic programming with nonlinear constraints," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 695-702.
doi: 10.1109/ICRA.2017.7989086
Abstract: Differential dynamic programming (DDP) is a widely used trajectory optimization technique that addresses nonlinear optimal control problems, and can readily handle nonlinear cost functions. However, it does not handle either state or control constraints. This paper presents a novel formulation of DDP that is able to accommodate arbitrary nonlinear inequality constraints on both state and control. The main insight in standard DDP is that a quadratic approximation of the value function can be derived using a recursive backward pass, however the recursive formulae are only valid for unconstrained problems. The main technical contribution of the presented method is a derivation of the recursive quadratic approximation formula in the presence of nonlinear constraints, after a set of active constraints has been identified at each point in time. This formula is used in a new Constrained-DDP (CDDP) algorithm that iteratively determines these active set and is guaranteed to converge toward a local minimum. CDDP is demonstrated on several underactuated optimal control problems up to 12D with obstacle avoidance and control constraints and is shown to outperform other methods for accommodating constraints.
keywords: {Trajectory;Optimal control;Optimization;Dynamic programming;Approximation algorithms;Standards;Iterative methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989086&isnumber=7988677

Y. Cho and A. Kim, "Visibility enhancement for underwater visual SLAM based on underwater light scattering model," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 710-717.
doi: 10.1109/ICRA.2017.7989087
Abstract: This paper presents a real-time visibility enhancement algorithm for effective underwater visual simultaneous localization and mapping (SLAM). Unlike an aerial environment, an underwater environment contains larger particles and is dominated by a different image degradation model. Our method starts with a thorough understanding of underwater particle physics (e.g., forward, back, multiple scattering, blur and noise). Targeting underwater image enhancement in a real-world application, we include an artificial light model in the derivation. The proposed method is effective for both color and gray images with substantial improvement in the process time compared to conventional methods. The proposed method is validated by using simulated synthetic images (color) and real-world underwater images (color and grayscale). Using two underwater image sets acquired from the same area but with different water turbidity, we evaluate the proposed visibility enhancement and camera registration improvement in SLAM.
keywords: {Scattering;Image color analysis;Attenuation;Simultaneous localization and mapping;Atmospheric modeling;Light sources;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989087&isnumber=7988677

S. Buck, R. Hanten, K. Bohlmann and A. Zell, "Multi-sensor payload detection and acquisition for truck-trailer AGVs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 718-723.
doi: 10.1109/ICRA.2017.7989088
Abstract: A fundamental task of automated guided vehicles is transporting heavy payloads. These payloads are often given in the form of large containers that are mounted onto a cart with four caster wheels. In this paper we investigate a combined detection and control architecture that allows an AGV to reliably detect and acquire such containers at any location, independently of a global localization system. We propose a solution using a horizontally mounted 2D laser scanner and a forward facing 3D time-of-flight camera to detect the payload. Furthermore we demonstrate the algorithm on an asymmetric AGV that consists of a differentially driven base and a trailer with a lifting unit.
keywords: {Containers;Three-dimensional displays;Wheels;Payloads;Two dimensional displays;Lasers;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989088&isnumber=7988677

J. K. Murthy, G. V. S. Krishna, F. Chhaya and K. M. Krishna, "Reconstructing vehicles from a single image: Shape priors for road scene understanding," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 724-731.
doi: 10.1109/ICRA.2017.7989089
Abstract: We present an approach for reconstructing vehicles from a single (RGB) image, in the context of autonomous driving. Though the problem appears to be ill-posed, we demonstrate that prior knowledge about how 3D shapes of vehicles project to an image can be used to reason about the reverse process, i.e., how shapes (back-)project from 2D to 3D. We encode this knowledge in shape priors, which are learnt over a small keypoint-annotated dataset. We then formulate a shape-aware adjustment problem that uses the learnt shape priors to recover the 3D pose and shape of a query object from an image. For shape representation and inference, we leverage recent successes of Convolutional Neural Networks (CNNs) for the task of object and keypoint localization, and train a novel cascaded fully-convolutional architecture to localize vehicle keypoints in images. The shape-aware adjustment then robustly recovers shape (3D locations of the detected keypoints) while simultaneously filling in occluded keypoints. To tackle estimation errors incurred due to erroneously detected keypoints, we use an Iteratively Re-weighted Least Squares (IRLS) scheme for robust optimization, and as a by-product characterize noise models for each predicted keypoint. We evaluate our approach on autonomous driving benchmarks, and present superior results to existing monocular, as well as stereo approaches.
keywords: {Shape;Three-dimensional displays;Two dimensional displays;Solid modeling;Image reconstruction;Cameras;Pipelines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989089&isnumber=7988677

M. Laranjeira, C. Dune and V. Hugel, "Catenary-based visual servoing for tethered robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 732-738.
doi: 10.1109/ICRA.2017.7989090
Abstract: Tethers are used to supply power and transfer data for teleoperated robots. They are known to limit the robot's workspace and could have the effect of hampering its motion. What if we could take advantage of the tether? In this paper a new visual servoing scheme for catenary shaped deformable objects is introduced in order to control the tether parametric shape by properly moving its fixation point. In most of the visual servoing approaches the target object is rigid and distant from the controlled robot. On the contrary, in this paper, the object is deformable and attached to the robot, thus its 3D shape changes while the robot is moving. The experimental system is composed of two terrestrial mobile robots of the same motion capabilities linked with a slack rope. Simulation and real experiments validate the proposed control scheme for proper tether handling.
keywords: {Robot kinematics;Shape;Mobile robots;Visual servoing;Cameras;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989090&isnumber=7988677

A. Hietanen, J. Halme, A. G. Buch, J. Latokartano and J. -. Kämäräinen, "Robustifying correspondence based 6D object pose estimation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 739-745.
doi: 10.1109/ICRA.2017.7989091
Abstract: We propose two methods to robustify point correspondence based 6D object pose estimation. The first method, curvature filtering, is based on the assumption that low curvature regions provide false matches, and removing points in these regions improves robustness. The second method, region pruning, is more general by making no assumptions about local surface properties. Our region pruning segments a model point cloud into cluster regions and searches good region combinations using a validation set. The robustifying methods are general and can be used with any correspondence based method. For the experiments, we evaluated three correspondence selection methods, Geometric Consistency (GC) [1], Hough Grouping (HG) [2] and Search of Inliers (SI) [3] and report systematic improvements for their robustified versions with two distinct datasets.
keywords: {Three-dimensional displays;Pose estimation;Robustness;Robots;Silicon;Solid modeling;Tools},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989091&isnumber=7988677

M. Johnson-Roberson, C. Barto, R. Mehta, S. N. Sridhar, K. Rosaen and R. Vasudevan, "Driving in the Matrix: Can virtual worlds replace human-generated annotations for real world tasks?," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 746-753.
doi: 10.1109/ICRA.2017.7989092
Abstract: Deep learning has rapidly transformed the state of the art algorithms used to address a variety of problems in computer vision and robotics. These breakthroughs have relied upon massive amounts of human annotated training data. This time consuming process has begun impeding the progress of these deep learning efforts. This paper describes a method to incorporate photo-realistic computer images from a simulation engine to rapidly generate annotated data that can be used for the training of machine learning algorithms. We demonstrate that a state of the art architecture, which is trained only using these synthetic annotations, performs better than the identical architecture trained on human annotated real-world data, when tested on the KITTI data set for vehicle detection. By training machine learning algorithms on a rich virtual world, real objects in real scenes can be learned and classified using synthetic data. This approach offers the possibility of accelerating deep learning's application to sensor-based classification problems like those that appear in self-driving cars. The source code and data to train and validate the networks described in this paper are made available for researchers.
keywords: {Engines;Training;Machine learning;Data models;Robots;Training data;Automobiles;deep learning;simulation;object detection;autonomous driving},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989092&isnumber=7988677

M. Volkov, D. A. Hashimoto, G. Rosman, O. R. Meireles and D. Rus, "Machine learning and coresets for automated real-time video segmentation of laparoscopic and robot-assisted surgery," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 754-759.
doi: 10.1109/ICRA.2017.7989093
Abstract: Context-aware segmentation of laparoscopic and robot assisted surgical video has been shown to improve performance and perioperative workflow efficiency, and can be used for education and time-critical consultation. Modern pressures on productivity preclude manual video analysis, and hospital policies and legacy infrastructure are often prohibitive of recording and storing large amounts of data. In this paper we present a system that automatically generates a video segmentation of laparoscopic and robot-assisted procedures according to their underlying surgical phases using minimal computational resources, and low amounts of training data. Our system uses an SVM and HMM in combination with an augmented feature space that captures the variability of these video streams without requiring analysis of the nonrigid and variable environment. By using the data reduction capabilities of online k-segment coreset algorithms we can efficiently produce results of approximately equal quality, in realtime. We evaluate our system in cross-validation experiments and propose a blueprint for piloting such a system in a real operating room environment with minimal risk factors.
keywords: {Surgery;Streaming media;Instruments;Laparoscopes;Robots;Hidden Markov models;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989093&isnumber=7988677

P. Schillinger, M. Bürger and D. V. Dimarogonas, "Multi-objective search for optimal multi-robot planning with finite LTL specifications and resource constraints," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 768-774.
doi: 10.1109/ICRA.2017.7989094
Abstract: We present an efficient approach to plan action sequences for a team of robots from a single finite LTL mission specification. The resulting execution strategy is proven to solve the given mission with minimal team costs, e.g., with shortest execution time. For planning, an established graph-based search method based on the multi-objective shortest path problem is adapted to multi-robot planning and extended to support resource constraints. We further improve planning efficiency significantly for missions which consist of independent parts by using previous results regarding LTL decomposition. The efficiency and practicality of the ROS implementation of our approach is demonstrated in example scenarios.
keywords: {Planning;Automata;Pareto optimization;Search problems;Indexes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989094&isnumber=7988677

W. Li and Y. Liu, "Dynamic coverage control for mobile robot network with limited and nonidentical sensory ranges," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 775-780.
doi: 10.1109/ICRA.2017.7989095
Abstract: The coverage control problem for multiple mobile robot system with limited and dissimilar sensing abilities is addressed in this article. There exist missing areas while taking the previously developed r-limited Voronoi partitions due to distinct sensing ranges. Thus, a modified partitioning approach is proposed to enhance coverage performance. Furthermore, the dynamic coverage controllers are developed with time-varying density function so that the system is more applicable to various tasks such as target tracking or information decays. In addition to theoretical analysis, numerical examples and experiments with four mobile robots are conducted to verify stability and coverage performance of mobile robot network utilizing the proposed coverage partition algorithm.
keywords: {Robot sensing systems;Mobile robots;Density functional theory;Linear programming;Silicon;coverage control;mobile robot network;r-limited Voronoi partitions;time-varying density function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989095&isnumber=7988677

C. K. Verginis, Z. Xu and D. V. Dimarogonas, "Decentralized motion planning with collision avoidance for a team of UAVs under high level goals," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 781-787.
doi: 10.1109/ICRA.2017.7989096
Abstract: This paper addresses the motion planning problem for a team of aerial agents under high level goals. We propose a hybrid control strategy that guarantees the accomplishment of each agent's local goal specification, which is given as a temporal logic formula, while guaranteeing inter-agent collision avoidance. In particular, by defining 3-D spheres that bound the agents' volume, we extend previous work on decentralized navigation functions and propose control laws that navigate the agents among predefined regions of interest of the workspace while avoiding collision with each other. This allows us to abstract the motion of the agents as finite transition systems and, by employing standard formal verification techniques, to derive a high-level control algorithm that satisfies the agents' specifications. Simulation and experimental results with quadrotors verify the validity of the proposed method.
keywords: {Planning;Navigation;Collision avoidance;Standards;Vehicle dynamics;Trajectory;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989096&isnumber=7988677

S. Solaimanpour and P. Doshi, "A layered HMM for predicting motion of a leader in multi-robot settings," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 788-793.
doi: 10.1109/ICRA.2017.7989097
Abstract: We focus on a mobile robot that must learn another robot's motion model from observations to track it in a given map. This problem has several real-world applications such as self-driving cars being electronically towed by other cars and for telepresence robots. Our context is a nested particle filter, a generalization of the traditional particle filter, that allows both self-localization and tracking of another robot simultaneously. While the robot's observations are used to weight nested particles, the problem arises during the propagation step of the nested particles during which a motion model is needed. We introduce a novel layered hidden Markov model for this problem and present an on-line algorithm which learns the HMM parameters from observations gathered during the run. We demonstrate significantly improved tracking accuracy on using this new model to predict the motion of a leading mobile robot, in comparison to pre-defined and random motion models as previously used in literature.
keywords: {Hidden Markov models;Tracking;Robot sensing systems;Monte Carlo methods;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989097&isnumber=7988677

L. Y. Ku, E. Learned-Miller and R. Grupen, "An aspect representation for object manipulation based on convolutional neural networks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 794-800.
doi: 10.1109/ICRA.2017.7989098
Abstract: We propose an intelligent visuomotor system that interacts with the environment and memorizes the consequences of actions. As more memories are recorded and more interactions are observed, the agent becomes more capable of predicting the consequences of actions and is, thus, better at planning sequences of actions to solve tasks. In previous work, we introduced the aspect transition graph (ATG) which represents how actions lead from one observation to another using a directed multi-graph. In this work, we propose a novel aspect representation based on hierarchical CNN features, learned with convolutional neural networks, that supports manipulation and captures the essential affordances of an object based on RGB-D images. In a traditional planning system, robots are given a pre-defined set of actions that take the robot from one symbolic state to another. However symbolic states often lack the flexibility to generalize across similar situations. Our proposed representation is grounded in the robot's observations and lies in a continuous space that allows the robot to handle similar unseen situations. The hierarchical CNN features within a representation also allow the robot to act precisely with respect to the spatial location of individual features. We evaluate the robustness of this representation using the Washington RGB-D Objects Dataset and show that it achieves state of the art results for instance pose estimation. We then test this representation in conjunction with an ATG on a drill grasping task on Robonaut-2. We show that given grasp, drag, and turn demonstrations on the drill, the robot is capable of planning sequences of learned actions to compensate for reachability constraints.
keywords: {Robots;Feature extraction;Three-dimensional displays;Planning;Backpropagation;Object recognition;Image segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989098&isnumber=7988677

F. Yang and N. Chakraborty, "Algorithm for optimal chance constrained linear assignment," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 801-808.
doi: 10.1109/ICRA.2017.7989099
Abstract: In this paper, we design provably-good algorithms for task allocation in multi-robot systems in the presence of payoff uncertainty. We consider a group of robots that has to perform a given set of tasks where each robot performs at most one task. The payoffs of the robots doing the tasks are assumed to be Gaussian random variables with known mean and variances. The total payoff of the robots is a sum of the individual payoffs of all the robots. The goal is to find an assignment with maximum payoff that can be achieved with a specified probability irrespective of the realization of the random variable. This problem can be formulated as a chance constrained combinatorial optimization problem. We develop a novel deterministic technique to solve this chance constrained optimization problem that ensures that the chance constraints are always satisfied. Adopting the notion of risk-aversion from the economics literature, we formulate a risk-averse task allocation problem, which is a deterministic integer optimization problem. We prove that by repeatedly solving the risk-averse task allocation problem using a one-dimensional search on the risk aversion parameter we find a solution for the chance constrained optimization formulation of the linear assignment problem with uncertain payoffs. We provide simulation results on randomly generated data to demonstrate our approach and also compare our method to existing approaches.
keywords: {Robots;Optimization;Resource management;Uncertainty;Random variables;Linear programming;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989099&isnumber=7988677

H. Kawano, "Tunneling-based self-reconfiguration of heterogeneous sliding cube-shaped modular robots in environments with obstacles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 825-832.
doi: 10.1109/ICRA.2017.7989100
Abstract: This paper studies a reconfiguration algorithm for heterogeneous cubic modular robots in environments with obstacles. Tunneling is suitable for the transformation of cubic modular robots in such an environment because a tunneling robot only passes spaces that are occupied by the robot in the start and goal configurations. We have also designed a permutation algorithm that can be executed in the space used by the tunneling robot. Considering the application in environments with obstacles, we assumed a motion primitive with only sliding motion along another module's surface. This differs from the previously studied one, which allows convex motions. The proposed algorithm uses a three-dimensional 2 × 2 × 2 meta-module to guarantee the existence of mobile modules and maintain the connectivity of the robot structure during the tunneling and permutation processes. We show that the algorithm is complete for a connected robot structure with more than one meta-module and that the reconfiguration in an environment with obstacles is executed in quadratic operating time cost.
keywords: {Robots;Tunneling;Algorithm design and analysis;Navigation;Mobile communication;Transforms;Lattices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989100&isnumber=7988677

B. Ning, J. Jin, Z. Zuo, J. Zheng and Q. -L. Han, "Distributed fixed-time cooperative tracking control for multi-robot systems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 833-838.
doi: 10.1109/ICRA.2017.7989101
Abstract: In this paper, we study the fixed-time cooperative tracking control problem for multi-robot systems with doubleintegrator dynamics. First, a novel distributed observer is proposed for each follower to estimate the leader state in a fixed time, then a local tracking controller based on sliding mode technique is proposed such that the estimated leader state is tracked in a fixed time. Both cases of a stationary leader and a dynamic leader are investigated. Since nonholonomic dynamics can better describe the mobile robots in reality, we further extend the results to achieve fixed-time cooperative tracking for multi-robot systems with nonholonomic dynamics. Different from the conventional finite-time cooperative tracking strategies, the fixed-time approach in this work guarantees that an upper bound of settling time can be prescribed without dependence on initial states of robots, which provides additional system information in advance. Finally, numerical simulations are given to demonstrate the effectiveness of the theoretical results.
keywords: {Multi-robot systems;Observers;Protocols;Upper bound;Heuristic algorithms;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989101&isnumber=7988677

G. J. Laguna and S. Bhattacharya, "Hybrid system for target tracking in triangulation graphs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 839-844.
doi: 10.1109/ICRA.2017.7989102
Abstract: We investigate a variation of the art gallery problem in which a team of mobile guards tries to track an unpredictable intruder in a simply-connected polygonal environment. The guards are deployed based on the strategy initially proposed in [1] which restricts them to move along a specific diagonal within the environment. However, the intruder can move freely within the environment. We define critical regions to generate event-triggered strategies for the guards. Additionally, a hybrid automaton is designed to model the problem, and sufficient conditions are presented for [n/4] guards for persistent surveillance.
keywords: {Target tracking;Mobile communication;Automata;Mathematical model;Observers;Reachability analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989102&isnumber=7988677

S. Baraldo and A. Valente, "Smooth joint motion planning for high precision reconfigurable robot manipulators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 845-850.
doi: 10.1109/ICRA.2017.7989103
Abstract: The accuracy of reconfigurable robot manipulators is a critical aspect which prevents their diffused industrial adoption. This work presents a novel model for designing joint motion profiles, particularly suitable for the motion planning of modular robots with high accuracy requirements. The model generates smooth motion profiles, without sacrificing execution time and taking into account the different characteristics of each joint and the requirements of each production task. The proposed method has been tested across the most performing motion planning approaches found in the literature, providing up to 39% faster jerk-bounded trajectories. Moreover, the model is flexible to the generation of adapted trajectories when degrading phenomena occur over the time.
keywords: {Trajectory;Planning;Robot kinematics;Kinematics;Acceleration;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989103&isnumber=7988677

M. Lauri, E. Heinänen and S. Frintrop, "Multi-robot active information gathering with periodic communication," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 851-856.
doi: 10.1109/ICRA.2017.7989104
Abstract: A team of robots sharing a common goal can benefit from coordination of the activities of team members, helping the team to reach the goal more reliably or quickly. We address the problem of coordinating the actions of a team of robots with periodic communication capability executing an information gathering task. We cast the problem as a multi-agent optimal decision-making problem with an information theoretic objective function. We show that appropriate techniques for solving decentralized partially observable Markov decision processes (Dec-POMDPs) are applicable in such information gathering problems. We quantify the usefulness of coordinated information gathering through simulation studies, and demonstrate the feasibility of the method in a real-world target tracking domain.
keywords: {Robot sensing systems;History;Uncertainty;Robot kinematics;Target tracking;Decision making},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989104&isnumber=7988677

A. Dutta and P. Dasgupta, "Bipartite graph matching-based coordination mechanism for multi-robot path planning under communication constraints," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 857-862.
doi: 10.1109/ICRA.2017.7989105
Abstract: We propose a coordination mechanism to avoid inter-robot collisions when the robots' paths overlap with each other. Our proposed coordination technique uses a weighted bipartite matching-based formulation to solve this problem. Initially, each robot is given a unique goal location. But the robots do not know about other robots' planned paths until they come within each other's communication ranges. When two or more robots get within an unsafe distance, they coordinate their paths to avoid collisions with each other. The objective of the coordination mechanism is to plan a modified path for each coordinating robot (if needed) so that all the robots can reach their goal locations without collision with each other and also while reducing the extra distance introduced while resolving path conflicts. We have proved the correctness and convergence of our coordination strategy. Our experimental results show that the robots using our proposed strategy travel up to 4.2 times less than a comparable heuristic approach.
keywords: {Robot kinematics;Collision avoidance;Path planning;Joining processes;Bipartite graph;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989105&isnumber=7988677

S. Omidshafiei, C. Amato, M. Liu, M. Everett, J. P. How and J. Vian, "Scalable accelerated decentralized multi-robot policy search in continuous observation spaces," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 863-870.
doi: 10.1109/ICRA.2017.7989106
Abstract: This paper presents the first ever approach for solving continuous-observation Decentralized Partially Observable Markov Decision Processes (Dec-POMDPs) and their semi-Markovian counterparts, Dec-POSMDPs. This contribution is especially important in robotics, where a vast number of sensors provide continuous observation data. A continuous-observation policy representation is introduced using Stochastic Kernel-based Finite State Automata (SK-FSAs). An SK-FSA search algorithm titled Entropy-based Policy Search using Continuous Kernel Observations (EPSCKO) is introduced and applied to the first ever continuous-observation Dec-POMDP/Dec-POSMDP domain, where it significantly outperforms state-of-the-art discrete approaches. This methodology is equally applicable to Dec-POMDPs and Dec-POSMDPs, though the empirical analysis presented focuses on Dec-POSMDPs due to their higher scalability. To improve convergence, an entropy injection policy search acceleration approach for both continuous and discrete observation cases is also developed and shown to improve convergence rates without degrading policy quality.
keywords: {Convergence;Entropy;Acceleration;Decision making;Robot sensing systems;Scalability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989106&isnumber=7988677

S. Omidshafiei et al., "Semantic-level decentralized multi-robot decision-making using probabilistic macro-observations," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 871-878.
doi: 10.1109/ICRA.2017.7989107
Abstract: Robust environment perception is essential for decision-making on robots operating in complex domains. Intelligent task execution requires principled treatment of uncertainty sources in a robot's observation model. This is important not only for low-level observations (e.g., accelerom-eter data), but also for high-level observations such as semantic object labels. This paper formalizes the concept of macro-observations in Decentralized Partially Observable Semi-Markov Decision Processes (Dec-POSMDPs), allowing scalable semantic-level multi-robot decision making. A hierarchical Bayesian approach is used to model noise statistics of low-level classifier outputs, while simultaneously allowing sharing of domain noise characteristics between classes. Classification accuracy of the proposed macro-observation scheme, called Hierarchical Bayesian Noise Inference (HBNI), is shown to exceed existing methods. The macro-observation scheme is then integrated into a Dec-POSMDP planner, with hardware experiments running onboard a team of dynamic quadrotors in a challenging domain where noise-agnostic filtering fails. To the best of our knowledge, this is the first demonstration of a real-time, convolutional neural net-based classification framework running fully onboard a team of quadrotors in a multi-robot decision-making domain.
keywords: {Robots;Decision making;Semantics;Scalability;Probabilistic logic;Uncertainty;Noise measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989107&isnumber=7988677

T. Munzer, M. Toussaint and M. Lopes, "Preference learning on the execution of collaborative human-robot tasks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 879-885.
doi: 10.1109/ICRA.2017.7989108
Abstract: We present a novel method to learn human preferences during, and for, the execution of concurrent joint humanrobot tasks. We consider tasks realized by a team of a human operator and a robot helper that should adapt to the human's task execution preferences. Different human operators can have different abilities, experiences, and personal preferences, so that a particular allocation of activities in the team is preferred over another. We cast the behavior of concurrent multi-agent cooperation as a semi Markov Decision Process and show how to model and learn human preferences over the team behavior. After proposing two different interactive learning algorithms, we evaluate them and show that the system can effectively learn and adapt to human preferences.
keywords: {Robots;Collaboration;Adaptation models;Regression tree analysis;Decision making;Planning;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989108&isnumber=7988677

L. P. Kaelbling and T. Lozano-Pérez, "Learning composable models of parameterized skills," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 886-893.
doi: 10.1109/ICRA.2017.7989109
Abstract: There has been a great deal of work on learning new robot skills, but very little consideration of how these newly acquired skills can be integrated into an overall intelligent system. A key aspect of such a system is compositionality: newly learned abilities have to be characterized in a form that will allow them to be flexibly combined with existing abilities, affording a (good!) combinatorial explosion in the robot's abilities. In this paper, we focus on learning models of the preconditions and effects of new parameterized skills, in a form that allows those actions to be combined with existing abilities by a generative planning and execution system.
keywords: {Planning;Robots;Training;Uncertainty;Generators;Intelligent systems;Explosions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989109&isnumber=7988677

T. Mar, V. Tikhanoff, G. Metta and L. Natale, "Self-supervised learning of tool affordances from 3D tool representation through parallel SOM mapping," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 894-901.
doi: 10.1109/ICRA.2017.7989110
Abstract: Future humanoid robots will be expected to carry out a wide range of tasks for which they had not been originally equipped by learning new skills and adapting to their environment. A crucial requirement towards that goal is to be able to take advantage of external elements as tools to perform tasks for which their own manipulators are insufficient; the ability to autonomously learn how to use tools will render robots far more versatile and simpler to design. Motivated by this prospect, this paper proposes and evaluates an approach to allow robots to learn tool affordances based on their 3D geometry. To this end, we apply tool-pose descriptors to represent tools combined with the way in which they are grasped, and affordance vectors to represent the effect tool-poses achieve in function of the action performed. This way, tool affordance learning consists in determining the mapping between these 2 representations, which is achieved in 2 steps. First, the dimensionality of both representations is reduced by unsupervisedly mapping them onto respective Self-Organizing Maps (SOMs). Then, the mapping between the neurons in the tool-pose SOM and the neurons in the affordance SOM for pairs of tool-poses and their corresponding affordance vectors, respectively, is learned with a neural based regression model. This method enables the robot to accurately predict the effect of its actions using tools, and thus to select the best action for a given goal, even with tools not seen on the learning phase.
keywords: {Tools;Robots;Three-dimensional displays;Feature extraction;Histograms;Geometry;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989110&isnumber=7988677

D. Drieß, P. Englert and M. Toussaint, "Constrained Bayesian optimization of combined interaction force/task space controllers for manipulations," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 902-907.
doi: 10.1109/ICRA.2017.7989111
Abstract: In this paper, we address the problem of how a robot can optimize parameters of combined interaction force/task space controllers under a success constraint in an active way. To enable the robot to explore its environment robustly, safely and without the risk of damaging anything, suitable control concepts have to be developed that enable compliant and force control in situations that are afflicted with high uncertainties. Instances of such concepts are impedance, operational space or hybrid control. However, the parameters of these controllers have to be tuned precisely in order to achieve reasonable performance, which is inherently challenging, as often no sufficient model of the environment is available. To overcome this, we propose to use constrained Bayesian optimization to enable the robot to tune its controller parameters autonomously. Unlike other controller tuning methods, this method allows us to include a success constraint into the optimization. Further, we introduce novel performance measures for compliant, force controlled robots. In real world experiments we show that our approach is able to optimize the parameters for a task that consists of establishing and maintaining contact between the robot and the environment efficiently and successfully.
keywords: {Aerospace electronics;Robots;Bayes methods;Force;Tuning;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989111&isnumber=7988677

S. Choudhury, A. Kapoor, G. Ranade and D. Dey, "Learning to gather information via imitation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 908-915.
doi: 10.1109/ICRA.2017.7989112
Abstract: The budgeted information gathering problem - where a robot with a fixed fuel budget is required to maximize the amount of information gathered from the world - appears in practice across a wide range of applications in autonomous exploration and inspection with mobile robots. Although there is an extensive amount of prior work investigating effective approximations of the problem, these methods do not address the fact that their performance is heavily dependent on distribution of objects in the world. In this paper, we attempt to address this issue by proposing a novel data-driven imitation learning framework. We present an efficient algorithm, EXPLORE, that trains a policy on the target distribution to imitate a clairvoyant oracle - an oracle that has full information about the world and computes non-myopic solutions to maximize information gathered. We validate the approach on a spectrum of results on a number of 2D and 3D exploration problems that demonstrates the ability of EXPLORE to adapt to different object distributions. Additionally, our analysis provides theoretical insight into the behavior of EXPLORE. Our approach paves the way forward for efficiently applying data-driven methods to the domain of information gathering.
keywords: {Robot sensing systems;History;Trajectory;Three-dimensional displays;Training;Time measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989112&isnumber=7988677

G. Masuyama and K. Umeda, "Apprenticeship learning in an incompatible feature space," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 932-938.
doi: 10.1109/ICRA.2017.7989113
Abstract: This study presents a novel apprenticeship learning method to enable a learner to utilize demonstrations observed in an incompatible feature space. It is assumed that an expert and a learner follow non-identical Markov decision processes (MDPs), and a mapping function is estimated to obtain feature expectation of the demonstrations in an agent space. A conditional density estimation technique is used to represent the feature expectation in closed-form. The proposed method is useful because it is expected to alleviate intractable processes to explicitly specify correspondence of heterogeneous MDPs for apprenticeship learning. Additionally, the method does not require any sampling method to approximate integrals over an agent feature space. A simulation is used to demonstrate the validity of the proposed method in three domains in which it is not possible to directly compare the features of the expert and learner.
keywords: {Robots;Estimation;Learning (artificial intelligence);Kernel;Solid modeling;Markov processes;Sampling methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989113&isnumber=7988677

P. S. Zarrin, A. Escoto, R. Xu, R. V. Patel, M. D. Naish and A. L. Trejos, "Development of an optical fiber-based sensor for grasping and axial force sensing," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 939-944.
doi: 10.1109/ICRA.2017.7989114
Abstract: In spite of the remarkable benefits that minimally invasive surgery provides for patients, the absence of force feedback is still a significant disadvantage. Several studies have been performed to address this issue; however, an accurate sterilizable force sensing technology for measuring axial and grasping forces is still missing. In this work, an innovative partial grasper has been designed and developed for a laparoscopic needle driver that can measure axial and grasping force information at the grasper tip. Fiber Bragg Grating sensors are used in this work because of their sterilizability and high sensitivity. Accuracies of 0.19 N and 0.26 N were achieved for the grasping and axial sensors respectively.
keywords: {Force measurement;Force;Grasping;Instruments;Surgery;Robot sensing systems;Bragg gratings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989114&isnumber=7988677

M. Capurso, M. M. G. Ardakani, R. Johansson, A. Robertsson and P. Rocco, "Sensorless kinesthetic teaching of robotic manipulators assisted by observer-based force control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 945-950.
doi: 10.1109/ICRA.2017.7989115
Abstract: In modern day industry, robots are indispensable for achieving high production rates and competitiveness. In small and medium scale enterprises, where the production may shift rapidly, it is vital to be able to reprogram robots quickly. Kinesthetic teaching, also known as lead-through programming (LTP), provides a fast approach for teaching a trajectory. In this approach, a trajectory is demonstrated by physical interaction with the robot, i.e., the user manually guides the manipulator. This paper presents a sensorless approach to LTP for redundant robots that eliminates the need for expensive force/torque sensors. The active implementation enhances the passive LTP by an admittance control in joint space based on the external forces applied by the user, estimated with a Kalman filter using the generalized momentum formulation. To improve the quality of the estimation and hence LTP, we use a dithering technique. The active LTP has been implemented on ABB YuMi robot and experimental comparison with an earlier passive LTP is presented.
keywords: {Friction;Robot sensing systems;Torque;Force;Observers;Admittance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989115&isnumber=7988677

W. Yuan, C. Zhu, A. Owens, M. A. Srinivasan and E. H. Adelson, "Shape-independent hardness estimation using deep learning and a GelSight tactile sensor," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 951-958.
doi: 10.1109/ICRA.2017.7989116
Abstract: Hardness is among the most important attributes of an object that humans learn about through touch. However, approaches for robots to estimate hardness are limited, due to the lack of information provided by current tactile sensors. In this work, we address these limitations by introducing a novel method for hardness estimation, based on the GelSight tactile sensor, and the method does not require accurate control of contact conditions or the shape of objects. A GelSight has a soft contact interface, and provides high resolution tactile images of contact geometry, as well as contact force and slip conditions. In this paper, we try to use the sensor to measure hardness of objects with multiple shapes, under a loosely controlled contact condition. The contact is made manually or by a robot hand, while the force and trajectory are unknown and uneven. We analyze the data using a deep constitutional (and recurrent) neural network. Experiments show that the neural net model can estimate the hardness of objects with different shapes and hardness ranging from 8 to 87 in Shore 00 scale.
keywords: {Force;Tactile sensors;Force measurement;Shape;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989116&isnumber=7988677

P. Piacenza et al., "Accurate contact localization and indentation depth prediction with an optics-based tactile sensor," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 959-965.
doi: 10.1109/ICRA.2017.7989117
Abstract: Traditional methods to achieve high localization accuracy with tactile sensors usually use a matrix of miniaturized individual sensors distributed on the area of interest. This approach usually comes at a price of increased complexity in fabrication and circuitry, and can be hard to adapt for non planar geometries. We propose to use low cost optic components mounted on the edges of the sensing area to measure how light traveling through an elastomer is affected by touch. Multiple light emitters and receivers provide us with a rich signal set that contains the necessary information to pinpoint both the location and depth of an indentation with high accuracy. We demonstrate sub-millimeter accuracy on location and depth on a 20mm by 20mm active sensing area. Our sensor provides high depth sensitivity as a result of two different modalities in how light is guided through our elastomer. This method results in a low cost, easy to manufacture sensor. We believe this approach can be adapted to cover non-planar surfaces, simplifying future integration in robot skin applications.
keywords: {Light emitting diodes;Receivers;Tactile sensors;Photodiodes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989117&isnumber=7988677

T. Paulino et al., "Low-cost 3-axis soft tactile sensors for the human-friendly robot Vizzy," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 966-971.
doi: 10.1109/ICRA.2017.7989118
Abstract: In this paper we present a low-cost and easy to fabricate 3-axis tactile sensor based on magnetic technology. The sensor consists in a small magnet immersed in a silicone body with an Hall-effect sensor placed below to detect changes in the magnetic field caused by displacements of the magnet, generated by an external force applied to the silicone body. The use of a 3-axis Hall-effect sensor allows to detect the three components of the force vector, and the proposed design assures high sensitivity, low hysteresis and good repeatability of the measurement: notably, the minimum sensed force is about 0.007N. All components are cheap and easy to retrieve and to assemble; the fabrication process is described in detail and it can be easily replicated by other researchers. Sensors with different geometries have been fabricated, calibrated and successfully integrated in the hand of the human-friendly robot Vizzy. In addition to the sensor characterization and validation, real world experiments of object manipulation are reported, showing proper detection of both normal and shear forces.
keywords: {Robot sensing systems;Force;Magnetic hysteresis;Sensitivity;Force sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989118&isnumber=7988677

A. Levratti, G. Riggio, A. De Vuono, C. Fantuzzi and C. Secchi, "Safe navigation and experimental evaluation of a novel tire workshop assistant robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 994-999.
doi: 10.1109/ICRA.2017.7989119
Abstract: This paper presents TIREBOT, a novel tire-workshop robotic co-worker that can safely move in a tire workshop and assist the operator in lifting and transporting wheels among several working stations. A safe and cooperative navigation strategy based on the concept of danger field is illustrated. Finally, TIREBOT is experimentally evaluated in a real tire-workshop and used by real operator in order to assess the usability and the effectiveness of the robot in a real operating scenario.
keywords: {Wheels;Mobile robots;Navigation;Tires;Conferences;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989119&isnumber=7988677

J. R. Guadarrama-Olvera, E. Dean and G. Cheng, "Using intentional contact to achieve tasks in tight environments," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1000-1005.
doi: 10.1109/ICRA.2017.7989120
Abstract: Skin technology enabled a powerful way to sense the environment in robotic systems. It allows simplifying the formulation of safety tasks such as collision avoidance between the robot, the environment and surrounding objects. In this paper, a hierarchy policy based on tactile feedback is proposed to let a robot interact with its environment while performing a set of tasks. Such policy lets the safety tasks as collision avoidance and physical interaction, be reduced to simple potential field rules fed directly with tactile feedback which keeps computation demand low. In this context, the concept of “Intentional Contact” is introduced to escape from classic undesired equilibrium points produced by local minima in the potential fields. Allowed contact with the environment empowers a robot to modify its surroundings in order to fulfil the main task. Such contact is permitted as long as the generated force remains under a specific limit, otherwise, a reactive action is taken to reduce it. This new concept is validated in simulation and on a real robot.
keywords: {Collision avoidance;Robot sensing systems;Force;Skin;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989120&isnumber=7988677

D. Whitney, E. Rosen, J. MacGlashan, L. L. S. Wong and S. Tellex, "Reducing errors in object-fetching interactions through social feedback," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1006-1013.
doi: 10.1109/ICRA.2017.7989121
Abstract: Fetching items is an important problem for a social robot. It requires a robot to interpret a person's language and gesture and use these noisy observations to infer what item to deliver. If the robot could ask questions, it would help the robot be faster and more accurate in its task. Existing approaches either do not ask questions, or rely on fixed question-asking policies. To address this problem, we propose a model that makes assumptions about cooperation between agents to perform richer signal extraction from observations. This work defines a mathematical framework for an item-fetching domain that allows a robot to increase the speed and accuracy of its ability to interpret a person's requests by reasoning about its own uncertainty as well as processing implicit information (implicatures). We formalize the item-delivery domain as a Partially Observable Markov Decision Process (POMDP), and approximately solve this POMDP in real time. Our model improves speed and accuracy of fetching tasks by asking relevant clarifying questions only when necessary. To measure our model's improvements, we conducted a real world user study with 16 participants. Our method achieved greater accuracy and a faster interaction time compared to state-of-the-art baselines. Our model is 2.17 seconds faster (25% faster) than a state-of-the-art baseline, while being 2.1% more accurate.
keywords: {Robots;Noise measurement;Speech;Markov processes;Real-time systems;Computational modeling;Natural languages},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989121&isnumber=7988677

A. Roncone, O. Mangin and B. Scassellati, "Transparent role assignment and task allocation in human robot collaboration," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1014-1021.
doi: 10.1109/ICRA.2017.7989122
Abstract: Collaborative robots represent a clear added value to manufacturing, as they promise to increase productivity and improve working conditions of such environments. Although modern robotic systems have become safe and reliable enough to operate close to human workers on a day-to-day basis, the workload is still skewed in favor of a limited contribution from the robot's side, and a significant cognitive load is allotted to the human. We believe the transition from robots as recipients of human instruction to robots as capable collaborators hinges around the implementation of transparent systems, where mental models about the task are shared between peers, and the human partner is freed from the responsibility of taking care of both actors. In this work, we implement a transparent task planner able to be deployed in realistic, near-future applications. The proposed framework is capable of basic reasoning capabilities for what concerns role assignment and task allocation, and it interfaces with the human partner at the level of abstraction he is most comfortable with. The system is readily available to non-expert users, and programmable with high-level commands in an intuitive interface. Our results demonstrate an overall improvement in terms of completion time, as well as a reduced cognitive load for the human partner.
keywords: {Robot kinematics;Collaboration;Uncertainty;Legged locomotion;Resource management;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989122&isnumber=7988677

B. Lim, S. Hyoung, J. Lee, K. Seo, J. Jang and Y. Shim, "Simulating gait assistance of a hip exoskeleton: Case studies for ankle pathologies," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1022-1027.
doi: 10.1109/ICRA.2017.7989123
Abstract: We propose a simulation framework for gait assistance with ankle pathologies. We first construct the neu-romuscular walking model, then design the parameters for assistance torques for stance and swing legs. The parameter values are determined by performing dynamic optimizations which takes into account the human-exoskeleton interactive dynamics. The simulated energy expenditure and kinematic data are compared with the real data. Case studies involve abnormal gaits with 1) foot drop, 2) foot drop and plantarflexion failure. We evaluate the gait efficiency and walking speed for the different gait types. Our result shows that each gait type should have a different assistance strategy (timing and magnitude) compared to the assistance strategy of a normal gait.
keywords: {Legged locomotion;Foot;Pathology;Muscles;Hip;Optimization;Exoskeletons},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989123&isnumber=7988677

H. -M. Gross et al., "Mobile robot companion for walking training of stroke patients in clinical post-stroke rehabilitation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1028-1035.
doi: 10.1109/ICRA.2017.7989124
Abstract: This paper introduces a novel robot-based approach to the stroke rehabilitation scenario, in which a mobile robot companion accompanies stroke patients during their walking self-training. This assistance enables them to move freely in the clinic practicing both their mobility and spatial orientation skills. Based on a set of questions for systematic evaluating the autonomy and practicability of assistive robots and a three-stage approach in conducting function and user tests in the clinical setting, we present the results of user trials performed with N=30 stroke patients in a stroke rehabilitation center between 4/2015 and 3/2016. This allowed us to make an honest inventory of the strengths and weaknesses of the developed robot companion and its already achieved practicability for clinical use. The results of the user studies show that patients and fellow patients were very open-minded and accepted the robotic coach. The robot motivated them for independent training and leaving their room, despite severe consequences of stroke (lower limbs paralysis, speech/language problems, loss of orientation, depression), provided a very self-determined training regime, and encouraged them to expand the radius of their training in the clinic.
keywords: {Training;Legged locomotion;Navigation;Mobile communication;Meters},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989124&isnumber=7988677

K. Sato, K. Watanabe, S. Mizuno, M. Manabe, H. Yano and H. Iwata, "Development of a block machine for volleyball attack training," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1036-1041.
doi: 10.1109/ICRA.2017.7989125
Abstract: This paper presents a system that consists of three robots to imitate the motion of top volleyball blockers. In a volleyball match, in order to score by spiking, it is essential to improve the spike decision rate of each spiker. To increase the spike decision rates, iterative spiking training with actual blockers is required. Therefore, in this study, a block machine system was developed that can be continuously used in an actual practice field to improve attack practice. In order to achieve the required operating speed and mechanical strength each robot has five degrees of freedom. This robot performs high speed movement on 9 m rails that are arranged in parallel with the volleyball net. In addition, an application with a graphical user interface to enable a coach to manipulate these robots was developed. It enables the coach to control block motions and change the parameters such as the robots' positions and operation timing. Through practical use in the practice field, the effectiveness of this system was confirmed.
keywords: {Training;Rails;Games;Timing;Rubber;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989125&isnumber=7988677

A. Elfes et al., "The Multilegged Autonomous eXplorer (MAX)," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1050-1057.
doi: 10.1109/ICRA.2017.7989126
Abstract: To address the goal of locomotion in very complex and difficult terrains, the authors are developing a new class of Ultralight Legged Robots. This paper presents the Multilegged Autonomous eXplorer (MAX), an ultralight, six-legged robot for traversal and exploration of challenging indoor and outdoor environments. The design of MAX emphasizes a low mass/size ratio, high locomotion efficiency, and high payload capability compared to total system mass. MAX is 2.25 m tall at full height and has a mass of approximately 60 kg, which makes it 5 to 20 times lighter than robots of comparable size. MAX is a research vehicle to explore modelling and control of Ultralight Legged Robots subject to flexing, oscillations and swaying; algorithms for gait planning and motion planning under uncertainty; and navigation planning for traversal of complex 3D terrains. This paper presents the design of MAX, provides an overview of the control system developed, summarizes results from indoor and outdoor tests, discusses system performance and outlines the challenges to be addressed next.
keywords: {Legged locomotion;Actuators;Planning;Foot;Payloads},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989126&isnumber=7988677

J. Duperret and D. E. Koditschek, "Empirical validation of a spined sagittal-plane quadrupedal model," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1058-1064.
doi: 10.1109/ICRA.2017.7989127
Abstract: We document empirically stable bounding using an actively powered spine on the Inu quadrupedal robot, and propose a reduced-order model to capture the dynamics associated with this additional, actuated spine degree of freedom. This model is sufficiently accurate as to roughly describe the robots mass center trajectory during a bounding limit cycle, thus making it a potential option for low dimensional representations of spine actuation in steady-state legged locomotion.
keywords: {Legged locomotion;Reduced order systems;Belts;Springs;Biology;Modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989127&isnumber=7988677

H. Heijnen, D. Howard and N. Kottege, "A testbed that evolves hexapod controllers in hardware," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1065-1071.
doi: 10.1109/ICRA.2017.7989128
Abstract: Evolutionary algorithms have previously shown promise in generating controllers for legged robots. Multiple evaluations across many evolutionary generations are typically required - simulators are frequently used to accommodate this. However, performance degradation is frequently observed when transferring controllers from simulation to reality due to inconsistencies between the two. In this paper we demonstrate a testbed that permits repeated, direct evolution of hexapod controllers as a closed-loop system. The testbed uses a two-stage evolutionary process. In stage 1, a multi-objective evolutionary algorithm spreads a population of controllers across a space of desirable criteria. The second stage allows for specific criteria to be selected for on a per-mission basis, with promising initial controller parameters taken from the first stage. As the optimisation occurs directly on the robot, performance is guaranteed. Furthermore, controllers can be made specific to irregularities in e.g., motor wear, and robot mass distribution, creating controllers that are sensitive to the hardware state of the individual robot.
keywords: {Legged locomotion;Optimization;Robot sensing systems;Hardware;Servomotors;Foot},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989128&isnumber=7988677

O. Y. Kanner, N. Rojas and A. M. Dollar, "Between-leg coupling schemes for passively-adaptive non-redundant legged robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1072-1079.
doi: 10.1109/ICRA.2017.7989129
Abstract: This paper studies the synthesis of between-leg coupling schemes for passively-adaptive non-redundant legged robots. Highly actuated legged robots can arbitrarily locate their feet relative to their bodies through active control, but often wind up kinematically over-constrained following ground contact, requiring complex redundant control for stable locomotion. The use of passive sprung joints can provide some minimal passive adaptability to terrain, but it is limited to relatively low terrain variability due to practical travel limits. In this paper, using a 4-RR platform as case study, we show that implementing parallel adaptive couplings between legs of a stance platform can yield substantial passive adaptability to rough terrain while still ensuring that the body is fully constrained in stance. This study uses screw theory-based mobility analysis methods to determine the number of constraints required to control the stance platform. Several coupling schemes are then considered and evaluated through a simulation of their stance capabilities over arbitrary terrain. An experimental validation of these simulation results is presented; it demonstrates the viability of the proposed scheme for passive adaptability.
keywords: {Legged locomotion;Fasteners;Foot;Couplings;Actuators;Hip},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989129&isnumber=7988677

T. T. Topping, G. Kenneally and D. E. Koditschek, "Quasi-static and dynamic mismatch for door opening and stair climbing with a legged robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1080-1087.
doi: 10.1109/ICRA.2017.7989130
Abstract: This paper contributes to quantifying the notion of robotic fitness by developing a set of necessary conditions that determine whether a small quadruped has the ability to open a class of doors or climb a class of stairs using only quasi-static maneuvers. After verifying that several such machines from the recent robotics literature are mismatched in this sense to the common human scale environment, we present empirical work-arounds for the Minitaur quadrupedal platform that enable it to leap up, force the door handle and push through the door, as well as bound up the stairs, thereby accomplishing through dynamical maneuvers otherwise (i.e., quasi-statically) unachievable tasks.
keywords: {Friction;Force;Dynamics;Legged locomotion;Springs;Latches},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989130&isnumber=7988677

C. Mastalli et al., "Trajectory and foothold optimization using low-dimensional models for rough terrain locomotion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1096-1103.
doi: 10.1109/ICRA.2017.7989131
Abstract: We present a trajectory optimization framework for legged locomotion on rough terrain. We jointly optimize the center of mass motion and the foothold locations, while considering terrain conditions. We use a terrain costmap to quantify the desirability of a foothold location. We increase the gait's adaptability to the terrain by optimizing the step phase duration and modulating the trunk attitude, resulting in motions with guaranteed stability. We show that the combination of parametric models, stochastic-based exploration and receding horizon planning allows us to handle the many local minima associated with different terrain conditions and walking patterns. This combination delivers robust motion plans without the need for warm-starting. Moreover, we use soft-constraints to allow for increased flexibility when searching in the cost landscape of our problem. We showcase the performance of our trajectory optimization framework on multiple terrain conditions and validate our method in realistic simulation scenarios and experimental trials on a hydraulic, torque controlled quadruped robot.
keywords: {Trajectory optimization;Legged locomotion;Planning;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989131&isnumber=7988677

Y. Dai, Y. Xue, J. Zhang and J. Li, "Biologically-inspired auditory perception during robotic bone milling," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1112-1116.
doi: 10.1109/ICRA.2017.7989132
Abstract: Bone milling is widely used in many hard tissue surgical procedures, and the main concern is the mechanical damage to some important tissues induced by the high-speed rotating tool. In this study, the behavior of the human auditory system is analyzed. Following this, a commercially available microphone is mounted on the robot arm and then measures the sound generated from bone milling. Inspired by the bandpass filtering in the cochlea, the recorded sound pressure signal is decomposed into a set of subband signals by wavelet packet transform. Inspired by encoding and perception mechanisms in human auditory system, the average amplitude of the wavelet coefficients in each subband is calculated and inputted to a self-organizing feature map so as to classify different milling states. In order to increase the robustness to noise, the sum of the Manhattan distances between all winning neurons is calculated to select the optimum dimension of the map. The experimental results in milling in vitro porcine spines prove that the proposed method can determine which type of tissue is being cut when the suction noise exists, and the success classification rate is no less than 85%. Therefore, the safety of the robot-assisted milling surgery is improved.
keywords: {Milling;Bones;Neurons;Surgery;Microphones;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989132&isnumber=7988677

J. B. Gafford, R. J. Wood and C. J. Walsh, "A high-force, high-stroke distal robotic add-on for endoscopy," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1117-1124.
doi: 10.1109/ICRA.2017.7989133
Abstract: `Snap-On' robotic modules that can integrate distally with existing commercially-available endoscopic equipment have the potential to provide new capabilities such as enhanced dexterity, bilateral manipulation and feedback sensing with minimal disruption of the current clinical workflow. However, the desire for fully-distal integration of sensors and actuators and the resulting form factor requirements preclude the use of many off-the-shelf actuators capable of generating the relevant strokes and forces required to interact with tools and tissue. In this work, we investigate the use of millimeter-scale, optimally-packed helical shape memory alloy (SMA) actuators in an antagonistic configuration to provide distal actuation without the need for a continuous mechanical coupling to proximal, off-board actuation packages to realize a truly plug-and-play solution. Using phenomenological modeling, we design and fabricate antagonistic helical SMA pairs and implement them in an at-scale roboendoscopic module to generate strokes and forces necessary for deflecting tools passed through the endoscope working port, thereby providing a controllable robotic `wrist' inside the body to otherwise passive flexible tools. Bandwidth is drastically improved through the integration of targeted fluid cooling. The integrated system can generate maximum lateral forces of 10N and demonstrates an additional 96 degrees of distal angulation, expanding the reachable workspace of tools passed through a standard endoscope.
keywords: {Actuators;Force;Mathematical model;Robot sensing systems;Strain;Stress},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989133&isnumber=7988677

T. Ranzani, S. Russo, F. Schwab, C. J. Walsh and R. J. Wood, "Deployable stabilization mechanisms for endoscopic procedures," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1125-1131.
doi: 10.1109/ICRA.2017.7989134
Abstract: Flexible endoscopes are still the gold standard in most natural orifice translumenal endoscopic surgery (NOTES) procedures; however their flexibility (necessary for navigating through the GI tract) limits their capabilities in terms of distal manipulation and stability. We propose a deployable endoscopic add-on aimed at locally counteracting forces applied at the tip of an endoscope. We analyze different designs: a fully soft version and two hybrid soft-folded versions. The hybrid designs exploit either an inextensible structure pressurized by a soft actuator or the stiffness provided by the unfolded “magic cube” origami structure. We focus on the fabrication and experimental characterization of the proposed structures and present some preliminary designs and integration strategies to mount them on top of current flexible endoscopes.
keywords: {Actuators;Endoscopes;Force;Strain;Fabrication;Instruments;Limiting},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989134&isnumber=7988677

D. Son, M. D. Dogan and M. Sitti, "Magnetically actuated soft capsule endoscope for fine-needle aspiration biopsy," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1132-1139.
doi: 10.1109/ICRA.2017.7989135
Abstract: This paper presents a magnetically actuated soft capsule endoscope for fine-needle aspiration biopsy (B-MASCE) in the upper gastrointestinal tract. A thin and hollow needle is attached to the capsule, which can penetrate deeply into tissues to obtain subsurface biopsy sample. The design utilizes a soft elastomer body as a compliant mechanism to guide the needle. An internal permanent magnet provides a means for both actuation and tracking. The capsule is designed to roll towards its target and then deploy the biopsy needle in a precise location selected as the target area. B-MASCE is controlled by multiple custom-designed electromagnets while its position and orientation are tracked by a magnetic sensor array. In in vitro trials, B-MASCE demonstrated rolling locomotion and biopsy of a swine tissue model positioned inside an anatomical human stomach model. It was confirmed after the experiment that a tissue sample was retained inside the needle.
keywords: {Needles;Biopsy;Stomach;Couplings;Endoscopes;Magnetic forces;Lesions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989135&isnumber=7988677

H. Zhao, E. Ambrose and A. D. Ames, "Preliminary results on energy efficient 3D prosthetic walking with a powered compliant transfemoral prosthesis," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1140-1147.
doi: 10.1109/ICRA.2017.7989136
Abstract: This work presents the preliminary experimental validation of a systematic prosthetic control strategy on a custom compliant transfemoral prosthesis with the end result being energy efficient 3-dimension (3D) multi-contact prosthetic walking. In particular, with the goal of capturing essential components of realistic amputee-prosthesis system, a 3D asymmetric hybrid system model is presented - this forms the foundation for formal gait design and control construction. Based on this model, a two-step direct collocation optimization method is utilized to design an energy efficient multi-contact prosthetic gait in 3D. The designed gaits are also subject to various practical constraints such as human-likeness constraints and comfortability constraints. For experimental validation, a 3D capable powered transfemoral prosthetic device is custom built so as to be amendable to realizing the designed 3D prosthetic gaits. Differentiating this device from existing powered prosthesis, compliant components are added to the three joints (two pitch joints and one roll joint) for the purpose of energy saving and human-like behaviors. Combining the presented control methodology and the novel hardware design, the end result is experimentally realized 3D multi-contact prosthetic walking with improved energy efficiency compared to other devices and control methods.
keywords: {Prosthetics;Three-dimensional displays;Legged locomotion;Systematics;Control systems;Springs},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989136&isnumber=7988677

N. Burkhard et al., "A rolling-diaphragm hydrostatic transmission for remote MR-guided needle insertion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1148-1153.
doi: 10.1109/ICRA.2017.7989137
Abstract: Magnetic resonance imaging (MRI) offers many benefits, including unsurpassed soft-tissue characterization and the ability to combine detection and biopsy into a single procedure. However, limited patient access in the narrow scanner bore requires tedious iterative positioning or use of robotic assistants that isolate the physician from the patient. As an alternative, we present a teleoperation technology for percutaneous procedures to meet the needs of interventional radiologists and overcome challenges imposed by the MR environment. The technology is demonstrated for a 1-DOF needle insertion procedure. The technology uses rolling diaphragms, a clutch, and a cable-capstan drive to propel the needle while relaying forces and motions to the operator. The system demonstrates excellent position tracking (< 0.7° error in the unloaded case) and reliably transmits changes in force. During needle teleoperation, users were able to detect light membrane punctures and differentiate spring stiffnesses nearly as accurately as by hand manipulation.
keywords: {Needles;Force;Biopsy;Haptic interfaces;Magnetic resonance imaging;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989137&isnumber=7988677

K. M. Popek, T. Hermans and J. J. Abbott, "First demonstration of simultaneous localization and propulsion of a magnetic capsule in a lumen using a single rotating magnet," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1154-1160.
doi: 10.1109/ICRA.2017.7989138
Abstract: This paper presents a method for closed-loop propulsion of a screw-type magnetic capsule with embedded Hall-effect sensors using a single rotating actuator magnet. The method estimates the six-degree-of-freedom (6-DOF) pose of the capsule while it is synchronously rotating with the applied field. It is intended for application in active capsule endoscopy of the intestines. An extended Kalman filter, which uses a simplified 2-DOF process model restricting the capsule to forward or backward movement and rotation about its principle axis, is used to provide a full 6-DOF estimate of the capsule's pose as the capsule travels through a lumen. The capsule's movement in the applied field is constantly monitored to determine if the capsule is synchronously rotating with the applied field. Based on this information, the rotation speed of the external source is adjusted to prevent a loss in the desired magnetic coupling. We experimentally demonstrate, for the first time, simultaneous localization and closed-loop propulsion of a capsule through a lumen using a single rotating magnet. Prior work assumed the capsule had no net motion during the localization phase, requiring decoupled localization and propulsion. This closed-loop performance results in a three times speed up in completion time, compared to the previous decoupled approach.
keywords: {Propulsion;Magnetic sensors;Robot sensing systems;Actuators;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989138&isnumber=7988677

H. Wakamatsu, E. Morinaga, E. Arai and T. Kubo, "A virtual paper model of a three piece brassiere cup to improve the efficiency of cup design process," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1169-1174.
doi: 10.1109/ICRA.2017.7989139
Abstract: A method is proposed to predict the shape of a paper model of a three piece brassiere cup, which consists of several cloth and wire parts. Currently, the shape of each part is determined by creating a paper model and then refining the model. This process is repeated until the desired shape is achieved. However, predicting the 3D shape with a simulation would improve design efficiency. As a model is made of paper, each part is assumed to be inextensible and its surface is represented as combination of developable surfaces. The potential energy of a cup and geometric constraints imposed on the cup are formulated by use of the normal curvature and the direction of a generatrix of each developable surface. Minimizing the potential energy under geometric constraints derives a stable shape of the cup model. The computed and measured cup shapes coincided qualitatively.
keywords: {Shape;Solid modeling;Ribs;Predictive models;Integrated circuit modeling;Wires;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989139&isnumber=7988677

C. Wu, C. Dai, G. Fang, Y. -J. Liu and C. C. L. Wang, "RoboFDM: A robotic system for support-free fabrication using FDM," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1175-1180.
doi: 10.1109/ICRA.2017.7989140
Abstract: This paper presents a robotic system - RoboFDM that targets at printing 3D models without support-structures, which is considered as the major restriction to the flexibility of 3D printing. The hardware of RoboFDM consists of a robotic arm providing 6-DOF motion to the platform of material accumulation and an extruder forming molten filaments of polylactic acid (PLA). The fabrication of 3D models in this system follows the principle of fused decomposition modeling (FDM). Different from conventional FDM, an input model fabricated by RoboFDM is printed along different directions at different places. A new algorithm is developed to decompose models into support-free parts that can be printed one by one in a collision-free sequence. The printing directions of all parts are also determined during the computation of model decomposition. Experiments have been successfully taken on our RoboFDM system to print general freeform objects in a support-free manner.
keywords: {Fabrication;Shape;Three-dimensional printing;Manipulators;Frequency division multiplexing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989140&isnumber=7988677

S. Lensgraf and R. R. Mettu, "An improved toolpath generation algorithm for fused filament fabrication," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1181-1187.
doi: 10.1109/ICRA.2017.7989141
Abstract: Widely-used methods for toolpath planning in fused filament fabrication slice the input 3D model into 2D layers and construct a toolpath. In prior work (ICRA 2016) we gave a simple greedy algorithm that changed this paradigm and constructed the toolpath in 3D by printing local features in their entirety. This algorithm significantly improved upon layer-based methods, achieving a 34% mean reduction of wasted motion. In this paper we give a new algorithm that is more robust and achieves significantly better performance than the greedy approach. Our algorithm utilizes local search and nearly doubles our prior improvement, achieving a mean/median reduction of 62% over layer-based methods on the same benchmark of over 400 models. We also study toolpath optimality using a novel integer linear programming formulation. This formulation allows us to solve a linear programming relaxation that, while computationally intensive, can give us a lower bound on the optimal solution quality, giving us the ability to rigorously characterize solution quality for a given input model.
keywords: {Computational modeling;Three-dimensional displays;Solid modeling;Printers;Fabrication;Printing;Greedy algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989141&isnumber=7988677

B. Canaday, S. Zapolsky and E. Drumwright, "Interactive, iterative robot design," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1188-1195.
doi: 10.1109/ICRA.2017.7989142
Abstract: Consider how a new robot is designed. Starting from a relative size (e.g., nanometer, centimeter, meter), the roboticist picks a morphological type (manipulator, quadruped, biped), and then uses intuition, experience, biological inspiration, or some combination of the three to select kinematic, dynamic, and geometric parameters. The designer then conducts preliminary checks to see whether the robot can satisfy its intended function: manipulation, locomotion, or both. The designer then iteratively adjusts the physical parameters and conducts checks using sample tasks, presumably until convergence is reached. This paper describes a means to automate part of this approach by combining interactive elements with powerful tools that use multi-rigid body simulation. We describe and demonstrate a virtual testing phase that first determines whether the physically situated robot would serve its intended purpose. If the robot is not capable of performing its target task, the virtual testing phase can determine which of the robot's morphological parameters should be modified in order to do so. The process keeps a human in the loop to help account for hard to quantify design aspects like appearance, quirks of the fabrication procedure (i.e., laser cutting, milling, 3D printing processes), or even expert knowledge. We intend for the described approach to be used as an interactive tool that gives a robot designer feedback on what morphological parameters are likely to limit the performance of a robot and how to modify the design to fix or offset such limitations. We demonstrate that, through simulated prototyping and testing methods, we can improve a robot design and iteratively locate morphological parameters that make efficient use of available hardware.
keywords: {Legged locomotion;Educational robots;Actuators;Robot kinematics;Morphology;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989142&isnumber=7988677

R. Desai, Y. Yuan and S. Coros, "Computational abstractions for interactive design of robotic devices," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1196-1203.
doi: 10.1109/ICRA.2017.7989143
Abstract: We present a computational design system that allows novices and experts alike to easily create custom robotic devices using modular electromechanical components. The core of our work consists of a design abstraction that models the way in which these components can be combined to form complex robotic systems. We use this abstraction to develop a visual design environment that enables an intuitive exploration of the space of robots that can be created using a given set of actuators, mounting brackets and 3d-printable components. Our computational system also provides support for design auto-completion operations, which further simplifies the task of creating robotic devices. Once robot designs are finished, they can be tested in physical simulations and iteratively improved until they meet the individual needs of their users. We demonstrate the versatility of our computational design system by creating an assortment of legged and wheeled robotic devices. To test the physical feasibility of our designs, we fabricate a wheeled device equipped with a 5-DOF arm and a quadrupedal robot.
keywords: {Pins;Legged locomotion;Libraries;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989143&isnumber=7988677

T. Tosun, D. Edgar, C. Liu, T. Tsabedze and M. Yim, "PaintPots: Low cost, accurate, highly customizable potentiometers for position sensing," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1212-1218.
doi: 10.1109/ICRA.2017.7989144
Abstract: The PaintPot manufacturing process is a new way to create low-cost, low-profile, highly customizable potentiometers for position sensing in robotic applications. It uses widely accessible materials, requires no special expertise, and creates custom potentiometers in a variety of shapes and sizes, including curved surfaces. PaintPots offer accuracy and precision performance comparable with commercial (non-customizable) options through a calibration process that trades small computation for cost. This paper includes detailed PaintPot manufacturing and calibration processes, and experiments that validate the accuracy, precision, and lifetime performance of PaintPots, comparable to commercial sensors. We also provide a case-study application in the SMORES-EP modular robot, and show how the PaintPot process can be used to create resistive surfaces capable of sensing position in 2D on planes and spheres.
keywords: {Potentiometers;Robot sensing systems;Surface treatment;Paints;Plastics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989144&isnumber=7988677

M. J. Kim, A. Werner, F. C. Loeffl and C. Ott, "Enhancing joint torque control of series elastic actuators with physical damping," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1227-1234.
doi: 10.1109/ICRA.2017.7989145
Abstract: This paper presents that the joint torque control capability can be enhanced by adding physical damper to a series elastic actuator (SEA). Joint torque tracking of standard SEA has known limitations that the torque dynamics has an relative order of two, and, as a consequence, the torque controller often requires acceleration feedback when the desired torque is defined by a function of velocity (for example, compliance control). This limitation can be removed by introducing physical damping, reducing the relative degree of torque dynamics by one. Based on this observation, we design a robust controller using the disturbance observer technique. The resulting control law is given by a feed-forward term combined with PI control. The proposed controller is verified in simulation and experiment.
keywords: {Torque;Torque control;Damping;Aerodynamics;Robots;Actuators;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989145&isnumber=7988677

A. Dahiya and D. J. Braun, "Efficiently tunable positive-negative stiffness actuator," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1235-1240.
doi: 10.1109/ICRA.2017.7989146
Abstract: Compliant actuators have found their place in areas of prosthetics, rehabilitation and robot locomotion because they enable safe human-robot and stable robot-environment interaction, both non-trivial to achieve using conventional rigid actuation. These actuators are capable of varying their equilibrium position and apparent output stiffness in a way humans change the resting position and compliance of their limbs. Just like antagonistically actuated human joints, these actuators require two motor units to provide control over the equilibrium position and the positive joint stiffness. Here we present a novel compliant actuation concept which affords control over the equilibrium position and joint stiffness using a single motor unit. In order to achieve this unconventional functionality, the actuator combines a passive positive feedback (negative stiffness) mechanism with an efficiently tunable negative feedback (positive stiffness) mechanism. This provides a novel design with two distinct operation modes, one leading to unprecedented stiffness tunability, while the other enabling equilibrium point controllability. We present the first practical implementation of this actuator using a prototype prosthetic limb design along with experimental data testifying the range of tunability, covering compliant to rigid behaviour, without paying much on the power input.
keywords: {Actuators;Force;Springs;Modulation;Negative feedback;Load modeling;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989146&isnumber=7988677

T. H. Chong, V. Chalvet and D. J. Braun, "Analytical conditions for the design of variable stiffness mechanisms," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1241-1247.
doi: 10.1109/ICRA.2017.7989147
Abstract: This paper introduces an analytical approach for the design of variable stiffness mechanisms. The basis of this approach is a general model - representing the potential energy function and the physical constraints - covering the design space of variable stiffness mechanisms. Using this model, we present a systematic procedure to analytically define classes of variable stiffness mechanisms from first principles. Consequently, we identify mechanisms capable of infinite range stiffness modulation using bounded motor forces, and define the simplest mathematical model representing mechanisms in this class. A prototype mechanism consistent with this canonical model is designed, fabricated and experimentally tested. The experimental data are consistent with our theoretical predictions showing constant motor force independent of the output deflection and output stiffness when the mechanism is subject to external load.
keywords: {Force;Potential energy;Actuators;Mathematical model;Modulation;Analytical models;Load modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989147&isnumber=7988677

N. Kashiri, D. G. Caldwell and N. Tsagarakis, "A self-adaptive variable impedance actuator based on intrinsic non-linear compliance and damping principles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1248-1254.
doi: 10.1109/ICRA.2017.7989148
Abstract: Despite the growing focus on the design of compliant mechanisms for robotics actuators that manifest several advantages in terms of robustness and interaction-related characteristics, the incorporation of elasticity in the actuation drive renders under-damped vibration modes and reduces the bandwidth of the system. The addition of damping principles into compliant systems can address such impediments to accuracy and stability, and enhance the passivity characteristics of the controlled compliant actuator. However, passive damping mechanisms integrated into compliant systems to exhibit user-defined passive dissipation profiles have not been realized. This paper proposes a non-linear stiffness compliant module, and introduces a novel non-linear damper which complements the elastic element. The cam-follower mechanism was employed for rendering the user-defined non-linear behaviour. While the passive compliance of the module is replicated using a curved leaf spring, the passive damping is generated by rolling/sliding motion of a rigid cylinder on an elastomer. The design of the module is described, the theoretical modelling is presented, and experimental results validating the functionality of the proposed design in dissipating under-damped oscillations are demonstrated.
keywords: {Springs;Damping;Shock absorbers;Actuators;Robots;Torque;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989148&isnumber=7988677

A. Toedtheide, E. Shahriari and S. Haddadin, "Tank based unified torque/impedance control for a pneumatically actuated antagonistic robot joint," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1255-1262.
doi: 10.1109/ICRA.2017.7989149
Abstract: In this paper the concept of a unified torque/impedance controller is applied to a pneumatically actuated, antagonistic robot joint. The investigated control algorithm consists of a cascaded structure in which the outer torque/impedance controller commands a desired torque to two cylinder-based force controllers. The torque-/impedance controller is equipped with a virtual tank that ensures passivity of the control loops above force level. Additionally, a shaping function provides a continuous transition to impedance control in case of sudden contact loss during a torque control operation. External torques used in the feedback loop for contact force regulation are estimated by a momentum observer. Experimental and simulation results show a maximum deflection of 9.7° over 130 ms in case of contact loss until a resting position is reached. Additionally, step and sinusoidal torque tracking up to 5 Hz was successfully tested at good performance.
keywords: {Impedance;Force;Torque;Pistons;Pneumatic systems;Tendons;Robots;compliance and impedance control;hydraulic/pneumatic actuators;tendon/wire mechanism},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989149&isnumber=7988677

P. A. York and R. J. Wood, "A geometrically-amplified in-plane piezoelectric actuator for mesoscale robotic systems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1263-1268.
doi: 10.1109/ICRA.2017.7989150
Abstract: Piezoelectric materials are an attractive option for electromechanical transduction on the mesoscale due to their intrinsic high force production, large bandwidth, and favorable scaling characteristics. However, the small displacements they inherently produce are typically too small to be directly used in robotic systems, and thus displacement amplification is needed. Here we present a piezoelectric actuator that uses geometric amplification to achieve 20 × the nominal piezoelectric displacement. Actuator performance is described in terms of blocked force (20 mN), displacement (115 μm), bandwidth (3 kHz), and power density (172 W/kg). The actuator is fabricated using printed circuit MEMS, an emerging mesoscale manufacturing paradigm. Expected applications include locomotion for terrestrial crawling robots and flapping wing micro-air vehicles.
keywords: {Carbon;Actuators;Couplings;Chemical lasers;Force;Fasteners;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989150&isnumber=7988677

N. Hayashi, T. Suehiro and S. Kudoh, "Planning method for a wrapping-with-fabric task using regrasping," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1285-1290.
doi: 10.1109/ICRA.2017.7989151
Abstract: This paper proposes a motion-planning method for a wrapping-with-fabric task. To wrap, robots require not only offhand paths (which represent the movement of a grasping point on fabric) but also actual robot motion. When a robot handles fabric, it must consider the range of motion and collisions. To overcome such limitations, the robot must pass fabric inter- and intra-hand. The proposition is based on the reliability of its movements. The method may be used to plan a combination of inter- and intra-hand passing motions to generate the basic movements for wrapping along an offhand path. Experiments show how, by using the proposed planning method, a dual-arm robot can wrap an L-shaped pipe.
keywords: {Fabrics;Grasping;Wrapping;Reliability;Collision avoidance;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989151&isnumber=7988677

S. Nozawa, S. Noda, M. Murooka, K. Okada and M. Inaba, "Online estimation of object-environment constraints for planning of humanoid motion on a movable object," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1291-1298.
doi: 10.1109/ICRA.2017.7989152
Abstract: This paper shows a method for achieving multi-contact motion for a humanoid robot on a movable object, such as climbing of a stepladder. Recent research has developed methods for achieving multi-contact motion that considers various constraints, such as joint limits, torques, balance constraints, reachability, and collision avoidance. In addition to these constraints, Motion On a Movable Object (MOMO) has the following features: it has to consider an object's balance during the changing of contact points; and it has to handle scenarios where the mass properties of an object are unknown. In this paper, in order to achieve a humanoid robot having MOMO, we propose balance constraints that consider the constraints imposed by an object as well as an online estimation of object's constraints. First, we use object-environment constraints as the robot's constraints, and then we show a method for estimating them based on information provided by the robot's sensors. Next, we show a method for applying the balance constraints to a humanoid motion planner and for executing planned motion with real-time sensor feedback controller. Finally, we evaluate our proposed method through experiments in which a life-sized humanoid robot climbs stepladders that have unknown mass properties.
keywords: {Planning;Estimation;Humanoid robots;Robot sensing systems;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989152&isnumber=7988677

Y. Izmirlioglu, B. A. Pehlivan, M. Turp and E. Erdem, "A general formal framework for multi-agent meeting problems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1299-1306.
doi: 10.1109/ICRA.2017.7989153
Abstract: The multi-agent meeting (MAM) problem asks for a meeting location for multiple heterogeneous agents such that the agents can get together within a given time or budget, possibly using different modes of transportation, subject to some constraints and preferences to visit specific locations on their ways to the meeting location. We mathematically model MAM as a graph problem, prove its intractability, and introduce a novel formal method to solve it and its variations using logic-based AI methods. We experimentally evaluate our approach with artificial benchmarks randomly generated over a grid, and show its real world applicability with instances generated over maps of Istanbul and Hong Kong.
keywords: {Roads;Robots;Time complexity;Meetings;Public transportation;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989153&isnumber=7988677

N. Staub, M. Mohammadi, D. Bicego, D. Prattichizzo and A. Franchi, "Towards robotic MAGMaS: Multiple aerial-ground manipulator systems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1307-1312.
doi: 10.1109/ICRA.2017.7989154
Abstract: In this paper we lay the foundation of the first heterogeneous multi-robot system of the Multiple Aerial-Ground Manipulator System (MAGMaS) type. A MAGMaS consists of a ground manipulator and a team of aerial robots equipped with a simple gripper manipulator the same object. The idea is to benefit from the advantages of both kinds of platforms, i.e., physical strength versus large workspace. The dynamic model of such robotic systems is derived, and its characteristic structure exhibited. Based on the dynamical structure of the system a nonlinear control scheme, augmented with a disturbance observer is proposed to perform trajectory tracking tasks in presence of model inaccuracies and external disturbances. The system redundancy is exploited by solving an optimal force/torque allocation problem that takes into account the heterogeneous system constraints and maximizes the force manipulability ellipsoid. Simulation results validated the proposed control scheme for this novel heterogeneous robotic system. We finally present a prototypical mechanical design and preliminary experimental evaluation of a MAGMaS composed by a kuka LWR4 and quadrotor based aerial robot.
keywords: {Unmanned aerial vehicles;Force;Manipulator dynamics;Torque;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989154&isnumber=7988677

Y. Zhang, S. Sreedharan, A. Kulkarni, T. Chakraborti, H. H. Zhuo and S. Kambhampati, "Plan explicability and predictability for robot task planning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1313-1320.
doi: 10.1109/ICRA.2017.7989155
Abstract: Intelligent robots and machines are becoming pervasive in human populated environments. A desirable capability of these agents is to respond to goal-oriented commands by autonomously constructing task plans. However, such autonomy can add significant cognitive load and potentially introduce safety risks to humans when agents behave in unexpected ways. Hence, for such agents to be helpful, one important requirement is for them to synthesize plans that can be easily understood by humans. While there exists previous work that studied socially acceptable robots that interact with humans in “natural ways”, and work that investigated legible motion planning, there is no general solution for high level task planning. To address this issue, we introduce the notions of plan explicability and predictability. To compute these measures, first, we postulate that humans understand agent plans by associating abstract tasks with agent actions, which can be considered as a labeling process. We learn the labeling scheme of humans for agent plans from training examples using conditional random fields (CRFs). Then, we use the learned model to label a new plan to compute its explicability and predictability. These measures can be used by agents to proactively choose or directly synthesize plans that are more explicable and predictable to humans. We provide evaluations on a synthetic domain and with a physical robot to demonstrate the effectiveness of our approach.
keywords: {Planning;Robots;Labeling;Computational modeling;Training;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989155&isnumber=7988677

J. M. Palacios-Gasós, Z. Talebpour, E. Montijano, C. Sagüés and A. Martinoli, "Optimal path planning and coverage control for multi-robot persistent coverage in environments with obstacles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1321-1327.
doi: 10.1109/ICRA.2017.7989156
Abstract: Persistent coverage aims to maintain a certain coverage level over time in an environment where such level deteriorates. This level can be associated to temperature, dust or sensor information. We propose an algorithmic solution in which each robot locally finds the best paths and coverage actions to keep the desired coverage level over the whole environment. Using Fast Marching Methods, optimal paths are computed in terms of coverage quality, while keeping a safety distance to obstacles. Additionally, our solution enables a computationally efficient evaluation of a list of potential trajectories, allowing us to choose the one that mostly improves the coverage along the whole path. The combination of this algorithm with a Dynamic Window navigation makes our approach competitive in terms of flexibility and robustness in changing environments with existing solutions. Finally, we also propose a coverage action controller, locally computed and optimal, that makes the robots maintain the coverage level of the environment significantly close to the objective. Simulations and real experiments validate the whole approach.
keywords: {Robot sensing systems;Planning;Trajectory;Collision avoidance;Production},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989156&isnumber=7988677

L. Li and J. Fu, "Sampling-based approximate optimal temporal logic planning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1328-1335.
doi: 10.1109/ICRA.2017.7989157
Abstract: In this paper, we propose a sampling-based policy iteration for optimal planning under temporal logic constraints. The method integrates approximate optimal control, importance sampling, and formal methods. For a subclass of linear temporal logic, the planning problem is transformed to an optimal control problem for a hybrid system where discrete transitions are triggered by linear time events in temporal logic. Instead of solving the Hamilton-Jacobi-Bellman equation, we use policy function approximation to reduce the problem into a search of an optimal weight vector that parametrizes the near-optimal policy for given bases. Then, we incorporate Model Reference Adaptive Search - an importance sampling-based optimization algorithm to perform a sample-efficient search within the parameter space of policy function approximations. Facing the discontinuity in cost function introduced by temporal logic constraints and system dynamics, we introduce (1) a rank function in formal logic specifications to enable sample-efficient search; (2) specification-guided basis selection. Under mild technical assumptions, the proposed algorithm converges, with probability one, to a global approximate optimal policy that ensures the satisfaction of temporal logic constraints. The correctness and efficiency of the method are demonstrated through numerical experiments including temporal logic planning for a linear system and a nonlinear mobile robot.
keywords: {Planning;Approximation algorithms;Trajectory;Function approximation;Nonlinear systems;Optimal control;Automata},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989157&isnumber=7988677

R. R. Ma, W. G. Bircher and A. M. Dollar, "Toward robust, whole-hand caging manipulation with underactuated hands," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1336-1342.
doi: 10.1109/ICRA.2017.7989158
Abstract: Human in-hand dexterity can be highly fluid and unstructured, but in contrast, prevailing research in robotic manipulation has focused on highly structured, well-controlled motions where contact points are carefully characterized. Maintaining grasp stability through traditional closure conditions during complex within-hand manipulation motions can be difficult, even with highly-articulated end-effectors. However, simple grippers can still achieve an effective range of in-hand manipulation tasks without strict closure conditions, as long as the object can be bounded locally relative to the hand frame. The end-effector can be utilized as a tool to limit the range of possible object poses. We show that the hand-object system's configuration space can be sampled to find a set of manipulation primitives that can reliably constrain the object inside the hand workspace even without feedback, a strategy proposed as whole-hand caging manipulation. Experimental results with a planar (gravity into the page), two-finger underactuated gripper (Yale OpenHand) are presented to validate this manipulation strategy, and it is shown that even though contacts are regularly broken and reformed, the object can be repeatability manipulated within the hand workspace without ejection, enabling challenging behaviors such as sliding and gaiting.
keywords: {Thumb;Actuators;Grippers;Robot kinematics;Geometry;dexterous manipulation;caging;whole-hand manipulation;open-loop},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989158&isnumber=7988677

L. Chen, J. Yang and H. Kong, "Lidar-histogram for fast road and obstacle detection," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1343-1348.
doi: 10.1109/ICRA.2017.7989159
Abstract: Detection of traversable road regions, positive and negative obstacles, and water hazards is a fundamental task for autonomous driving vehicles, especially in off-road environment. This paper proposes an efficient method, called Lidar-histogram. It can be used to integrate the detection of traversable road regions, obstacles and water hazards into one single framework. The weak assumption of the Lidar-histogram is that a decent-sized area in front of the vehicle is flat. The Lidar-histogram is derived from an efficient organized map of Lidar point cloud, called Lidar-imagery, to index, describe and store Lidar data. The organized point-cloud map can be easily obtained by indexing the original unordered 3D point cloud to a Lidar-specific 2D coordinate system. In the Lidar-histogram representation, the 3D traversable road plane in front of vehicle can be projected as a straight line segment, and the positive and negative obstacles are projected above and below the line segment, respectively. In this way, the problem of detecting traversable road and obstacles is converted into a simple linear classification task in 2D space. Experiments have been conducted in different kinds of off-road and urban scenes, and we have obtained very promising results.
keywords: {Roads;Three-dimensional displays;Laser radar;Hazards;Two dimensional displays;Histograms;Lasers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989159&isnumber=7988677

Y. Shen, L. Zhang and L. Shao, "Semi-supervised vision-language mapping via variational learning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1349-1354.
doi: 10.1109/ICRA.2017.7989160
Abstract: Understanding the semantic relations between vision and language data has become a research trend in artificial intelligence and robotic systems. The lack of training data is an essential issue for vision-language understanding. We address the problem of image and sentence cross-modal retrieval when paired training samples are not sufficient. Inspired by recent works in variational inference, in this paper, the autoencoding variational Bayes framework is novelly extended to a semi-supervised model for image-sentence mapping task. Our method does not require all training images and sentences to be paired. The proposed model is an end-to-end system, and consists of a two-level variational embedding structure where unpaired data are involved in the first level embedding to give support to intra-modality statistics so that the lower bound of the joint marginal likelihood of paired data embeddings can be better approximated. The proposed retrieval model is evaluated on two popular datasets, i.e. Flickr30K and Flickr8K, producing superior performances compared with related state-of-the-art methods.
keywords: {Training;Data models;Neural networks;Probabilistic logic;Bayes methods;Semantics;Stochastic processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989160&isnumber=7988677

M. Engelcke, D. Rao, D. Z. Wang, C. H. Tong and I. Posner, "Vote3Deep: Fast object detection in 3D point clouds using efficient convolutional neural networks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1355-1361.
doi: 10.1109/ICRA.2017.7989161
Abstract: This paper proposes a computationally efficient approach to detecting objects natively in 3D point clouds using convolutional neural networks (CNNs). In particular, this is achieved by leveraging a feature-centric voting scheme to implement novel convolutional layers which explicitly exploit the sparsity encountered in the input. To this end, we examine the trade-off between accuracy and speed for different architectures and additionally propose to use an L1 penalty on the filter activations to further encourage sparsity in the intermediate representations. To the best of our knowledge, this is the first work to propose sparse convolutional layers and L1 regularisation for efficient large-scale processing of 3D data. We demonstrate the efficacy of our approach on the KITTI object detection benchmark and show that Vote3Deep models with as few as three layers outperform the previous state of the art in both laser and laser-vision based approaches by margins of up to 40% while remaining highly competitive in terms of processing time.
keywords: {Three-dimensional displays;Convolution;Two dimensional displays;Object detection;Robots;Neural networks;Benchmark testing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989161&isnumber=7988677

F. M. Carlucci, P. Russo and B. Caputo, "A deep representation for depth images from synthetic data," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1362-1369.
doi: 10.1109/ICRA.2017.7989162
Abstract: Convolutional Neural Networks (CNNs) trained on large scale RGB databases have become the secret sauce in the majority of recent approaches for object categorization from RGB-D data. Thanks to colorization techniques, these methods exploit the filters learned from 2D images to extract meaningful representations in 2.5D. Still, the perceptual signature of these two kind of images is very different, with the first usually strongly characterized by textures, and the second mostly by silhouettes of objects. Ideally, one would like to have two CNNs, one for RGB and one for depth, each trained on a suitable data collection, able to capture the perceptual properties of each channel for the task at hand. This has not been possible so far, due to the lack of a suitable depth database. This paper addresses this issue, proposing to opt for synthetically generated images rather than collecting by hand a 2.5D large scale database. While being clearly a proxy for real data, synthetic images allow to trade quality for quantity, making it possible to generate a virtually infinite amount of data. We show that the filters learned from such data collection, using the very same architecture typically used on visual data, learns very different filters, resulting in depth features (a) able to better characterize the different facets of depth images, and (b) complementary with respect to those derived from CNNs pre-trained on 2D datasets. Experiments on two publicly available databases show the power of our approach.
keywords: {Solid modeling;Databases;Three-dimensional displays;Machine learning;Feature extraction;Protocols;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989162&isnumber=7988677

K. Behrendt, L. Novak and R. Botros, "A deep learning approach to traffic lights: Detection, tracking, and classification," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1370-1377.
doi: 10.1109/ICRA.2017.7989163
Abstract: Reliable traffic light detection and classification is crucial for automated driving in urban environments. Currently, there are no systems that can reliably perceive traffic lights in real-time, without map-based information, and in sufficient distances needed for smooth urban driving. We propose a complete system consisting of a traffic light detector, tracker, and classifier based on deep learning, stereo vision, and vehicle odometry which perceives traffic lights in real-time. Within the scope of this work, we present three major contributions. The first is an accurately labeled traffic light dataset of 5000 images for training and a video sequence of 8334 frames for evaluation. The dataset is published as the Bosch Small Traffic Lights Dataset and uses our results as baseline. It is currently the largest publicly available labeled traffic light dataset and includes labels down to the size of only 1 pixel in width. The second contribution is a traffic light detector which runs at 10 frames per second on 1280×720 images. When selecting the confidence threshold that yields equal error rate, we are able to detect traffic lights as small as 4 pixels in width. The third contribution is a traffic light tracker which uses stereo vision and vehicle odometry to compute the motion estimate of traffic lights and a neural network to correct the aforementioned motion estimate.
keywords: {Training;Neural networks;Computer architecture;Agriculture;Machine learning;Microprocessors;Kernel},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989163&isnumber=7988677

P. Ammirato, P. Poirson, E. Park, J. Košecká and A. C. Berg, "A dataset for developing and benchmarking active vision," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1378-1385.
doi: 10.1109/ICRA.2017.7989164
Abstract: We present a new public dataset with a focus on simulating robotic vision tasks in everyday indoor environments using real imagery. The dataset includes 20,000+ RGB-D images and 50,000+ 2D bounding boxes of object instances densely captured in 9 unique scenes. We train a fast object category detector for instance detection on our data. Using the dataset we show that, although increasingly accurate and fast, the state of the art for object detection is still severely impacted by object scale, occlusion, and viewing direction all of which matter for robotics applications. We next validate the dataset for simulating active vision, and use the dataset to develop and evaluate a deep-network-based system for next best move prediction for object classification using reinforcement learning. Our dataset is available for download at cs.unc.edu/~ammirato/active_vision_dataset_website/.
keywords: {Cameras;Image reconstruction;Three-dimensional displays;Robot vision systems;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989164&isnumber=7988677

A. Zeng et al., "Multi-view self-supervised deep learning for 6D pose estimation in the Amazon Picking Challenge," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1386-1383.
doi: 10.1109/ICRA.2017.7989165
Abstract: Robot warehouse automation has attracted significant interest in recent years, perhaps most visibly in the Amazon Picking Challenge (APC) [1]. A fully autonomous warehouse pick-and-place system requires robust vision that reliably recognizes and locates objects amid cluttered environments, self-occlusions, sensor noise, and a large variety of objects. In this paper we present an approach that leverages multiview RGB-D data and self-supervised, data-driven learning to overcome those difficulties. The approach was part of the MIT-Princeton Team system that took 3rd- and 4th-place in the stowing and picking tasks, respectively at APC 2016. In the proposed approach, we segment and label multiple views of a scene with a fully convolutional neural network, and then fit pre-scanned 3D object models to the resulting segmentation to get the 6D object pose. Training a deep neural network for segmentation typically requires a large amount of training data. We propose a self-supervised method to generate a large labeled dataset without tedious manual segmentation. We demonstrate that our system can reliably estimate the 6D pose of objects under a variety of scenarios. All code, data, and benchmarks are available at http://apc.cs.princeton.edu/
keywords: {Three-dimensional displays;Cameras;Solid modeling;Machine vision;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989165&isnumber=7988677

W. Wang, N. Wang, X. Wu, S. You and U. Neumann, "Self-paced cross-modality transfer learning for efficient road segmentation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1394-1401.
doi: 10.1109/ICRA.2017.7989166
Abstract: Accurate road segmentation is a prerequisite for autonomous driving. Current state-of-the-art methods are mostly based on convolutional neural networks (CNNs). Nevertheless, their good performance is at expense of abundant annotated data and high computational cost. In this work, we address these two issues by a self-paced cross-modality transfer learning framework with efficient projection CNN. To be specific, with the help of stereo images, we first tackle a relevant but easier task, i.e. free-space detection with well developed unsupervised methods. Then, we transfer these useful but noisy knowledge in depth modality to single RGB modality with self-paced CNN learning. Finally, we only need to fine-tune the CNN with a few annotated images to get good performance. In addition, we propose an efficient projection CNN, which can improve the fine-grained segmentation results with little additional cost. At last, we test our method on KITTI road benchmark. Our proposed method surpasses all published methods at a speed of 15fps.
keywords: {Roads;Image segmentation;Semantics;Training;Noise measurement;Convolution;Machine learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989166&isnumber=7988677

J. Miller and J. P. How, "Predictive positioning and quality of service ridesharing for campus mobility on demand systems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1402-1408.
doi: 10.1109/ICRA.2017.7989167
Abstract: Autonomous Mobility On Demand (MOD) systems can utilize fleet management strategies in order to provide a high customer quality of service (QoS). Previous works on autonomous MOD systems have developed methods for rebalancing single capacity vehicles, where QoS is maintained through large fleet sizing. This work focuses on MOD systems utilizing a small number of vehicles, such as those found on a campus, where additional vehicles cannot be introduced as demand for rides increases. A predictive positioning method is presented for improving customer QoS by identifying key locations to position the fleet in order to minimize expected customer wait time. Ridesharing is introduced as a means for improving customer QoS as arrival rates increase. However, with ridesharing perceived QoS is dependent on an often unknown customer preference. To address this challenge, a customer ratings model, which learns customer preference from a 5-star rating, is developed and incorporated directly into a ridesharing algorithm. The predictive positioning and ridesharing methods are applied to simulation of a real-world campus MOD system. A combined predictive positioning and ridesharing approach is shown to reduce customer service times by up to 29%. and the customer ratings model is shown to provide the best overall MOD fleet management performance over a range of customer preferences.
keywords: {Quality of service;Measurement;Prediction algorithms;Schedules;Predictive models;Cost function;Artificial neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989167&isnumber=7988677

C. Guo, T. Owaki, K. Kidono, T. Machida, R. Terashima and Y. Kojima, "Toward human-like lane following behavior in urban environment with a learning-based behavior-induction potential map," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1409-1416.
doi: 10.1109/ICRA.2017.7989168
Abstract: In order to achieve harmony in the mixed traffic, it is crucial to have autonomous vehicles behave like human drivers. This work addresses a vision-based approach toward human-like lane following behavior in complex urban environment. At first, a deep architecture is adopted to generate a set of vehicle hypotheses. Subsequently, a hybrid merging procedure is performed to jointly output the final detection results based on both the image evidence and the statistical support of vehicle hypotheses. After that, the detected vehicles are classified into six categories by Bayesian Network, i.e., leader vehicle, parking vehicle, tail-end vehicle, exiting vehicle, merging vehicle and other vehicle. With this information, a learning-based instance-level behavior-induction potential map is constructed to generate a safe as well as reasonable local path for following a predefined lane-level route. Experimental results in various typical but challenging urban traffic scenes substantiated the effectiveness of the proposed approach.
keywords: {Merging;Urban areas;Detectors;Roads;Vehicle detection;Computer architecture;Automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989168&isnumber=7988677

B. Suger and W. Burgard, "Global outer-urban navigation with OpenStreetMap," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1417-1422.
doi: 10.1109/ICRA.2017.7989169
Abstract: Publicly available map services are widely used by humans for navigation and nowadays provide almost complete road network data. When utilizing such maps for autonomous navigation with mobile robots one is faced with the problem of inaccuracies of the map and the uncertainty about the position of the robot relative to the map. In this paper, we present a probabilistic approach to autonomous robot navigation using data from OpenStreetMap that associates tracks from Open-StreeetMap with the trails detected by the robot based on its 3D-LiDAR data. It combines semantic terrain information, derived from the 3D-LiDAR data, with a Markov-Chain Monte-Carlo technique to match the tracks from OpenStreetMap with the sensor data. This enables our robot to utilize OpenStreetMap for navigation planning and to still stay on the trails during the execution of these plans. We present the results of extensive experiments carried out in real world settings that demonstrate the robustness of our system regarding the alignment of the vehicle pose relative to the OpenStreetMap data.
keywords: {Robot sensing systems;Roads;Semantics;Global Positioning System;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989169&isnumber=7988677

R. Gomez-Ojeda, F. Moreno and J. Gonzalez-Jimenez, "Accurate stereo visual odometry with gamma distributions," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1423-1428.
doi: 10.1109/ICRA.2017.7989170
Abstract: Point-based stereo visual odometry systems typically estimate the camera motion by minimizing a cost function of the projection residuals between consecutive frames. Under some mild assumptions, such minimization is equivalent to maximizing the probability of the measured residuals given a certain pose change, for which a suitable model of the error distribution (sensor model) becomes of capital importance in order to obtain accurate results. This paper proposes a robust probabilistic model for projection errors, based on real world data. For that, we argue that projection distances follow Gamma distributions, and hence, the introduction of these models in a probabilistic formulation of the motion estimation process increases both precision and accuracy. Our approach has been validated through a series of experiments with both synthetic and real data, revealing an improvement in accuracy while not increasing the computational burden.
keywords: {Robustness;Cost function;Cameras;Visualization;Histograms;Minimization;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989170&isnumber=7988677

K. Eckenhoff, P. Geneva and G. Huang, "Direct visual-inertial navigation with analytical preintegration," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1429-1435.
doi: 10.1109/ICRA.2017.7989171
Abstract: Recent advancements in the performance and affordability of cameras and inertial measurement units (IMUs) have caused demand for efficient, accurate visual-inertial navigation solutions. In this paper, we present a system for the fusion of preintegrated inertial measurements with highly informative direct alignment of images. In particular, our preintegration theory is based on closed-form solutions of the continuous-time IMU kinematic model, instead of discrete time. This allows for more accurate computation of preintegrated measurements and their uncertainty as well as bias Jacobians. These measurements are fused via graph-based methods with relative pose constraints obtained from direct image alignment from a stereo platform. The proposed system is validated on publicly-available real-world datasets.
keywords: {Current measurement;Optimization;Jacobian matrices;Quaternions;Cameras;Visualization;Atmospheric measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989171&isnumber=7988677

S. Lee and S. Seo, "A learning-based framework for handling dilemmas in urban automated driving," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1436-1442.
doi: 10.1109/ICRA.2017.7989172
Abstract: Over the last decade, automated vehicles have been widely researched and their massive potential has been verified through several milestone demonstrations. However, there are still many challenges ahead. One of the biggest challenges is integrating them into urban environments in which dilemmas occur frequently. Conventional automated driving strategies make automated vehicles foolish in dilemmas such as making lane-change in heavy traffic, handling a yellow traffic light and crossing a double-yellow line to pass an illegally parked car. In this paper, we introduce a novel automated driving strategy that allows automated vehicles to tackle these dilemmas. The key insight behind our automated driving strategy is that expert drivers understand human interactions on the road and comply with mutually-accepted rules, which are learned from countless experiences. In order to teach the driving strategy of expert drivers to automated vehicles, we propose a general learning framework based on maximum entropy inverse reinforcement learning and Gaussian process. Experiments are conducted on a 5.2 km-long campus road at Seoul National University and demonstrate that our framework performs comparably to expert drivers in planning trajectories to handle various dilemmas.
keywords: {Trajectory;Gaussian processes;Automobiles;Roads;Entropy;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989172&isnumber=7988677

G. E. Mullins, P. G. Stankiewicz and S. K. Gupta, "Automated generation of diverse and challenging scenarios for test and evaluation of autonomous vehicles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1443-1450.
doi: 10.1109/ICRA.2017.7989173
Abstract: We propose a novel method for generating test scenarios for a black box autonomous system that demonstrate critical transitions in its performance modes. In complex environments it is possible for an autonomous system to fail at its assigned mission even if it complies with requirements for all subsystems and throws no faults. This is particularly true when the autonomous system may have to choose between multiple exclusive objectives. The standard approach of testing robustness through fault detection is directly stimulating the system and detecting violations of the system requirements. Our approach differs by instead running the autonomous system through full missions in a simulated environment and measuring performance based on high-level mission criteria. The result is a method of searching for challenging scenarios for an autonomous system under test that exercise a variety of performance modes. We utilize adaptive sampling to intelligently search the state space for test scenarios which exist on the boundary between distinct performance modes. Additionally, using unsupervised clustering techniques we can group scenarios by their performance modes and sort them by those which are most effective at diagnosing changes in the autonomous system's behavior.
keywords: {Software;Autonomous vehicles;Robustness;Fault detection;Software testing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989173&isnumber=7988677

A. Caccavale and M. Schwager, "A distributed algorithm for mapping the graphical structure of complex environments with a swarm of robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1459-1466.
doi: 10.1109/ICRA.2017.7989174
Abstract: This paper presents a novel multi-robot mapping algorithm which allows a large number of simple robots to map the discrete graphical structure underlying an environment of multiple disjoint subregions. Examples of such environments include rooms in a building, buildings in a town, chambers in a cave network, or islands in an archipelago. Each robot is limited to a small communication range, compass, GPS sensor, and a short-range proximity sensor (e.g. bump sensor). Furthermore memory is limited, so no metric map of the environment is stored. Instead the algorithm determines which robots inhabit the same subregion, and which of these groups of robots are able to communicate. This information is captured in a disk graph representation. It is proven that these simple capabilities are sufficient to guarantee that all agents will determine the graphical structure in a finite time. Two environment configurations were tested with a range of quantities of robots. These simulations confirm that processing time is polynomial in the number of robots and indicate that the number of steps to convergence is linear in the number of robots.
keywords: {Robot sensing systems;Robot kinematics;Buildings;Collision avoidance;Measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989174&isnumber=7988677

F. Schiano and P. R. Giordano, "Bearing rigidity maintenance for formations of quadrotor UAVs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1467-1474.
doi: 10.1109/ICRA.2017.7989175
Abstract: This paper considers the problem of controlling a formation of quadrotor UAVs equipped with onboard cameras with the goal of maintaining bearing rigidity during motion despite the presence of several sensing constraints, that is, minimum/maximum range, limited camera field of view, and possible occlusions caused by the agents of the formation. To this end, a decentralized gradient-based control action is developed, based on a suitable ‘degree of infinitesimal rigidity’ linked to the spectral properties of the bearing rigidity matrix. The approach is then experimentally validated with five quadrotor UAVs.
keywords: {Cameras;Robot vision systems;Robot kinematics;Maintenance engineering},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989175&isnumber=7988677

J. Yu, S. D. Han, W. N. Tang and D. Rus, "A portable, 3D-printing enabled multi-vehicle platform for robotics research and education," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1475-1480.
doi: 10.1109/ICRA.2017.7989176
Abstract: microMVP is an affordable, portable, and open source micro-scale mobile robot platform designed for robotics research and education. As a complete and unique multi-vehicle platform enabled by 3D printing and the maker culture, microMVP can be easily reproduced and requires little maintenance: a set of six micro vehicles, each measuring 8 × 5 × 6 cubic centimeters and weighing under 100 grams, and the accompanying tracking platform can be fully assembled in under two hours, all from readily available components. In this paper, we describe microMVP's hardware and software architecture, and the design thoughts that go into the making of the platform. The capabilities of microMVP APIs are then demonstrated with several single- and multi-robot path and motion planning algorithms. microMVP supports all common operation systems.
keywords: {Robot kinematics;Mobile robots;Cameras;Robot sensing systems;Hardware;Software},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989176&isnumber=7988677

C. Vasile, J. Tumova, S. Karaman, C. Belta and D. Rus, "Minimum-violation scLTL motion planning for mobility-on-demand," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1481-1488.
doi: 10.1109/ICRA.2017.7989177
Abstract: This work focuses on integrated routing and motion planning for an autonomous vehicle in a road network. We consider a problem in which customer demands need to be met within desired deadlines, and the rules of the road need to be satisfied. The vehicle might not, however, be able to satisfy these two goals at the same time. We propose a systematic way to compromise between delaying the satisfaction of the given demand and violating the road rules. We utilize scLTL formulas to specify desired behavior and develop a receding horizon approach including a periodically interacting routing algorithm and a RRT*-based motion planner. The proposed solution yields a provably minimum-violation trajectory. An illustrative case study is included.
keywords: {Roads;Planning;Vehicle dynamics;Sensors;Labeling;Routing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989177&isnumber=7988677

S. Claici, J. Romanishin, J. I. Lipton, S. Bonardi, K. W. Gilpin and D. Rus, "Distributed aggregation for modular robots in the pivoting cube model," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1489-1496.
doi: 10.1109/ICRA.2017.7989178
Abstract: We present a distributed control strategy for the aggregation of multiple modular robots into one connected structure optimized for use with 3D modular pivoting cube robots such as the 3D M-Blocks [1]. We use the intensity from a light source as input to a decentralized control algorithm that drives the robots together. We describe the algorithm, give provable guarantees on convergence, and discuss experiments carried out in simulation and with a hardware platform of ten 3D M-Blocks modules. In this paper we contribute provably correct algorithms for the aggregation of generic modular robots; we show how these algorithms can be applied on real hardware by evaluating them on the 3D M-Blocks platform.
keywords: {Robot sensing systems;Three-dimensional displays;Robot kinematics;Lattices;Hardware;Aggregates},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989178&isnumber=7988677

L. Paull et al., "Duckietown: An open, inexpensive and flexible platform for autonomy education and research," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1497-1504.
doi: 10.1109/ICRA.2017.7989179
Abstract: Duckietown is an open, inexpensive and flexible platform for autonomy education and research. The platform comprises small autonomous vehicles (“Duckiebots”) built from off-the-shelf components, and cities (“Duckietowns”) complete with roads, signage, traffic lights, obstacles, and citizens (duckies) in need of transportation. The Duckietown platform offers a wide range of functionalities at a low cost. Duckiebots sense the world with only one monocular camera and perform all processing onboard with a Raspberry Pi 2, yet are able to: follow lanes while avoiding obstacles, pedestrians (duckies) and other Duckiebots, localize within a global map, navigate a city, and coordinate with other Duckiebots to avoid collisions. Duckietown is a useful tool since educators and researchers can save money and time by not having to develop all of the necessary supporting infrastructure and capabilities. All materials are available as open source, and the hope is that others in the community will adopt the platform for education and research.
keywords: {Cameras;Roads;Robot sensing systems;Image color analysis;Education;Lighting;Calibration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989179&isnumber=7988677

A. Li, W. Luo, S. Nagavalli and K. Sycara, "Decentralized coordinated motion for a large team of robots preserving connectivity and avoiding collisions," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1505-1511.
doi: 10.1109/ICRA.2017.7989180
Abstract: We consider the general problem of moving a large number of networked robots toward a goal position through a cluttered environment while preserving network communication connectivity and avoiding both inter-robot collisions and collision with obstacles. In contrast to previous approaches that either plan complete paths for each individual robot in the high-dimensional joint configuration space or control the robot group as a whole with explicit constraints on the group's boundary and inter-robot pairwise distance, we propose a novel decentralized online behavior-based algorithm that relies on the topological structure of the multi-robot communication and sensing graphs to solve this problem. We formally describe the communication graph as a simplicial complex that enables robots to iteratively identify the frontier nodes and coordinate forward motion through the sensing graph. This approach is proved to automatically deform robot teams for collision avoidance and always preserve connectivity. The effectiveness of our approach is demonstrated using numerical simulations. The algorithm is shown to scale linearly in the number of robots.
keywords: {Robot sensing systems;Robot kinematics;Collision avoidance;Multi-robot systems;Topology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989180&isnumber=7988677

L. Armesto, J. Bosga, V. Ivan and S. Vijayakumar, "Efficient learning of constraints and generic null space policies," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1520-1526.
doi: 10.1109/ICRA.2017.7989181
Abstract: A large class of motions can be decomposed into a movement task and null-space policy subject to a set of constraints. When learning such motions from demonstrations, we aim to achieve generalisation across different unseen constraints and to increase the robustness to noise while keeping the computational cost low. There exists a variety of methods for learning the movement policy and the constraints. The effectiveness of these techniques has been demonstrated in low-dimensional scenarios and simple motions. In this paper, we present a fast and accurate approach to learning constraints from observations. This novel formulation of the problem allows the constraint learning method to be coupled with the policy learning method to improve policy learning accuracy, which enables us to learn more complex motions. We demonstrate our approach by learning a complex surface wiping policy in a 7-DOF robotic arm.
keywords: {Null space;Robots;Redundancy;Measurement;Learning systems;Computational modeling;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989181&isnumber=7988677

M. Pfeiffer, M. Schaeuble, J. Nieto, R. Siegwart and C. Cadena, "From perception to decision: A data-driven approach to end-to-end motion planning for autonomous ground robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1527-1533.
doi: 10.1109/ICRA.2017.7989182
Abstract: Learning from demonstration for motion planning is an ongoing research topic. In this paper we present a model that is able to learn the complex mapping from raw 2D-laser range findings and a target position to the required steering commands for the robot. To our best knowledge, this work presents the first approach that learns a target-oriented end-to-end navigation model for a robotic platform. The supervised model training is based on expert demonstrations generated in simulation with an existing motion planner. We demonstrate that the learned navigation model is directly transferable to previously unseen virtual and, more interestingly, real-world environments. It can safely navigate the robot through obstacle-cluttered environments to reach the provided targets. We present an extensive qualitative and quantitative evaluation of the neural network-based motion planner, and compare it to a grid-based global approach, both in simulation and in real-world experiments.
keywords: {Navigation;Collision avoidance;Robot sensing systems;Planning;Training;Data mining},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989182&isnumber=7988677

I. Havoutis and S. Calinon, "Supervisory teleoperation with online learning and optimal control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1534-1540.
doi: 10.1109/ICRA.2017.7989183
Abstract: We present a general approach for online learning and optimal control of manipulation tasks in a supervisory teleoperation context, targeted to underwater remotely operated vehicles (ROVs). We use an online Bayesian nonparametric learning algorithm to build models of manipulation motions as task-parametrized hidden semi-Markov models (TP-HSMM) that capture the spatiotemporal characteristics of demonstrated motions in a probabilistic representation. Motions are then executed autonomously using an optimal controller, namely a model predictive control (MPC) approach in a receding horizon fashion. This way the remote system locally closes a high-frequency control loop that robustly handles noise and dynamically changing environments. Our system automates common and recurring tasks, allowing the operator to focus only on the tasks that genuinely require human intervention. We demonstrate how our solution can be used for a hot-stabbing motion in an underwater teleoperation scenario. We evaluate the performance of the system over multiple trials and compare with a state-of-the-art approach. We report that our approach generalizes well with only a few demonstrations, accurately performs the learned task and adapts online to dynamically changing task conditions.
keywords: {Hidden Markov models;Supervisory control;Manipulators;Adaptation models;Bayes methods;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989183&isnumber=7988677

K. Shiarlis, J. Messias and S. Whiteson, "Rapidly exploring learning trees," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1541-1548.
doi: 10.1109/ICRA.2017.7989184
Abstract: Inverse Reinforcement Learning (IRL) for path planning enables robots to learn cost functions for difficult tasks from demonstration, instead of hard-coding them. However, IRL methods face practical limitations that stem from the need to repeat costly planning procedures. In this paper, we propose Rapidly Exploring Learning Trees (RLT*), which learns the cost functions of Optimal Rapidly Exploring Random Trees (RRT*) from demonstration, thereby making inverse learning methods applicable to more complex tasks. Our approach extends Maximum Margin Planning to work with RRT* cost functions. Furthermore, we propose a caching scheme that greatly reduces the computational cost of this approach. Experimental results on simulated and real-robot data from a social navigation scenario show that RLT* achieves better performance at lower computational cost than existing methods. We also successfully deploy control policies learned with RLT* on a real telepresence robot.
keywords: {Cost function;Planning;Learning (artificial intelligence);Mobile robots;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989184&isnumber=7988677

J. Vogel, N. Takemura, H. Höppner, P. van der Smagt and G. Ganesh, "Hitting the sweet spot: Automatic optimization of energy transfer during tool-held hits," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1549-1556.
doi: 10.1109/ICRA.2017.7989185
Abstract: Tool-held hitting tasks, like hammering a nail or striking a ball with a bat, require humans, and robots, to purposely collide and transfer momentum from their limbs to the environment. Due to the vibrational dynamics, every tool has a location where a hit is most efficient results in minimal tool vibrations, and consequently maximum energy transfer to the environment. In sports, this location is often referred to as the “sweet spot” of a bat, or racquet. Our recent neuroscience study suggests that humans optimize hits by using the jerk and torque felt at their hand. Motivated by this result, in this work we first analyze the vibrational dynamics of an end-effector-held bat to understand the signature projected by a sweet spot on the jerk and torque sensed at the end-effector. We then use this analysis to develop a controller for a robotic “baseball hitter”. The controller enables the robot-hitter to iteratively adjust its swing trajectory to ensure that the contact with the ball occurs at the sweet spot of the bat. We tested the controller on the DLR LWR III manipulator with three different bats. Like a human, our robot hitter is able to optimize the energy transfer, specifically maximize the ball velocity, during hits, by using its end effector position and torque sensors, and without any prior knowledge of the shape, size or material of the held bat.
keywords: {Vibrations;Robot sensing systems;Shape;Energy exchange;Torque;Tools},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989185&isnumber=7988677

A. Marco et al., "Virtual vs. real: Trading off simulations and physical experiments in reinforcement learning with Bayesian optimization," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1557-1563.
doi: 10.1109/ICRA.2017.7989186
Abstract: In practice, the parameters of control policies are often tuned manually. This is time-consuming and frustrating. Reinforcement learning is a promising alternative that aims to automate this process, yet often requires too many experiments to be practical. In this paper, we propose a solution to this problem by exploiting prior knowledge from simulations, which are readily available for most robotic platforms. Specifically, we extend Entropy Search, a Bayesian optimization algorithm that maximizes information gain from each experiment, to the case of multiple information sources. The result is a principled way to automatically combine cheap, but inaccurate information from simulations with expensive and accurate physical experiments in a cost-effective manner. We apply the resulting method to a cart-pole system, which confirms that the algorithm can find good control policies with fewer experiments than standard Bayesian optimization on the physical system only.
keywords: {Bayes methods;Robots;Learning (artificial intelligence);Entropy;Cost function;Kernel},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989186&isnumber=7988677

G. Vezzani, U. Pattacini and L. Natale, "A grasping approach based on superquadric models," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1579-1586.
doi: 10.1109/ICRA.2017.7989187
Abstract: This paper addresses the problem of grasping unknown objects with a humanoid robot. Conventional approaches fail when the shape, dimension or pose of the objects are missing. We propose a novel approach in which the grasping problem is solved by modeling the object and the volume graspable by the hand with superquadric functions. The object model is computed in real-time using stereo vision. Pose computation is formulated as a nonlinear constrained optimization problem, which is solved in real-time using the Ipopt software package. Notably, our method finds solutions in which the fingers are located on portions of the object that are occluded by vision. The performance of our approach has been assessed on a real robotic system, the iCub humanoid robot. The experiments show that the proposed method computes proper poses, suitable for grasping even small objects, while avoiding hitting the table with the fingers.
keywords: {Grasping;Computational modeling;Robots;Shape;Solid modeling;Mathematical model;Ellipsoids},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989187&isnumber=7988677

A. Cirillo, P. Cirillo, G. De Maria, C. Natale and S. Pirozzi, "Control of linear and rotational slippage based on six-axis force/tactile sensor," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1587-1594.
doi: 10.1109/ICRA.2017.7989188
Abstract: In-hand manipulation is certainly one of the most challenging problems in robotic manipulation. Solutions to this problem depend on the specific device used to grab the object, but nowadays, the trend is to exploit not only the gripper but also external constraints, such as other objects in the environment or external forces, like gravity. This allows a robot to manipulate an object even with very simple grippers, like a parallel gripper. Nevertheless, even for a simple grasping task, which aims at grabbing the object with a given fixed orientation or for executing a controlled slip, information on the contact between the fingers of the gripper and the object is relevant. In these cases, both linear and rotational slipping should be controlled during the grasping phase and during the motion phase. The present paper proposes a control strategy for the first objective, namely slipping avoidance. The strategy is based on contact information provided by a six-axis force/tactile sensor, able to measure contact force and torque as well as able to provide information on the contact geometry, that means orientation of the object with respect to the gripper. Experiments on a parallel gripper sensorized with a new force/tactile sensor and mounted on a Kuka iiwa show how the strategy successfully allows the robot to safely manipulate a rigid object in various friction conditions of its surface.
keywords: {Robot sensing systems;Grippers;Force;Friction;Force measurement;Grasping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989188&isnumber=7988677

R. Krug, Y. Bekiroglu and M. A. Roa, "Grasp quality evaluation done right: How assumed contact force bounds affect Wrench-based quality metrics," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1595-1600.
doi: 10.1109/ICRA.2017.7989189
Abstract: Wrench-based quality metrics play an important role in many applications such as grasp planning or grasp success prediction. In this work, we study the following discrepancy which is frequently overlooked in practice: the quality metrics are commonly computed under the assumption of sum-magnitude bounded contact forces, but the corresponding grasps are executed by a fully actuated device where the contact forces are limited independently. By means of experiments carried out in simulation and on real hardware, we show that in this setting the values of these metrics are severely underestimated. This can lead to erroneous conclusions regarding the actual capabilities of the grasps under consideration. Our findings highlight the importance of matching the physical properties of the task and the grasping device with the chosen quality metrics.
keywords: {Measurement;Force;Friction;Grasping;Ellipsoids;Robot sensing systems;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989189&isnumber=7988677

L. Pinto, J. Davidson and A. Gupta, "Supervision via competition: Robot adversaries for learning tasks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1601-1608.
doi: 10.1109/ICRA.2017.7989190
Abstract: There has been a recent paradigm shift in robotics to data-driven learning for planning and control. Due to large number of experiences required for training, most of these approaches use a self-supervised paradigm: using sensors to measure success/failure. However, in most cases, these sensors provide weak supervision at best. In this work, we propose an adversarial learning framework that pits an adversary against the robot learning the task. In an effort to defeat the adversary, the original robot learns to perform the task with more robustness leading to overall improved performance. We show that this adversarial framework forces the robot to learn a better grasping model in order to overcome the adversary. By grasping 82% of presented novel objects compared to 68% without an adversary, we demonstrate the utility of creating adversaries. We also demonstrate via experiments that having robots in adversarial setting might be a better learning strategy as compared to having collaborative multiple robots. For supplementary video see: youtu.be/QfK3Bqhc6Sk.
keywords: {Grasping;Training;Robustness;Robot sensing systems;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989190&isnumber=7988677

D. Guo, F. Sun, H. Liu, T. Kong, B. Fang and N. Xi, "A hybrid deep architecture for robotic grasp detection," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1609-1614.
doi: 10.1109/ICRA.2017.7989191
Abstract: The robotic grasp detection is a great challenge in the area of robotics. Previous work mainly employs the visual approaches to solve this problem. In this paper, a hybrid deep architecture combining the visual and tactile sensing for robotic grasp detection is proposed. We have demonstrated that the visual sensing and tactile sensing are complementary to each other and important for the robotic grasping. A new THU grasp dataset has also been collected which contains the visual, tactile and grasp configuration information. The experiments conducted on a public grasp dataset and our collected dataset show that the performance of the proposed model is superior to state of the art methods. The results also indicate that the tactile data could help to enable the network to learn better visual features for the robotic grasp detection task.
keywords: {Robot sensing systems;Visualization;Grasping;Planning;Data collection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989191&isnumber=7988677

N. Tian et al., "A cloud robot system using the dexterity network and berkeley robotics and automation as a service (Brass)," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1615-1622.
doi: 10.1109/ICRA.2017.7989192
Abstract: In support of Cloud Robotics, Robotics and Automation as a Service (RAaaS) frameworks have the potential to reduce the complexity of software development, simplify software installation and maintenance, and facilitate data sharing for machine learning. In this proof-of-concept paper, we describe Berkeley Robotics and Automation as a Service (Brass), a RAaaS prototype that allows robots to access a remote server that hosts a robust grasp-planning system (Dex-Net 1.0) that maintains data on hundreds of candidate grasps on thousands of 3D object meshes and uses perturbation sampling to estimate and update a stochastic robustness metric for each grasp. Results suggest that such a system can increase grasp reliability over naive locally-computed grasping strategies with network latencies of 30 and 200 msec for servers 500 and 6000 miles away, respectively. We also study how the system can use execution reports from robots in the field to update grasp recommendations over time.
keywords: {Cloud computing;Robot kinematics;Robustness;Planning;Measurement;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989192&isnumber=7988677

A. H. Qureshi, Y. Nakamura, Y. Yoshikawa and H. Ishiguro, "Show, attend and interact: Perceivable human-robot social interaction through neural attention Q-network," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1639-1645.
doi: 10.1109/ICRA.2017.7989193
Abstract: For a safe, natural and effective human-robot social interaction, it is essential to develop a system that allows a robot to demonstrate the perceivable responsive behaviors to complex human behaviors. We introduce the Multimodal Deep Attention Recurrent Q-Network using which the robot exhibits human-like social interaction skills after 14 days of interacting with people in an uncontrolled real world. Each and every day during the 14 days, the system gathered robot interaction experiences with people through a hit-and-trial method and then trained the MDARQN on these experiences using end-to-end reinforcement learning approach. The results of interaction based learning indicate that the robot has learned to respond to complex human behaviors in a perceivable and socially acceptable manner.
keywords: {Random access memory;Robot sensing systems;Training;Neural networks;Visualization;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989193&isnumber=7988677

X. Zhou, H. Cai, Y. Li and H. Liu, "Two-eye model-based gaze estimation from a Kinect sensor," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1646-1653.
doi: 10.1109/ICRA.2017.7989194
Abstract: In this paper, we present an effective and accurate gaze estimation method based on two-eye model of a subject with the tolerance of free head movement from a Kinect sensor. To accurately and efficiently determine the point of gaze, i) we employ two-eye model to improve the estimation accuracy; ii) we propose an improved convolution-based means of gradients method to localize the iris center in 3D space; iii) we present a new personal calibration method that only needs one calibration point. The method approximates the visual axis as a line from the iris center to the gaze point to determine the eyeball centers and the Kappa angles. The final point of gaze can be calculated by using the calibrated personal eye parameters. We experimentally evaluate the proposed gaze estimation method on eleven subjects. Experimental results demonstrate that our gaze estimation method has an average estimation accuracy around 1.99°, which outperforms many leading methods in the state-of-the-art.
keywords: {Estimation;Iris;Calibration;Three-dimensional displays;Solid modeling;Head;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989194&isnumber=7988677

E. Cha, T. Trehon, L. Wathieu, C. Wagner, A. Shukla and M. J. Matarić, "ModLight: Designing a modular light signaling tool for human-robot interaction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1654-1661.
doi: 10.1109/ICRA.2017.7989195
Abstract: Recent work has shown the potential for lights to act as simple, yet expressive signaling mechanisms for use in a variety of human-robot applications. However, the wide range of robot shapes and sizes makes it difficult for researchers to quickly prototype and evaluate different light configurations and signal designs. In this work, we present the design of ModLight, a modular research tool consisting of a set of low cost light blocks that can be easily reconfigured to fit a myriad of robots and applications. ModLight also provides researchers, designers, and students with open-source software tools that enable them to visually design new signals and easily integrate them into existing systems. This work also serves to motivate the need for further research in developing light behaviors for use in human-robot interaction. Towards this goal, we present our design rationale including a brief analysis of the signaling needs of several robots and applications.
keywords: {Robot kinematics;Service robots;Tools;Shape;Light emitting diodes;Software},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989195&isnumber=7988677

D. Su, T. Vidal-Calleja and J. V. Miro, "Towards real-time 3D sound sources mapping with linear microphone arrays," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1662-1668.
doi: 10.1109/ICRA.2017.7989196
Abstract: In this paper, we present a method for real-time 3D sound sources mapping using an off-the-shelf robotic perception sensor equipped with a linear microphone array. Conventional approaches to map sound sources in 3D scenarios use dedicated 3D microphone arrays, as this type of arrays provide two degrees of freedom (DOF) observations. Our method addresses the problem of 3D sound sources mapping using a linear microphone array, which only provides one DOF observations making the estimation of the sound sources location more challenging. In the proposed method, multi hypotheses tracking is combined with a new sound source parametrisation to provide with a good initial guess for an online optimisation strategy. A joint optimisation is carried out to estimate 6 DOF sensor poses and 3 DOF landmarks together with the sound sources locations. Additionally, a dedicated sensor model is proposed to accurately model the noise of the Direction of Arrival (DOA) observation when using a linear microphone array. Comprehensive simulation and experimental results show the effectiveness of the proposed method. In addition, a real-time implementation of our method has been made available as open source software for the benefit of the community.
keywords: {Microphone arrays;Three-dimensional displays;Direction-of-arrival estimation;Robot sensing systems;Estimation;Sensor arrays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989196&isnumber=7988677

T. Shu, X. Gao, M. S. Ryoo and S. -C. Zhu, "Learning social affordance grammar from videos: Transferring human interactions to human-robot interactions," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1669-1676.
doi: 10.1109/ICRA.2017.7989197
Abstract: In this paper, we present a general framework for learning social affordance grammar as a spatiotemporal AND-OR graph (ST-AOG) from RGB-D videos of human interactions, and transfer the grammar to humanoids to enable a real-time motion inference for human-robot interaction (HRI). Based on Gibbs sampling, our weakly supervised grammar learning can automatically construct a hierarchical representation of an interaction with long-term joint sub-tasks of both agents and short term atomic actions of individual agents. Based on a new RGB-D video dataset with rich instances of human interactions, our experiments of Baxter simulation, human evaluation, and real Baxter test demonstrate that the model learned from limited training data successfully generates human-like behaviors in unseen scenarios and outperforms both baselines.
keywords: {Grammar;Robots;Videos;Human-robot interaction;Spatiotemporal phenomena;Grounding;Real-time systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989197&isnumber=7988677

M. R. Loghmani, S. Rovetta and G. Venture, "Emotional intelligence in robots: Recognizing human emotions from daily-life gestures," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1677-1684.
doi: 10.1109/ICRA.2017.7989198
Abstract: The rapid advancement of robotics poses the problem of a deep integration of robotic systems in human environments. In order to achieve this symbiosis between humans and robots, the artificial systems have to take into account one of the most important aspects in human life: emotions. The recognition and understanding of human emotions is crucial for robotic systems to behave in appropriate ways according to the situation and smoothly integrate with all the different aspects of human life. This paper proposes a novel algorithm which uses state-of-the-art techniques in Machine Learning, in particular Recurrent Neural Networks, to automatically infer emotional clues from non-stylized motions (i.e. motions which are not supposed to convey emotional information as primary goal). This algorithm recognized human emotions with an accuracy between 0.68 and 0.80, depending on the considered motion, and clearly overcomes human capacity in the same task for the considered cases studied. Since the implemented algorithm is able to perform online, its results can be used to allow a behavioural programming which gives the robot the flexibility to act in a more human-oriented way.
keywords: {Robots;Emotion recognition;Logic gates;Recurrent neural networks;Sensors;Machine learning;Support vector machines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989198&isnumber=7988677

A. Vemula, K. Muelling and J. Oh, "Modeling cooperative navigation in dense human crowds," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1685-1692.
doi: 10.1109/ICRA.2017.7989199
Abstract: For robots to be a part of our daily life, they need to be able to navigate among crowds not only safely but also in a socially compliant fashion. This is a challenging problem because humans tend to navigate by implicitly cooperating with one another to avoid collisions, while heading toward their respective destinations. Previous approaches have used handcrafted functions based on proximity to model human-human and human-robot interactions. However, these approaches can only model simple interactions and fail to generalize for complex crowded settings. In this paper, we develop an approach that models the joint distribution over future trajectories of all interacting agents in the crowd, through a local interaction model that we train using real human trajectory data. The interaction model infers the velocity of each agent based on the spatial orientation of other agents in his vicinity. During prediction, our approach infers the goal of the agent from its past trajectory and uses the learned model to predict its future trajectory. We demonstrate the performance of our method against a state-of-the-art approach on a public dataset and show that our model outperforms when predicting future trajectories for longer horizons.
keywords: {Trajectory;Robots;Collision avoidance;Predictive models;Navigation;Data models;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989199&isnumber=7988677

D. Pickem et al., "The Robotarium: A remotely accessible swarm robotics research testbed," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1699-1706.
doi: 10.1109/ICRA.2017.7989200
Abstract: This paper describes the Robotarium - a remotely accessible, multi-robot research facility. The impetus behind the Robotarium is that multi-robot testbeds constitute an integral and essential part of the multi-robot research cycle, yet they are expensive, complex, and time-consuming to develop, operate, and maintain. These resource constraints, in turn, limit access for large groups of researchers and students, which is what the Robotarium is remedying by providing users with remote access to a state-of-the-art multi-robot test facility. This paper details the design and operation of the Robotarium and discusses the considerations one must take when making complex hardware remotely accessible. In particular, safety must be built into the system already at the design phase without overly constraining what coordinated control programs users can upload and execute, which calls for minimally invasive safety routines with provable performance guarantees.
keywords: {Robot kinematics;Collision avoidance;Robot sensing systems;Hardware;Safety;Servers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989200&isnumber=7988677

N. Kumar et al., "Design, development and experimental assessment of a robotic end-effector for non-standard concrete applications," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1707-1713.
doi: 10.1109/ICRA.2017.7989201
Abstract: Despite the recent advances in, and the adoption of robotic technologies in the construction industry, the architectural processes which demand a high degree of geometric freedom still remain largely labour intensive and manual. This is due to the inherent difficulties in robotizing the current implementation of such processes coupled with the lack of alternate robotic technologies. A specific example, which is also the focus of this paper, is that of building a steel reinforced concrete structure, with varying curvature or cross-section. This process still remains rather manual and requires extensive support of customized form-work. In this paper, first we describe an alternate novel robotic fabrication process for building steel wire meshes which act as both reinforcement and formwork. The robotization of such a process is discussed with the use of a previously developed mobile robotic system. Based on the specifications derived from the process, design of a novel custom designed robotic end-effector, enabling this process, is detailed. Automation of the full robotic system comprising the mobile robotic system and the robotic end-effector is discussed from simulation to control. Through experimental evaluation of the robotic system, we demonstrate the ability to fully automate the construction of non-standard steel reinforced steel meshes of varying curvature and cell sizes.
keywords: {Wires;Steel;Concrete;Service robots;Fabrication;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989201&isnumber=7988677

G. Williams et al., "Information theoretic MPC for model-based reinforcement learning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1714-1721.
doi: 10.1109/ICRA.2017.7989202
Abstract: We introduce an information theoretic model predictive control (MPC) algorithm capable of handling complex cost criteria and general nonlinear dynamics. The generality of the approach makes it possible to use multi-layer neural networks as dynamics models, which we incorporate into our MPC algorithm in order to solve model-based reinforcement learning tasks. We test the algorithm in simulation on a cart-pole swing up and quadrotor navigation task, as well as on actual hardware in an aggressive driving task. Empirical results demonstrate that the algorithm is capable of achieving a high level of performance and does so only utilizing data collected from the system.
keywords: {Robots;Heuristic algorithms;Trajectory;Learning (artificial intelligence);Cost function;Optimal control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989202&isnumber=7988677

S. L. Bowman, N. Atanasov, K. Daniilidis and G. J. Pappas, "Probabilistic data association for semantic SLAM," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1722-1729.
doi: 10.1109/ICRA.2017.7989203
Abstract: Traditional approaches to simultaneous localization and mapping (SLAM) rely on low-level geometric features such as points, lines, and planes. They are unable to assign semantic labels to landmarks observed in the environment. Furthermore, loop closure recognition based on low-level features is often viewpoint-dependent and subject to failure in ambiguous or repetitive environments. On the other hand, object recognition methods can infer landmark classes and scales, resulting in a small set of easily recognizable landmarks, ideal for view-independent unambiguous loop closure. In a map with several objects of the same class, however, a crucial data association problem exists. While data association and recognition are discrete problems usually solved using discrete inference, classical SLAM is a continuous optimization over metric information. In this paper, we formulate an optimization problem over sensor states and semantic landmark positions that integrates metric information, semantic information, and data associations, and decompose it into two interconnected problems: an estimation of discrete data association and landmark class probabilities, and a continuous optimization over the metric states. The estimated landmark and robot poses affect the association and class distributions, which in turn affect the robot-landmark pose optimization. The performance of our algorithm is demonstrated on indoor and outdoor datasets.
keywords: {Semantics;Simultaneous localization and mapping;Optimization;Measurement;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989203&isnumber=7988677

D. Ćehajić, P. B. g. Dohmann and S. Hirche, "Estimating unknown object dynamics in human-robot manipulation tasks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1730-1737.
doi: 10.1109/ICRA.2017.7989204
Abstract: Knowing accurately the dynamic parameters of a manipulated object is required for common coordination strategies in physical human-robot interaction. Bias in object dynamics results in inaccurately calculated robot wrenches, which may disturb the human during interaction and bias the recognition of the human motion intention. This paper presents an identification strategy of object dynamics for physical human-robot interaction, which allows the tracking of desired human motion and inducing the motions necessary for parameter identification. The estimation of object dynamics is performed online and the estimator minimizes the least square error between the measured and estimated wrenches acting on the object. Identification-relevant motions are derived by analyzing the persistence of excitation condition, necessary for estimation convergence. Such motions are projected in the null space of the partial grasp matrix, relating the human and the robot redundant motion directions, to avoid disturbance of the human desired motion. The approach is evaluated in a physical human-robot object manipulation scenario.
keywords: {Dynamics;Robot kinematics;Estimation;Kinematics;Manipulator dynamics;Robot motion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989204&isnumber=7988677

R. J. Varghese, P. Berthet-Rayne, P. Giataganas, V. Vitiello and G. Yang, "A framework for sensorless and autonomous probe-tissue contact management in robotic endomicroscopic scanning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1738-1745.
doi: 10.1109/ICRA.2017.7989205
Abstract: Advances in optical imaging, and probe-based Confocal Laser Endomicroscopy (pCLE) in particular, offer real-time cellular level information for in-vivo tissue characterization. However for large area coverage, the limited field-of-view necessitates the use of a technique known as mosaicking to generate usable information from the incoming image stream. Mosaicking also needs a continuous stream of good quality images, but this is challenging as the probe needs to be maintained within an optimal working range and the contact force controlled to minimize tissue deformation. Robotic manipulation presents a potential solution to these challenges, but the lack of haptic feedback in current surgical robot systems hinders the technology's clinical adoption. This paper proposes a sensorless alternative based on processing the incoming image stream and deriving a quantitative measure representative of the image quality. This measure is then used by a controller, designed using model-free reinforcement learning techniques, to maintain optimal contact autonomously. The developed controller has shown near real-time performance in overcoming typical loss-of-contact and excess-deformation scenarios experienced during endomicroscopy scanning procedures.
keywords: {Measurement;Imaging;Aerospace electronics;Probes;Robot sensing systems;Image quality},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989205&isnumber=7988677

M. E. M. K. Abdelaziz, V. Groenhuis, J. Veltman, F. Siepel and S. Stramigioli, "Controlling the Stormram 2: An MRI-compatible robotic system for breast biopsy," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1746-1753.
doi: 10.1109/ICRA.2017.7989206
Abstract: Breast cancer is the most frequently life-threatening diagnosed type of cancer among women. Early and accurate diagnosis by acquiring a tissue sample using biopsy techniques is essential. However, small lesions only visible by MRI are often missed in standard methods, indicating the need for a robotic-assisted biopsy system that is MRI-compatible. Existing proof-of-concepts are difficult to employ due to large sizes and/or actuation complexities. Therefore, a compact pneumatically-actuated 5 DOF MRI-compatible robot was further developed and controlled by a computerized valve manifold. Accuracy and efficiency measurements have been performed using two different PVC breast phantoms with embedded fish oil capsules (mimicking lesions) inside a 0.25T MRI scanner. Preliminary results show that the end-effector was able to hit the targeted capsules, and that the position accuracy is in the range of 4.7-7.3 mm. The developed robotic system has potential to perform MRI-guided breast biopsies accurately and improve the clinical workflow.
keywords: {Robots;Needles;Pneumatic systems;Magnetic resonance imaging;Pistons;Biopsy;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989206&isnumber=7988677

G. Dagnino et al., "RAFS: A computer-assisted robotic system for minimally invasive joint fracture surgery, based on pre- and intra-operative imaging," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1754-1759.
doi: 10.1109/ICRA.2017.7989207
Abstract: The integration of minimally invasive robotic assistance and image-guidance can have positive impact on joint fracture surgery, providing a better clinical outcome with respect to the current open procedure. In this paper, a new design of the RAFS surgical system is presented. The redesign of the robotic system and its integration with a novel 3D navigation system through a new clinical workflow, overcomes the drawbacks of the earlier prototype. This makes the RAFS surgical system more suitable to clinical scenarios in the operating theatre. System accuracy and effectiveness are successfully demonstrated through laboratory trials and preliminary cadaveric trials. The experimental results demonstrate that the system allows the surgeon to reduce a 2-fragment distal femur fracture in a cadaveric specimen, with a reduction accuracy of up to 0.85 mm and 2.2°. Preliminary cadaveric trials also provided a positive and favorable outcome pointing to the usability and safety of the RAFS system in the operating theatre, potentially enhancing the capacity of joint fracture surgeries.
keywords: {Pins;Tools;Bones;Surgery;Three-dimensional displays;Robots;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989207&isnumber=7988677

C. J. Perera, T. D. Lalitharatne and K. Kiguchi, "EEG-controlled meal assistance robot with camera-based automatic mouth position tracking and mouth open detection," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1760-1765.
doi: 10.1109/ICRA.2017.7989208
Abstract: A Meal Assistance Robot is an assistive device that is used to aid individuals who cannot independently direct food to their mouths for consuming. For individuals who undergo loss of upper limb functions due to amputations, spinal cord injuries or cerebral palsy, self-feeding can be impossible, and to assist such individuals in regaining their independence meal assistance robots have been introduced. In this paper we propose a meal assistance robot that is controlled using user intentions based on Electroencephalography (EEG) signals while incorporating camera-based automatic mouth position tracking and mouth open detection systems. In the proposed system, users select any solid food item that they desire to consume from three different containers by looking at corresponding flickering LED matrices. User intentions are identified through EEG signals using a Steady State Visual Evoked Potentials (SSVEP) based intention detection method. Initial motion commands for scooping food from the containers are generated and sent to the meal assistance robot from this first stage. At the second stage, a camera-based mouth position tracking method is proposed for automatically detecting the user's mouth position and thereby moving the spoon or end-effector of the meal assistance robot towards the mouth of the user. This method is capable of automatically tracking the mouth position of users irrespective of their individual body differences and seating positions. A mouth open/closed recognition method is implemented at the final stage in order to feed food to the users when they desire consumption, indicated by the opening/closing of their mouth. A set of experiments were carried out with healthy subjects to validate the proposed system and results are here presented.
keywords: {Mouth;Electroencephalography;Tracking;Cameras;Robot vision systems;Containers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989208&isnumber=7988677

H. M. Le, T. N. Do, L. Cao and S. J. Phee, "Towards active variable stiffness manipulators for surgical robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1766-1771.
doi: 10.1109/ICRA.2017.7989209
Abstract: Variable stiffness for robotics is attracting increasing attention from researchers in the field of surgical robots. A surgical robot that can access the human colon or stomach via natural orifices must be flexible enough to pass through tortuous paths and to work in a confined space. Meanwhile, the robot must also be stiff enough to ensure pushability and to hold high payloads during the surgery. Thus, surgical robots with variable stiffness are desirable. This paper presents a new design concept for variable stiffness manipulators using a thermoplastic material - Polyethylene Terephthalate (PET) - and a flexible stainless steel sheath as a heating solution. The stiffness of PET can be flexibly adjusted through temperature. Experiments and validations were carried out at different conditions. The results showed that our proposed design is at least as flexible as a typical commercial endoscope when flexibility is desired and meanwhile at least 9 times stiffer than the endoscope when stiffness is desired (Flexural modulus was compared). A tendon-driven manipulator based on the proposed concept was also developed. Validation tests showed that the manipulator in compliant mode can be significantly bent through cable actuation, and the manipulator in stiff mode is able to maintain its shape against considerably large loads.
keywords: {Endoscopes;Electron tubes;Manipulators;Glass;Steel;Medical robotics;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989209&isnumber=7988677

X. Jin, Y. Cai, A. Prado and S. K. Agrawal, "Effects of exoskeleton weight and inertia on human walking," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1772-1777.
doi: 10.1109/ICRA.2017.7989210
Abstract: Various leg exoskeletons have been designed for gait rehabilitation. The transparency of these exoskeletons is crucial to their effectiveness in gait training. The weight and inertia of an exoskeleton are two important factors affecting its transparency. In this study, using a light-weight leg exoskeleton C-ALEX, we conducted a series of experiments to explore the effect of exoskeleton weight and inertia on the natural walking of twelve healthy subjects. They walked in C-ALEX under three levels of mass added to the leg: (i) no added mass, (ii) 1.8 kg, and (iii) 3.6 kg, and three different setups of C-ALEX: (i) freewalking without C-ALEX, (ii) with C-ALEX, and (iii) with C-ALEX compensating for the weight of the added mass. The result shows that increasing exoskeleton mass increases step length, decreases step height, and reduces maximum knee flexion. After weight compensation, the step height, and the maximum knee flexion partially restored, but the step length did not, implying that the inertia is responsible for the change in step length. The study demonstrates that compensating for weight alone cannot eliminate the changes due to exoskeleton mass. On the other hand, reducing the overall mass of the exoskeleton can better preserve the natural gait of the subjects.
keywords: {Exoskeletons;Legged locomotion;Knee;Thigh;Read only memory;Hip;Gravity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989210&isnumber=7988677

H. Dong, M. Cong, Y. Zhang, Y. Liu and H. Chen, "Real time welding parameter prediction for desired character performance," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1794-1799.
doi: 10.1109/ICRA.2017.7989211
Abstract: In arc welding processes, real time control algorithms have to be developed in order to achieve desired weld quality. However, there could exist big uncertainties and noise in the process, which nullifies the conventional online control method. Besides, due to the modelling difficulty and low experimental efficiency, this task is usually performed offline. In this paper, a real time parameter optimization method is developed to find the optimal welding parameters to achieve desired characteristic performance. Gaussian Process Regression (GPR), a non-parametric modelling technique, is employed to model the relationship between input welding parameters and output characteristic performance. The GPR surrogated Bayesian Optimization Algorithm (GPRBOA) is proposed to optimize the welding parameters. Lower Confidence Bound (LCB) and Upper Confidence Bound (UCB) acquisition functions are utilized. Gas tungsten arc welding experiments were performed and the corresponding experimental data are collected and utilized to validate the proposed modelling method. The predicted characteristic performance is compared with the original data and it shows that the modelling method can accurately predict the weld bead geometry. The control algorithms were demonstrated and the results are presented. This paper opens a door for real time parameter tuning to achieve desired performance, hence the proposed method will innovate the arc welding process.
keywords: {Welding;Ground penetrating radar;Data models;Predictive models;Process control;Real-time systems;Gaussian processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989211&isnumber=7988677

A. S. Kembaum, M. Kitchell and M. Crittenden, "An ultra-compact infinitely variable transmission for robotics," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1800-1807.
doi: 10.1109/ICRA.2017.7989212
Abstract: A novel infinitely variable transmission (IVT) is presented that has the potential to be an order of magnitude smaller than existing technologies leading to several potential applications in robotics (Fig. 1). Unlike more common continuously variable transmissions (CVTs), this transmission can reverse the direction of the output relative to the input without clutches or extra stages, affording new opportunities for energy savings or power bursts. This potentially enables its use across a broad range of mechanical energy conversion applications including robotics, transportation, and heavy industry, where it could dramatically increase total system efficiency. Its controllable impedance also makes it well suited to human-safe robotics and haptic feedback systems.
keywords: {Pulleys;Belts;Service robots;Industries;Propagation losses;Gears},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989212&isnumber=7988677

V. Chawda and G. Niemeyer, "Toward controlling a KUKA LBR IIWA for interactive tracking," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1808-1814.
doi: 10.1109/ICRA.2017.7989213
Abstract: In this paper we use KUKA's Fast Robot Interface (FRI) to design and implement a tracking controller on the Lightweight Robot (LBR) IIWA. We seek low latency, accurate and smooth tracking of the link positions to facilitate human interaction tasks. Focusing on a single joint and its low-level series elastic dynamics, we identify the internal torque control structure and its characteristics. Tracking controllers of varying complexity are tested in an optical motion capture system to provide an independent external reference measurement. Using full state feedback of both motor position and sensed joint torque, we achieve smooth and good tracking of the unsensed link positions.
keywords: {Torque;Tracking;Friction;Mathematical model;Transfer functions;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989213&isnumber=7988677

G. Qiao, C. Schlenoff and B. A. Weiss, "Quick positional health assessment for industrial robot prognostics and health management (PHM)," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1815-1820.
doi: 10.1109/ICRA.2017.7989214
Abstract: Robot calibration and performance will degrade if proper maintenance isn't performed. There have been challenges for manufacturers to optimize the maintenance strategy and minimize unexpected shutdowns. Prognostics and health management (PHM) can be applied to industrial robots through the development of performance metrics, test methods, reference datasets, and supporting tools. A subset of this research involves developing a quick health assessment methodology emphasizing the identification of the positional health (position and orientation accuracy) changes. This methodology enables manufacturers to quickly assess the static/dynamic position and orientation accuracies of their robot systems. In this paper, the National Institute of Standards and Technology's (NIST) effort to develop the measurement science to support this development is presented, including the modeling and algorithm development for the test method, the advanced sensor development to measure 7-D information (time, X, Y, Z, roll, pitch, and yaw), algorithms to analyze the data, and a use case to present the results.
keywords: {Robot sensing systems;Prognostics and health management;Service robots;Robot kinematics;Monitoring;Maintenance engineering},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989214&isnumber=7988677

Q. Yuan, T. S. Lembono, I. -M. Chen, S. N. Landén and V. Malmgren, "Automatic robot taping with force feedback," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1821-1826.
doi: 10.1109/ICRA.2017.7989215
Abstract: In surface treatment processes like plasma spraying and spray painting of workpieces, protecting the uninvolved surface by applying masking tape is a common process. Due to the operation complexity for different geometries, such taping tasks depend on a lot of manual works, which is tedious and tiring. This paper introduces an automatic agile robotic system and the corresponding algorithm to do the surface taping. The automatic taping system consists of a 3D scanner for workpiece 3D model reconstruction, a taping end-effector which is mounted on a robot manipulator to handle the taping task, and a rotating platform that is used to hold the workpiece. The surface covering method and the taping path planning algorithms using the scanned model are introduced. With the implementation of the compliance mechanism, the force feedback and the tape cutting mechanism, the system is able to tape flat, cylindrical, freeform, and grooved surfaces. Experiments conducted on taping an engine inner liner shows that the surface can be covered with uniform taping overlap and very little wrinkle. The proposed system is a useful taping package for industrial applications such as workpiece repairing and surface protection, where surface treatments are involved.
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989215&isnumber=7988677

K. H. Cho et al., "Biomimetic robotic joint mechanism driven by soft linear actuators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1850-1855.
doi: 10.1109/ICRA.2017.7989216
Abstract: From being soft, flexible and producing movement by contracting, soft linear actuators are said to have muscle-like properties. Due to these similarities, they are often called “artificial muscle actuator.” However, the strain produced by these actuators is generally insufficient to be utilized in a large range of applications. Some solutions have been developed, but they sacrifice force to increase the displacement. Meanwhile, the force produced by skeletal muscles increases as it contracts due to its working principle, which is based on the “sliding filament mechanism.” The limitations of soft linear actuators could be overcome by mimicking the contraction process of skeletal muscles. Two types of muscle-inspired robotic joint mechanisms based on the sliding filament mechanism principle are proposed in this work. The mechanisms can be operated using any type of soft linear actuators as well as traditional actuators or motors, and this work realizes the implementation using shape memory alloy wires and 3D printed mechanical parts. The feasibility of both proposed mechanisms, and their capabilities were experimentally verified.
keywords: {Actuators;Force;Muscles;Robots;Prototypes;Wires;Strain},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989216&isnumber=7988677

K. Nakahara, K. Narumi, R. Niiyama and Y. Kawahara, "Electric phase-change actuator with inkjet printed flexible circuit for printable and integrated robot prototyping," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1856-1863.
doi: 10.1109/ICRA.2017.7989217
Abstract: The integrated fabrication of body structures, actuators, sensors, and electronic circuits into one robot system is an open problem in robotics. Simple and rapid construction of electric actuators in the body through existing approaches is difficult. We take advantage of the liquid-to-gas phase change, and propose an electric phase-change actuator comprising a printable fluidic actuator controlled by an inkjet printed electric heater. The actuator can easily be integrated with origami robots. We theoretically analyze the dynamics of electro-fluidic conversion in the actuator and compare it with actual measurement data. The proposed actuator is verified in real examples of a shape-shifting origami structure and a robot gripper with a printed touch sensor.
keywords: {Actuators;Liquids;Heating systems;Robot sensing systems;Fabrication;Time factors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989217&isnumber=7988677

D. M. Bodily, T. F. Allen and M. D. Killpack, "Multi-objective design optimization of a soft, pneumatic robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1864-1871.
doi: 10.1109/ICRA.2017.7989218
Abstract: We present a method for the design optimization of a soft, inflatable robot. The method described utilizes a multi-objective fitness function together with custom, platform-specific metrics related to the dexterity and load-bearing capacity of inflatable manipulators. Candidate designs are scored by computing these metrics at many randomly generated configurations and then by appropriately combining these scores within the multi-objective optimization framework. High performing designs are propagated through a genetic algorithm. The final result is a set of diverse, optimal designs lying along a Pareto front spanning the design space. By examining variations and trade-offs within this set, a designer can more appropriately choose design parameters for a target application. This is especially relevant for robots with many design parameters that can quickly be manufactured as is the case with emerging, soft robot technologies.
keywords: {Manipulators;Measurement;Optimization;Genetic algorithms;Robot sensing systems;Robot kinematics;Design Optimization;Mobile Robots;Soft Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989218&isnumber=7988677

H. Woo, B. Na and K. Kong, "Design of a compact rotary series elastic actuator for improved actuation transparency and mechanical safety," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1872-1877.
doi: 10.1109/ICRA.2017.7989219
Abstract: Actuators for human-interactive robot systems require transparency and guaranteed safety. An actuation system is called transparent, when it is able to generate an actuation force as desired without any actuator dynamics. The requirements for the transparent actuation include high precision and large frequency bandwidth in actuation force generation, zero mechanical impedance, and so on. In this paper, a compact rotary series elastic actuator (cRSEA) is designed considering the actuation transparency and the mechanical safety; the mechanical parameters of a cRSEA are optimally selected for the controllability, the input and output torque transmissibility, and the mechanical impedance. A mechanical clutch that automatically disengages the transmission is devised such that the human is mechanically protected from an excessive actuation torque due to any possible controller malfunction or any external impact from a collision. The proposed cRSEA with a mechanical clutch is applied to develop a wearable robot for incomplete paraplegic patients. Experimental results of a manufactured cRSEA system are introduced in this paper also.
keywords: {Torque;Gears;Impedance;Robots;Springs;Controllability;DC motors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989219&isnumber=7988677

X. Chen, J. Peng, J. Zhou, Y. Chen, M. Y. Wang and Z. Wang, "A robotic manipulator design with novel soft actuators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1878-1884.
doi: 10.1109/ICRA.2017.7989220
Abstract: Soft robots are inherently compliant and adaptive, therefore they are promising candidates for interacting with humans. However robotic manipulators utilizing soft actuators are often constrained by a series of actuator performance limitations. In this work we design a novel linear soft robotic actuator with significantly improved performances over the existing products, achieving 300% deformation ratio, quasi-constant output force over a wide motion range, while maintaining passive compliance and adaptability. Moreover, the novel actuator is less prone to friction, and could be fabricated using inject molding and 3D printing, hence having high repeatability at very low cost. An analytical model was developed to characterize the actuator behavior and provide a guideline for actuator design according to performance specifications. A 6 DOF soft manipulator was designed and fabricated utilizing the novel soft actuator. The manipulator arm had a serial kinematic structure with a biomimetic wrist and was driven by 12 soft actuators mounted onto the arm links. With 1.2m workspace radius and 1kg payload, the working air pressure could be as low as 1bar. Preliminary results have shown the validity of the novel soft actuator and manipulator designs, as well as the strong potential of soft robots in human-oriented applications.
keywords: {Actuators;Manipulators;Force;Muscles;Kinematics;Bellows},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989220&isnumber=7988677

T. Yamamoto, M. Konyo, K. Tadakuma and S. Tadokoro, "A self-locking-type expansion mechanism to achieve high holding force and pipe-passing capability for a pneumatic in-pipe robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1900-1907.
doi: 10.1109/ICRA.2017.7989221
Abstract: This study proposes a self-locking-type expansion mechanism for in-pipe robots. Previously, we proposed a highspeed locomotion mechanism using pneumatic hollow-shaft actuators; however, this mechanism lacked holding force and could not pass through a bent pipe. The proposed mechanism generates a large holding force and can easily pass through a bent pipe by invoking a self-locking phenomenon. We conceptualize and design the novel expansion mechanism and introduce its associated mathematical model to formulate the holding force and mechanism design. The characteristics and capabilities of the mechanism are elucidated by experiments. From the experimental results, we optimize the applied pressure and the design of the mechanism. The proposed mechanism generates a maximum holding force of 69.7 N, which is 5.2 times higher than that of the previous mechanism, and drastically improves the robot's bent-pipe-passing capability. Finally, the performance of this mechanism is confirmed in a simulated pipe test. In this trial, a robot equipped with the proposed mechanism smoothly and steadily moves through complex pipe configurations, including the vertical and bent pipes.
keywords: {Force;Actuators;Robots;Electron tubes;Pneumatic systems;Springs;Pins},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989221&isnumber=7988677

K. S. Kim and L. Sentis, "Human body part multicontact recognition and detection methodology," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1908-1915.
doi: 10.1109/ICRA.2017.7989222
Abstract: In this paper we focus on a mobile platform which physically interacts with a human operator. We detect the contact gestures of a human operator in real-time using a labmade time-of-flight 3D scanner mounted on the platform as well as rotary torque sensors mounted along the drivetrain of its omni-directional wheels. Through the fusion of these two different sensors, touch gestures of an operator are processed inferring information about the body parts in contact and the applied forces. Behaviors that respond to touch-based gestures are programmed a priori, and with the previous sensor data we classify them into a set of known contact gestures that allow the platform to quickly react. We investigate these physical human-robot cooperative functions in a testbed consisting of a sensorized mobile platform and a human operator.
keywords: {Robot sensing systems;Three-dimensional displays;Laser radar;Mobile communication;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989222&isnumber=7988677

S. Roelofsen, D. Gillet and A. Martinoli, "Collision avoidance with limited field of view sensing: A velocity obstacle approach," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1922-1927.
doi: 10.1109/ICRA.2017.7989223
Abstract: Collision avoidance, in particular between robots, is an important component for autonomous robots. It is a necessary component in numerous applications such as humanrobot interaction, automotive or unmanned aerial vehicles. While many collision avoidance algorithms take into account actuation constraints, only a few consider sensing limitations. In this paper, we present a reciprocal collision avoidance algorithm based on the velocity obstacle approach that guarantees collision-free maneuvers even when the robots are only capable to sense their environment within a limited Field Of View (FOV). We also present the challenges associated to sensors with limited FOV, show the conditions under which maneuvering can be safely done, and the modifications that a velocity obstacle approach requires to satisfy such conditions. We provide simulations and real robot experiments to validate our approach.
keywords: {Collision avoidance;Robot sensing systems;Robot kinematics;Automotive engineering;Unmanned aerial vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989223&isnumber=7988677

W. Schwarting, J. Alonso-Mora, L. Pauli, S. Karaman and D. Rus, "Parallel autonomy in automated vehicles: Safe motion generation with minimal intervention," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1928-1935.
doi: 10.1109/ICRA.2017.7989224
Abstract: Current state-of-the-art vehicle safety systems, such as assistive braking or automatic lane following, are still only able to help in relatively simple driving situations. We introduce a Parallel Autonomy shared-control framework that produces safe trajectories based on human inputs even in much more complex driving scenarios, such as those commonly encountered in an urban setting. We minimize the deviation from the human inputs while ensuring safety via a set of collision avoidance constraints. We develop a receding horizon planner formulated as a Non-linear Model Predictive Control (NMPC) including analytic descriptions of road boundaries, and the configurations and future uncertainties of other traffic participants, and directly supplying them to the optimizer without linearization. The NMPC operates over both steering and acceleration simultaneously. Furthermore, the proposed receding horizon planner also applies to fully autonomous vehicles. We validate the proposed approach through simulations in a wide variety of complex driving scenarios such as left-turns across traffic, passing on busy streets, and under dynamic constraints in sharp turns on a race track.
keywords: {Vehicles;Roads;Optimization;Safety;Acceleration;Trajectory;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989224&isnumber=7988677

M. Cefalo, E. Magrini and G. Oriolo, "Parallel collision check for sensor based real-time motion planning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1936-1943.
doi: 10.1109/ICRA.2017.7989225
Abstract: In this paper we present a real-time collision check algorithm based on the parallel computation capabilities of recent graphics card's GPUs. We show an effective application of the proposed algorithm to solve the task-constrained real-time motion planning problem for a redundant manipulator. We propose a proof-of-concept motion planner based on fast collision check of predicted robot motion over a given planning horizon. Obstacles are avoided exploiting the redundancy of the robot. Reactive velocities are computed for some control points placed on the robot and projected in the null space of the task Jacobian. The approach is validated through simulations in V-Rep environments and experiments on the KUKA LWR-IV 7-DoF manipulator.
keywords: {Collision avoidance;Graphics processing units;Robot kinematics;Real-time systems;Cameras;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989225&isnumber=7988677

J. S. Park, C. Park and D. Manocha, "Efficient probabilistic collision detection for non-convex shapes," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1944-1951.
doi: 10.1109/ICRA.2017.7989226
Abstract: We present new algorithms to perform fast probabilistic collision queries between convex as well as non-convex objects. Our approach is applicable to general shapes, where one or more objects are represented using Gaussian probability distributions. We present a fast new algorithm for a pair of convex objects, and extend the approach to non-convex models using hierarchical representations. We highlight the performance of our algorithms with various convex and non-convex shapes on complex synthetic benchmarks and trajectory planning benchmarks for a 7-DOF Fetch robot arm.
keywords: {Collision avoidance;Probabilistic logic;Gaussian distribution;Probability distribution;Three-dimensional displays;Shape;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989226&isnumber=7988677

K. Berger, R. Voorhies and L. H. Matthies, "Depth from stereo polarization in specular scenes for urban robotics," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1966-1973.
doi: 10.1109/ICRA.2017.7989227
Abstract: 3-D perception of scenes with specular surfaces is still challenging for robotics applications in urban areas, for both active and passive range sensors; there is a need for improved solutions that work without artificial illumination over a wide range of distances. The advent of cameras with microgrid polarization filter arrays, which allow acquiring four orientations of linearly polarized images simultaneously, has potential to make the use of polarization information in 3-D perception more practical. It is well-known that polarization can provide information about the orientation of specular surfaces; however, prior work with polarization for 3-D perception has had several limitations. We present the first unified formulation of depth perception with stereo and polarization by extending previous energy minimization formulations to include surface orientation constraints computed from the polarization channels. We apply an existing quadratic pseudo-boolean optimization (QPBO) method to approximate the optimal depth map. We use synthetic and real indoor/outdoor images to demonstrate that the new method achieves better results than prior methods, with fewer assumptions and limitations.
keywords: {Cameras;Lighting;Robot sensing systems;Optimization;Refractive index},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989227&isnumber=7988677

S. Chan, X. Zhou, Z. Zhang and S. Chen, "Compressive tracking with locality sensitive histograms features," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1974-1981.
doi: 10.1109/ICRA.2017.7989228
Abstract: Currently, Compressive Tracking (CT) method has drawn great attention because of its high efficiency. However, it cannot well deal with some appearance variations due to its limitations of feature expression and it only uses a fixed parameter to update the appearance model. In order to handle such matters, we propose an adaptive CT method that combines the predicted target position with CT based on Locality Sensitive Histograms (LSH) features. Our method significantly improves CT in four aspects. First, the efficient illumination invariant features extracted based on LSH are used to represent an effective appearance model that is robust to illumination changes. Second, the color attributes tracker is adopted to predict the target position for re-building the new weighted discriminant function which brings in the color information to make up for the inadequacy of Haar-like characteristics. Third, a new model update mechanism is proposed to preserve the stable features while avoid the noisy appearance variations during tracking. Fourth, a trajectory rectification method is employed to refine the tracking location when possible inaccurate tracking occurs. Finally, we show that our tracker achieves state-of-the-art performance in a comprehensive evaluation over 47 challenging color sequences.
keywords: {Target tracking;Feature extraction;Image color analysis;Histograms;Computed tomography;Prediction algorithms;Lighting},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989228&isnumber=7988677

U. Shah, R. Khawad and K. M. Krishna, "Detecting, localizing, and recognizing trees with a monocular MAV: Towards preventing deforestation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1982-1987.
doi: 10.1109/ICRA.2017.7989229
Abstract: We propose a novel pipeline for detecting, localizing, and recognizing trees with a quadcoptor equipped with monocular camera. The quadcoptor flies in an area of semidense plantation filled with many trees of more than 5 meter in height. Trees are detected on a per frame basis using state of the art Convolutional Neural Networks inspired by recent rapid advancements showcased in Deep Learning literature. Once detected, the trees are tagged with a GPS coordinate through our global localizing and positioning framework. Further the localized trees are segmented, characterized by feature descriptors, and stored in a database by their GPS coordinates. In a subsequent run in the same area, the trees that get detected are queried to the database and get associated with the trees in the database. The association problem is posed as a dynamic programming problem and the optimal association is inferred. The algorithm has been verified in various zones in our campus infested with trees with varying density on the Bebop 2 drone equipped with omnidirectional vision. High percentage of successful recognition and association of the trees between two or more runs is the cornerstone of this effort. The proposed method is also able to identify if trees are missing from their expected GPS tagged locations thereby making it possible to immediately alert concerned authorities about possible unlawful felling of trees. We also propose a novel way of obtaining dense disparity map for quadcopter with monocular camera.
keywords: {Vegetation;Global Positioning System;Cameras;Neural networks;Databases;Computer architecture;Agriculture},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989229&isnumber=7988677

A. Osep, W. Mehner, M. Mathias and B. Leibe, "Combined image- and world-space tracking in traffic scenes," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1988-1995.
doi: 10.1109/ICRA.2017.7989230
Abstract: Tracking in urban street scenes plays a central role in autonomous systems such as self-driving cars. Most of the current vision-based tracking methods perform tracking in the image domain. Other approaches, e.g. based on LIDAR and radar, track purely in 3D. While some vision-based tracking methods invoke 3D information in parts of their pipeline, and some 3D-based methods utilize image-based information in components of their approach, we propose to use image- and world-space information jointly throughout our method. We present our tracking pipeline as a 3D extension of image-based tracking. From enhancing the detections with 3D measurements to the reported positions of every tracked object, we use world-space 3D information at every stage of processing. We accomplish this by our novel coupled 2D-3D Kalman filter, combined with a conceptually clean and extendable hypothesize-and-select framework. Our approach matches the current state-of-the-art on the official KITTI benchmark, which performs evaluation in the 2D image domain only. Further experiments show significant improvements in 3D localization precision by enabling our coupled 2D-3D tracking.
keywords: {Three-dimensional displays;Proposals;Radar tracking;Two dimensional displays;Tracking;Laser radar;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989230&isnumber=7988677

M. Kaya, E. Senel, A. Ahmad and O. Bebek, "Visual tracking of multiple moving targets in 2D ultrasound guided robotic percutaneous interventions," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1996-2002.
doi: 10.1109/ICRA.2017.7989231
Abstract: Percutaneous needle procedures are mostly carried out with the guidance of 2D ultrasound (US) imaging. US images are inherently noisy and their resolutions are low. Hence, target tracking can be challenging. Image based tracking methods can be used to track the needle and the target. This paper proposes visual tracking of multiple moving points, such as biopsy needles and targets, in 2D US images using normalized cross correlation and mutual information similarity functions. Both moving and deformable targets can be tracked. An affine motion model is used for small and moving target tracking and a thin plate spline motion model is used for deformable target tracking. During the tracking, needle and target template images are updated with a template update strategy. Also, tracking outputs of normalized cross correlation and mutual information are fused using the Kalman filter to reduce the tracking error. During the experiments, needle is inserted using a needle insertion robot. 2D US probe is attached to a robotic arm's end effector to servo the probe along the needle insertion path. Proposed needle and target tracking methods were tested with phantoms. Accuracies of the needle tip and moving target tracking methods were measured using an optical tracking system. Experimental results showed that the proposed tracking method could be used to simultaneously track the needle tip and the targets in real-time in 2D US guided percutaneous needle procedures.
keywords: {Needles;Target tracking;Robots;Visualization;Two dimensional displays;Probes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989231&isnumber=7988677

S. -H. Kim, G. Choe, B. Ahn and I. S. Kweon, "Deep representation of industrial components using simulated images," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2003-2010.
doi: 10.1109/ICRA.2017.7989232
Abstract: In this paper, we present a visual learning framework to retrieve a 3D model and estimate its pose from a single image. To increase the quantity and quality of training data, we define our simulation space in the near infrared (NIR) band, and utilize the quasi-Monte Carlo (MC) method for scalable photorealistic rendering of manufactured components. Two types of convolutional neural network (CNN) architectures are trained over these synthetic data and a relatively small amount of real data. The first CNN model seeks the most discriminative information and uses it to classify industrial components with fine-grained shape attributes. Once a 3D model is identified, one of the category-specific CNNs is tested for pose regression in the second phase. The mixed data for learning object categories is useful in domain adaptation and attention mechanism in our system. We validate our data-driven method with 88 component models, and the experimental results are qualitatively demonstrated. Also, the CNNs trained with various conditions of mixed data are quantitatively analyzed.
keywords: {Three-dimensional displays;Rendering (computer graphics);Computational modeling;Solid modeling;Shape;Cameras;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989232&isnumber=7988677

G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis and K. Daniilidis, "6-DoF object pose from semantic keypoints," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2011-2018.
doi: 10.1109/ICRA.2017.7989233
Abstract: This paper presents a novel approach to estimating the continuous six degree of freedom (6-DoF) pose (3D translation and rotation) of an object from a single RGB image. The approach combines semantic keypoints predicted by a convolutional network (convnet) with a deformable shape model. Unlike prior work, we are agnostic to whether the object is textured or textureless, as the convnet learns the optimal representation from the available training image data. Furthermore, the approach can be applied to instance- and class-based pose recovery. Empirically, we show that the proposed approach can accurately recover the 6-DoF object pose for both instance- and class-based scenarios with a cluttered background. For class-based object pose estimation, state-of-the-art accuracy is shown on the large-scale PASCAL3D+ dataset.
keywords: {Shape;Solid modeling;Three-dimensional displays;Heating systems;Two dimensional displays;Cameras;Semantics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989233&isnumber=7988677

P. McGarey, M. Polzin and T. D. Barfoot, "Falling in line: Visual route following on extreme terrain for a tethered mobile robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2027-2034.
doi: 10.1109/ICRA.2017.7989234
Abstract: This paper describes visual route following for a cliff-climbing, tethered mobile robot for the purpose of autonomously traversing extreme terrain in the presence of obstacles. When the robot's tether contacts an obstacle, an intermediate anchor is formed. In order to detach from intermediate anchors and avoid entanglement, the robot must backtrack along its outgoing trajectory. We use the Visual Teach & Repeat (VT&R) algorithm to autonomously repeat a manually taught path. However, our problem is complicated by the fact that the robot's tether must (i) remain taut regardless of inclination, (ii) allow the robot to drive freely, and (iii) provide motion assistance when wheel traction is reduced on steep slopes. To enable visual route following over varied terrain, we have developed a novel tether controller that selects a safe, steady-state tension based on the robot's inclination while also accounting for vehicle motion. Experiments are performed on our Tethered Robotic Explorer (TReX), which autonomously repeats paths while tethered in both flat-indoor and steep-outdoor environments in the presence of obstacles.
keywords: {Visualization;Mobile robots;Robot sensing systems;Feature extraction;Force;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989234&isnumber=7988677

V. Peretroukhin, L. Clement and J. Kelly, "Reducing drift in visual odometry by inferring sun direction using a Bayesian Convolutional Neural Network," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2035-2042.
doi: 10.1109/ICRA.2017.7989235
Abstract: We present a method to incorporate global orientation information from the sun into a visual odometry pipeline using only the existing image stream, where the sun is typically not visible. We leverage recent advances in Bayesian Convolutional Neural Networks to train and implement a sun detection model that infers a three-dimensional sun direction vector from a single RGB image. Crucially, our method also computes a principled uncertainty associated with each prediction, using a Monte Carlo dropout scheme. We incorporate this uncertainty into a sliding window stereo visual odometry pipeline where accurate uncertainty estimates are critical for optimal data fusion. Our Bayesian sun detection model achieves a median error of approximately 12 degrees on the KITTI odometry benchmark training set, and yields improvements of up to 42% in translational ARMSE and 32% in rotational ARMSE compared to standard VO. An open source implementation of our Bayesian CNN sun estimator (Sun-BCNN) using Caffe is available at https://github.com/utiasSTARS/sun-bcnn-vo.
keywords: {Sun;Bayes methods;Neural networks;Visualization;Pipelines;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989235&isnumber=7988677

S. Wang, R. Clark, H. Wen and N. Trigoni, "DeepVO: Towards end-to-end visual odometry with deep Recurrent Convolutional Neural Networks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2043-2050.
doi: 10.1109/ICRA.2017.7989236
Abstract: This paper studies monocular visual odometry (VO) problem. Most of existing VO algorithms are developed under a standard pipeline including feature extraction, feature matching, motion estimation, local optimisation, etc. Although some of them have demonstrated superior performance, they usually need to be carefully designed and specifically fine-tuned to work well in different environments. Some prior knowledge is also required to recover an absolute scale for monocular VO. This paper presents a novel end-to-end framework for monocular VO by using deep Recurrent Convolutional Neural Networks (RCNNs). Since it is trained and deployed in an end-to-end manner, it infers poses directly from a sequence of raw RGB images (videos) without adopting any module in the conventional VO pipeline. Based on the RCNNs, it not only automatically learns effective feature representation for the VO problem through Convolutional Neural Networks, but also implicitly models sequential dynamics and relations using deep Recurrent Neural Networks. Extensive experiments on the KITTI VO dataset show competitive performance to state-of-the-art methods, verifying that the end-to-end Deep Learning technique can be a viable complement to the traditional VO systems.
keywords: {Feature extraction;Neural networks;Pipelines;Cameras;Image sequences;Visualization;Videos},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989236&isnumber=7988677

N. Cazy, P. Wieber, P. R. Giordano and F. Chaumette, "Visual servoing using model predictive control to assist multiple trajectory tracking," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2057-2064.
doi: 10.1109/ICRA.2017.7989237
Abstract: We propose in this paper a new active perception scheme based on Model Predictive Control under constraints for generating a sequence of visual servoing tasks. The proposed control scheme is used to compute the motion of a camera whose task is to successively observe a set of robots for measuring their position and improving the accuracy of their localization. This method is based on the prediction of an uncertainty model (due to actuation and measurement noise) for determining which robot has to be observed by the camera. Simulation results are presented for validating the approach.
keywords: {Cameras;Robot vision systems;Robot kinematics;Predictive control;Trajectory;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989237&isnumber=7988677

K. MacTavish, M. Paton and T. D. Barfoot, "Visual triage: A bag-of-words experience selector for long-term visual route following," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2065-2072.
doi: 10.1109/ICRA.2017.7989238
Abstract: Our work builds upon Visual Teach & Repeat 2 (VT&R2): a vision-in-the-loop autonomous navigation system that enables the rapid construction of route networks, safely built through operator-controlled driving. Added routes can be followed autonomously using visual localization. To enable long-term operation that is robust to appearance change, its Multi-Experience Localization (MEL) leverages many previously driven experiences when localizing to the manually taught network. While this multi-experience method is effective across appearance change, the computation becomes intractable as the number of experiences grows into the tens and hundreds. This paper introduces an algorithm that prioritizes experiences most relevant to live operation, limiting the number of experiences required for localization. The proposed algorithm uses a visual Bag-of-Words description of the live view to select relevant experiences based on what the vehicle is seeing right now, without having to factor in all possible environmental influences on scene appearance. This system runs in the loop, in real time, does not require bootstrapping, can be applied to any pointfeature MEL paradigm, and eliminates the need for visual training using an online, local visual vocabulary. By picking a subset of visually similar experiences to the live view, we demonstrate safe, vision-in-the-loop route following over a 31 hour period, despite appearance as different as night and day.
keywords: {Visualization;Robots;Vocabulary;Real-time systems;Algorithm design and analysis;Robustness;Windows},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989238&isnumber=7988677

D. -K. Kim and M. R. Walter, "Satellite image-based localization via learned embeddings," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2073-2080.
doi: 10.1109/ICRA.2017.7989239
Abstract: We propose a vision-based method that localizes a ground vehicle using publicly available satellite imagery as the only prior knowledge of the environment. Our approach takes as input a sequence of ground-level images acquired by the vehicle as it navigates, and outputs an estimate of the vehicle's pose relative to a georeferenced satellite image. We overcome the significant viewpoint and appearance variations between the images through a neural multi-view model that learns location-discriminative embeddings in which ground-level images are matched with their corresponding satellite view of the scene. We use this learned function as an observation model in a filtering framework to maintain a distribution over the vehicle's pose. We evaluate our method on different benchmark datasets and demonstrate its ability localize ground-level images in environments novel relative to training, despite the challenges of significant viewpoint and appearance variations.
keywords: {Satellites;Databases;Visualization;Robustness;Lighting;Global Positioning System;Buildings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989239&isnumber=7988677

N. Sharma, S. Elbaum and C. Detweiler, "Rate impact analysis in robotic systems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2089-2096.
doi: 10.1109/ICRA.2017.7989240
Abstract: Changes to robotic systems as they are updated or upgraded often affect the flow of control and sensor data. Developers and users spend a significant amount of time tracing the impact of these changes that could otherwise have negative impacts on the robot's performance and behavior. Changes to the rates at which data is published from sensors, controllers, and other parts of the system are particularly subtle and difficult to detect. These rate changes, even if minor (e.g. lowering the frame rate of a camera), can propagate throughout the system and have broad impacts. In this work, we develop and implement an approach to help identify the set of components whose rate may be impacted by a system change. The approach builds on the insight that certain code patterns render component's outgoing data rate independent of the component's incoming data rate. We use that insight to reduce the number of components reported as affected by the change to minimize the number of components that must be reevaluated by the developer. A study of an implementation of the approach on three ROS systems shows that it can reduce the size of the impact set by up to 41% in cases when the changes have broad data impacts. The analysis is performed at compile time and only adds a third more to the compilation time.
keywords: {Robot sensing systems;Publishing;Publish-subscribe;Tools;Cameras;Solids},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989240&isnumber=7988677

L. Sabattini, C. Secchi and C. Fantuzzi, "Achieving the desired dynamic behavior in multi-robot systems interacting with the environment," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2097-2102.
doi: 10.1109/ICRA.2017.7989241
Abstract: In this paper we consider the problem of controlling the dynamic behavior of a multi-robot system while interacting with the environment. In particular, we propose a general methodology that, by means of locally scaling inter-robot coupling relationships, leads to achieving a desired interactive behavior. The proposed method is shown to guarantee passivity preservation, which ensures a safe interaction. The performance of the proposed methodology is evaluated in simulation, over large-scale multi-robot systems.
keywords: {Multi-robot systems;Couplings;Robot kinematics;Force;Damping;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989241&isnumber=7988677

P. Hołobut and J. Lengiewicz, "Distributed computation of forces in modular-robotic ensembles as part of reconfiguration planning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2103-2109.
doi: 10.1109/ICRA.2017.7989242
Abstract: We discuss selected mechanical aspects of self-reconfiguration of densely-packed modular robots. The change of connection topology and transport of modules are fundamental mechanisms for these systems, which determine their desired emergent behavior, e.g., movement, shape change or interaction with their surroundings. At the same time, reconfiguration affects the forces between modules. We present a distributed procedure by which a robot can predict if the next planned reconfiguration step will overstress intermodular connections. We use a Finite Element model of a modular robot, with one-node-per-module discretization and beam elements representing intermodular connections. The analysis is restricted to static loads and linear elasticity. We present a distributed procedure of aggregation of the stiffness matrix and iterative solution of the resulting equations of elasticity. The procedure is illustrated with numerical examples and analyzed in terms of its efficiency.
keywords: {Mathematical model;Finite element analysis;Topology;Shape;Robot sensing systems;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989242&isnumber=7988677

A. Marino, G. Muscio and F. Pierri, "Distributed cooperative object parameter estimation and manipulation without explicit communication," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2110-21116.
doi: 10.1109/ICRA.2017.7989243
Abstract: The paper presents a two stages distributed algorithm for cooperative manipulating an unknown object rigidly grasped by mobile manipulators, in the absence of both a central unit and any explicit information exchange among robots. In the first stage, robots cooperatively estimate the object kinematic and dynamic parameters by properly moving the object or applying specific contact wrenches. In the second stage, the estimated parameters are used in a distributed cooperative algorithm aimed at controlling the object pose while limiting both the squeezing wrenches exerted by the manipulators and the wrench exerted by the environment on the object. Numerical simulations demonstrate the feasibility of the approach.
keywords: {Manipulator dynamics;Estimation;Kinematics;Dynamics;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989243&isnumber=7988677

L. Zhou and P. Tokekar, "Active target tracking with self-triggered communications," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2117-2123.
doi: 10.1109/ICRA.2017.7989244
Abstract: We study the problem of reducing the amount of communication in a distributed target tracking problem. We focus on the scenario where a team of robots are allowed to move on the boundary of the environment. Their goal is to seek a formation so as to best track a target moving in the interior of the environment. The robots are capable of measuring distances to the target. Decentralized control strategies have been proposed in the past that guarantee that the robots asymptotically converge to the optimal formation. However, existing methods require that the robots exchange information with their neighbors at all time steps. Instead, we focus on reducing the amount of communication among robots. We propose a self-triggered communication strategy that decides when a particular robot should seek up-to-date information from its neighbors and when it is safe to operate with possibly outdated information from the neighbor. We prove that this strategy converges to an optimal formation. We compare the two approaches (constant communication and self-triggered communication) through simulations of tracking stationary and mobile targets.
keywords: {Target tracking;Algorithm design and analysis;Motion segmentation;Partitioning algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989244&isnumber=7988677

S. Kemna, J. G. Rogers, C. Nieto-Granda, S. Young and G. S. Sukhatme, "Multi-robot coordination through dynamic Voronoi partitioning for informative adaptive sampling in communication-constrained environments," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2124-2130.
doi: 10.1109/ICRA.2017.7989245
Abstract: Autonomous underwater vehicles (AUVs) are cost- and time-efficient systems for environmental sampling. Informative adaptive sampling has been shown to be an effective method of sampling a lake or ocean for environmental modeling. In this paper, we focus on multi-robot coordination for informative adaptive sampling. We use a dynamic Voronoi partitioning approach whereby the vehicles, in a decentralized fashion, repeatedly calculate weighted Voronoi partitions for the space. Each vehicle then runs informative adaptive sampling within their partition. The vehicles can request surfacing events to share data between vehicles. Simulation results show that the addition of the coordination with dynamic Voronoi partitioning results in obtaining higher quality models faster. Thus we created a decentralized, multi-robot coordination approach for informative, adaptive sampling of unknown environments.
keywords: {Robot kinematics;Adaptation models;Vehicle dynamics;Entropy;Density functional theory;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989245&isnumber=7988677

Y. Suzuki, Y. Tsutsui, M. Yaegashi and S. Kobayashi, "Modular robot using helical magnet for bonding and transformation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2131-2137.
doi: 10.1109/ICRA.2017.7989246
Abstract: A self-reconfigurable modular robotic system has potential to carry out a wide variety of tasks in various fields and conditions. For realizing such versatileness and robustness, the compositional modules have to be designed so that the combined structure is equipped with high degree of freedom of the self-reconfiguration. We propose a new design of a modular robot using helically magnetized axes. The axes are arranged at all of the edges of the cubic-shaped module and contribute to both connection and transformation among the modules. The mechanism enables the modules to construct a 3-D orthogonal lattice structure, execute slide movement to neighboring vacant grid positions, and change the structural configuration by themselves. This paper firstly describes the conceptual design and fabrication method of the helically magnetized axis. Then, total design and specification of the module are explained. Finally, experimental results to evaluate the performance of connection and transformation are presented.
keywords: {Robots;Force;Magnetic levitation;Transforms;DC motors;Bonding;Lattices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989246&isnumber=7988677

A. Nair et al., "Combining self-supervised learning and imitation for vision-based rope manipulation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2146-2153.
doi: 10.1109/ICRA.2017.7989247
Abstract: Manipulation of deformable objects, such as ropes and cloth, is an important but challenging problem in robotics. We present a learning-based system where a robot takes as input a sequence of images of a human manipulating a rope from an initial to goal configuration, and outputs a sequence of actions that can reproduce the human demonstration, using only monocular images as input. To perform this task, the robot learns a pixel-level inverse dynamics model of rope manipulation directly from images in a self-supervised manner, using about 60K interactions with the rope collected autonomously by the robot. The human demonstration provides a high-level plan of what to do and the low-level inverse model is used to execute the plan. We show that by combining the high and low-level plans, the robot can successfully manipulate a rope into a variety of target shapes using only a sequence of human-provided images for direction.
keywords: {Robot kinematics;Visualization;Predictive models;Neural networks;Mathematical model;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989247&isnumber=7988677

A. H. Chang, C. M. Hubicki, J. J. Aguilar, D. I. Goldman, A. D. Ames and P. A. Vela, "Learning to jump in granular media: Unifying optimal control synthesis with Gaussian process-based regression," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2154-2160.
doi: 10.1109/ICRA.2017.7989248
Abstract: The varied and complex dynamics of deformable terrain are significant impediments toward real-world viability of locomotive robotics, particularly for legged machines. We explore vertical jumping on granular media (GM) as a model task for legged locomotion on uncharacterized deformable terrain. By integrating (Gaussian process) GP-based regression and evaluation to estimate ground forcing as a function of state, a one-dimensional jumper acquires the ability to learn forcing profiles exerted by its environment in tandem to achieving its control objective. The GP-based dynamical model initially assumes a baseline rigid, non-compliant surface. As part of an iterative procedure, the optimizer employing this model generates an optimal control to achieve a target jump height while respecting known hardware limitations of the robot model. Trajectory and forcing data recovered from evaluation on the true GM surface model simulation is applied to train the GP, and in turn, provide the optimizer a more richly informed dynamical model of the environment. After three iterations, predicted optimal control trajectories coincide with execution results, within 1.2% jumping height error, as the GP-based approximation converges to the true GM model.
keywords: {Optimal control;Robots;Substrates;Media;Mathematical model;Springs;Solids},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989248&isnumber=7988677

L. Pinto and A. Gupta, "Learning to push by grasping: Using multiple tasks for effective learning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2161-2168.
doi: 10.1109/ICRA.2017.7989249
Abstract: Recently, end-to-end learning frameworks are gaining prevalence in the field of robot control. These frameworks input states/images and directly predict the torques or the action parameters. However, these approaches are often critiqued due to their huge data requirements for learning a task. The argument of the difficulty in scalability to multiple tasks is well founded, since training these tasks often require hundreds or thousands of examples. But do end-to-end approaches need to learn a unique model for every task? Intuitively, it seems that sharing across tasks should help since all tasks require some common understanding of the environment. In this paper, we attempt to take the next step in data-driven end-to-end learning frameworks: move from the realm of task-specific models to joint learning of multiple robot tasks. In an astonishing result we show that models with multi-task learning tend to perform better than task-specific models trained with same amounts of data. For example, a deep-network learned with 2.5K grasp and 2.5K push examples performs better on grasping than a network trained on 5K grasp examples.
keywords: {Grasping;Training;Robot sensing systems;Data models;Visualization;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989249&isnumber=7988677

C. Devin, A. Gupta, T. Darrell, P. Abbeel and S. Levine, "Learning modular neural network policies for multi-task and multi-robot transfer," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2169-2176.
doi: 10.1109/ICRA.2017.7989250
Abstract: Reinforcement learning (RL) can automate a wide variety of robotic skills, but learning each new skill requires considerable real-world data collection and manual representation engineering to design policy classes or features. Using deep reinforcement learning to train general purpose neural network policies alleviates some of the burden of manual representation engineering by using expressive policy classes, but exacerbates the challenge of data collection, since such methods tend to be less efficient than RL with low-dimensional, hand-designed representations. Transfer learning can mitigate this problem by enabling us to transfer information from one skill to another and even from one robot to another. We show that neural network policies can be decomposed into “task-specific” and “robot-specific” modules, where the task-specific modules are shared across robots, and the robot-specific modules are shared across all tasks on that robot. This allows for sharing task information, such as perception, between robots and sharing robot information, such as dynamics and kinematics, between tasks. We exploit this decomposition to train mix-and-match modules that can solve new robot-task combinations that were not seen during training. Using a novel approach to train modular neural networks, we demonstrate the effectiveness of our transfer method for enabling zero-shot generalization with a variety of robots and tasks in simulation for both visual and non-visual tasks.
keywords: {Neural networks;Robot sensing systems;Learning (artificial intelligence);Games;Training;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989250&isnumber=7988677

Y. Zhou and K. Hauser, "Incorporating side-channel information into convolutional neural networks for robotic tasks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2177-2183.
doi: 10.1109/ICRA.2017.7989251
Abstract: Convolutional neural networks (CNN) are a deep learning technique that has achieved state-of-the-art prediction performance in computer vision and robotics, but assume the input data can be formatted as an image or video (e.g. predicting a robot grasping location given RGB-D image input). This paper considers the problem of augmenting a traditional CNN for handling image-like input (called main-channel input) with additional, highly predictive, non-image-like input (called side-channel input). An example of such a task would be to predict whether a robot path is collision-free given an occupancy grid of the environment and the path's start and goal configurations; the occupancy grid is the main-channel and the start and goal are the side-channel. This paper presents several candidate network architectures for doing so. Empirical tests on robot collision prediction and control problems compare the proposed architectures in terms of learning speed, memory usage, learning capacity, and susceptibility to overfitting.
keywords: {Computer architecture;Kernel;Robots;Collision avoidance;Tensile stress;Two dimensional displays;Convolution},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989251&isnumber=7988677

A. Rai, G. Sutanto, S. Schaal and F. Meier, "Learning feedback terms for reactive planning and control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2184-2191.
doi: 10.1109/ICRA.2017.7989252
Abstract: With the advancement of robotics, machine learning, and machine perception, increasingly more robots will enter human environments to assist with daily tasks. However, dynamically-changing human environments requires reactive motion plans. Reactivity can be accomplished through re-planning, e.g. model-predictive control, or through a reactive feedback policy that modifies on-going behavior in response to sensory events. In this paper, we investigate how to use machine learning to add reactivity to a previously learned nominal skilled behavior. We approach this by learning a reactive modification term for movement plans represented by nonlinear differential equations. In particular, we use dynamic movement primitives (DMPs) to represent a skill and a neural network to learn a reactive policy from human demonstrations. We use the well explored domain of obstacle avoidance for robot manipulation as a test bed. Our approach demonstrates how a neural network can be combined with physical insights to ensure robust behavior across different obstacle settings and movement durations. Evaluations on an anthropomorphic robotic system demonstrate the effectiveness of our work.
keywords: {Couplings;Collision avoidance;Robot sensing systems;Trajectory;Neural networks;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989252&isnumber=7988677

Y. Zheng, "Computing the best grasp in a discrete point set," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2208-2214.
doi: 10.1109/ICRA.2017.7989253
Abstract: This paper solves the problem of computing the best grasp in a discrete point set based on a popular grasp quality measure, namely the largest origin-centered ball contained in the grasp wrench set. So far, the solution to this problem is very limited. Noticing that the quality measure for a grasp is equal to the minimum value of the support function of its grasp wrench set over all directions and its computation together with force closure test can be fulfilled by evaluating the support function in a sequence of directions, we can quickly determine that a new grasp is worse whenever its support function in the sequence of directions or any other specific direction is less than the quality value of the current best grasp and avoid further computation. Furthermore, we enumerate candidate grasps in the point set in an adaptive way such that grasps that are more likely to outperform the current best grasp will be checked first, which helps find the best grasp earlier and significantly reduce the number of candidate grasps to be fully examined. With the aid of the adaptive enumeration and the quick comparison of grasps, the proposed algorithm takes tens of seconds to several hours on a normal PC to compute the best grasp in tens to hundreds of points on 3-D objects and it is two to several orders of magnitude faster than the brute-force search.
keywords: {Force;Planning;Force measurement;Grasping;Robots;Algorithm design and analysis;Search problems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989253&isnumber=7988677

Y. Liu, L. Jiang, S. Fan, D. Yang, J. Zhao and H. Liu, "A novel actuation configuration of robotic hand and the mechanical implementation via postural synergies," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2215-2222.
doi: 10.1109/ICRA.2017.7989254
Abstract: How to design a robotic hand for reproducing the move characteristics of human hand joints is a big challenge in robotics. In this paper, we present an approach to determine the actuation configuration based on the statistical results of hand joint angle in different grasps. A relationship between the basic statistical metrics and actuation configuration strategies is built. In this case, a novel actuation configuration is proposed and the joints of four fingers are arranged into five actuation modules. For the mechanical implementation, the motion of human four finger joints is decomposed to proportion motion, differential motion and chain proportion motion, mechanically implemented by pulley, planetary gear differential module and gear transmission chain. Finally, the implemented mechanism is embedded in palm, and the mechanical implementation to the human hand move characteristics is verified by the measured joint angles of the robotic hand when actuators separately move along PC1 and PC2. Meanwhile, the robotic hand can grasp different objects with a versatile grasp function.
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989254&isnumber=7988677

S. Liu et al., "Grasp quality evaluation and planning for objects with negative curvature," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2223-2229.
doi: 10.1109/ICRA.2017.7989255
Abstract: We consider the problem of grasping concave objects, i.e., objects whose surface includes regions with negative curvature. When a multifingered hand is used to restrain these objects, these areas can be advantageously used to determine grasps capable of more robustly resisting to external disturbance wrenches. We propose a new grasp quality metric specifically suited for this case, and we use it to inform a grasp planner searching the space of possible grasps. Our findings are validated both in simulation and on a real robot system executing a bin picking task. Experimental validation shows that our method is more effective than those not explicitly considering negative curvature.
keywords: {Measurement;Force;Friction;Grasping;Robots;Resists;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989255&isnumber=7988677

D. A. Klein, B. Illing, B. Gaspers, D. Schulz and A. B. Cremers, "Hierarchical salient object detection for assisted grasping," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2230-2237.
doi: 10.1109/ICRA.2017.7989256
Abstract: Visual scene decomposition into semantic entities is one of the major challenges when creating a reliable object grasping system. Recently, we introduced a bottom-up hierarchical clustering approach [1] which is able to segment objects and parts in a scene. In this paper, we introduce a transform from such a segmentation into a corresponding, hierarchical saliency function. In comprehensive experiments we demonstrate its ability to detect salient objects in a scene. Furthermore, this hierarchical saliency defines a most salient corresponding region (scale) for every point in an image. Based on this, an easy-to-use pick and place manipulation system was developed and tested exemplarily.
keywords: {Image segmentation;Grasping;Transforms;Visualization;Object detection;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989256&isnumber=7988677

D. Cockbum, J. -P. Roberge, T. -H. -L. Le, A. Maslyczyk and V. Duchaine, "Grasp stability assessment through unsupervised feature learning of tactile images," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2238-2244.
doi: 10.1109/ICRA.2017.7989257
Abstract: Grasping tasks have always been challenging for robots, despite recent innovations in vision-based algorithms and object-specific training. If robots are to match human abilities and learn to pick up never-before-seen objects, they must combine vision with tactile sensing. This paper present a novel way to improve robotic grasping: by using tactile sensors and an unsupervised feature-learning approach, a robot can find the common denominators behind successful and failed grasps, and use this knowledge to predict whether a grasp attempt will succeed or fail. This method is promising as it uses only high-level features from two tactile sensors to evaluate grasp quality, and works for the training set as well as for new objects. In total, using a total of 54 different objects, our system recognized grasp failure 83.70% of time.
keywords: {Dictionaries;Image reconstruction;Grasping;Tactile sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989257&isnumber=7988677

J. Xu, N. Alt, Z. Zhang and E. Steinbach, "Grasping posture estimation for a two-finger parallel gripper with soft material jaws using a curved contact area friction model," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2253-2260.
doi: 10.1109/ICRA.2017.7989258
Abstract: We present a friction model for the curved contact area between a deformable object and soft parallel gripper jaws for grasping posture estimation. We show that the assumption of a planar contact area leads to an overestimation of the frictional force and torque, which might cause the object to slip. We simulate the contact with the Finite Element Method, then compute the friction wrenches, which are fitted with two limit surface models: an ellipsoid and a convex 4th-order polynomial. Despite a slightly higher fitting error, the ellipsoid limit surface is chosen to compute the grasp quality because of its simplicity. We compare the limit surfaces of our friction model with the planar contact model and show the improved accuracy obtainable with our model. We then apply the presented model for grasping posture estimation by simulating the contact for all grasp candidates. We show a grasp quality map (quality of all grasp candidates) and the best possible grasp location for several deformable objects.
keywords: {Friction;Computational modeling;Grippers;Force;Torque;Grasping;Ellipsoids},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989258&isnumber=7988677

A. M. Pace and S. A. Burden, "Decoupled limbs yield differentiable trajectory outcomes through intermittent contact in locomotion and manipulation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2261-2266.
doi: 10.1109/ICRA.2017.7989259
Abstract: When limbs are decoupled, we find that trajectory outcomes in mechanical systems subject to unilateral constraints vary differentiably with respect to initial conditions, even as the contact mode sequence varies.
keywords: {Trajectory;Legged locomotion;Mechanical systems;Adaptation models;Mathematical model;Jacobian matrices;Time factors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989259&isnumber=7988677

S. Sheng et al., "Design of an SSVEP-based BCI system with visual servo module for a service robot to execute multiple tasks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2267-2272.
doi: 10.1109/ICRA.2017.7989260
Abstract: Brain-computer interface (BCI) systems can translate the human mind into control commands, which makes it feasible to improve the life quality of physically challenged people. However, in real-life situations, it is still difficult for users to utilize robots to provide basic services with BCI systems. We aimed to propose a BCI-based system with a visual servo module to operate a service robot. We recorded single-channel steady-state visual evoked potentials (SSVEP) as input signals for the BCI system of this study. The visual stimuli for inducing SSVEP were modulated at seven different frequencies with the sampled sinusoidal method. Correspondingly, this SSVEP-based BCI system can generate seven control commands for the operation of the service robot, which can provide three fundamental services: mobility, manipulation, and delivery. The visual servo module was established to reduce the burden of users and accelerate service procedures. To evaluate the performance of this system, subjects were recruited to participate in the experiments. All the participants succeed in operating the robot to provide the basic services. According to the experimental results, this SSVEP-based BCI system that incorporates the visual servo module can be effectively used to operate service robots with reduced number of channels and increased ability to perform multiple tasks.
keywords: {Visualization;Servomotors;Histograms;Service robots;Frequency modulation;Electrodes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989260&isnumber=7988677

Y. Iwashita, M. Kakeshita, H. Sakano and R. Kurazume, "Making gait recognition robust to speed changes using mutual subspace method," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2273-2278.
doi: 10.1109/ICRA.2017.7989261
Abstract: Mutual subspace method (MSM), which is one of image-based approaches, showed strong discrimination capability in gait recognition. In general, 2D image matrices are transformed into 1D image vectors to be used as input into MSM, and then principal component analysis (PCA) is applied to 1D vectors to generate a subspace. However, due to the high dimensionalities of 1D vectors, the evaluation accuracy of the covariance matrix in PCA is not high enough. This results in a decrease in performance, especially in case that speed difference between gallery and probe dataset is big. Thus in this paper we propose a method, which expands the MSM-based method, to recognize people with higher accuracy. The proposed method divides the human body area into multiple areas, followed by adaptive choice of areas that have high discrimination capability. Moreover, the proposed method utilizes the frieze pattern, which is one of gait features, as an additional input into MSM. The use of divided areas and the frieze pattern allows us to evaluate the covariance matrix with higher accuracy. In experiments we applied the proposed method to challenging databases with speed variations, and we show the effectiveness of the proposed method.
keywords: {Feature extraction;Gait recognition;Probes;Covariance matrices;Robustness;Principal component analysis;Databases},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989261&isnumber=7988677

R. Weitschat, J. Vogel, S. Lantermann and H. Höppner, "End-effector airbags to accelerate human-robot collaboration," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2279-2284.
doi: 10.1109/ICRA.2017.7989262
Abstract: A fundamental problem in human-robot collaboration is to ensure safety for humans being located in the workspace of the robot. Several new robots, referred to as collaborative robots, are pushing into the market. Most of these so-called co-bots have similar properties. They are small, lightweight and designed with big roundings to ensure safety in the case of a collision with a human. Equipped with torque sensors, external torque observers, tactile skins, etc., they are able to stop the robot when an emergency occurs. While developing more and more co-bots, the main focus lies on the robot itself. But to make a robot deployable, a special tool for a defined task is needed. These tools are often sharp-edged and dangerous in case of a collision with a human. In this paper we present a new safety module for robots to ensure safety for different tools in collaborative tasks. This module, filled with air pressure during the robot motion, covers mounted tools and carried workpieces. In case of a non or very slow moving robot, the safety module is able to pull back and the tool is uncovered. In our experiments we found out that we can increase the velocity up to 1 m/s while satisfying the requirements of the ISO/TS 15066 and retain the full functionality of the tool.
keywords: {Robot sensing systems;Tools;Safety;Collision avoidance;Service robots;Collaboration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989262&isnumber=7988677

L. Milliken and G. A. Hollinger, "Modeling user expertise for choosing levels of shared autonomy," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2285-2291.
doi: 10.1109/ICRA.2017.7989263
Abstract: In shared autonomy, a robot and human user both have some level of control in order to achieve a shared goal. Choosing the balance of control given to the user and the robot can be a challenging problem since different users have different preferences and vary in skill levels when operating a robot. We propose using a novel formulation of Partially Observable Markov Decision Process (POMDP) to represent a model of the user's expertise in controlling the robot. The POMDP uses observations from the user's actions and from the environment to update the belief of the user's skill and chooses a level of control between the robot and the user. The level of control given between the user and the robot is encapsulated in macro-action controllers. A user study was run to test the performance of our formulation. Users drive a simulated robot through an obstacle-filled map while the POMDP model chooses appropriate macro-action controllers based on the belief state of the user's skill level. The results of the user study show that our model can encapsulate user skill. The results also show that using the controller with greater robot autonomy helped users of low skill avoid obstacles more than it helped users of high skill.
keywords: {Adaptation models;Markov processes;Predictive models;Collaboration;Conferences;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989263&isnumber=7988677

M. Angerer, S. Musić and S. Hirche, "Port-Hamiltonian based control for human-robot team interaction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2292-2299.
doi: 10.1109/ICRA.2017.7989264
Abstract: In this paper we consider the problem in which the human commands the overall behavior of a robot team while the robots are controlled to comply with formation constraints. Such human-robot team interaction is challenging in terms of system complexity and control synthesis. Port-Hamiltonian framework is suitable for modeling the interconnected systems. In this paper we model the robotic team, cooperatively manipulating an object, as a constrained port-Hamiltonian system. Furthermore, we propose a passivity-based control approach in the port-Hamiltonian framework for the cooperative manipulation system guided by the human. The control mechanism is based on the energy shaping for achieving a desired behavior of the formation and its preservation. An energy tank in the cascade is introduced to guarantee passivity of the system commanded by the human and safe interaction with humans in the robot environment. We validate the proposed approach with simulation and experiments.
keywords: {Robot kinematics;Springs;Manipulators;Collision avoidance;Safety;Shock absorbers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989264&isnumber=7988677

P. A. Lasota and J. A. Shah, "A multiple-predictor approach to human motion prediction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2300-2307.
doi: 10.1109/ICRA.2017.7989265
Abstract: The ability to accurately predict human motion is imperative for any human-robot interaction application in which the human and robot interact in close proximity to one another. Although a variety of human motion prediction approaches have already been developed, they are often designed for specific types of tasks or motions, and thus do not generalize well. Furthermore, it is not always obvious which of these methods is appropriate for a given task, making human motion prediction difficult to implement in practice. We address this problem by introducing a multiple-predictor system (MPS) for human motion prediction. In our approach, the system learns directly from task data in order to determine the most favorable parameters for each implemented prediction method and which combination of these predictors to use. Our implementation consists of three complementary methods: velocity-based position projection, time series classification, and sequence prediction. We describe the process of forming the MPS and our evaluation of its performance against the individual methods in terms of accuracy of predictions of human position over a range of look-ahead time values. We report that our method leads to a reduction in mean error of 18.5%, 28.9%, and 37.3% when compared with the three individual methods, respectively.
keywords: {Time series analysis;Hidden Markov models;Trajectory;Legged locomotion;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989265&isnumber=7988677

H. W. Park, M. Gelsomini, J. J. Lee, T. Zhu and C. Breazeal, "Backchannel opportunity prediction for social robot listeners," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2308-2314.
doi: 10.1109/ICRA.2017.7989266
Abstract: This paper investigates how a robot that can produce contingent listener response, i.e., backchannel, can deeply engage children as a storyteller. We propose a backchannel opportunity prediction (BOP) model trained from a dataset of children's dyad storytelling and listening activities. Using this dataset, we gain better understanding of what speaker cues children can decode to find backchannel timing, and what type of nonverbal behaviors they produce to indicate engagement status as a listener. Applying our BOP model, we conducted two studies, within- and between-subjects, using our social robot platform, Tega. Behavioral and self-reported analyses from the two studies consistently suggest that children are more engaged with a contingent backchanneling robot listener. Children perceived the contingent robot as more attentive and more interested in their story compared to a non-contingent robot. We find that children significantly gaze more at the contingent robot while storytelling and speak more with higher energy to a contingent robot.
keywords: {Feature extraction;Robot sensing systems;Speech;Predictive models;Timing;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989266&isnumber=7988677

D. Hughes, A. Krauthammer and N. Correll, "Recognizing social touch gestures using recurrent and convolutional neural networks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2315-2321.
doi: 10.1109/ICRA.2017.7989267
Abstract: Deep learning approaches have been used to perform classification in several applications with high-dimensional input data. In this paper, we investigate the potential for deep learning for classifying affective touch on robotic skin in a social setting. Three models are considered, a convolutional neural network, a convolutional-recurrent neural network and an autoencoder-recurrent neural network. These models are evaluated on two publicly available affective touch datasets, and compared with models built to classify the same datasets. The deep learning approaches provide a similar level of accuracy, and allows gestures to be predicted in real-time at a rate of 6 to 9 Hertz. The memory requirements of the models demonstrate that they can be implemented on small, inexpensive microcontrollers, demonstrating that classification can be performed in the skin itself by collocating computing elements with the sensor array.
keywords: {Robot sensing systems;Training;Feature extraction;Hidden Markov models;Kernel;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989267&isnumber=7988677

M. P. Polverini, S. Formentin, L. A. Dao and P. Rocco, "Data-driven design of implicit force control for industrial robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2322-2327.
doi: 10.1109/ICRA.2017.7989268
Abstract: Standard control design for robot implicit force control is a typical example of model-based regulator synthesis. This paper proposes a method to improve closed-loop performance of standard model-based controllers for robot implicit force control in terms of closed-loop model matching, between desired and achieved closed-loop behaviour. To this end, a data-driven controller design method, based on the Virtual Reference Feedback Tuning (VRFT) approach, is introduced. Advantages in terms of robustness with respect to unknown environment stiffness are discussed and demonstrated. The effectiveness of the proposed control strategy is experimentally validated on an industrial robot equipped with a force sensor.
keywords: {Force control;Service robots;Robot kinematics;Transfer functions;Standards;Tuning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989268&isnumber=7988677

H. Kim, H. Lee, S. Choi, Y. -k. Noh and H. J. Kim, "Motion planning with movement primitives for cooperative aerial transportation in obstacle environment," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2328-2334.
doi: 10.1109/ICRA.2017.7989269
Abstract: This paper presents a motion planning approach for cooperative transportation using aerial robots. We describe a framework based on Parametric Dynamic Movement Primitives (PDMPs) for coordinating multiple aerial robots and their manipulators quickly in an environment cluttered with obstacles. In order to emulate the optimal motion, we combine PDMPs and Rapidly Exploring Randomized Trees star (RRT*) by using the results of RRT* as demonstrations for PDMPs. For efficient description of the motions corresponding to the environment, we utilize Gaussian Process Regression (GPR) to acquire of the explicit relationship between environmental parameters and style parameters of PDMPs which decide the motions. Simulation and experiment results are attached to validate the proposed framework.
keywords: {Manipulator dynamics;Planning;Dynamics;Trajectory;Grasping;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989269&isnumber=7988677

R. Sakashita and M. Higashimori, "1-Actuator 3-DoF parts feeding using hybrid joint mechanism with twisted axis layout," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2335-2342.
doi: 10.1109/ICRA.2017.7989270
Abstract: This paper proposes a nonprehensile manipulation scheme using the vibration of a plate, where a 3-DoF (degree of freedom) motion of a part is controlled using a single actuator. A manipulator is introduced, the end effector of which is a flat plate. The manipulator employs a hybrid joint mechanism with a twisted axis layout. The characteristic of this mechanism is that the shape of the trajectory of the plate can be varied three dimensionally based on the sinusoidal displacement input to the actuator. The behaviors of multiple point masses on the plate are then analyzed to understand the approximated 3-DoF motion of a part. The results of the simulation reveal that the whirlpool-like characteristics of the trajectory map, which aids in the rotational and translational motions of the part, can be governed. Based on the characteristics, five primitives for manipulating the part are defined and their arrangements for a 3-DoF parts feeding task are shown. Finally, the proposed approach is demonstrated via experiments.
keywords: {Trajectory;Actuators;Manipulator dynamics;Layout;End effectors;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989270&isnumber=7988677

M. Sheckells, G. Garimella and M. Kobilarov, "Robust policy search with applications to safe vehicle navigation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2343-2349.
doi: 10.1109/ICRA.2017.7989271
Abstract: This work studies the design of reliable control laws of robotic systems operating in uncertain environments. We introduce a new approach to stochastic policy optimization based on probably approximately correct (PAC) bounds on the expected performance of control policies. An algorithm is constructed which directly minimizes an upper confidence bound on the expected cost of trajectories instead of employing a standard approach based on the expected cost itself. This algorithm thus has built-in robustness to uncertainty, since the bound can be regarded as a certificate for guaranteed future performance. The approach is evaluated on two challenging robot control scenarios in simulation: a car with side slip and a quadrotor navigating through obstacle-ridden environments. We show that the bound accurately predicts future performance and results in improved robustness measured by lower average cost and lower probability of collision. The performance of the technique is studied empirically and compared to several existing policy search algorithms.
keywords: {Stochastic processes;Optimization;Robustness;Robots;Approximation algorithms;Picture archiving and communication systems;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989271&isnumber=7988677

F. Furrer et al., "Autonomous robotic stone stacking with online next best object target pose planning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2350-2356.
doi: 10.1109/ICRA.2017.7989272
Abstract: Predominately, robotic construction is applied as prefabrication in structured indoor environments with standard building materials. Our work, on the other hand, focuses on utilizing irregular materials found on-site, such as rubble and rocks, for autonomous construction. We present a pipeline that detects randomly placed objects in a scene that are used by our next best stacking pose searching method employing gradient descent with a random initial orientation, exploiting a physics engine. This approach is validated in an experimental setup using a robotic manipulator by constructing balancing vertical stacks without mortars and adhesives. We show the results of eleven consecutive trials to form such towers autonomously using four arbitrarily in front of the robot placed rocks.
keywords: {Robots;Physics;Search problems;Three-dimensional displays;Transforms;Stacking;Engines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989272&isnumber=7988677

W. Chi et al., "A learning based training and skill assessment platform with haptic guidance for endovascular catheterization," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2357-2363.
doi: 10.1109/ICRA.2017.7989273
Abstract: Increasing demands in endovascular intervention have motivated technical skill training and competency-based measures of performance. However, there are no well-established online metrics for technical skill assessment; few studies have explored operator behavioral patterns from catheter motion and operator hand motions. This paper proposes a platform for active online training and objective assessment of endovascular skills, through learning optimum catheter motions from multiple demonstrations. An ungrounded hand-held haptic device for providing intuitive haptic guidance to novice users based on this learnt information is also proposed. Statistical models are implemented to extract the underlying catheter motion patterns, and utilize them for performance evaluation and haptic guidance. The results show significant improvements in endovascular navigation for inexperienced operators. Finer catheter motions were achieved with the provided haptic guidance. The results suggest that the proposed platform can be integrated into current clinical training setups, and motivate the improvement of endovascular training platforms with better realism.
keywords: {Haptic interfaces;Hidden Markov models;Catheters;Training;Solid modeling;Catheterization;Measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989273&isnumber=7988677

J. Rosen et al., "Roboscope: A flexible and bendable surgical robot for single portal Minimally Invasive Surgery," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2364-2370.
doi: 10.1109/ICRA.2017.7989274
Abstract: Minimally Invasive Surgery (MIS) can reduce iatrogenic injury and decrease the possibility of surgical complications. This paper presents a novel flexible and bendable endoscopic device, “Roboscope”, which delivers two instruments, two miniature scanning fiber endoscopes, and a suction/irrigation port to the operation site through a single portal. Compared with existing bendable and steerable robotic surgical systems, Roboscope provides two bending degrees of freedom for its outer sheath and two insertion degrees of freedom, while simultaneously delivering two instruments and two endoscopes to the surgical site. Each bending axis and insertion freedom of Roboscope is independently controllable via an external actuation pack. Surgical tools can be changed without retracting the robot arm. This paper presents the design of the Roboscope mechanical system, electrical system, and control and software systems, design requirements and prototyping validation as well as analysis of Roboscope workspece.
keywords: {Instruments;Tools;Surgery;Endoscopes;Medical robotics;Prototypes;Surgical Robot;Flexible and Bendable Robot;System Design;Skullbase and Sinus Surgery;NeuroSurgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989274&isnumber=7988677

B. Thananjeyan, A. Garg, S. Krishnan, C. Chen, L. Miller and K. Goldberg, "Multilateral surgical pattern cutting in 2D orthotropic gauze with deep reinforcement learning policies for tensioning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2371-2378.
doi: 10.1109/ICRA.2017.7989275
Abstract: In the Fundamentals of Laparoscopic Surgery (FLS) standard medical training regimen, the Pattern Cutting task requires residents to demonstrate proficiency by maneuvering two tools, surgical scissors and tissue gripper, to accurately cut a circular pattern on surgical gauze suspended at the corners. Accuracy of cutting depends on tensioning, wherein the gripper pinches a point on the gauze in R3 and pulls to induce and maintain tension in the material as cutting proceeds. An automated tensioning policy maps the current state of the gauze to output a direction of pulling as an action. The optimal tensioning policy depends on both the choice of pinch point and cutting trajectory. We explore the problem of learning a tensioning policy conditioned on specific cutting trajectories. Every timestep, we allow the gripper to react to the deformation of the gauze and progress of the cutting trajectory with a translation unit vector along an allowable set of directions. As deformation is difficult to analytically model and explicitly observe, we leverage deep reinforcement learning with direct policy search methods to learn tensioning policies using a finite-element simulator and then transfer them to a physical system. We compare the Deep RL tensioning policies with fixed and analytic (opposing the error vector with a fixed pinch point) policies on a set of 17 open and closed curved contours in simulation and 4 patterns in physical experiments with the da Vinci Research Kit (dVRK). Our simulation results suggest that learning to tension with Deep RL can significantly improve performance and robustness to noise and external forces.
keywords: {Trajectory;Robots;Training;Learning (artificial intelligence);Minimally invasive surgery;Tools;Deformable models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989275&isnumber=7988677

P. Wisanuvej, P. Giataganas, K. Leibrandt, J. Liu, M. Hughes and G. -Z. Yang, "Three-dimensional robotic-assisted endomicroscopy with a force adaptive robotic arm," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2379-2384.
doi: 10.1109/ICRA.2017.7989276
Abstract: Effective in situ, in vivo tumour margin assessment is an important, yet unmet, clinical demand in surgical oncology. Recent advances in probe-based optical imaging tools such as confocal endomicroscopy is making inroads in clinical applications. In practice, maintaining consistent tissue contact whilst ensuring large area surveillance is crucial for its practical adoption and for this reason there is a great demand for robotic assistance so that high-speed endomicroscopes can be combined with autonomous scanning, thus simplifying its incorporation in routine surgical workflows. In this paper, a cooperatively controlled robotic manipulator is developed, which provides a stable mechatronically-enhanced platform for micro-scanning tools to perform local high resolution mosaics over 3D undulating moving surfaces. Detailed kinematic and overall system performance analyses are provided and the results demonstrate the adaptability in terms of both contact force and orientation control of the system, and thus its simplicity in practical deployment and value for clinical adoption.
keywords: {Probes;Force;Tools;Robot sensing systems;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989276&isnumber=7988677

S. Kim, N. Gandhi, M. A. Lediju Bell and P. Kazanzides, "Improving the safety of telerobotic drilling of the skull base via photoacoustic sensing of the carotid arteries," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2385-2390.
doi: 10.1109/ICRA.2017.7989277
Abstract: One of the risks of the endonasal approach to skull base surgery is inadvertent damage to one of the two carotid arteries that are located behind the bone being drilled. Photoacoustic imaging, which combines a pulsed laser with an ultrasound receiver probe, has been shown to be able to image blood vessels behind bone. We therefore integrated a photoacoustic imaging system with a telerobotic system, where the pulsed laser is delivered via an optical fiber attached to the drill held by one robot arm and the ultrasound receiver is positioned, at some distance from the drilling site, by another robot arm. This paper describes a new method for accurately determining the safe region for drilling, which is defined by the center-line between the two carotid arteries, and presents the first phantom experiments with this system. The results show that the system can determine the center point with an accuracy better than 2 mm, which suggests that it may be sufficient for clinical scenarios where the two carotid arteries can be within 8 mm of each other.
keywords: {Carotid arteries;Photoacoustic imaging;Surgery;Ultrasonic imaging;Telerobotics;Instruments},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989277&isnumber=7988677

S. A. Pedram, P. Ferguson, J. Ma, E. Dutson and J. Rosen, "Autonomous suturing via surgical robot: An algorithm for optimal selection of needle diameter, shape, and path," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2391-2398.
doi: 10.1109/ICRA.2017.7989278
Abstract: In autonomous suturing with a surgical robot, needle shape, diameter, and path are critical parameters that directly affect suture depth and tissue trauma. This paper presents an optimization-based approach to specify these parameters. Given clinical suturing guidelines, a kinematic model of needle-tissue interaction was developed to quantify suture parameters and constraints. The model was further used to formulate constant curvature needle path planning as a nonlinear optimization problem. The inputs of the optimization include the tissue geometry, surgeon defined entry/exit points, and optimization weighting factors. The outputs are the needle geometry and suggested path. Off-line simulations were used to evaluate the accuracy and performance of the proposed model, and to determine optimized needle geometry and path for several clinically relevant input sets. The output and the optimization results were confirmed experimentally with the Raven II surgical system. The proposed needle path planning algorithm guarantees minimal tissue trauma and complies with a wide range of suturing requirements.
keywords: {Needles;Surgery;Kinematics;Path planning;Geometry;Shape;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989278&isnumber=7988677

J. Sganga and D. Camarillo, "Orientation estimation of a continuum manipulator in a phantom lung," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2399-2405.
doi: 10.1109/ICRA.2017.7989279
Abstract: Tendon-driven continuum manipulators are widely used in minimally invasive surgeries, yet autonomous control has proven difficult given the uncertainty in modeling the robot's interaction with the anatomy. In this paper, we test the hypothesis that the anatomy's effect on the robotic manipulator can be approximated as a rotation of the model-based Jacobian. Two methods are described that estimate the orientation using a magnetic position sensor at the robot's distal tip, enabling task-space control in unknown, constrained environments. One method, Rα, determines the orientation of the robot's model using the measured orientation of the distal tip. In the second approach, RΔx, an unscented Kalman filter transforms the tip's measured change in position into an orientation estimate. These methods are validated on the manipulator in free space at three pre-rotated positions (α = 0°, -45°, -90°) and compared to model-based control and model-less control in an autonomous trajectory-following task through an anatomically accurate silicone phantom of a human lung. The results show that by rotating the model-based Jacobian through either of the two methods presented, feedback control successfully navigates the continuum manipulator farther into the lung phantom than static model-based control and model-less control.
keywords: {Robot sensing systems;Manipulators;Estimation;Jacobian matrices;Lungs;Position measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989279&isnumber=7988677

P. Wang, J. Yi, T. Liu and Y. Zhang, "Trajectory tracking and balance control of an autonomous bikebot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2414-2419.
doi: 10.1109/ICRA.2017.7989280
Abstract: We present trajectory tracking and balance control of an autonomous bikebot. The bikebot is a single-track autonomous mobile robot that is designed to study unstable physical human-robot interactions. The controller is built on the property of the external-internal convertible (EIC) structure for the bikebot dynamics. We present two types of the designs and analyses of the control systems and also demonstrate their performance through extensive experiments. The comparison results with the human riding experiments show that the rider's motor skills generate the similar strategies as the proposed EIC-based balance control.
keywords: {Wheels;Trajectory tracking;Bicycles;Trajectory;Control design;Human-robot interaction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989280&isnumber=7988677

A. Bouton, C. Grand and F. Benamar, "Obstacle negotiation learning for a compliant wheel-on-leg robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2420-2425.
doi: 10.1109/ICRA.2017.7989281
Abstract: Generic control of wheel-on-leg robots on arbitrary uneven terrains is a challenging task due to the complexity of the robot dynamics, surface interactions, and environmental structures. This paper deals with the control of a wheel-on-leg robot with passive and active internal compliance that enables estimation of wheel-ground interaction forces. The proposed method is based on a continuous state space Q-learning approach that uses the contact forces estimates to learn, through trial and error, the appropriate control policy from a set of predefined behaviors. Without any prior knowledge of the ground geometry, the robot is able to react to unanticipated obstacles. The learned policy proves to be generic and allows the robot to negotiate complex obstacles that had not been considered during learning phase.
keywords: {Wheels;Legged locomotion;Torque;Geometry;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989281&isnumber=7988677

M. Andreetto, S. Divan, D. Fontanelli and L. Palopoli, "Harnessing steering singularities in passive path following for robotic walkers," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2426-2432.
doi: 10.1109/ICRA.2017.7989282
Abstract: Assistive passive robotic walkers are naturally modelled as rear-driven bicycle with control on the front steering wheels. Standard path following algorithms used for unicycle-like robots can then be readily available, e.g. using backstepping techniques, to control the walker on desired paths. However, such an approach is usually singular in the very common situation of zero velocity, e.g. whenever the vehicle starts its motion or the user stops for any reason. The paper proposes a non-singular passive path following algorithm for an assistive robotic walker equipped with front steering wheels. The control law avoids the singularities, since it is velocity-independent, and allows the designer to specify saturation limits on the steering angles. The converging properties of the non-singular velocity-independent controller in the presence of saturation constraints are firstly formally proved and tested in simulations. Then extensive experiments performed on 14 testers are presented. These tests underline the promising performance of the proposed controller and the importance of singularities-avoidance in real-world scenarios to increase human comfort along the planned trajectory.
keywords: {Legged locomotion;Wheels;Vehicle dynamics;Angular velocity;Bicycles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989282&isnumber=7988677

V. Pitkänen, A. Tikanmäki, A. Kemppainen and J. Röning, "Path following controller for planar robots with articulated, actuated and independently steerable velocity-limited wheels," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2433-2440.
doi: 10.1109/ICRA.2017.7989283
Abstract: Pseudo-omnidirectional robots with individually steerable wheels ofïer a good balance between mobility, robustness and load-carrying capacity. However, accurate synchronization of the wheels' steering and rolling speeds is necessary to prevent energy-loss, mechanical stress and wheel slippage due to actuator infighting. This has proven to be a complex problem, especially when the wheels are not fixed to the robot body but are instead connected to it via actuated chains. This paper presents a mathematically simple method consisting of closed-form equations for path following and synchronizing the steering and rolling speeds of planar robots with a variable or fixed footprint, while respecting the velocity limits of each wheel's steering and rolling actuators. The presented method is thoroughly explained and simulation results are presented to show its performance.
keywords: {Wheels;Mobile robots;Robot kinematics;Mathematical model;Actuators;Silicon},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989283&isnumber=7988677

E. Dean-Leon et al., "TOMM: Tactile omnidirectional mobile manipulator," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2441-2447.
doi: 10.1109/ICRA.2017.7989284
Abstract: In this paper, we present the mechatronic design of our Tactile Omnidirectional Robot Manipulator (TOMM), which is a dual arm wheeled humanoid robot with 6DoF on each arm, 4 omnidirectional wheels and 2 switchable end-effectors (1 DoF grippers and 12 DoF Hands). The main feature of TOMM is its arms and hands which are covered with robot skin. We exploit the multi-modal tactile information of our robot skin to provide a rich tactile interaction system for robots. In particular, for the robot TOMM, we provide a general control framework, capable of modifying the dynamic behavior of the entire robot, e.g., producing compliance in a non-compliant system. We present the hardware, software and middleware components of the robot and provide a compendium of the base technologies deployed in it. Furthermore, we show some applications and results that we have obtained using this robot.
keywords: {Mobile robots;Service robots;Manipulators;Skin;Robot sensing systems;Mobile communication},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989284&isnumber=7988677

J. T. Costa and M. Yim, "Designing for uniform mobility using holonomicity," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2448-2453.
doi: 10.1109/ICRA.2017.7989285
Abstract: Holonomic systems are often complex and expensive with poor terrain handling capabilities. This paper introduces HAMR, a platform that is simple and low-cost with good terrain handling capabilities which was designed using a new method for characterizing mobility. A mobility ellipsoid (analogous to a manipulability ellipsoid) is introduced as a design tool. A metric called holonomicity measures the extent to which a vehicle can move equally in all directions. The holonomicity of HAMR is measured experimentally. It is shown that non-holonomic vehicles can have relatively high holonomicity as well.
keywords: {Wheels;Mobile robots;Ellipsoids;Measurement;Mobile communication;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989285&isnumber=7988677

F. Fleckenstein, C. Dornhege and W. Burgard, "Efficient path planning for mobile robots with adjustable wheel positions," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2454-2460.
doi: 10.1109/ICRA.2017.7989286
Abstract: Efficient navigation planning for mobile robots in complex environments is a challenging problem. In this paper we consider the path planning problem for mobile robots with adjustable relative wheel positions, which further increase the navigation capabilities. In particular we account for changes of these relative wheel positions during planning time, thus fully leveraging the capabilities of the robot. Whereas these additional degrees of freedom increase flexibility, they introduce a more challenging planning problem. The approach proposed in this paper is built upon a search-based planner. We describe how to flexibly integrate joint angle changes in the path planning process and furthermore propose a representation of the robot configuration that substantially reduces the computational burden. In addition, we introduce search guidance heuristics that are particularly useful in environments in which a robot is required to pass over obstacles, such as on agricultural fields. An extensive evaluation on simulated and real-world data with our BoniRob agricultural robot demonstrates the efficiency of our approach.
keywords: {Mobile robots;Planning;Wheels;Robot kinematics;Collision avoidance;Lattices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989286&isnumber=7988677

K. Lee, J. Oh, O. Sim, H. Bae and J. Oh, "Inverse kinematics with strict nonholonomic constraints on mobile manipulator," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2469-2474.
doi: 10.1109/ICRA.2017.7989287
Abstract: The unified approach algorithm to control a mobile robot is useful in simplifying path planning and inverse kinematics by considering a mobile platform as hypothetical joints. Applying the damped least square method by using the Jacobian prevents the divergence of the joint angle. However, it is possible to violate the nonholonomic constraint on mobility by distorting the Jacobian. In robot manipulation, the end-effector position error due to a violation of the constraint can be fatal, because such an error can damage a nearby object or the robot itself. In this paper, we propose a method that strictly guarantees nonholonomic constraints on a mobile manipulator. We also propose a compensation technique for faster convergence of the position and orientation of the end effector. The effectiveness of the proposed methods was confirmed through simulations.
keywords: {Mobile communication;Jacobian matrices;Kinematics;End effectors;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989287&isnumber=7988677

L. Žlajpah, "On orientation control of functional redundant robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2475-2482.
doi: 10.1109/ICRA.2017.7989288
Abstract: There are tasks that do not require a controlled motion in all spatial directions. These unused degrees-of-freedom (DOF) make the robot functionally redundant. Traditional methods for redundancy resolution developed for intrinsic redundant robots cannot be used directly for resolving functional redundancy. The functional redundancy is in general not reflected as rows in the Jacobian matrix and therefore, the unused DOFs cannot be mapped into the null-space. In the paper we present a novel approach for the orientation related functional redundancy resolution based on the task space rotation. We define a time-variant task space frame so that one or more frame axes are aligned with the unused directions. This allows that the rows of Jacobian matrix corresponding to functional redundant DOFs are excluded. As the standard quaternion control is not appropriate to control orientation of such functional redundant robots, we propose two control algorithms to control one or two orientation directions. Two examples then show how the proposed control algorithms can be implemented and finally, we present the application of the algorithm on a two-arm robot system.
keywords: {Redundancy;Aerospace electronics;Jacobian matrices;Robot kinematics;Kinematics;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989288&isnumber=7988677

A. Müller, "Recursive second-order inverse dynamics for serial manipulators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2483-2489.
doi: 10.1109/ICRA.2017.7989289
Abstract: Various model-based control schemes, e.g. feedback-linearizing control of robotic manipulators with series elastic actuators require time derivatives of the control forces, i.e. of the equations of motion. This is referred to as the higher-order inverse dynamics problem. As this must be evaluated on the controller hardware, computationally efficient formulations are crucial. While recursive O (n) inverse dynamics algorithms are well-established, such for the higherorder inverse dynamics are relatively new. O (n) algorithms for the latter problem were published recently building upon the known recursive inverse dynamics algorithms in terms of Denavit-Hartenber (DH) parameters. The DH convention is restrictive, however. Also the higher-order formulations are naturally very complex. Both issues are addresses in this paper with concepts from screw and Lie group theory. An O (n) algorithm for determining the first and second time derivative of the inverse dynamics solution is presented. The Lie group approach provides a high level of compactness while ensuring the computational efficiency. Being frame invariant this formulation allows for using representations in different frame. Two formulations are presented, one using the body-fixed and the other the so-called hybrid representation of twists. The latter is deemed to be computationally more efficient that the classical body-fixed version. Results are shown for a 6-DOF industrial manipulator.
keywords: {Heuristic algorithms;Fasteners;Manipulator dynamics;Kinematics;Dynamics;Inverse dynamics;series-elastic actuators;feedback linearization;serial manipulator;O(n) methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989289&isnumber=7988677

Y. S. Krieger, D. B. Roppenecker, I. Kuru and T. C. Lueth, "Multi-arm snake-like robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2490-2495.
doi: 10.1109/ICRA.2017.7989290
Abstract: Since the minimally invasive surgery has significant benefits for the patient, special equipment and techniques are constantly enhanced in this relatively new surgical field, so that more challenging surgical applications can be achieved. Thereby, the major aim is to enable the surgeon to manipulate instruments inside the human body intuitively, despite restricted access to the operating field and limited workspace. With our spine like overtube system for use with standard endoscopes and standard endoscopic instruments, we provide a system facilitating tissue manipulation with sufficient triangulation. In this paper we describe our 3D-printed manipulator system for minimally invasive applications and its pure mechanical control and actuation concepts. Following our aim of an individualized disposable system, in a first step we demonstrate the feasibility of a 3D-printed surgical robotic system by laboratory experiments and a clinical evaluation on a porcine model.
keywords: {Manipulators;Instruments;Wires;Standards;Endoscopes;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989290&isnumber=7988677

R. Wakatabe, Y. Kuniyoshi and G. Cheng, "O (logn) algorithm for forward kinematics under asynchronous sensory input," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2502-2507.
doi: 10.1109/ICRA.2017.7989291
Abstract: This paper presents a new algorithm for forward kinematics, called Asynchronous Forward Kinematics (AFK). The algorithm has the complexity of O(log n) for updating one joint angle, and O(logn) for obtaining a homogeneous transformation matrix between links. AFK enables computation for efficient forward kinematics under asynchronous sensory data. Moreover, AFK peovides localise computational resources at sensitive joints to the position of the endpoint (e.g. a fingertip), like a root joint. We provide comparative results including computation time, evaluating AFK against the conventional forward kinematics (CFK). The results showed that the computation time is well adequate for real-time computation. Computation time for 100 links takes less than 20 us for 1 query. Moreover, computation time with over 50000 links takes less than 35 us for 1 query.
keywords: {Kinematics;Robot kinematics;Heuristic algorithms;Time complexity;Tactile sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989291&isnumber=7988677

R. Takano, H. Mochiyama and N. Takesue, "Real-time shape estimation of Kirchhoff elastic rod based on force/torque sensor," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2508-2515.
doi: 10.1109/ICRA.2017.7989292
Abstract: In this paper, we propose a real-time spatial shape estimation method for an elastic rod. Our proposed method does not use any image sensor nor shape sensor, but does use a six-axis force/torque sensor placed near one end of the elastic rod. In the proposed shape estimation method, the occlusion problem never occurs principally because the shape of a flexible object will be estimated based on an elastic rod model. We utilize the discretized Kirchhoff elastic rod for shape estimation, which can be viewed as a serial chain of rigid bodies connected with three-degree-of-freedom rotational spring joints. We show that real-time spatial shape estimation is possible based on real-time sensing of force/torque information. The computational time of the proposed shape estimation algorithm is linear in the number of rigid-body partition. Moreover, the required calculations are very simple owing to deep understanding of robot manipulator kinematics. Thus we can compute the spatial rod shape in realtime. We show experimental results in order to validate our proposed method.
keywords: {Shape;Estimation;Robot sensing systems;Real-time systems;Mathematical model;Springs},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989292&isnumber=7988677

C. S. Weerasekera, Y. Latif, R. Garg and I. Reid, "Dense monocular reconstruction using surface normals," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2524-2531.
doi: 10.1109/ICRA.2017.7989293
Abstract: This paper presents an efficient framework for dense 3D scene reconstruction using input from a moving monocular camera. Visual SLAM (Simultaneous Localisation and Mapping) approaches based solely on geometric methods have proven to be quite capable of accurately tracking the pose of a moving camera and simultaneously building a map of the environment in real-time. However, most of them suffer from the 3D map being too sparse for practical use. The missing points in the generated map correspond mainly to areas lacking texture in the input images, and dense mapping systems often rely on hand-crafted priors like piecewise-planarity or piecewise-smooth depth. These priors do not always provide the required level of scene understanding to accurately fill the map. On the other hand, Convolutional Neural Networks (CNNs) have had great success in extracting high-level information from images and regressing pixel-wise surface normals, semantics, and even depth. In this work we leverage this high-level scene context learned by a deep CNN in the form of a surface normal prior. We show, in particular, that using the surface normal prior leads to better reconstructions than the weaker smoothness prior.
keywords: {Surface reconstruction;Cameras;Image reconstruction;Three-dimensional displays;Neural networks;Simultaneous localization and mapping;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989293&isnumber=7988677

R. Senanayake, S. O'Callaghan and F. Ramos, "Learning highly dynamic environments with stochastic variational inference," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2532-2539.
doi: 10.1109/ICRA.2017.7989294
Abstract: Understanding the dynamics of urban environments is crucial for path planning and safe navigation. However, the dynamics might be extremely complex making learning the environment an unfathomable task. Within the methods available for learning dynamic environments, dynamic Gaussian process occupancy maps (DGPOM) are very attractive because they can produce spatially-continuous occupancy maps taking into account neighborhood information, and provide probabilistic estimates, naturally inferring the uncertainty of predictions. Despite these properties, they are extremely slow, especially in dynamic mapping where the parameters of the map have to be updated as new data arrive from range sensors such as LiDARs. In this work, we leverage recent advancements in stochastic variational inference (SVI) to quickly learn dynamic areas in an online fashion. Further, we propose an information-driven technique to “intelligently” select inducing points required for SVI without relying on any object trackers which essentially improves computational time as well as robustness. These long-term occupancy maps entertain all attractive properties of DGPOM while the learning process is significantly faster, yet accurate. Our experiments with both simulation and real robot data on road intersections show a significant improvement in speed while maintaining a comparable or better accuracy.
keywords: {Vehicle dynamics;Gaussian processes;Data models;Robots;Roads;Computational modeling;Hidden Markov models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989294&isnumber=7988677

S. Zhang, W. Xie, G. Zhang, H. Bao and M. Kaess, "Robust stereo matching with surface normal prediction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2540-2547.
doi: 10.1109/ICRA.2017.7989295
Abstract: Traditional stereo matching approaches generally have problems in handling textureless regions, strong occlusions and reflective regions that do not satisfy a Lambertian surface assumption. In this paper, we propose to combine the predicted surface normal by deep learning to overcome these inherent difficulties in stereo matching. With the selected reliable disparities from stereo matching method and effective edge fusion strategy, we can faithfully convert the predicted surface normal map to a disparity map by solving a least squares system which maintains discontinuity on object boundaries and continuity on other regions. Then we refine the disparity map iteratively by bilateral filtering-based completion and edge feature refinement. Experimental results on the Middlebury dataset and our own captured stereo sequences demonstrate the effectiveness of the proposed approach.
keywords: {Image segmentation;Image edge detection;Three-dimensional displays;Estimation;Robustness;Machine learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989295&isnumber=7988677

K. Ma et al., "Robot mapping and localisation in metal water pipes using hydrophone induced vibration and map alignment by dynamic time warping," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2548-2553.
doi: 10.1109/ICRA.2017.7989296
Abstract: Water is a highly valuable resource so asset management of associated infrastructure is of critical importance. Water distribution pipe networks are usually buried, and so are difficult to access. Robots are therefore appealing for performing inspection and detecting damage to target repairs. However, robot mapping and localisation of buried water pipes has not been widely investigated to date, and is challenging because pipes tend to be relatively featureless. In this paper we propose a mapping and localisation algorithm for metal water pipes with two key novelties: the development of a new type of map based on hydrophone induced vibration signals of metal pipes, and a mapping algorithm based on spatial warping and averaging of dead reckoning signals used to calibrate the map (using dynamic time warping). Localisation is performed using both terrain-based extended Kalman filtering and also particle filtering. We successfully demonstrate and evaluate the approach on a combination of experimental and simulation data, showing improved localisation compared to dead reckoning.
keywords: {Robot sensing systems;Sonar equipment;Heuristic algorithms;Vibrations;Metals},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989296&isnumber=7988677

L. Fermin-Leon, J. Neira and J. A. Castellanos, "Incremental contour-based topological segmentation for robot exploration," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2554-2561.
doi: 10.1109/ICRA.2017.7989297
Abstract: We propose an alternative to the common approaches to the topological segmentation in structured or unstructured environments, Contour-Based Segmentation. It is faster and equally accurate, without the need of fine tuning parameters or heuristics. During robotic exploration, we propose an incremental version that reduces the processing time by reusing the previous segmentation. Tests demonstrate the velocity and quality in room segmentation in both batch and incremental mode. Tests also demonstrate the incremental version outperforms the state of the art in incremental topological segmentation.
keywords: {Image segmentation;Two dimensional displays;Robots;Bridges;Measurement;Transforms;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989297&isnumber=7988677

M. Luperto, A. Riva and F. Amigoni, "Semantic classification by reasoning on the whole structure of buildings using statistical relational learning techniques," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2562-2568.
doi: 10.1109/ICRA.2017.7989298
Abstract: Semantic mapping for autonomous mobile robots includes the place classification task that associates semantic labels (like `corridor' or `office') to rooms perceived in indoor environments. The mainstream approaches to place classification are characterized by local reasoning, where only features relative to the neighbourhood of each room are considered. In this paper, we propose a method for global reasoning on the whole structure of buildings, considered as single structured objects. We use a statistical relational learning algorithm, called kLog, and we compare it against a classifier, Extra-Trees, which resembles classical local approaches, in three tasks: classification of rooms, classification of entire floors of buildings, and validation of simulated worlds. Our results show that our global approach performs better than local approaches when the classification task involves reasoning on the regularities of buildings and when available information about rooms is coarse-grained.
keywords: {Semantics;Buildings;Cognition;Labeling;Sensors;Feature extraction;Periodic structures},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989298&isnumber=7988677

D. De Gregorio and L. Di Stefano, "SkiMap: An efficient mapping framework for robot navigation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2569-2576.
doi: 10.1109/ICRA.2017.7989299
Abstract: We present a novel mapping framework for robot navigation which features a multi-level querying system capable to obtain rapidly representations as diverse as a 3D voxel grid, a 2.5D height map and a 2D occupancy grid. These are inherently embedded into a memory and time efficient core data structure organized as a Tree of SkipLists. Compared to the well-known Octree representation, our approach exhibits a better time efficiency, thanks to its simple and highly parallelizable computational structure, and a similar memory footprint when mapping large workspaces. Peculiarly within the realm of mapping for robot navigation, our framework supports real-time erosion and re-integration of measurements upon reception of optimized poses from the sensor tracker, so as to improve continuously the accuracy of the map.
keywords: {Three-dimensional displays;Robot sensing systems;Navigation;Two dimensional displays;Octrees},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989299&isnumber=7988677

J. Banfi, A. Q. Li, N. Basilico, I. Rekleitis and F. Amigoni, "Multirobot online construction of communication maps," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2577-2583.
doi: 10.1109/ICRA.2017.7989300
Abstract: The importance of communication in many multirobot information-gathering tasks requires the availability of reliable communication maps. These provide estimates of the radio signal strength and can be used to predict the presence of communication links between different locations of the environment. In the problem we consider, a team of mobile robots has to build such maps autonomously in a robot-to-robot communication setting. The solution we propose models the signal's distribution with a Gaussian Process and exploits different online sensing strategies to coordinate and guide the robots during their data acquisition. Our methods show interesting operative insights both in simulations and on real TurtleBot 2 platforms.
keywords: {Robot kinematics;Robot sensing systems;Uncertainty;Multi-robot systems;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989300&isnumber=7988677

F. Han, X. Yang, Y. Zhang and H. Zhang, "Sequence-based multimodal apprenticeship learning for robot perception and decision making," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2584-2591.
doi: 10.1109/ICRA.2017.7989301
Abstract: Apprenticeship learning has recently attracted a wide attention due to its capability of allowing robots to learn physical tasks directly from demonstrations provided by human experts. Most previous techniques assumed that the state space is known a priori or employed simple state representations that usually suffer from perceptual aliasing. Different from previous research, we propose a novel approach named Sequence-based Multimodal Apprenticeship Learning (SMAL), which is capable to simultaneously fusing temporal information and multimodal data, and to integrate robot perception with decision making. To evaluate the SMAL approach, experiments are performed using both simulations and real-world robots in the challenging search and rescue scenarios. The empirical study has validated that our SMAL approach can effectively learn plans for robots to make decisions using sequence of multimodal observations. Experimental results have also showed that SMAL outperforms the baseline methods using individual images.
keywords: {Decision making;Feature extraction;Robot sensing systems;Cameras;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989301&isnumber=7988677

F. Han, C. Reardon, L. E. Parker and H. Zhang, "Minimum uncertainty latent variable models for robot recognition of sequential human activities," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2592-2599.
doi: 10.1109/ICRA.2017.7989302
Abstract: Recognition of sequential human activities, such as “sitting down” and “standing up”, is a common but challenging problem in human-robot interaction, which requires modeling their underlying temporal patterns. Although previous sequence modeling methods, such as Hidden Conditional Random Fields (HCRFs), demonstrated satisfactory recognition accuracy, they do not explicitly model the uncertainty in underlying temporal patterns, which can provide valuable information to characterize sequential activities. To address this problem, we introduce a novel Minimum Uncertainty HCRF (MU, or μHCRF). Different from traditional HCRF-based techniques that only utilize the negative log-likelihood of the categories' conditional probability as the loss function, the proposed μ-HCRF also introduces a regularization term to model the underlying temporal pattern of the latent variables. As another theoretical contribution, we provide a derivation to show that the formulated problem has a closed-form solution, and prove that inference of the proposed μHCRF is tractable. Extensive empirical study is performed to evaluate our approach, using four public benchmark datasets. Experimental results have shown that our μHCRFs outperform previous techniques and achieve state-of-the-art performance on human activity recognition, especially on sequential activities.
keywords: {Activity recognition;Hidden Markov models;Uncertainty;Entropy;Robots;Computational modeling;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989302&isnumber=7988677

T. -Y. Chen, P. -W. Ting, M. -Y. Wu and L. -C. Fu, "Learning a deep network with spherical part model for 3D hand pose estimation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2600-2605.
doi: 10.1109/ICRA.2017.7989303
Abstract: 3D hand pose estimation is a hot research topic in recent years. It's been widely used in many advanced applications for virtual reality and human-computer interaction, since it provides a natural interface for communication between human and cyberspace. Despite the fast development of this field, it is still a difficult task due to the various challenges. In this paper, we aim to build a 3D hand pose estimation system which can correctly detect human hands and accurately estimate its pose using depth images. To guarantee the robustness of our system, we design a hand model called spherical part model (SPM), and train a deep convolutional neural network using this model. Moreover, to reduce the influence of human's omissions, we use a data-driven approach to integrate them together. Our network can more accurately estimate hand pose based on prior knowledge of human hand. To demonstrate the superiority of our method, a complete experiment is conducted on two public and one self-built datasets. The results show that our system can detect human hands with average precision at almost 90% and the average error distance of the pose estimation is about 10 millimeters, and is better than the other state of the art works.
keywords: {Pose estimation;Training;Three-dimensional displays;Detectors;Robustness;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989303&isnumber=7988677

W. Li, A. Leonardis and M. Fritz, "Visual stability prediction for robotic manipulation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2606-2613.
doi: 10.1109/ICRA.2017.7989304
Abstract: Understanding physical phenomena is a key competence that enables humans and animals to act and interact under uncertain perception in previously unseen environments containing novel objects and their configurations. Developmental psychology has shown that such skills are acquired by infants from observations at a very early stage. In this paper, we contrast a more traditional approach of taking a model-based route with explicit 3D representations and physical simulation by an end-to-end approach that directly predicts stability from appearance. We ask the question if and to what extent and quality such a skill can directly be acquired in a data-driven way — bypassing the need for an explicit simulation at run-time. We present a learning-based approach based on simulated data that predicts stability of towers comprised of wooden blocks under different conditions and quantities related to the potential fall of the towers. We first evaluate the approach on synthetic data and compared the results to human judgments on the same stimuli. Further, we extend this approach to reason about future states of such towers that in return enables successful stacking.
keywords: {Stability analysis;Poles and towers;Visualization;Predictive models;Physics;Engines;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989304&isnumber=7988677

T. Naseer, G. L. Oliveira, T. Brox and W. Burgard, "Semantics-aware visual localization under challenging perceptual conditions," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2614-2620.
doi: 10.1109/ICRA.2017.7989305
Abstract: Visual place recognition under difficult perceptual conditions remains a challenging problem due to changing weather conditions, illumination and seasons. Long-term visual navigation approaches for robot localization should be robust to these dynamics of the environment. Existing methods typically leverage feature descriptions of whole images or image regions from Deep Convolutional Neural Networks. Some approaches also exploit sequential information to alleviate the problem of spatially inconsistent and non-perfect image matches. In this paper, we propose a novel approach for learning a discriminative holistic image representation which exploits the image content to create a dense and salient scene description. These salient descriptions are learnt over a variety of datasets under large perceptual changes. Such an approach enables us to precisely segment the regions of an image which are geometrically stable over large time lags. We combine features from these salient regions and an off-the-shelf holistic representation to form a more robust scene descriptor. We also introduce a semantically labeled dataset which captures extreme perceptual and structural scene dynamics over the course of 3 years. We evaluated our approach with extensive experiments on data collected over several kilometers in Freiburg and show that our learnt image representation outperforms off-the-shelf features from the deep networks and hand-crafted features.
keywords: {Robustness;Image segmentation;Visualization;Training;Feature extraction;Semantics;Computer architecture},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989305&isnumber=7988677

F. Han, X. Yang, C. Reardon, Y. Zhang and H. Zhang, "Simultaneous Feature and Body-Part Learning for real-time robot awareness of human behaviors," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2621-2628.
doi: 10.1109/ICRA.2017.7989306
Abstract: Robot awareness of human actions is an essential research problem in robotics with many important real-world applications, including human-robot collaboration and teaming. Over the past few years, depth sensors have become a standard device widely used by intelligent robots for 3D perception, which can also offer human skeletal data in 3D space. Several methods based on skeletal data were designed to enable robot awareness of human actions with satisfactory accuracy. However, previous methods treated all body parts and features equally important, without the capability to identify discriminative body parts and features. In this paper, we propose a novel simultaneous Feature And Body-part Learning (FABL) approach that simultaneously identifies discriminative body parts and features, and efficiently integrates all available information together to enable real-time robot awareness of human behaviors. We formulate FABL as a regression-like optimization problem with structured sparsity-inducing norms to model interrelationships of body parts and features. We also develop an optimization algorithm to solve the formulated problem, which possesses a theoretical guarantee to find the optimal solution. To evaluate FABL, three experiments were performed using public benchmark datasets, including the MSR Action3D and CAD-60 datasets, as well as a Baxter robot in practical assistive living applications. Experimental results show that our FABL approach obtains a high recognition accuracy with a processing speed of the order-of-magnitude of 101 Hz, which makes FABL a promising method to enable real-time robot awareness of human behaviors in practical robotics applications.
keywords: {Real-time systems;Robot sensing systems;Skeleton;Feature extraction;Three-dimensional displays;Biological system modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989306&isnumber=7988677

C. Schenck and D. Fox, "Visual closed-loop control for pouring liquids," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2629-2636.
doi: 10.1109/ICRA.2017.7989307
Abstract: Pouring a specific amount of liquid is a challenging task. In this paper we develop methods for robots to use visual feedback to perform closed-loop control for pouring liquids. We propose both a model-based and a model-free method utilizing deep learning for estimating the volume of liquid in a container. Our results show that the model-free method is better able to estimate the volume. We combine this with a simple PID controller to pour specific amounts of liquid, and show that the robot is able to achieve an average 38ml deviation from the target amount. To our knowledge, this is the first use of raw visual feedback to pour liquids in robotics.
keywords: {Liquids;Containers;Robots;Kernel;Convolution;Hidden Markov models;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989307&isnumber=7988677

S. Leonardos, X. Zhou and K. Daniilidis, "Distributed consistent data association via permutation synchronization," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2645-2652.
doi: 10.1109/ICRA.2017.7989308
Abstract: Data association is one of the fundamental problems in multi-sensor systems. Most current techniques rely on pairwise data associations which can be spurious even after the employment of outlier rejection schemes. Considering multiple pairwise associations at once significantly increases accuracy and leads to consistency. In this work, we propose a fully decentralized method for globally consistent data association from pairwise data associations based on a distributed averaging scheme on the set of doubly stochastic matrices. We demonstrate the effectiveness of the proposed method using theoretical analysis and experimental evaluation.
keywords: {Distributed databases;Robot sensing systems;Computer vision;Algorithm design and analysis;Eigenvalues and eigenfunctions},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989308&isnumber=7988677

A. K. Bozcuoğlu and M. Beetz, "A cloud service for robotic mental simulations," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2653-2658.
doi: 10.1109/ICRA.2017.7989309
Abstract: Robotic agents that do everyday manipulation tasks can hugely benefit from being able to predict consequences of their actions just before the execution. However, such a simulation technique is usually computationally-expensive and may not be achieved with agents' self computing power. For this problem, cloud robotics may offer a solution. Cloud robotics is an emerging field in the intersection of robotics and cloud computing which enables robots to access a greater amount of processing power and storage capacity than it can employ within itself. In this work, we introduce a mental simulation service to, one of the cloud engines, openEASE [1]. Using this service, researchers and robots can describe the world model, the state of the agent and the problem that is being dealt with. In return, it simulates the world and runs a learning algorithm and suggests a solution how the robotic agent can handle the problem. This service does not only offer a free remote access to simulation which is computationally expensive but also thanks to OPEnEASE's rich reasoning techniques these simulated experiments can be reasoned later on using prolog queries.
keywords: {Robots;Data models;Computational modeling;Trajectory;Cognition;Engines;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989309&isnumber=7988677

E. Schaffernicht, V. H. Bennetts and A. J. Lilienthal, "Mobile robots for learning spatio-temporal interpolation models in sensor networks — The Echo State map approach," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2659-2665.
doi: 10.1109/ICRA.2017.7989310
Abstract: Sensor networks have limited capabilities to model complex phenomena occuring between sensing nodes. Mobile robots can be used to close this gap and learn local interpolation models. In this paper, we utilize Echo State Networks in order to learn the calibration and interpolation model between sensor nodes using measurements collected by a mobile robot. The use of Echo State Networks allows to deal with temporal dependencies implicitly, while the spatial mapping with a Gaussian Process estimator exploits the fact that Echo State Networks learn linear combinations of complex temporal dynamics. The resulting Echo State Map elegantly combines spatial and temporal cues into a single representation. We showcase the method in the exposure modeling task of building dust distribution maps for foundries, a challenge which is of great interest to occupational health researchers. Results from simulated data and real world experiments highlight the potential of Echo State Maps. While we focus on particulate matter measurements, the method can be applied for any other environmental variables like temperature or gas concentration.
keywords: {Robot sensing systems;Mobile robots;Interpolation;Wireless sensor networks;Foundries},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989310&isnumber=7988677

A. Alahi, J. Wilson, L. Fei-Fei and S. Savarese, "Unsupervised camera localization in crowded spaces," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2666-2673.
doi: 10.1109/ICRA.2017.7989311
Abstract: Existing camera networks in public spaces such as train terminals or malls can help social robots to navigate crowded scenes. However, the localization of the cameras is required, i.e., the positions and poses of all cameras in a unique reference. In this work, we estimate the relative location of any pair of cameras by solely using noisy trajectories observed from each camera. We propose a fully unsupervised learning technique using unlabelled pedestrians motion patterns captured in crowded scenes. We first estimate the pairwise camera parameters by optimally matching single-view pedestrian tracks using social awareness. Then, we show the impact of jointly estimating the network parameters. This is done by formulating a nonlinear least square optimization problem, leveraging a continuous approximation of the matching function. We evaluate our approach in real-world environments such as train terminals, where several hundreds of individuals need to be tracked across dozens of cameras every second.
keywords: {Cameras;Robot vision systems;Tracking;Optimization;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989311&isnumber=7988677

S. Nagavalli, N. Chakraborty and K. Sycara, "Automated sequencing of swarm behaviors for supervisory control of robotic swarms," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2674-2681.
doi: 10.1109/ICRA.2017.7989312
Abstract: Robotic swarms are distributed systems that exhibit global behaviors arising from local interactions between individual robots. Each robot can be programmed with several local control laws that can be activated depending on an operator's choice of global swarm behavior. While some simple behaviors (e.g. rendezvous) with guaranteed performance on known objectives under strict assumptions have been studied in the literature, real missions occur in uncontrolled environments with dynamically arising objectives and require combinations of behaviors. Given a library of swarm behaviors, a supervisory operator commanding the swarm must choose a sequence of behaviors to execute in order to accomplish a particular task during a mission composed of many dynamically arising tasks. In this paper, we formalize the problem of finding an optimal behavior sequence to maximize swarm performance on a complex task. Given the swarm behavior library, a set of decision time points and a performance criterion, we present an informed search algorithm that computes the maximum performance behavior sequence. The algorithm is proven to be optimal and complete. A relevant modification is presented that generates bounded suboptimal solutions more quickly. We apply the algorithm to a swarm navigation application and a dynamic area coverage application, demonstrating the utility of our algorithm even in situations where the behaviors in the library have not been designed for the task at hand.
keywords: {Libraries;Heuristic algorithms;Robot sensing systems;Silicon;Algorithm design and analysis;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989312&isnumber=7988677

C. Baykal, G. Rosman, S. Claici and D. Rus, "Persistent surveillance of events with unknown, time-varying statistics," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2682-2689.
doi: 10.1109/ICRA.2017.7989313
Abstract: We consider the problem of monitoring stochastic, time-varying events occurring at discrete locations. Our problem formulation extends prior work in persistent surveillance by considering the objective of maximizing event detections in unknown, dynamic environments where the rates of events are time-inhomogeneous and may be subject to abrupt changes. We propose a novel monitoring algorithm that effectively strikes a balance between exploration and exploitation as well as a balance between remembering and discarding information to handle temporal variations in unknown environments. We present an analysis proving the long-run average optimality of the policies generated by our algorithm under the assumption that the total temporal variations are sub-linear. We present simulation results demonstrating the effectiveness of our algorithm in several monitoring scenarios inspired by real-world applications, and its robustness to both continuous-random and abrupt changes in the statistics of the observed processes.
keywords: {Surveillance;Heuristic algorithms;Robot sensing systems;Algorithm design and analysis;Transient analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989313&isnumber=7988677

H. W. Wopereis, J. J. Hoekstra, T. H. Post, G. A. Folkertsma, S. Stramigioli and M. Fumagalli, "Application of substantial and sustained force to vertical surfaces using a quadrotor," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2704-2709.
doi: 10.1109/ICRA.2017.7989314
Abstract: In the field of aerial robotics, one of the key challenges is to enable aerial manipulators to exert substantial forces on the environment. Enabling this will allow the technology to perform meaningful tasks airborne, such as cleaning or grinding surfaces. While in contact and applying a large, continuous force, control of the UAV's attitude is a challenge. In this work, we show that a regular (PID-based) attitude controller is incapable of stabilizing aerial manipulators that apply physical contact forces on the environment that are comparable to the UAV's weight. We present a novel control algorithm that uses an LQR-optimized state feedback on the roll and yaw angle while in contact. Experiments on a UAV of 1.5 kg show that the proposed controller is capable of applying a contact force of over 15 N - equal to the UAV's weight - sustained for several minutes.
keywords: {Force;Manipulator dynamics;Attitude control;Heuristic algorithms;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989314&isnumber=7988677

T. Oliveira, A. P. Aguiar and P. Encarnação, "Three dimensional moving path following for fixed-wing unmanned aerial vehicles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2710-2716.
doi: 10.1109/ICRA.2017.7989315
Abstract: Moving Path Following (MPF) control laws allows an autonomous vehicle to converge to and follow a path that is moving with respect to an inertial frame. This paper formally extends the MPF methods present in the literature to the case of three dimensional paths that can be moving with time-varying linear and angular velocities with respect to an inertial frame. A 3D MPF error space and a MPF Lyapunov-based control law is derived at kinematic level for a fixed-wing unmanned aerial vehicle. Formal convergence proofs and validation using flight test results are presented, demonstrating the effectiveness of the proposed method.
keywords: {Angular velocity;Three-dimensional displays;Kinematics;Aerospace electronics;Unmanned aerial vehicles;Quaternions;Convergence},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989315&isnumber=7988677

J. Y. Lee, S. H. Song, H. W. Shon, H. R. Choi and W. Yim, "Modeling and control of a saucer type Coandä effect UAV," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2717-2722.
doi: 10.1109/ICRA.2017.7989316
Abstract: The concept of utilizing the Coandia effect to produce stable flight in saucer type Aerial Vehicles (AV) was first conceived in 1935 by Henri Marie Coanda. Coanda's proposed AV design remained a relatively unexplored curiosity for decades until the recent surge in popularity of small Unmanned Aerial Vehicles (UAV) revitalized interest in the topic. Coandä effect UAV offer some distinct advantages over standard multirotors due to their robust frame design, which offers a unique mix of crash resistance, flight safety, and flight performance making them ideal for Human-Robot Interaction (HRI) applications. While much work has been performed in the area of characterization for Coanda surfaces and improved mechanical design of saucer type UAV, little work has been found in the literature discussing stability and attitude control of the platform. This work seeks to contribute to the study of these drones by introducing an approximate servo mapping for desired control effort of a particular prototype, and an experimental control law implemented within the framework of a modified commercially available flight stack.
keywords: {Rotors;Drones;Atmospheric modeling;Force;Propellers;Prototypes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989316&isnumber=7988677

M. Muehlebach, C. Sferrazza and R. D'Andrea, "Implementation of a parametrized infinite-horizon model predictive control scheme with stability guarantees," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2723-2730.
doi: 10.1109/ICRA.2017.7989317
Abstract: This article discusses the implementation of an infinite-horizon model predictive control approach that is based on representing input and state trajectories by a linear combination of basis functions. An iterative constraint sampling strategy is presented for guaranteeing constraint satisfaction over all times. It will be shown that the proposed method converges. In addition, we will discuss the implementation of the resulting (online) model predictive control algorithm on an unmanned aerial vehicle and provide experimental results. The computational efficiency of the algorithm is highlighted by the fact that a sampling rate of 100 Hz was achieved on an embedded platform.
keywords: {Trajectory;Predictive control;Optimization;Stability analysis;Optimal control;Prediction algorithms;Unmanned aerial vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989317&isnumber=7988677

R. Ritz and R. D'Andrea, "A global controller for flying wing tailsitter vehicles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2731-2738.
doi: 10.1109/ICRA.2017.7989318
Abstract: We present a global controller for tracking nominal trajectories with a flying wing tailsitter vehicle. The control strategy is based on a first-principles model of the vehicle dynamics that captures all relevant aerodynamic effects, and we apply an onboard parameter learning scheme in order to estimate unknown aerodynamic parameters. A cascaded control architecture is used: Based on position and velocity errors an outer control loop computes a desired attitude keeping the vehicle in coordinated flight, while an inner control loop tracks the desired attitude using a lookup table with precomputed optimal attitude trajectories. The proposed algorithms can be implemented on a typical microcontroller and the performance is demonstrated in various experiments.
keywords: {Aerodynamics;Propellers;Force;Torque;Vehicle dynamics;Attitude control;Atmospheric modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989318&isnumber=7988677

I. Alzugaray, L. Teixeira and M. Chli, "Short-term UAV path-planning with monocular-inertial SLAM in the loop," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2739-2746.
doi: 10.1109/ICRA.2017.7989319
Abstract: Small Unmanned Aerial Vehicles (UAVs) are some of the most promising robotic platforms in a variety of applications due to their high mobility. Their restricted computational and payload capabilities, however, translate into significant challenges in automating their navigation. With Simultaneous Localization And Mapping (SLAM) systems recently demonstrated to be employable onboard UAVs, the focus fall on path-planning on the quest of achieving autonomous navigation. With the vast body of path-planning literature often assuming perfect maps or maps known a priori, the biggest challenge lies in dealing with the robustness and accuracy limitations of onboard SLAM in real missions. In this spirit, this paper proposes a path-planning algorithm designed to work in the loop of the SLAM estimation of a monocular-inertial system. This point-to-point planner is demonstrated to navigate in an unknown environment using the incrementally generated SLAM map, while dictating the navigation strategy for preferable acquisition of sensor data for better estimations within SLAM. A thorough evaluation testbed of both simulated and real data is presented, demonstrating the robustness of the proposed pipeline against the state-of-the-art and its dramatically lower computational complexity, revealing its suitability to UAV navigation.
keywords: {Simultaneous localization and mapping;Navigation;Planning;Trajectory;Unmanned aerial vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989319&isnumber=7988677

G. Michieletto, M. Ryll and A. Franchi, "Control of statically hoverable multi-rotor aerial vehicles and application to rotor-failure robustness for hexarotors," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2747-2752.
doi: 10.1109/ICRA.2017.7989320
Abstract: Standard hexarotors are often mistakenly considered `by definition' fail-safe multi-rotor platforms because of the two additional propellers when compared to quadrotors. However this is not true, in fact, a standard hexarotor cannot statically hover with `only' five propellers. In this paper we provide a set of new general algebraic conditions to ensure static hover for any multi-rotor platform with any number of generically oriented rotors. These are elegantly formulated as the full-rankness of the control moment input matrix, and the non-orthogonality between its null-space and the row space of the control force input matrix. Input saturations and safety margins are also taken into account with an additional condition on the null-space of control moment input matrix. A deep analysis on the hoverability properties is then carried out focusing on the propeller loss in a hexarotor platform. Leveraging our general results we explain why a standard hexarotor is not robust and how it can be made robust thanks to a particular tilt of the rotors. We finally propose a novel cascaded controller based on a preferential direction in the null-space of the control moment input matrix for the large class of statically hoverable multi-rotors, which goes far beyond standard platforms, and we apply this controller to the case of failed tilted hexarotor.
keywords: {Propellers;Rotors;Spinning;Robustness;Standards;Force;Attitude control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989320&isnumber=7988677

E. Coronado, J. Villalobos, B. Bruno and F. Mastrogiovanni, "Gesture-based robot control: Design challenges and evaluation with humans," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2761-2767.
doi: 10.1109/ICRA.2017.7989321
Abstract: In this paper we introduce a gesture-based robot control framework, we discuss the adopted design principles and we report results about its evaluation with humans. Gesture-based control using wearable devices may constitute a novel form of human-robot interaction, but its implications have not been discussed in the literature. We discuss the main challenging issues, possible design guidelines and an open source, freely available implementation using commercially available devices and robots. The overall performance of the architecture, as well as its validation with 27 untrained volunteers, is reported.
keywords: {Mobile robots;Automobiles;Robot kinematics;Robot sensing systems;Robot control;Usability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989321&isnumber=7988677

J. Tay, M. Veloso and I. -M. Chen, "Learning individual motion preferences from audience feedback of motion sequences," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2768-2773.
doi: 10.1109/ICRA.2017.7989322
Abstract: A robot performs a sequence of motions to animate a given input, e.g., dancing to music or telling a story. Each input is pre-processed to determine labels, e.g., emotions of the music or words in the story. Each label corresponds to multiple motions, and each motion has multiple labels. Therefore, the robot can choose one sequence from multiple motion sequences to animate the input. We aim to choose the best sequence to animate based on the audience's preferences. The audience prefers some motions over others, and each motion has an initially unknown preference value. At the end of the motion sequence, the audience provides feedback which is the sum of the motions' preference values. However, the observation of the feedback is noisy due to the device used to capture the audience's feedback. To select the most preferred sequence, the robot has to determine the sequence to query the audience with, so as to learn the preference values of individual motions from noisy observations of the audience's feedback. By learning the individual motion preference values, the most preferred sequence can be determined. Moreover, the audience may get bored of watching the same single motion in multiple sequences and the preference value will degrade based on the number of times the motion is viewed. We contribute MAK (Multi-Armed bandit and Kalman filter) and show that MAK outperforms least squares regression in selecting the best sequence with lower degradation in our simulation experiments.
keywords: {Noise measurement;Kalman filters;Robots;Degradation;Libraries;Learning (artificial intelligence);Markov processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989322&isnumber=7988677

J. Young, L. Kunze, V. Basile, E. Cabrio, N. Hawes and B. Caputo, "Semantic web-mining and deep vision for lifelong object discovery," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2774-2779.
doi: 10.1109/ICRA.2017.7989323
Abstract: Autonomous robots that are to assist humans in their daily lives must recognize and understand the meaning of objects in their environment. However, the open nature of the world means robots must be able to learn and extend their knowledge about previously unknown objects on-line. In this work we investigate the problem of unknown object hypotheses generation, and employ a semantic Web-mining framework along with deep-learning-based object detectors. This allows us to make use of both visual and semantic features in combined hypotheses generation. Experiments on data from mobile robots in real world application deployments show that this combination improves performance over the use of either method in isolation.
keywords: {Semantics;Knowledge based systems;Three-dimensional displays;Visualization;Mobile robots;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989323&isnumber=7988677

C. Finn and S. Levine, "Deep visual foresight for planning robot motion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2786-2793.
doi: 10.1109/ICRA.2017.7989324
Abstract: A key challenge in scaling up robot learning to many skills and environments is removing the need for human supervision, so that robots can collect their own data and improve their own performance without being limited by the cost of requesting human feedback. Model-based reinforcement learning holds the promise of enabling an agent to learn to predict the effects of its actions, which could provide flexible predictive models for a wide range of tasks and environments, without detailed human supervision. We develop a method for combining deep action-conditioned video prediction models with model-predictive control that uses entirely unlabeled training data. Our approach does not require a calibrated camera, an instrumented training set-up, nor precise sensing and actuation. Our results show that our method enables a real robot to perform nonprehensile manipulation - pushing objects - and can handle novel objects not seen during training.
keywords: {Predictive models;Robot sensing systems;Visualization;Robot kinematics;Data models;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989324&isnumber=7988677

J. Sung, I. Lenz and A. Saxena, "Deep multimodal embedding: Manipulating novel objects with point-clouds, language and trajectories," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2794-2801.
doi: 10.1109/ICRA.2017.7989325
Abstract: A robot operating in a real-world environment needs to perform reasoning over a variety of sensor modalities such as vision, language and motion trajectories. However, it is extremely challenging to manually design features relating such disparate modalities. In this work, we introduce an algorithm that learns to embed point-cloud, natural language, and manipulation trajectory data into a shared embedding space with a deep neural network. To learn semantically meaningful spaces throughout our network, we use a loss-based margin to bring embeddings of relevant pairs closer together while driving less-relevant cases from different modalities further apart. We use this both to pre-train its lower layers and fine-tune our final embedding space, leading to a more robust representation. We test our algorithm on the task of manipulating novel objects and appliances based on prior experience with other objects. On a large dataset, we achieve significant improvements in both accuracy and inference time over the previous state of the art. We also perform end-to-end experiments on a PR2 robot utilizing our learned embedding space.
keywords: {Trajectory;Natural languages;Neural networks;Inference algorithms;Machine learning;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989325&isnumber=7988677

J. Sung, J. K. Salisbury and A. Saxena, "Learning to represent haptic feedback for partially-observable tasks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2802-2809.
doi: 10.1109/ICRA.2017.7989326
Abstract: The sense of touch, being the earliest sensory system to develop in a human body [1], plays a critical part of our daily interaction with the environment. In order to successfully complete a task, many manipulation interactions require incorporating haptic feedback. However, manually designing a feedback mechanism can be extremely challenging. In this work, we consider manipulation tasks that need to incorporate tactile sensor feedback in order to modify a provided nominal plan. To incorporate partial observation, we present a new framework that models the task as a partially observable Markov decision process (POMDP) and learns an appropriate representation of haptic feedback which can serve as the state for a POMDP model. The model, that is parametrized by deep recurrent neural networks, utilizes variational Bayes methods to optimize the approximate posterior. Finally, we build on deep Q-learning to be able to select the optimal action in each state without access to a simulator. We test our model on a PR2 robot for multiple tasks of turning a knob until it clicks.
keywords: {Haptic interfaces;Tactile sensors;Bayes methods;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989326&isnumber=7988677

B. Kim, L. P. Kaelbling and T. Lozano-Pérez, "Learning to guide task and motion planning using score-space representation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2810-2817.
doi: 10.1109/ICRA.2017.7989327
Abstract: In this paper, we propose a learning algorithm that speeds up the search in task and motion planning problems. Our algorithm proposes solutions to three different challenges that arise in learning to improve planning efficiency: what to predict, how to represent a planning problem instance, and how to transfer knowledge from one problem instance to another. We propose a method that predicts constraints on the search space based on a generic representation of a planning problem instance, called score space, where we represent a problem instance in terms of performance of a set of solutions attempted so far. Using this representation, we transfer knowledge, in the form of constraints, from previous problems based on the similarity in score space. We design a sequential algorithm that efficiently predicts these constraints, and evaluate it in three different challenging task and motion planning problems. Results indicate that our approach perform orders of magnitudes faster than an unguided planner.
keywords: {Planning;Prediction algorithms;Algorithm design and analysis;Robots;Search problems;Measurement;Reliability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989327&isnumber=7988677

A. H. Memar, N. Mastronarde and E. T. Esfahani, "Design of a novel variable stiffness gripper using permanent magnets," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2818-2823.
doi: 10.1109/ICRA.2017.7989328
Abstract: This paper presents the design of a novel variable stiffness gripper with two parallel fingers (jaws). Compliance of the system is generated by using permanent magnets as the nonlinear springs. Based on the presented design, the position and stiffness level of the fingers can be adjusted simultaneously by changing the air gap between the magnets. The modeling of magnetic repulsion force and stiffness are presented and verified experimentally. An experiment is also conducted to demonstrate the functionality of the gripper to improve safety when a fragile object was grasped and the gripper collided with an obstacle.
keywords: {Grippers;Force;Magnetic levitation;Magnetic resonance imaging;Springs;Robots;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989328&isnumber=7988677

M. A. Estrada, H. Jiang, B. Noll, E. W. Hawkes, M. Pavone and M. R. Cutkosky, "Force and moment constraints of a curved surface gripper and wrist for assistive free flyers," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2824-2830.
doi: 10.1109/ICRA.2017.7989329
Abstract: Free-flying robots have the potential to autonomously fulfill a wide range of tasks involving manipulation of objects in space. In this paper we study the design of a wrist mechanism for free-flying robots that are equipped with an adhesive gripper for attaching to objects and surfaces. The wrist and gripper allow the robots to apply moments in addition to forces, which increases their versatility for object manipulation. We apply grasp optimization to establish limitations on the forces/moments that the wrist can impart, subject to adhesion capabilities. Building on these results, we present considerations for tuning a passive wrist mechanism, or controlling an active wrist, to broaden the range of forces and moments that the robot can exert. Our theoretical insights and wrist designs are validated in simulations and on a planar micro-gravity test bed.
keywords: {Grippers;Wrist;Force;Robots;Adhesives;Optimization;Tuning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989329&isnumber=7988677

M. Guo et al., "Design of parallel-jaw gripper tip surfaces for robust grasping," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2831-2838.
doi: 10.1109/ICRA.2017.7989330
Abstract: Parallel-jaw robot grippers can grasp almost any object and are ubiquitous in industry. Although the shape, texture, and compliance of gripper jaw surfaces affect grasp robustness, almost all commercially available grippers provide a pair of rectangular, planar, rigid jaw surfaces. Practitioners often modify these surfaces with a variety of ad-hoc methods such as adding rubber caps and/or wrapping with textured tape. This paper explores data-driven optimization of gripper jaw surfaces over a design space based on shape, texture, and compliance using rapid prototyping. In total, 37 jaw surface design variations were created using 3D printed casting molds and silicon rubber. The designs were evaluated with 1377 physical grasp experiments using a 4-axis robot (with automated reset). These tests evaluate grasp robustness as the probability that the jaws will acquire, lift, and hold a training set of objects at nominal grasp configurations computed by Dex-Net 1.0. Hill-climbing in parameter space yielded a grid pattern of 0.03 inch void depth and 0.0375 inch void width on a silicone polymer with durometer of A30. We then evaluated performance of this design using an ABB YuMi robot grasping a set of eight difficult-to-grasp 3D printed objects in 80 grasps with four gripper surfaces. The factory-provided gripper tips succeeded in 28.7% of the 80 trials, increasing to 68.7% when the tips were wrapped with tape. Gripper tips with gecko-inspired surfaces succeeded in 80.0% of trials, and gripper tips with the designed silicone surfaces succeeded in 93.7% of trials.
keywords: {Grippers;Surface texture;Service robots;Three-dimensional displays;Surface treatment;Friction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989330&isnumber=7988677

B. Calli and A. M. Dollar, "Vision-based model predictive control for within-hand precision manipulation with underactuated grippers," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2839-2845.
doi: 10.1109/ICRA.2017.7989331
Abstract: Precision manipulation with underactuated hands is a challenging problem due to difficulties in obtaining precise gripper, object and contact models. Using vision feedback provides a degree of robustness to modeling inaccuracies, but conventional visual servoing schemes may suffer from performance degradation if inaccuracies are large and/or unmodeled phenomena (e.g. friction) have significant effect on the system. In this paper, we propose the use of Model Predictive Control (MPC) framework within a visual servoing scheme to achieve high performance precision manipulation even with very rough models of the manipulation process. With experiments using step and periodic reference signals (in total 204 experiments), we show that the utilization of MPC provides superior performance in terms of accuracy and efficiency comparing to the conventional visual servoing methods.
keywords: {Actuators;Visual servoing;Optimization;Jacobian matrices;Predictive control;Grippers;Thumb},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989331&isnumber=7988677

C. Liu and C. Chiu, "Optimal design of a soft robotic gripper with high mechanical advantage for grasping irregular objects," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2846-2851.
doi: 10.1109/ICRA.2017.7989332
Abstract: This study presents a soft robotic gripper for grasping irregular objects. The optimal design is based on the proposed topology optimization and size optimization methods with the objective to maximize the mechanical advantage (MA, which is defined as the ratio of output force to the input force) of the analyzed compliant mechanism. The optimal design is prototyped using silicon rubber material. Experimental tests including MA test, geometric advantage (GA, which is defined as the ratio of output displacement to the input displacement) test, adaptability test, and grasping test are carried out to investigate the design. A performance index has also been proposed to evaluate the grasping performance of the grippers. The results show the developed gripper is with the highest performance index, which represents the developed gripper is with better adaptability, faster response, higher payload and stability in overall.
keywords: {Grippers;Optimization;Topology;Grasping;Linear programming;Manufacturing processes;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989332&isnumber=7988677

A. Umali and D. Berenson, "A framework for robot-assisted doffing of personal protective equipment," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2874-2881.
doi: 10.1109/ICRA.2017.7989333
Abstract: When treating highly-infectious diseases such as Ebola, health workers are at high risk of infection during the doffing of Personal Protective Equipment (PPE). This is due to factors such as fatigue, hastiness, and inconsistency in training. The introduction of a semi-autonomous robot doffing assistant has the potential to increase the safety of the doffing procedure by assisting the human during high-risk sub-tasks. However, using a robotic assistant requires transforming a purely human task into a sequence of safe and effective human-robot collaborative actions. Since diseases like Ebola can spread through the mucous membranes of the face our goal in synthesizing these actions is to keep the human's hands away from his or her face as much as possible. As a secondary goal, we also seek to minimize the human's effort. We segment the doffing procedure into a sequence of human and robot actions such that the robot only assists when necessary and the human performs the more intricate parts of the procedure. Our framework then synthesizes assistive motions for the robot that perform parts of the tasks. Our experiments on five doffing tasks suggest that the introduction of a robot assistant improves the safety of the procedure in three out of four of the high-risk doffing tasks while reducing effort in all five tasks.
keywords: {Trajectory;Measurement;Robot motion;Robot sensing systems;Safety;Face},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989333&isnumber=7988677

D. Vogt, S. Stepputtis, S. Grehl, B. Jung and H. Ben Amor, "A system for learning continuous human-robot interactions from human-human demonstrations," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2882-2889.
doi: 10.1109/ICRA.2017.7989334
Abstract: We present a data-driven imitation learning system for learning human-robot interactions from human-human demonstrations. During training, the movements of two interaction partners are recorded through motion capture and an interaction model is learned. At runtime, the interaction model is used to continuously adapt the robot's motion, both spatially and temporally, to the movements of the human interaction partner. We show the effectiveness of the approach on complex, sequential tasks by presenting two applications involving collaborative human-robot assembly. Experiments with varied object hand-over positions and task execution speeds confirm the capabilities for spatio-temporal adaption of the demonstrated behavior to the current situation.
keywords: {Hidden Markov models;Human-robot interaction;Adaptation models;Collaboration;Robot kinematics;Runtime},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989334&isnumber=7988677

J. Li, Z. Li and K. Hauser, "A study of bidirectionally telepresent tele-action during robot-mediated handover," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2890-2896.
doi: 10.1109/ICRA.2017.7989335
Abstract: The addition of manipulation capabilities to telepresence robots holds the promise of enabling remote humans to perform tele-labor, hands-on training, and collaborative manipulation, but the use of a robot as a mediator to humanhuman physical interaction is not yet well understood. This paper studies the impact of telepresence modalities in the context of robot-mediated object handover. A teleoperation system was developed involving a bimanual mobile manipulator with telepresence head and sensing capabilities, and a user study was conducted with n=10 pairs of subjects under a variety of audio and visual telepresence conditions. Results show that telepresence does not significantly affect objective handover fluency, but both audio and video telepresence do significantly improve user experience on subjective measures including intimacy and perceived fluency.
keywords: {Robot kinematics;Handover;Robot sensing systems;Manipulators;Mobile communication},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989335&isnumber=7988677

V. Gabler, T. Stahl, G. Huber, O. Oguz and D. Wollherr, "A game-theoretic approach for adaptive action selection in close proximity human-robot-collaboration," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2897-2903.
doi: 10.1109/ICRA.2017.7989336
Abstract: With the integration of Human-Robot Collaboration (HRC) in industrial assembly scenarios, robot systems face numerous challenges. In contrast to classic robot systems which follow a pre-programmed and fixed sequence of actions, an interaction scenario with humans in the loop requires mutual adaptation. In this paper a framework based on game theory is presented that allows robots to choose appropriate actions with respect to the action of human coworkers when collaborating in close proximity. The proposed framework models HRC scenarios as iterative games and selects action-strategies for the Human-Robot Team (HRT) by finding the Nash-Equilibria (NEs) of these games. In contrast to most common approaches, our proposed HRC-game treats the decision-making behavior equally for all agents involved. Therefore, the concept of game theory is applied to evaluate the mutual interference of all actions on the HRT to obtain pareto-optimal NEs, i.e. team-optimal action-allocations. The general framework of the proposed HRC-game is realized on an interactive pick-and-place scenario in close proximity. This exemplary HRC-game is tested in a human subject experiment of a KUKA LWR 4+ robot and a human coworker assembling toy-bricks in close proximity. The experimental measurements and statistically significant improvements in the subjective feedback hold as a proof-of-concept of the proposed HRC-game model.
keywords: {Games;Game theory;Service robots;Planning;Adaptation models;Collaboration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989336&isnumber=7988677

Y. Yun et al., "Maestro: An EMG-driven assistive hand exoskeleton for spinal cord injury patients," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2904-2910.
doi: 10.1109/ICRA.2017.7989337
Abstract: In this paper, we present an electromyography (EMG)-driven assistive hand exoskeleton for spinal-cord-injury (SCI) patients. We developed an active assistive orthosis, called Maestro, which is light, comfortable, compliant, and capable of providing various hand poses. The EMG signals are obtained from a subject's forearm, post-processed, and classified for operating Maestro. The performance of Maestro is evaluated by a standardized hand function test, called the Sollerman hand function test. The experimental results show that Maestro improved the hand function of the SCI patients.
keywords: {Electromyography;Muscles;Exoskeletons;Thumb;Force;Performance evaluation;Mechanical engineering},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989337&isnumber=7988677

C. T. Landi, F. Ferraguti, L. Sabattini, C. Secchi and C. Fantuzzi, "Admittance control parameter adaptation for physical human-robot interaction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2911-2916.
doi: 10.1109/ICRA.2017.7989338
Abstract: In physical human-robot interaction, the coexistence of robots and humans in the same workspace requires the guarantee of a stable interaction, trying to minimize the effort for the operator. To this aim, the admittance control is widely used and the appropriate selection of the its parameters is crucial, since they affect both the stability and the ability of the robot to interact with the user. In this paper, we present a strategy for detecting deviations from the nominal behavior of an admittance-controlled robot and for adapting the parameters of the controller while guaranteeing the passivity. The proposed methodology is validated on a KUKA LWR 4+.
keywords: {Admittance;Damping;Service robots;Stability analysis;Robot sensing systems;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989338&isnumber=7988677

C. Lee and S. Oh, "Interactive force control of an elastically actuated bi-articular two-link manipulator," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2917-2922.
doi: 10.1109/ICRA.2017.7989339
Abstract: In this paper, elastically actuated bi-articular manipulator is developed using a novel compact planetary geared elastic actuator. The newly developed SEA, which is compact and has little backlash, can achieve high force control performance. The configuration of the developed manipulator is designed based on the bi-articular muscle coordination, which can simplify the kinematics of the manipulator. The SEA and bi-articular actuator configuration of the developed manipulator can achieve high performance force control in the workspace, and thus can be utilized for various applications related to the service robot. The mechanism and control algorithm of the novel SEA, and the novel kinematics and dynamics of the developed manipulator are introduced in this paper. Impedance controller is designed based on the kinematics and dynamics of the manipulator and its performance is verified through experiments.
keywords: {Gears;Actuators;Torque;Manipulator dynamics;Springs;Force control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989339&isnumber=7988677

J. Shim, R. Arkin and M. Pettinatti, "An intervening ethical governor for a robot mediator in patient-caregiver relationship: Implementation and evaluation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2936-2942.
doi: 10.1109/ICRA.2017.7989340
Abstract: A robot mediator can enhance the quality of patient care in a health care context. Patients with Parkinson's disease can experience difficulties in precisely expressing their emotions due to the loss of control of their facial musculature, leading to their stigmatization by caregivers. To remedy this challenge, a robot mediator can be inserted into a patient-caregiver relationship. In this context, it is essential to handle the ethical issues of neglect to ensure human dignity. In an earlier paper [19], we proposed an intervening ethical governor (IEG) model, which enables a robot to ethically intervene in a situation where patients or caregivers go across accepted ethical boundaries. In this paper, we show how the IEG model can be implemented and applied in a real robotics system. In addition, by conducting interviews with the target population (adults 60 years of age or older), we evaluate the current intervention rules in the model, discuss potential improvements to the model, and consider uses of the model in real clinical contexts.
keywords: {Interviews;Videos;Sensors;Medical services;Service robots;Monitoring},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989340&isnumber=7988677

S. Mukherjee, S. Yang, R. A. MacLachlan, L. A. Lobes, J. N. Martel and C. N. Riviere, "Toward monocular camera-guided retinal vein cannulation with an actively stabilized handheld robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2951-2956.
doi: 10.1109/ICRA.2017.7989341
Abstract: In this paper we describe work towards retinal vessel cannulation using an actively stabilized handheld robot, guided by monocular vision. We employ a previously developed monocular camera based surface reconstruction method using automated laser beam scanning over the retina. We use the reconstructed plane to find a coordinate transform between the 2D image plane coordinate system and the global 3D frame. Within a hemispherical region around the target, we use motion scaling for higher precision. The contribution of this work is the homography matrix estimation using monocular vision and application of the previously developed laser surface reconstruction to Micron guided vein cannulation. Experiments are conducted in a wet eye phantom to show the higher accuracy of the surface reconstruction as compared to standard stereo reconstruction. Further, experiments to show the increased surgical accuracy due to motion scaling are also carried out.
keywords: {Retina;Tools;Image reconstruction;Surface reconstruction;Laser beams;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989341&isnumber=7988677

S. Zuo, M. Hughes and G. -Z. Yang, "A balloon endomicroscopy scanning device for diagnosing barrett's oesophagus," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2964-2970.
doi: 10.1109/ICRA.2017.7989342
Abstract: Confocal endomicroscopy can be used for identification of early mucosal dysplasia in various gastrointestinal conditions, and has particular potential in the monitoring of Barrett's oesophagus and the early stages of oesophageal cancer. However, it can be difficult to systematically scan a significant area of the oesophagus because of the small field-of-view and limited flexibility of the probe. Tissue deformation and inconsistent probe-tissue contact also make it difficult to form large mosaics. A mechanical scanning device is therefore desirable for controlled, large area surface scanning and mosaicing of the oesophagus. This paper proposes a robotic catheter encapsulated in an inflatable balloon, providing stable scanning over the oesophageal surface. It has an outer diameter of 3 mm, making it suitable for deployment through an endoscope working channel, and uses a custom endomicroscopy probe based on a leached flexible fibre bundle and an external confocal laser scanning system. Detailed mechanical performance and image quality evaluations were performed to assess the clinical potential of the device. In ex vivo studies using swine oesophagus, long helical scans were obtained, demonstrating that the device is able to scan the lumen stably and maintain good probe-tissue contact. The experimental results demonstrate the potential of the robotic catheter for systematic high-resolution imaging of the oesophageal mucosa, potentially reducing or even eliminating the need for physical biopsy.
keywords: {Electron tubes;Endoscopes;Wires;Torque;Probes;Fluorescence;Optical fibers;Barrett's Oesophagus;mechanical design;surgical robot;confocal endomicroscopy;image mosaicing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989342&isnumber=7988677

P. Wang and Q. Xu, "Design of a flexure-based micro-motion stage with constant output force," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 2994-2999.
doi: 10.1109/ICRA.2017.7989343
Abstract: This paper presents the design of a flexure-based precision positioning micro-motion stage system with constant output force. The stage mechanism is devised using folded leaf flexure (FLF) to achieve positive-stiffness structure. Bistable beams are employed to design negative-stiffness structure by using their buckling characteristics. Two bistable beams and two FLFs are combined together as a zero-stiffness structure. Complete models of the amplifier and the zero-stiffness structure are established and verified by using finite element analysis (FEA) simulation. The structural parameters are carefully designed to guarantee the performance requirement of motion range, stiffness and driving force. A prototype stage is fabricated by 3D printing process and a series of experiments are conducted for performance testing. Experimental results show that the developed positioning stage delivers a reachable constant-force motion range of 138 μm with good motion repeatability.
keywords: {Force;Mathematical model;Stress;Analytical models;Prototypes;Testing;Control systems;Micro-motion stage;zero stiffness;constant force;compliant mechanisms;micro-/nanopositioining},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989343&isnumber=7988677

J. Bös, A. Wahrburg and K. D. Listmann, "Iteratively Learned and Temporally Scaled Force Control with application to robotic assembly in unstructured environments," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3000-3007.
doi: 10.1109/ICRA.2017.7989344
Abstract: Robotic assembly tasks are subject to uncertainties arising from part tolerances. A popular approach to deal with such partially unstructured environments is to introduce compliance by using admittance control schemes. For such schemes, contact forces and torques are speed dependent, which often limits the achievable assembly speed. To overcome this limitation, we present a new method for increasing the achievable speed of compliant manipulators by iteratively reducing contact forces. The presented concept of Iteratively Learned and Temporally Scaled Force Control (ILTSFC) is based on two coupled iterative learning controllers where one increases the assembly speed and the other one adjusts the reference trajectory to reduce contact forces. The approach is verified by an experimental peg-in-hole study on an ABB YuMi, a dual-arm collaborative robot with 7DOF each arm.
keywords: {Admittance;Trajectory;Tools;Force control;Manipulator dynamics;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989344&isnumber=7988677

M. Bauza and A. Rodriguez, "A probabilistic data-driven model for planar pushing," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3008-3015.
doi: 10.1109/ICRA.2017.7989345
Abstract: This paper presents a data-driven approach to model planar pushing interaction to predict both the most likely outcome of a push and its expected variability. The learned models rely on a variation of Gaussian processes with input-dependent noise called Variational Heteroscedastic Gaussian processes (VHGP) [1] that capture the mean and variance of a stochastic function. We show that we can learn accurate models that outperform analytical models after less than 100 samples and saturate in performance with less than 1000 samples. We validate the results against a collected dataset of repeated trajectories, and use the learned models to study questions such as the nature of the variability in pushing, and the validity of the quasi-static assumption.
keywords: {Gaussian processes;Robots;Analytical models;Kernel;Training;Predictive models;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989345&isnumber=7988677

Y. Yang, H. Hu and Y. Liu, "A distributed approach to automated manufacturing systems with complex structures using Petri nets," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3016-3023.
doi: 10.1109/ICRA.2017.7989346
Abstract: One of the major challenges from both a theoretical and practical perspectives, for effectively establishing unattended operation of automated manufacturing systems (AMSs), is to resolve the deadlock. In the existing methods on deadlock problem, most of them are focused on the models with either flexible routes or assembly operations, whereas few method investigates them with both. Furthermore, applying these methods into large-scale systems is usually nontrivial, primarily because of the fact that they generally require the enumeration of all the states or siphons. The work presented in this paper proposes a Petri net-based model which can deal with both features and develops an innovative distributed strategy that provides an online and dynamic mechanism for deadlock resolution. Each step's execution depends on a search-based procedure that seeks to determine whether there exists a feasible event sequence bringing the currently-active process or sub-processes to the nearest global critical place when other processes stagnate. By taking our approach, system can benefit from minimal communication amount among different processes, better toleration to many contingencies like resource failure, and improved system performance like throughput.
keywords: {System recovery;Electromyography;Robustness;Manufacturing systems;Petri nets;System performance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989346&isnumber=7988677

P. Lottes, R. Khanna, J. Pfeifer, R. Siegwart and C. Stachniss, "UAV-based crop and weed classification for smart farming," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3024-3031.
doi: 10.1109/ICRA.2017.7989347
Abstract: Unmanned aerial vehicles (UAVs) and other robots in smart farming applications offer the potential to monitor farm land on a per-plant basis, which in turn can reduce the amount of herbicides and pesticides that must be applied. A central information for the farmer as well as for autonomous agriculture robots is the knowledge about the type and distribution of the weeds in the field. In this regard, UAVs offer excellent survey capabilities at low cost. In this paper, we address the problem of detecting value crops such as sugar beets as well as typical weeds using a camera installed on a light-weight UAV. We propose a system that performs vegetation detection, plant-tailored feature extraction, and classification to obtain an estimate of the distribution of crops and weeds in the field. We implemented and evaluated our system using UAVs on two farms, one in Germany and one in Switzerland and demonstrate that our approach allows for analyzing the field and classifying individual plants.
keywords: {Agriculture;Vegetation mapping;Feature extraction;Sugar industry;Soil;Pipelines;Indexes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989347&isnumber=7988677

M. Schwarz et al., "NimbRo picking: Versatile part handling for warehouse automation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3032-3039.
doi: 10.1109/ICRA.2017.7989348
Abstract: Part handling in warehouse automation is challenging if a large variety of items must be accommodated and items are stored in unordered piles. To foster research in this domain, Amazon holds picking challenges. We present our system which achieved second and third place in the Amazon Picking Challenge 2016 tasks. The challenge required participants to pick a list of items from a shelf or to stow items into the shelf. Using two deep-learning approaches for object detection and semantic segmentation and one item model registration method, our system localizes the requested item. Manipulation occurs using suction on points determined heuristically or from 6D item model registration. Parametrized motion primitives are chained to generate motions. We present a full-system evaluation during the APC 2016 and component-level evaluations of the perception system on an annotated dataset.
keywords: {Robot sensing systems;Proposals;Support vector machines;Feature extraction;Training;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989348&isnumber=7988677

S. McCammon and G. A. Hollinger, "Planning and executing optimal non-entangling paths for tethered underwater vehicles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3040-3046.
doi: 10.1109/ICRA.2017.7989349
Abstract: In this paper, we present a method to improve the navigation of tethered underwater vehicles by computing optimal paths that prevent their tethers from becoming entangled in obstacles. To accomplish this, we define the Non-Entangling Travelling Salesperson Problem (NE-TSP) as an extension of the Travelling Salesperson Problem with a non-entangling constraint. We compute the optimal solution to the NE-TSP by constructing a Mixed Integer Programming model, leveraging homotopy augmented graphs to plan an optimal trajectory through a set of inspection points, while maintaining a non-entangling guarantee. To avoid the computational expense of computing an optimal solution to the NE-TSP, we also introduce several methods to compute near-optimal solutions. In a set of simulated trials, our method was able to plan optimal non-entangling paths through a variety of environments. These results were then validated in a set of pool and field trials using a Seabotix vLBV300 underwater vehicle. The paths generated by our method were then compared to human-generated paths.
keywords: {Trajectory;Planning;Inspection;Computational modeling;Service robots;Underwater vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989349&isnumber=7988677

E. Sariyildiz, H. Wang and H. Yu, "A sliding mode controller design for the robust position control problem of series elastic actuators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3055-3061.
doi: 10.1109/ICRA.2017.7989350
Abstract: In this paper, a new robust position controller is proposed for Series Elastic Actuators (SEAs) by using Sliding Mode Control (SMC) and a second order Disturbance Observer (DOb). The latter estimates not only disturbances but also their first and second order successive derivatives. A simple yet efficient dynamic model of the position control system is derived by using the analogy of a two-mass-spring-damper system. It is of fourth order and suffers from collocated and non-collocated disturbances. The former is directly cancelled by feeding-back its estimation through control input. The latter is suppressed by treating the estimations of disturbances and their first and second order time derivatives in the design of the SMC-based robust position controller. By cancelling disturbances via their estimations, not only the robustness of the position control system is improved but also the control signal chattering is lowered. The proposed robust controller significantly improves the position control performance of SEAs by suppressing plant uncertainties and external disturbances, such as friction, backlash, inertia variation and load. The validity of the proposed robust position controller is verified by giving experimental results of an SEA.
keywords: {Conferences;Automation;TV},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989350&isnumber=7988677

J. Cho and K. Kong, "Realizing natural springy motion of a robotic leg by cancelling the undesired damping factors," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3062-3067.
doi: 10.1109/ICRA.2017.7989351
Abstract: A Spring-Loaded-Inverted Pendulum (SLIP) model has been applied to many legged robots, such as quadruped robots, for realizing trotting, bounding, and galloping motions. The indecipherable damping factors, however, hindered the implementation of the SLIP model in practice. In this paper, a control algorithm is proposed to realize the ideal springy motion of a robotic leg. A Kalman filter with a damped SLIP model as the reference system is utilized for estimating a longitudinal velocity of the robotic leg (i.e., the length change rate between the proximal joint and the tip toe). By cancelling the undesired damping factors through positive feedback based on the Kalman filter estimate, the robotic leg is controlled to realize an undamped SLIP model. The proposed method is verified by simulation and experiment. The results showed that the proposed control algorithm enabled the robotic leg to keep continuously hopping as a spring even in the presence of nonlinear frictions.
keywords: {Legged locomotion;Damping;Springs;Mathematical model;Force;Pneumatic systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989351&isnumber=7988677

R. S. Pierre, N. Paul and S. Bergbreiter, "3DFlex: A rapid prototyping approach for multi-material compliant mechanisms in millirobots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3068-3073.
doi: 10.1109/ICRA.2017.7989352
Abstract: This paper describes an intuitive method for the design and fabrication of small-scale robots with multi-material compliant mechanisms in 3D. The rigid components are 3D printed, and flexures are inserted into the rigid components, creating the final mechanism. The assembled mechanisms are robust, requiring over 1 N of force to delaminate, and surviving 150,000 cycles of bending without failure. A 6 g walking quadrupedal millirobot is presented as a case study for the design and manufacturing methodology. The quadrupedal millirobot has been demonstrated moving at top speeds of 9 mm/s (0.3 body lengths/s).
keywords: {Legged locomotion;Three-dimensional displays;Adhesives;Manufacturing processes;Force;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989352&isnumber=7988677

B. LaFerriere, C. E. Schlect and J. P. Swensen, "Compliant, bi-stable mechanisms with multiple stiffnesses through controlled spring buckling," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3074-3079.
doi: 10.1109/ICRA.2017.7989353
Abstract: The ability to change stiffness is a capability exhibited through the animal kingdom, with many recent advances in tunable stiffness in the area of robotics. In this paper, we propose a mechanism design that provides the ability to make modular subcomponents with tunable stiffness by creating a bi-stable mechanism that exhibits different stiffnesses in each of the stable configurations. The design is based on controlled buckling of two linear springs in series and allows design-time control over the stiffnesses, equilibrium points, and energy required to transition between the stable configurations.
keywords: {Springs;Potential energy;Force;Actuators;Mathematical model;Robots;Prototypes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989353&isnumber=7988677

I. Hussain, G. Salvietti, M. Malvezzi and D. Prattichizzo, "On the role of stiffness design for fingertip trajectories of underactuated modular soft hands," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3096-3101.
doi: 10.1109/ICRA.2017.7989354
Abstract: In this work, we propose a method to compute the stiffness of flexible joints and its realization in order to let the fingers track a certain predefined trajectory. We refer to tendon-driven, underactuated and passively compliant hands composed of deformable joints and rigid links. Specific stiffness and pre-form shapes can be assigned to the finger joints can be given s such that a single-cable actuation can be used. We firstly define a procedure to determine suitable joints stiffness and then we propose a possible realization of soft joints using rapid prototyping techniques. The stiffness computation is obtained leveraging on the the mechanics of tendon-driven hands and on compliant systems, while for its implementation beam theory has been exploited. We validate the proposed framework both in simulation and with experiments using the robotic Soft-SixthFinger, a wearable robot for grasping compensation in patients with a paretic hand, as a case study. The proposed framework can be used to design the stiffness of the passive joints in several model of underactuated tendon-driven soft hands so to improve their grasping capabilities.
keywords: {Tendons;Trajectory;Robots;Shape;Geometry;Finite element analysis;Grasping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989354&isnumber=7988677

D. Fridovich-Keil, E. Nelson and A. Zakhor, "AtomMap: A probabilistic amorphous 3D map representation for robotics and surface reconstruction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3110-3117.
doi: 10.1109/ICRA.2017.7989355
Abstract: We present a new 3D probabilistic occupancy map representation for robotics applications by relaxing the commonly-assumed constraint that space must be perfectly tessellated. We replace the regular structure of 3D grids with an unstructured collection of non-overlapping, equally-sized spheres, which we call “atoms”. Abandoning the grid structure allows a more accurate representation of space directly tangent to surfaces, which facilitates a number of applications such as high fidelity surface reconstruction and surface-guided path planning. Maps composed of atoms can distinguish between free, occupied, and unknown space, support computationally efficient insertions and collision queries, provide free space planning guarantees, and achieve state-of-the-art memory efficiency over large volumes. This is achieved while simultaneously reducing quantization effects in the vicinity of surfaces and defining a useful implicit surface representation.
keywords: {Robot sensing systems;Atomic measurements;Three-dimensional displays;Probabilistic logic;Surface reconstruction;Atomic beams},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989355&isnumber=7988677

K. Doherty, J. Wang and B. Englot, "Bayesian generalized kernel inference for occupancy map prediction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3118-3124.
doi: 10.1109/ICRA.2017.7989356
Abstract: We consider the problem of building accurate and descriptive 3D occupancy maps of an environment from sparse and noisy range sensor data. We seek to accomplish this task by constructing a predictive model online and inferring the occupancy probability of regions we have not directly observed. We propose a novel algorithm leveraging recent advances in data structures for mapping, sparse kernels, and Bayesian nonparametric inference. The resulting inference model has several desirable properties in comparison to existing methods, including speed of computation, the ability to be recursively updated without approximation, and consistency between batch and online inference. The method also reverts to the use of a specified prior state when insufficient relevant training data exist to predict the occupancy probability of a query point, a property which is attractive for motion planning and exploration applications with mobile robots.
keywords: {Kernel;Training data;Bayes methods;Training;Three-dimensional displays;Data models;Predictive models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989356&isnumber=7988677

V. Narayanan and M. Likhachev, "Deliberative object pose estimation in clutter," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3125-3130.
doi: 10.1109/ICRA.2017.7989357
Abstract: A fundamental robot perception task is that of identifying and estimating the poses of objects with known 3D models in RGB-D data. While feature-based and discriminative approaches have been traditionally used for this task, recent work on deliberative approaches such as PERCH and D2P have shown improved robustness in handling scenes with severe inter-object occlusions. These deliberative approaches work by treating multi-object pose estimation as a combinatorial search over the space of possible rendered scenes of the objects, thereby inherently being able to predict and account for occlusions. However, these methods have so far been restricted to scenes comprising only of known objects, and have been unable to handle extraneous clutter — a common occurrence in many real-world settings. This work significantly increases the practical relevance of deliberative perception methods by developing a formulation that: i) accounts for extraneous unmodeled clutter in scenes, and ii) provides object pose uncertainty estimates. Our algorithm is complete and provides bounded suboptimality guarantees for the cost function chosen to be optimized. Empirically, we demonstrate successful object recognition and uncertainty-aware localization in challenging scenes with unmodeled clutter, where previous deliberative methods perform unsatisfactorily. In addition, this work was used as part of the perception system by Carnegie Mellon University's Team HARP in the 2016 Amazon Picking Challenge.
keywords: {Three-dimensional displays;Clutter;Solid modeling;Pose estimation;Uncertainty;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989357&isnumber=7988677

L. Sun, T. Vidal-Calleja and J. V. Miro, "Coupling conditionally independent submaps for large-scale 2.5D mapping with Gaussian Markov Random Fields," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3131-3137.
doi: 10.1109/ICRA.2017.7989358
Abstract: Building large-scale 2.5D maps when spatial correlations are considered can be quite expensive, but there are clear advantages when fusing data. While optimal submapping strategies have been explored previously in covariance-form using Gaussian Process for large-scale mapping, this paper focuses on transferring such concepts into information form. By exploiting the conditional independence property of the Gaussian Markov Random Field (GMRF) models, we propose a submapping approach to build a nearly optimal global 2.5D map. In the proposed approach data is fused by first fitting a GMRF to one sensor dataset; then conditional independent submaps are inferred using this model and updated individually with new data arrives. Finally, the information is propagated from submap to submap to later recover the fully updated map. This is efficiently achieved by exploiting the inherent structure of the GMRF, fusion and propagation all in information form. The key contribution of this paper is the derivation of the algorithm to optimally propagate information through submaps by only updating the common parts between submaps. Our results show the proposed method reduces the computational complexity of the full mapping process while maintaining the accuracy. The performance is evaluated on synthetic data from the Canadian Digital Elevation Data.
keywords: {Covariance matrices;Sparse matrices;Bayes methods;Correlation;Computational modeling;Training;Markov random fields},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989358&isnumber=7988677

A. Loquercio, M. Dymczyk, B. Zeisl, S. Lynen, I. Gilitschenski and R. Siegwart, "Efficient descriptor learning for large scale localization," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3170-3177.
doi: 10.1109/ICRA.2017.7989359
Abstract: Many robotics and Augmented Reality (AR) systems that use sparse keypoint-based visual maps operate in large and highly repetitive environments, where pose tracking and localization are challenging tasks. Additionally, these systems usually face further challenges, such as limited computational power, or insufficient memory for storing large maps of the entire environment. Thus, developing compact map representations and improving retrieval is of considerable interest for enabling large-scale visual place recognition and loop-closure. In this paper, we propose a novel approach to compress descriptors while increasing their discriminability and match-ability, based on recent advances in neural networks. At the same time, we target resource-constrained robotics applications in our design choices. The main contributions of this work are twofold. First, we propose a linear projection from descriptor space to a lower-dimensional Euclidean space, based on a novel supervised learning strategy employing a triplet loss. Second, we show the importance of including contextual appearance information to the visual feature in order to improve matching under strong viewpoint, illumination and scene changes. Through detailed experiments on three challenging datasets, we demonstrate significant gains in performance over state-of-the-art methods.
keywords: {Training;Three-dimensional displays;Optimization;Visualization;Supervised learning;Solid modeling;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989359&isnumber=7988677

X. Wang, S. Vozar and E. Olson, "FLAG: Feature-based Localization between Air and Ground," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3178-3184.
doi: 10.1109/ICRA.2017.7989360
Abstract: In GPS-denied environments, robot systems typically revert to navigating with dead-reckoning and relative mapping, accumulating error in their global pose estimate. In this paper, we propose Feature-based Localization between Air and Ground (FLAG), a method for computing global position updates by matching features observed from ground to features in an aerial image. Our method uses stable, descriptorless features associated with vertical structure in the environment around a ground robot in previously unmapped areas, referencing only overhead imagery, without GPS. Multiple-hypothesis data association with a particle filter enables efficient recovery from data association error and odometry uncertainty. We implement a stereo system to demonstrate our vertical feature based global positioning approach in both indoor and outdoor scenarios, and show comparable performance to laser-scan-matching results in both environments.
keywords: {Image edge detection;Feature extraction;Three-dimensional displays;Cameras;Robot kinematics;Buildings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989360&isnumber=7988677

F. Rezazadegan, S. Shirazi, B. Upcrofit and M. Milford, "Action recognition: From static datasets to moving robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3185-3191.
doi: 10.1109/ICRA.2017.7989361
Abstract: Deep learning models have achieved state-of-the-art performance in recognizing human activities, but often rely on utilizing background cues present in typical computer vision datasets that predominantly have a stationary camera. If these models are to be employed by autonomous robots in real world environments, they must be adapted to perform independently of background cues and camera motion effects. To address these challenges, we propose a new method that firstly generates generic action region proposals with good potential to locate one human action in unconstrained videos regardless of camera motion and then uses action proposals to extract and classify effective shape and motion features by a ConvNet framework. In a range of experiments, we demonstrate that by actively proposing action regions during both training and testing, state-of-the-art or better performance is achieved on benchmarks. We show the outperformance of our approach compared to the state-of-the-art in two new datasets; one emphasizes on irrelevant background, the other highlights the camera motion. We also validate our action recognition method in an abnormal behavior detection scenario to improve workplace safety. The results verify a higher success rate for our method due to the ability of our system to recognize human actions regardless of environment and camera motion.
keywords: {Cameras;Computer vision;Robot vision systems;Proposals;Image motion analysis;Optical imaging},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989361&isnumber=7988677

M. Gehrig, E. Stumm, T. Hinzmann and R. Siegwart, "Visual place recognition with probabilistic voting," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3192-3199.
doi: 10.1109/ICRA.2017.7989362
Abstract: We propose a novel scoring concept for visual place recognition based on nearest neighbor descriptor voting and demonstrate how the algorithm naturally emerges from the problem formulation. Based on the observation that the number of votes for matching places can be evaluated using a binomial distribution model, loop closures can be detected with high precision. By casting the problem into a probabilistic framework, we not only remove the need for commonly employed heuristic parameters but also provide a powerful score to classify matching and non-matching places. We present methods for both a 2D-2D image matching and a 2D-3D landmark matching based on the above scoring. The approach maintains accuracy while being efficient enough for online application through the use of compact (low-dimensional) descriptors and fast nearest neighbor retrieval techniques. The proposed methods are evaluated on several challenging datasets in varied environments, showing state-of-the-art results with high precision and high recall.
keywords: {Probabilistic logic;Databases;Nearest neighbor searches;Visualization;Simultaneous localization and mapping;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989362&isnumber=7988677

H. Merzić, E. Stumm, M. Dymczyk, R. Siegwart and I. Gilitschenski, "Map quality evaluation for visual localization," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3200-3206.
doi: 10.1109/ICRA.2017.7989363
Abstract: A variety of end-user devices involving keypoint-based mapping systems are about to hit the market e.g. as part of smartphones, cars, robotic platforms, or virtual and augmented reality applications. Thus, the generated map data requires automated evaluation procedures that do not require experienced personnel or ground truth knowledge of the underlying environment. A particularly important question enabling commercial applications is whether a given map is of sufficient quality for localization. This paper proposes a framework for predicting localization performance in the context of visual landmark-based mapping. Specifically, we propose an algorithm for predicting performance of vision-based localization systems from different poses within the map. To achieve this, a metric is defined that assigns a score to a given query pose based on the underlying map structure. The algorithm is evaluated on two challenging datasets involving indoor data generated using a handheld device and outdoor data from an autonomous fixed-wing unmanned aerial vehicle (UAV). Using these, we are able to show that the score provided by our method is highly correlated to the true localization performance. Furthermore, we demonstrate how the predicted map quality can be used within a belief based path planning framework in order to provide reliable trajectories through high-quality areas of the map.
keywords: {Visualization;Uncertainty;Robots;Navigation;Measurement;Path planning;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989363&isnumber=7988677

R. Camoriano, G. Pasquale, C. Ciliberto, L. Natale, L. Rosasco and G. Metta, "Incremental robot learning of new objects with fixed update time," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3207-3214.
doi: 10.1109/ICRA.2017.7989364
Abstract: We consider object recognition in the context of lifelong learning, where a robotic agent learns to discriminate between a growing number of object classes as it accumulates experience about the environment. We propose an incremental variant of the Regularized Least Squares for Classification (RLSC) algorithm, and exploit its structure to seamlessly add new classes to the learned model. The presented algorithm addresses the problem of having an unbalanced proportion of training examples per class, which occurs when new objects are presented to the system for the first time. We evaluate our algorithm on both a machine learning benchmark dataset and two challenging object recognition tasks in a robotic setting. Empirical evidence shows that our approach achieves comparable or higher classification performance than its batch counterpart when classes are unbalanced, while being significantly faster.
keywords: {Training;Robots;Computational modeling;Object recognition;Machine learning algorithms;Training data;Standards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989364&isnumber=7988677

R. Toris and S. Chernova, "Temporal persistence modeling for object search," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3215-3222.
doi: 10.1109/ICRA.2017.7989365
Abstract: We present a novel solution to the object search problem for domains in which object permanence cannot be assumed and other agents may move objects between locations without the robot's knowledge. We formalize object search as a failure analysis problem and contribute temporal persistence modeling (TPM), an algorithm for probabilistic prediction of the time that an object is expected to remain at a given location given sparse prior observations. We show that probabilistic exponential distributions augmented with a Gaussian component can accurately represent probable object locations and search suggestions based entirely on sparsely made visual observations. We evaluate our work in two domains, a large scale GPS location data set for person tracking, and multi-object tracking on a mobile robot operating in a small-scale household environment over a 2-week period. TPM performance exceeds four baseline methods across all study conditions.
keywords: {Search problems;Mathematical model;Semantics;Probabilistic logic;Visualization;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989365&isnumber=7988677

Z. Chen et al., "Deep learning features at scale for visual place recognition," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3223-3230.
doi: 10.1109/ICRA.2017.7989366
Abstract: The success of deep learning techniques in the computer vision domain has triggered a range of initial investigations into their utility for visual place recognition, all using generic features from networks that were trained for other types of recognition tasks. In this paper, we train, at large scale, two CNN architectures for the specific place recognition task and employ a multi-scale feature encoding method to generate condition- and viewpoint-invariant features. To enable this training to occur, we have developed a massive Specific PlacEs Dataset (SPED) with hundreds of examples of place appearance change at thousands of different places, as opposed to the semantic place type datasets currently available. This new dataset enables us to set up a training regime that interprets place recognition as a classification problem. We comprehensively evaluate our trained networks on several challenging benchmark place recognition datasets and demonstrate that they achieve an average 10% increase in performance over other place recognition algorithms and pre-trained CNNs. By analyzing the network responses and their differences from pre-trained networks, we provide insights into what a network learns when training for place recognition, and what these results signify for future research in this area.
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989366&isnumber=7988677

A. R. Spielvogel and L. L. Whitcomb, "A stable adaptive attitude estimator on SO(3) for true-North seeking gyrocompass systems: Theory and preliminary simulation evaluation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3231-3236.
doi: 10.1109/ICRA.2017.7989367
Abstract: This paper reports a novel stable adaptive attitude estimator and preliminary simulation results of a true-North gyrocompass system employing the attitude adaptive identifier and a commercially available low-cost inertial measurement unit (IMU) comprising a 3-axis fiber optic gyroscope (FOG) with a 3-axis micro-electro-mechanical systems (MEMS) accelerometer. Optical North-seeking gyrocompass systems typically employ a microprocessor system to sample the low-level raw sensor values for angular-rate and linear-acceleration at a high sampling rate and estimate true-North heading, pitch, and roll. This paper reports the first adaptive attitude estimator on SO (3) which utilizes 3-axis angular-rate sensor data and 3-axis linear acceleration sensor data to estimate the instrument's 3-degrees of freedom (DOF) attitude (roll, pitch, and heading) without using magnetometry of the Earth's magnetic field. A stability proof and preliminary numerical simulation results are reported. The simulation results for a rotating IMU configuration are promising, and further experimental evaluation and extension of the algorithm for the case of a translating IMU configuration typically found on moving robotic vehicles are needed.
keywords: {Instruments;Magnetometers;Accelerometers;Sonar navigation;Acceleration;Angular velocity;Optical sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989367&isnumber=7988677

X. Li, W. Wang and J. Yi, "Ground substrate classification for adaptive quadruped locomotion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3237-3243.
doi: 10.1109/ICRA.2017.7989368
Abstract: In order to realize adaptive quadruped locomotion on terrains with different properties (such as surface friction or elasticity modulus), we plan to collect the foot-ground contact force and gyroscope information during locomotion on different ground substrates, then classify the ground substrates with the feature vector extracted from the collected data using Support Vector Machine (SVM) algorithm. However, the quadruped walk gait generated by Central Pattern Generators (CPGs) does not perform well on certain ground substrates, e.g., robots may be stuck in the soft ground substrates with small elasticity modulus. Therefore, for one thing, we present a Center of Gravity (COG) adjustment method to eliminate the offset between the control signal generated by CPGs and the actual phase of the quadruped limb, so the limb in theoretical swing phase is able to lift off the ground. For another, we combine CPGs with a foot path planning method to make the lift height controllable. Using these methods, the quadruped robot Biodog realizes the sensor data collection on five different ground substrates. Then we train and classify the sensor data with the SVM. About 99.33% of the five ground substrates can be classified correctly.
keywords: {Foot;Legged locomotion;Substrates;Force;Robot kinematics;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989368&isnumber=7988677

N. Yao, E. Anaya, Q. Tao, S. Cho, H. Zheng and F. Zhang, "Monocular vision-based human following on miniature robotic blimp," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3244-3249.
doi: 10.1109/ICRA.2017.7989369
Abstract: We present an approach that allows the Georgia Tech Miniature Autonomous Blimp (GT-MAB) to detect and follow a human. This accomplishment is the first Human Robot Interaction (HRI) demonstration between an uninstrumented human and a robotic blimp. GT-MAB is an ideal platform for HRI missions because it is safe to humans and can support sufficient flight time for HRI experiments. However, due to complex aerodynamic influence on the blimp, the human following task for GT-MAB with a single on-board camera is a challenging problem. We integrate Haar face detector and KLT feature tracker to achieve robust human tracking. After a human face is detected in the real-time video stream, we estimated the 3D positions of the human with respect to GT-MAB. Visionbased PID controllers are designed based on estimated relative position and the motion primitives of GT-MAB such that it can achieve stable and continuous human following behavior. Experimental results are presented to demonstrate the human following capability on GT-MAB.
keywords: {Face;Cameras;Face detection;Streaming media;Robot vision systems;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989369&isnumber=7988677

A. Moschetti, L. Fiorini, D. Esposito, P. Dario and F. Cavallo, "Daily activity recognition with inertial ring and bracelet: An unsupervised approach," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3250-3255.
doi: 10.1109/ICRA.2017.7989370
Abstract: Daily activity recognition can help people to maintain a healthy lifestyle and robot to better interact with users. Robots could therefore use the information coming from the activities performed by users to give them some custom hints to improve lifestyle and daily routine. The pervasiveness of smart things together with advances in cloud robotics can help the robot to perceive and collect more information about the users and the environment. In particular thanks to the miniaturization and low cost of Inertial Measurement Units, in the last years, body-worn activity recognition has gained popularity. In this work, we investigated the performances with an unsupervised approach to recognize eight different gestures performed in daily living wearing a system composed of two inertial sensors placed on the hand and on the wrist. In this context our aim is to evaluate whether the system is able to recognize the gestures in more realistic applications, where is not possible to have a training set. The classification problem was analyzed using two unsupervised approaches (K-Mean and Gaussian Mixture Model), with an intra-subject and an inter-subject analysis, and two supervised approaches (Support Vector Machine and Random Forest), with a 10-fold cross validation analysis and with a Leave-One-Subject-Out analysis to compare the results. The outcomes show that even in an unsupervised context the system is able to recognize the gestures with an averaged accuracy of 0.917 in the K-Mean inter-subject approach and 0.796 in the Gaussian Mixture Model inter-subject one.
keywords: {Robots;Wearable sensors;Wrist;Machine learning algorithms;Activity recognition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989370&isnumber=7988677

M. Miezal, B. Taetz and G. Bleser, "Real-time inertial lower body kinematics and ground contact estimation at anatomical foot points for agile human locomotion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3256-3263.
doi: 10.1109/ICRA.2017.7989371
Abstract: The ability to accurately capture locomotion is relevant in various use cases, in particular in the sports and health area. With the major goal of providing a measurement system that can deliver different types of relevant information (3D body segment kinematics, spatiotemporal locomotion parameters, and locomotion patterns) in-field and in real-time, we propose a novel probabilistic (single-plane) ground contact estimation method, using four contact points defined through a biomechanical foot model, and integrate this into an existing inertial motion capturing method. The resulting method is quantitatively evaluated on simulated and real IMU data in comparison to an optical motion capture system on walking, running, and jumping sequences. The results show its ability to maintain a good average 3D kinematics estimation error on low- and high-acceleration locomotion, whereas many previous accuracy studies restrict themselves to movements with low to moderate global accelerations, such as upper body activities or slow locomotion. Moreover, a qualitative evaluation of the estimated ground contact probabilities demonstrates the method's ability to also provide consistent information also for deriving spatiotemporal locomotion parameters as well as locomotion patterns (e.g., over-pronation/-supination) simultaneously with the 3D kinematics.
keywords: {Foot;Estimation;Kinematics;Mathematical model;Legged locomotion;Acceleration;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989371&isnumber=7988677

X. Zheng, Z. Moratto, M. Li and A. I. Mourikis, "Photometric patch-based visual-inertial odometry," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3264-3271.
doi: 10.1109/ICRA.2017.7989372
Abstract: In this paper we present a novel direct visual-inertial odometry algorithm, for estimating motion in unknown environments. The algorithm utilizes image patches extracted around image features, and formulates measurement residuals in the image intensity space directly. One key characteristic of the proposed method is that it models the true irradiance at each pixel as a random variable to be estimated and marginalized out. The formulation of the photometric residual explicitly accounts for the camera response function and lens vignetting (which can be calibrated in advance), as well as unknown illumination gains and biases, which are estimated on a per-feature or per-image basis. We present a detailed evaluation of our algorithm on 50 datasets with high-precision ground truth, which amount to approximately 1.5 hours of localization data. Through a direct comparison with a point-feature based method, we demonstrate that the use of photometric residuals results in increased pose estimation accuracy, with approximately 23% lower estimation errors, on average.
keywords: {Cameras;Random variables;Lighting;Feature extraction;Solid modeling;Three-dimensional displays;Lenses},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989372&isnumber=7988677

S. Pourmehr, J. Thomas, J. Bruce, J. Wawerla and R. Vaughan, "Robust sensor fusion for finding HRI partners in a crowd," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3272-3278.
doi: 10.1109/ICRA.2017.7989373
Abstract: We present a simple probabilistic framework for multimodal sensor fusion that allows a mobile robot to reliably locate and approach the most promising interaction partner among a group of people, in an uncontrolled environment. Our demonstration integrates three complementary sensor modalities, each of which detects features of nearby people. The output is an occupancy grid approximation of a probability density function over the locations of people that are actively seeking interaction with the robot. We show empirically that simply driving towards the peak of this distribution is sufficient to allow the robot to correctly engage an interested user in a crowd of bystanders.
keywords: {Robot sensing systems;Legged locomotion;Detectors;Target tracking;Torso;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989373&isnumber=7988677

P. O. Pereira and D. V. Dimarogonas, "Stability of load lifting by a quadrotor under attitude control delay," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3287-3292.
doi: 10.1109/ICRA.2017.7989374
Abstract: We propose a control law for stabilization of a quadrotor-load system, and provide conditions on the control law's gains that guarantee exponential stability of the equilibrium. The system is composed of a load and an unmanned aerial vehicle (UAV) attached to each other by a cable of fixed length, which behaves as a rigid link under tensile forces; and the control input is composed of a three dimensional force requested to the UAV, which the UAV provides with or without delay. Given the proposed control law, we analyze the stability of the equilibrium in two separate parts. In the first, the system is modeled assuming that the UAV provides the requested control input without delay, and we verify that the equilibrium is exponentially stable. In the second part, the UAV is modeled as possessing an attitude inner loop, and we provide a lower bound on the attitude gain for which exponential stability of the equilibrium is preserved. An integral action term is also included in the control law, which compensates for battery drainage or model mismatches, such as an unknown load mass. We present experiments for different scenarios that demonstrate and validate the robustness of the proposed control law.
keywords: {Stability analysis;Unmanned aerial vehicles;Load modeling;Delays;Trajectory;Attitude control;Control theory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989374&isnumber=7988677

L. Wang, A. D. Ames and M. Egerstedt, "Safe certificate-based maneuvers for teams of quadrotors using differential flatness," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3293-3298.
doi: 10.1109/ICRA.2017.7989375
Abstract: Safety Barrier Certificates that ensure collision-free maneuvers for teams of differential flatness-based quadrotors are presented in this paper. Synthesized with control barrier functions, the certificates are used to modify the nominal trajectory in a minimally invasive way to avoid collisions. The proposed collision avoidance strategy complements existing flight control and planning algorithms by providing trajectory modifications with provable safety guarantees. The effectiveness of this strategy is supported both by the theoretical results and experimental validation on a team of five quadrotors.
keywords: {Safety;Trajectory;Planning;Shape;Collision avoidance;Propellers;Minimally invasive surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989375&isnumber=7988677

J. A. Preiss, W. Honig, G. S. Sukhatme and N. Ayanian, "Crazyswarm: A large nano-quadcopter swarm," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3299-3304.
doi: 10.1109/ICRA.2017.7989376
Abstract: We define a system architecture for a large swarm of miniature quadcopters flying in dense formation indoors. The large number of small vehicles motivates novel design choices for state estimation and communication. For state estimation, we develop a method to reliably track many small rigid bodies with identical motion-capture marker arrangements. Our communication infrastructure uses compressed one-way data flow and supports a large number of vehicles per radio. We achieve reliable flight with accurate tracking (<; 2 cm mean position error) by implementing the majority of computation onboard, including sensor fusion, control, and some trajectory planning. We provide various examples and empirically determine latency and tracking performance for swarms with up to 49 vehicles.
keywords: {Trajectory;Tracking;Planning;Iterative closest point algorithm;State estimation;Base stations;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989376&isnumber=7988677

C. J. Salaan, K. Tadakuma, Y. Okada, E. Takane, K. Ohno and S. Tadokoro, "UAV with two passive rotating hemispherical shells for physical interaction and power tethering in a complex environment," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3305-3312.
doi: 10.1109/ICRA.2017.7989377
Abstract: For the past few years, unmanned aerial vehicles (UAVs) have been successfully employed in several investigations and exploration tasks such as aerial inspection and manipulations. However, most of these UAVs are limited to open spaces distant from any obstacles because of the high risk of falling as a result of an exposed propeller or not enough protection. On the other hand, a UAV with a passive rotating spherical shell can fly over a complex environment but cannot engage in physical interaction and perform power tethering because of the passive rotation of the spherical shell. In this study, we propose a new mechanism that allows physical interaction and power tethering while the UAV is well-protected and has a good flight stability, which enables exploration in a complex environment such as disaster sites. We address the current problem by dividing the whole shell into two separate hemispherical shells that provide a gap unaffected by passive rotation. In this paper, we mainly discuss the concept, general applications, and design of the proposed system. The capabilities of the proposed system for physical interaction and power tethering in a complex space were initially verified through laboratory-based test flights of our experimental prototype.
keywords: {Power cables;Unmanned aerial vehicles;Stability analysis;Manipulators;Prototypes;Gravity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989377&isnumber=7988677

M. Piccoli and M. Yim, "Piccolissimo: The smallest micro aerial vehicle," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3328-3333.
doi: 10.1109/ICRA.2017.7989378
Abstract: The goal of Piccolissimo is to create a small, simple, and self-powered flying vehicle. Piccolissimo has just one motor and two rigid bodies, which are propellers that spin in opposite directions. The mass distribution and relative rotor speeds are designed to maintain passive stability in hover. Cartesian velocity control is obtained by introducing an asymmetry in the rotation axis of the two rotating bodies and pulsing the thrust at appropriate times. The dynamic model for this device is developed and presented, highlighting the terms that enable a workable design. Two devices are discussed: a vertically controllable version that is 28 mm in the largest dimension and Cartesion controllable version that is 39 mm in the largest dimension.
keywords: {Stability analysis;Propellers;Sensitivity;Force;Aerodynamics;Rotors;Blades},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989378&isnumber=7988677

G. Kahn, T. Zhang, S. Levine and P. Abbeel, "PLATO: Policy learning using adaptive trajectory optimization," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3342-3349.
doi: 10.1109/ICRA.2017.7989379
Abstract: Policy search can in principle acquire complex strategies for control of robots and other autonomous systems. When the policy is trained to process raw sensory inputs, such as images and depth maps, it can also acquire a strategy that combines perception and control. However, effectively processing such complex inputs requires an expressive policy class, such as a large neural network. These high-dimensional policies are difficult to train, especially when learning to control safety-critical systems. We propose PLATO, a continuous, reset-free reinforcement learning algorithm that trains complex control policies with supervised learning, using model-predictive control (MPC) to generate the supervision, hence never in need of running a partially trained and potentially unsafe policy. PLATO uses an adaptive training method to modify the behavior of MPC to gradually match the learned policy in order to generate training samples at states that are likely to be visited by the learned policy. PLATO also maintains the MPC cost as an objective to avoid highly undesirable actions that would result from strictly following the learned policy before it has been fully trained. We prove that this type of adaptive MPC expert produces supervision that leads to good long-horizon performance of the resulting policy. We also empirically demonstrate that MPC can still avoid dangerous on-policy actions in unexpected situations during training. Our empirical results on a set of challenging simulated aerial vehicle tasks demonstrate that, compared to prior methods, PLATO learns faster, experiences substantially fewer catastrophic failures (crashes) during training, and often converges to a better policy.
keywords: {Training;Neural networks;Supervised learning;Robots;Robustness;Trajectory optimization;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989379&isnumber=7988677

R. Martinez-Cantin, "Bayesian optimization with adaptive kernels for robot control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3350-3356.
doi: 10.1109/ICRA.2017.7989380
Abstract: Active policy search combines the trial-and-error methodology from policy search with Bayesian optimization to actively find the optimal policy. First, policy search is a type of reinforcement learning which has become very popular for robot control, for its ability to deal with complex continuous state and action spaces. Second, Bayesian optimization is a sample efficient global optimization method that uses a surrogate model, like a Gaussian process, and optimal decision making to carefully select each sample during the optimization process. Sample efficiency is of paramount importance when each trial involves the real robot, expensive Monte Carlo runs, or a complex simulator. Black-box Bayesian optimization generally assumes a cost function from a stationary process, because nonstationary modeling is usually based on prior knowledge. However, many control problems are inherently nonstationary due to their failure conditions, terminal states and other abrupt effects. In this paper, we present a kernel function specially designed for Bayesian optimization, that allows nonstationary modeling without prior knowledge, using an adaptive local region. The new kernel results in an improved local search (exploitation), without penalizing the global search (exploration), as shown experimentally in well-known optimization benchmarks and robot control scenarios. We finally show its potential for the design of the wing shape of a UAV.
keywords: {Kernel;Optimization;Bayes methods;Gaussian processes;Robots;Adaptation models;Learning (artificial intelligence)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989380&isnumber=7988677

Y. Zhu et al., "Target-driven visual navigation in indoor scenes using deep reinforcement learning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3357-3364.
doi: 10.1109/ICRA.2017.7989381
Abstract: Two less addressed issues of deep reinforcement learning are (1) lack of generalization capability to new goals, and (2) data inefficiency, i.e., the model requires several (and often costly) episodes of trial and error to converge, which makes it impractical to be applied to real-world scenarios. In this paper, we address these two issues and apply our model to target-driven visual navigation. To address the first issue, we propose an actor-critic model whose policy is a function of the goal as well as the current state, which allows better generalization. To address the second issue, we propose the AI2-THOR framework, which provides an environment with high-quality 3D scenes and a physics engine. Our framework enables agents to take actions and interact with objects. Hence, we can collect a huge number of training samples efficiently. We show that our proposed method (1) converges faster than the state-of-the-art deep reinforcement learning methods, (2) generalizes across targets and scenes, (3) generalizes to a real robot scenario with a small amount of fine-tuning (although the model is trained in simulation), (4) is end-to-end trainable and does not need feature engineering, feature matching between frames or 3D reconstruction of the environment.
keywords: {Navigation;Training;Visualization;Learning (artificial intelligence);Three-dimensional displays;Physics;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989381&isnumber=7988677

S. R. Friedrich and M. Buss, "A robust stability approach to robot reinforcement learning based on a parameterization of stabilizing controllers," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3365-3372.
doi: 10.1109/ICRA.2017.7989382
Abstract: Reinforcement learning has become more and more popular in robotics for acquiring feedback controllers. Many approaches aim for learning a controller from scratch, i.e., data-driven without any modeling of the physical plant. However, stability properties of the closed loop are often not considered, or established only a-posteriori or ad hoc. We propose to employ reinforcement learning in the context of model-based control, allowing to learn in a framework of stabilizing controllers built by using only little prior model knowledge. This way, the action space is suitably structured for safe learning of a feedback controller to compensate for uncertainties due to model mismatch or external disturbances. The resulting scheme is developed around a decentralized PD feedback controller. Therefore, given such a controller, by the proposed method one can also add a learning module for performance enhancement. We demonstrate our approach both in simulation and in a hardware experiment using a two degree of freedom robot manipulator.
keywords: {Learning (artificial intelligence);Adaptive control;Stability analysis;Robot control;Adaptation models;Standards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989382&isnumber=7988677

W. Montgomery, A. Ajay, C. Finn, P. Abbeel and S. Levine, "Reset-free guided policy search: Efficient deep reinforcement learning with stochastic initial states," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3373-3380.
doi: 10.1109/ICRA.2017.7989383
Abstract: Autonomous learning of robotic skills can allow general-purpose robots to learn wide behavioral repertoires without extensive manual engineering. However, robotic skill learning must typically make trade-offs to enable practical real-world learning, such as requiring manually designed policy or value function representations, initialization from human demonstrations, instrumentation of the training environment, or extremely long training times. We propose a new reinforcement learning algorithm that can train general-purpose neural network policies with minimal human engineering, while still allowing for fast, efficient learning in stochastic environments. We build on the guided policy search (GPS) algorithm, which transforms the reinforcement learning problem into supervised learning from a computational teacher (without human demonstrations). In contrast to prior GPS methods, which require a consistent set of initial states to which the system must be reset after each episode, our approach can handle random initial states, allowing it to be used even when deterministic resets are impossible. We compare our method to existing policy search algorithms in simulation, showing that it can train high-dimensional neural network policies with the same sample efficiency as prior GPS methods, and can learn policies directly from image pixels. We also present real-world robot results that show that our method can learn manipulation policies with visual features and random initial states.
keywords: {Robots;Global Positioning System;Neural networks;Learning (artificial intelligence);Supervised learning;Training;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989383&isnumber=7988677

Y. Chebotar, M. Kalakrishnan, A. Yahya, A. Li, S. Schaal and S. Levine, "Path integral guided policy search," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3381-3388.
doi: 10.1109/ICRA.2017.7989384
Abstract: We present a policy search method for learning complex feedback control policies that map from high-dimensional sensory inputs to motor torques, for manipulation tasks with discontinuous contact dynamics. We build on a prior technique called guided policy search (GPS), which iteratively optimizes a set of local policies for specific instances of a task, and uses these to train a complex, high-dimensional global policy that generalizes across task instances. We extend GPS in the following ways: (1) we propose the use of a model-free local optimizer based on path integral stochastic optimal control (PI2), which enables us to learn local policies for tasks with highly discontinuous contact dynamics; and (2) we enable GPS to train on a new set of task instances in every iteration by using on-policy sampling: this increases the diversity of the instances that the policy is trained on, and is crucial for achieving good generalization. We show that these contributions enable us to learn deep neural network policies that can directly perform torque control from visual input. We validate the method on a challenging door opening task and a pick-and-place task, and we demonstrate that our approach substantially outperforms the prior LQR-based local policy optimizer on these tasks. Furthermore, we show that on-policy sampling significantly increases the generalization ability of these policies.
keywords: {Global Positioning System;Robots;Trajectory;Visualization;Training;Search methods;Stochastic processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989384&isnumber=7988677

S. Gu, E. Holly, T. Lillicrap and S. Levine, "Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3389-3396.
doi: 10.1109/ICRA.2017.7989385
Abstract: Reinforcement learning holds the promise of enabling autonomous robots to learn large repertoires of behavioral skills with minimal human intervention. However, robotic applications of reinforcement learning often compromise the autonomy of the learning process in favor of achieving training times that are practical for real physical systems. This typically involves introducing hand-engineered policy representations and human-supplied demonstrations. Deep reinforcement learning alleviates this limitation by training general-purpose neural network policies, but applications of direct deep reinforcement learning algorithms have so far been restricted to simulated settings and relatively simple tasks, due to their apparent high sample complexity. In this paper, we demonstrate that a recent deep reinforcement learning algorithm based on off-policy training of deep Q-functions can scale to complex 3D manipulation tasks and can learn deep neural network policies efficiently enough to train on real physical robots. We demonstrate that the training times can be further reduced by parallelizing the algorithm across multiple robots which pool their policy updates asynchronously. Our experimental evaluation shows that our method can learn a variety of 3D manipulation skills in simulation and a complex door opening skill on real robots without any prior demonstrations or manually designed representations.
keywords: {Robots;Training;Instruction sets;Learning (artificial intelligence);Neural networks;Safety;Heuristic algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989385&isnumber=7988677

J. Euler and O. von Stryk, "Optimized vehicle-specific trajectories for cooperative process estimation by sensor-equipped UAVs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3397-3403.
doi: 10.1109/ICRA.2017.7989386
Abstract: This paper presents a sequential optimum design approach for estimating the parameters of an atmospheric dispersion process model based on measurement data gathered by a team of cooperating sensor-equipped UAVs. Locally optimal waypoint sequences that account for each UAV's possibly heterogeneous motion dynamics are computed by minimizing a suitable optimality criterion. Following these waypoints, the UAVs cooperatively maximize the information gain of the acquired measurements. A decentralized data-driven online control scheme is proposed that couples parameter estimation, waypoint calculation, and vehicle control and enables the UAVs to adaptively observe the dynamic process and iteratively improve the parameter estimate. Simulations demonstrate the effectiveness of the proposed scheme in reducing the error between the estimated and the true dispersion model parameters compared to non-adaptive sensing strategies. In addition, the effect of using different optimality criteria, different numbers and types of UAVs as well as two options for decentralizing the waypoint calculation are investigated.
keywords: {Atmospheric modeling;Vehicle dynamics;Dynamics;Atmospheric measurements;Pollution measurement;Dispersion;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989386&isnumber=7988677

O. Erin, J. Giltinan, L. Tsai and M. Sitti, "Design and actuation of a magnetic millirobot under a constant unidirectional magnetic field," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3404-3410.
doi: 10.1109/ICRA.2017.7989387
Abstract: Magnetic untethered millirobots, which are actuated and controlled by remote magnetic fields, have been proposed for medical applications due to their ability to safely pass through tissues at long ranges. For example, magnetic resonance imaging (MRI) systems with a 3-7 T constant unidirectional magnetic field and 3D gradient coils have been used to actuate magnetic robots. Such magnetically constrained systems place limits on the degrees of freedom that can be actuated for untethered devices. This paper presents a design and actuation methodology for a magnetic millirobot that exhibits both position and orientation control in 2D under a magnetic field, dominated by a constant unidirectional magnetic field as found in MRI systems. Placing a spherical permanent magnet, which is free to rotate inside the millirobot and located away from the center of mass, allows the generation of net forces and torques with applied 3D magnetic field gradients. We model this system in a 3D planar case and experimentally demonstrate open-loop control of both position and orientation by the applied 2D field gradients. The actuation performance is characterized across the most important design variables, and we experimentally demonstrate that the proposed approach is feasible.
keywords: {Robots;Conferences;Automation;Intelligent systems;Mechanical engineering;Magnetic fields;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989387&isnumber=7988677

M. Giftthaler, F. Farshidian, T. Sandy, L. Stadelmann and J. Buchli, "Efficient kinematic planning for mobile manipulators with non-holonomic constraints using optimal control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3411-3417.
doi: 10.1109/ICRA.2017.7989388
Abstract: This work addresses the problem of kinematic trajectory planning for mobile manipulators with non-holonomic constraints, and holonomic operational-space tracking constraints. We obtain whole-body trajectories and time-varying kinematic feedback controllers by solving a Constrained Sequential Linear Quadratic Optimal Control problem. The employed algorithm features high efficiency through a continuous-time formulation that benefits from adaptive step-size integrators and through linear complexity in the number of integration steps. In a first application example, we solve kinematic trajectory planning problems for a 26 DoF wheeled robot. In a second example, we apply Constrained SLQ to a real-world mobile manipulator in a receding-horizon optimal control fashion, where we obtain optimal controllers and plans at rates up to 100 Hz.
keywords: {Kinematics;Planning;Trajectory;Optimal control;Robot kinematics;Heuristic algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989388&isnumber=7988677

N. Fazeli, E. Donlon, E. Drumwright and A. Rodriguez, "Empirical evaluation of common contact models for planar impact," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3418-3425.
doi: 10.1109/ICRA.2017.7989389
Abstract: In this paper we evaluate the predictive performance of six commonly used rigid body impact models on real planar impacts captured with a motion tracking system. We propose a metric to evaluate the performance of impact models on a task (based on predicting post impact momentum) and use this metric to tune the six parametric models. We evaluate model performance in predicting impact outcomes against the defined metric and discuss the implications of uncertainty in geometric models and initial conditions. We show that the models can fairly effectively predict the outcomes of single impacts on our chosen task. We motivate further study into consensus and hybrid impact models by showing that a hypothetical hybrid model would significantly outperform the isolated models by providing a post-hoc model that demonstrates an upper bound on the combined predictive power of the models. We use perturbation analysis to compute the predictive range of the models and show that bifurcations can cause the model predictions to cluster into regions of the state space.
keywords: {Predictive models;Computational modeling;Mathematical model;Robots;Adaptation models;Deformable models;Friction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989389&isnumber=7988677

P. S. Schmitt, W. Neubauer, W. Feiten, K. M. Wurm, G. V. Wichert and W. Burgard, "Optimal, sampling-based manipulation planning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3426-3432.
doi: 10.1109/ICRA.2017.7989390
Abstract: When robots perform manipulation tasks, they need to determine their own movement, as well as how to grasp and release an object. Reasoning about the motion of the robot and the object simultaneously leads to a multi-modal planning problem in a high-dimensional configuration space. In this paper we propose an asymptotically optimal manipulation planner. Our approach extends optimal sampling-based roadmap planners to efficiently explore the configuration space of the robot and the object. We prove probabilistic completeness and global, asymptotic optimality. Extensive simulations of a typical pick-and-place scenario show that our approach significantly outperforms a (nonoptimal) state-of-the-art approach. We implemented our planner on a real manipulator and were able to compute high quality solutions in less than a second.
keywords: {Planning;Nickel;Manipulators;Kinematics;Probabilistic logic;Buildings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989390&isnumber=7988677

T. Wiste and M. Goldfarb, "Design of a simplified compliant anthropomorphic robot hand," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3433-3438.
doi: 10.1109/ICRA.2017.7989391
Abstract: This paper introduces the SCCA Hand, a five motor robot hand developed using a minimalist design approach that focused on grasping abilities in real-world environments. Notable features include a novel bidirectional tendon underactuated finger design that biases actuator force toward finger flexion, an additive manufactured monocoque steel construction that enabled enhanced feature density and a low parts count, low grasp impedance by means of series elastic actuation, shock absorption for protection from impacts, and anthropomorphic speed, strength, and size. In addition to a description of its design, experimental characterizations of speed and force capabilities as well as demonstrated achievement of eight canonical grasps and postures are provided.
keywords: {Thumb;Tendons;Springs;Robots;Actuators;Grasping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989391&isnumber=7988677

J. A. Haustein, K. Hang and D. Kragic, "Integrating motion and hierarchical fingertip grasp planning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3439-3446.
doi: 10.1109/ICRA.2017.7989392
Abstract: In this work, we present an algorithm that simultaneously searches for a high quality fingertip grasp and a collision-free path for a robot hand-arm system to achieve it. The algorithm combines a bidirectional sampling-based motion planning approach with a hierarchical contact optimization process. Rather than tackling these problems in a decoupled manner, the grasp optimization is guided by the proximity to collision-free configurations explored by the motion planner. We implemented the algorithm for a 13-DoF manipulator and show that it is capable of efficiently planning reachable high quality grasps in cluttered environments. Further, we show that our algorithm outperforms a decoupled integration in terms of planning runtime.
keywords: {Planning;Robots;Approximation algorithms;Collision avoidance;Optimization;Kinematics;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989392&isnumber=7988677

P. Rao, G. C. Thomas, L. Sentis and A. D. Deshpande, "Analyzing achievable stiffness control bounds of robotic hands with coupled finger joints," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3447-3452.
doi: 10.1109/ICRA.2017.7989393
Abstract: The mechanical design of robotic hands has been converging towards low-inertia, tendon-driven strategies. As tendon driven robotic fingers are serial chain systems, routing strategies with compliant tendons lead to multi-articular coupling between the degrees of freedom. We propose a generalized analysis of such serial chain linkages with coupled passive joint stiffnesses. We analyze the effect of such coupling on maximum achievable stiffness control boundaries while maintaining passivity at the actuators by analytically deriving the boundaries. We believe that we can use this information to form mechanical design guidelines for intelligently selecting arrangements of compliance elements (mechanical springs) and transmission strategies, i.e. tendon routing and pulley radii, to provide intrinsic stability and customizable controller stiffness limits for high performance manipulation in robotic hands.
keywords: {Tendons;Joints;Torque;Springs;Actuators;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989393&isnumber=7988677

W. G. Bircher, A. M. Dollar and N. Rojas, "A two-fingered robot gripper with large object reorientation range," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3453-3460.
doi: 10.1109/ICRA.2017.7989394
Abstract: It is very challenging for a robotic gripper to achieve large reorientations with grasped objects without accidental object ejection. This paper presents a simple gripper that can repeatedly achieve large reorientations over π/2 rad through the kinematics of the hand-object system alone, without the use of high fidelity contact sensors, complex control of active finger surfaces, or highly actuated fingers. This gripper is the result of two kinematic parameter search optimizations connected in cascade. Besides the large range of reorientation attained, the obtained gripper also corresponds to a novel topology since ternary joints in the palm are presented. The in-hand planar reorientation capabilities of the proposed gripper are experimentally tested with success.
keywords: {Grippers;Thumb;Couplings;Mathematical model;Friction;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989394&isnumber=7988677

K. Yamamoto, "Robust walking by resolved viscoelasticity control explicitly considering structure-variability of a humanoid," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3461-3468.
doi: 10.1109/ICRA.2017.7989395
Abstract: This paper discusses the resolved viscoelasticity control (RVC) method that explicitly considers the structure-variability for a humanoid. In a previous report, the author proposed resolving the virtual viscoelasticity at the center of gravity into the joint viscoelasticity considering redundant degrees of freedom, and named this method as RVC. However, the author considered only the single support phase; therefore, the humanoid could be regarded as an open kinematic chain and the RVC was implemented easily. In this paper, the author extends the previous work on the RVC by considering structure-variability - the method now considers an open kinematic chain in the single support phase and a closed kinematic chain in the double support phase. This extension helps realize stable and robust walking motion on uneven terrains. The proposed method is validated using forward dynamics simulations.
keywords: {Kinematics;Jacobian matrices;Trajectory;Viscosity;Legged locomotion;Springs;Foot},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989395&isnumber=7988677

D. Wilbers, R. Lioutikov and J. Peters, "Context-driven movement primitive adaptation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3469-3475.
doi: 10.1109/ICRA.2017.7989396
Abstract: Humanlike robot skills, e.g., cleaning a table or handing over a plate, can often be generalized to different task variations. Usually, these are start-/goal position, and trained environment changes. We investigate how to modify motion primitives to context changes, which are not included in the training data. Specifically, we focus on maintaining humanlike motion characteristics and generalizability, while adapting to unseen context. Therefore, we present an optimization technique, which maximizes the expected return and minimizes the Kullback-Leibler Divergence to the demonstrations at the same time. Simultaneously, our algorithm learns how to linearly combine the adapted primitive with the demonstrations, such that only relevant parts of the primitive are adapted. We evaluate our approach in obstacle avoidance and broken joint scenarios in simulation, as well as on a real robot.
keywords: {Trajectory;Robots;Optimization;Shape;Mathematical model;Gaussian distribution;Standards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989396&isnumber=7988677

X. Da, R. Hartley and J. W. Grizzle, "Supervised learning for stabilizing underactuated bipedal robot locomotion, with outdoor experiments on the wave field," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3476-3483.
doi: 10.1109/ICRA.2017.7989397
Abstract: Supervised learning is used to build a control policy for robust, stable, dynamic walking of an underactuated bipedal robot. The training and testing sets consist of controllers based on a full dynamic model, virtual constraints, and parameter optimization to meet torque limits, friction cone, and environmental conditions. The controllers are designed to induce locally exponentially stable periodic walking gaits at various speeds, both forward and backward, and for various constant ground slopes. They are also designed to induce aperiodic gaits that transition among a subset of the periodic gaits in a fixed number of steps. In experiments, the learned policy allows a 3D bipedal robot to recover from a significant kick. It also enables the robot to walk down a 22 degree slope and walk on sinusoidally varying terrain, all without using a camera. During the development of these results, it is demonstrated that supervised learning of locally exponentially stable controllers can result in a loss of stability and a means to avoid this is suggested.
keywords: {Legged locomotion;Optimization;Supervised learning;Training;Testing;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989397&isnumber=7988677

M. Azad, J. Babič and M. Mistry, "Dynamic manipulability of the center of mass: A tool to study, analyse and measure physical ability of robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3484-3490.
doi: 10.1109/ICRA.2017.7989398
Abstract: This paper introduces dynamic manipulability of the center of mass (CoM) as a metric to measure robots' physical abilities to accelerate their CoMs in different directions. By decomposing the effects of velocity dependent constraints, such as unilateral contacts and friction cones, CoM dynamic manipulability is defined as a velocity independent metric which depends only on robot's configuration and inertial parameters. Thus, this metric is independent of any choice of controller and expresses only physical abilities of robots. This important property makes the proposed metric a proper tool to study, analyse and design current and future robots. The outcome of the CoM dynamic manipulability analysis in this paper is an ellipsoid in the CoM acceleration space which graphically shows accessible points due to the unit weighted norm of joint torques. Physical meanings and concepts of two reasonable choices for the weighting matrix, which is used in the weighted norm of joint torques, are discussed and illustrative examples are presented. Since the proposed metric measures physical ability to accelerate the CoM, it is claimed to be a suitable tool to study balance ability of legged robots.
keywords: {Acceleration;Measurement;Jacobian matrices;Ellipsoids;Robot kinematics;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989398&isnumber=7988677

Y. You, C. Zhou, Z. Li and N. Tsagarakis, "A study of nonlinear forward models for dynamic walking," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3491-3496.
doi: 10.1109/ICRA.2017.7989399
Abstract: This paper offers a novel insight of using nonlinear models for the control to produce more robust and natural walking gaits for humanoid robots. The sagittal and lateral gait control needs to be treated differently, hence, we proposed two types of suitable nonlinear models, which allow forward simulations to look ahead, and thus, predict accurately the future trajectory/state at the end of the current step. Subsequently, by performing multiple forward simulations in a similar manner for the next step and using the gradient descent method, an appropriate foot placement can be found to achieve precise walking speed. By doing this two-step lookahead, all trajectories of the support and the swing leg can be generated. Our proposed controller can plan trajectories at the beginning of each step or actively re-plan according to task state errors. It is validated effectively in simulations performed in both ADAMS and Open Dynamic Engine. The robot can successfully traverse up/down a stair and recover from pushes with more natural looking gaits compared to the conventional bent-knee style. The reasonable computational time also indicates the feasibility of real-time implementation on real robots.
keywords: {Legged locomotion;Foot;Computational modeling;Mathematical model;Predictive models;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989399&isnumber=7988677

J. Z. Tang, A. M. Boudali and I. R. Manchester, "Invariant funnels for underactuated dynamic walking robots: New phase variable and experimental validation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3497-3504.
doi: 10.1109/ICRA.2017.7989400
Abstract: We address the problem of finding useful invariant funnels for dynamic walking robots, i.e. sets of initial conditions from which continued walking in a stable manner is guaranteed. The construction is based on transverse dynamics and sum-of-squares verification. This paper makes two main contributions: firstly, we show that for typical models of walking robots the construction of such funnels can be significantly simplified by use of a new phase variable. Secondly, we provide the first hardware validation of the resulting funnels on an experimental testbed.
keywords: {Legged locomotion;Trajectory;Switches;Stability analysis;Power system stability;Hardware},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989400&isnumber=7988677

M. Shafiee-Ashtiani, A. Yousefi-Koma and M. Shariat-Panahi, "Robust bipedal locomotion control based on model predictive control and divergent component of motion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3505-3510.
doi: 10.1109/ICRA.2017.7989401
Abstract: In this paper, previous works on the Model Predictive Control (MPC) and the Divergent Component of Motion (DCM) for bipedal walking control are extended. To this end, we employ a single MPC which uses a combination of Center of Pressure (CoP) manipulation, step adjustment, and Centroidal Moment Pivot (CMP) modulation to design a robust walking controller. Furthermore, we exploit the concept of time-varying DCM to generalize our walking controller for walking in uneven surfaces. Using our scheme, a general and robust walking controller is designed which can be implemented on robots with different control authorities, for walking on various environments, e.g. uneven terrains or surfaces with a very limited feasible area for stepping. The effectiveness of the proposed approach is verified through simulations on different scenarios and comparison to the state of the art.
keywords: {Legged locomotion;Robustness;Mathematical model;Trajectory;Modulation;Humanoid robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989401&isnumber=7988677

R. Wang, S. Wang, Y. Wang and C. Tang, "Path following for a biomimetic underwater vehicle based on ADRC," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3519-3524.
doi: 10.1109/ICRA.2017.7989402
Abstract: This paper addresses the problem of path following for a biomimetic underwater vehicle (BUV) propelled by undulatory fins with uncertain model and unknown disturbance. The mechanical structure of the BUV is briefly described. Moreover, the general kinematics and dynamics models of the vehicle are presented and the path following problem is formulated. The controller combining line-of-sight (LOS) guidance system with active disturbance rejection control (ADRC) technique is designed to maneuver the BUV to follow a predefined parameterized curve. Specifically, a guidance system based on LOS principle is implemented to decouple the multi-variable system to steer the surge speed and the course respectively. Furthermore, in order to deal with model uncertainty, ADRC is used in development of the surge speed controller and the course controller. Finally, simulations and experimental results validated the performance of the proposed path following control scheme.
keywords: {Propulsion;Surges;Force;Underwater vehicles;Real-time systems;Damping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989402&isnumber=7988677

I. Rañó, M. Khamassi and K. Wong-Lin, "A drift diffusion model of biological source seeking for mobile robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3525-3531.
doi: 10.1109/ICRA.2017.7989403
Abstract: Braitenberg vehicles have been used in multiple real world robotic implementations of bio-inspired local navigation. While sensor based control strategies - including existing models of Braitenberg vehicles - typically neglect sensor noise, real robot implementations suffer from different levels of noise, especially in the case of low cost robots and highly stochastic environments. This paper presents a novel drift-diffusion model of Braitenberg vehicle 3a - a bio-inspired source seeking controller for non-holonomic robots - accounting for the sensor noise. The stochastic differential equations obtained provide means to accurately simulate the behaviour of this bio-inspired control mechanism. Although these equations do not have analytic solutions in general, under some simplifying assumptions, we obtain the deterministic equations for the average and dispersion of the vehicles while performing source seeking. Moreover, we found an analytic bound for the distribution of the heading direction of the robots. Simulations illustrate and confirm the theoretical results presented.
keywords: {Robot sensing systems;Mathematical model;Stochastic processes;Biological system modeling;Differential equations;Wheels},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989403&isnumber=7988677

A. H. Chang and P. A. Vela, "Closed-loop path following of traveling wave rectilinear motion through obstacle-strewn terrain," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3532-3537.
doi: 10.1109/ICRA.2017.7989404
Abstract: High-level, closed-loop traversal through obstacle-strewn environments remains an open and challenging endeavor for snake-like robotic platforms. Rectilinear forms of locomotion, despite their unique mobility advantages compared to other gait shapes, have seen relatively little progress toward this objective. A dynamical exposition of traveling wave rectilinear motion is reviewed and applied to generate a functional mapping from gait parameter space to corresponding averaged steady-behavior body velocities. We demonstrate the system dynamics, in this case, resemble that of a fixed forward-velocity unicycle where average body curvature presents itself as a versatile control input, modulating angular body velocity in a linear manner. Target body velocities computed to track non-trivial planned paths, then, are mapped to average body curvature commands, enabling autonomous path following, by a physical, multi-link robotic snake, through a series of distinct obstacle arrangements.
keywords: {Robots;Shape;Mathematical model;Dynamics;Friction;Tracking;Numerical models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989404&isnumber=7988677

B. Goldberg, N. Doshi and R. J. Wood, "High speed trajectory control using an experimental maneuverability model for an insect-scale legged robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3538-3545.
doi: 10.1109/ICRA.2017.7989405
Abstract: This paper presents an off-board trajectory controller for a range of stride frequencies (2-45 Hz) that enables zero-radius turns and holonomic control on one of the smallest and fastest legged robots, the Harvard Ambulatory MicroRobot (HAMR). An experimental model is used as the basis for control to capture the highly nonlinear response of the robot to input signals. Closed-loop trajectories are performed with an RMS position error at or below 0.3 body lengths (BL) using gaits at speeds up to 6.5 BL/s (29.4 cm/s) for straight-line and sinusoidal trajectories.
keywords: {Legged locomotion;Heat-assisted magnetic recording;Trajectory;Actuators;Frequency control;Voltage control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989405&isnumber=7988677

C. Zhang, J. Triesch and B. E. Shi, "Learning multisensory cue integration on mobile robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3546-3551.
doi: 10.1109/ICRA.2017.7989406
Abstract: Developmental robotics seeks to build robots that learn to interact with the environment largely autonomously. These robots can calibrate their sensorimotor competencies on their own, much like developing children. In this paper, we build a developmental model of image stabilization based on the active efficient coding (AEC) framework and apply the model to a real robotic platform. In the visual system of primates, the optokinetic response (OKR) and the vestibulo-ocular reflex (VOR) cooperate to ensure image stabilization during relative motion between the observer and the environment. Inspired by these biological findings, our model integrates visual, inertial and motor encoder sensory cues. The sensory processing and the motor policy co-develop. The visual processing is based on a sparse coding algorithm. Motor behavior is learned using reinforcement learning. Our results show that the stabilization performance is improved by integrating visual and inertial inputs. Importantly, the weighting between the two inputs is learned automatically as the robot interacts with the environment.
keywords: {Robot sensing systems;Visualization;Neurons;Cameras;Head},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989406&isnumber=7988677

R. Emery, F. Rahbar, A. Marjovi and A. Martinoli, "Adaptive Lévy Taxis for odor source localization in realistic environmental conditions," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3552-3559.
doi: 10.1109/ICRA.2017.7989407
Abstract: Odor source localization with mobile robots has recently been subject to many research works, but remains a challenging task mainly due to the large number of environmental parameters that make it hard to describe gas concentration fields. We designed a new algorithm called Adaptive Lévy Taxis (ALT) to achieve odor plume tracking through a correlated random walk. In order to compare its performances with well-established solutions, we have implemented three moth-inspired algorithms on the same robotic platform. To improve the performance of the latter algorithms, we developed a rigorous way to determine one of their key parameters, the odor concentration threshold at which the robot considers to be inside or outside the plume. The methods have been systematically evaluated in a large wind tunnel under various environmental conditions. Experiments revealed that the performance of ALT is consistently good in all environmental conditions (in particular when compared to the three reference algorithms) in terms of both distance traveled to find the source and success rate.
keywords: {Robots;Public transportation;Algorithm design and analysis;Hidden Markov models;Probability distribution;Complexity theory;Classification algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989407&isnumber=7988677

U. A. Syed, A. Ramezani, S. -J. Chung and S. Hutchinson, "From Rousettus aegyptiacus (bat) landing to robotic landing: Regulation of CG-CP distance using a nonlinear closed-loop feedback," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3560-3567.
doi: 10.1109/ICRA.2017.7989408
Abstract: Bats are unique in that they can achieve unrivaled agile maneuvers due to their functionally versatile wing conformations. Among these maneuvers, roosting (landing) has captured attentions because bats perform this acrobatic maneuver with a great composure. This work attempts to reconstruct bat landing maneuvers with a Micro Aerial Vehicle (MAV) called Allice. Allice is capable of adjusting the position of its Center of Gravity (CG) with respect to the Center of Pressure (CP) using a nonlinear closed-loop feedback. This nonlinear control law, which is based on the method of input-output feedback linearization, enables attitude regulations through variations in CG-CP distance. To design the model-based nonlinear controller, the Newton-Euler dynamic model of the robot is considered, in which the aerodynamic coefficients of lift and drag are obtained experimentally. The performance of the proposed control architecture is validated by conducting several experiments.
keywords: {Attitude control;Aerodynamics;Animals;Abdomen;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989408&isnumber=7988677

F. Tang, B. Si and D. Ji, "A prey-predator model for efficient robot tracking," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3568-3574.
doi: 10.1109/ICRA.2017.7989409
Abstract: Tracking is a common topic in various areas of robotics research. Motivated by the hunting behavior of predators in nature, we propose a prey-predator model for efficient robot tracking. The head direction and speed of the pursuer is automatically adjusted according to the position and velocity of the prey. Under the situation with perception uncertainty, where the actual location of the prey is not observable, the pursuer predicts the location of the prey according to simple inference, an online adaptive autoregressive model, or an online adaptive echo state network. Simulation results demonstrate that the proposed prey-predator model is able to control the pursuer and to track the prey efficiently, even under perception uncertainty. Simple inference gives better results when the motion of the target is piecewise linear, while echo state network is more suitable when the dynamics of the target are more complex. The proposed prey-predator model thus provides an efficient method tracking targets with various statistical nature of trajectories for applications such as underwater robot tracking, human tracking and team formation.
keywords: {Target tracking;Kalman filters;Navigation;Mobile robots;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989409&isnumber=7988677

C. Hu et al., "In vivo tracking and measurement of pollen tube vesicle motion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3575-3580.
doi: 10.1109/ICRA.2017.7989410
Abstract: Particle tracking has emerged as a powerful tool for investigating the swarm control of microrobots and the dynamic biological processes in the life sciences. In seed plants, pollen tubes, a part of the male gametophyte, are excellent models for understanding plant growth and cellular behavior, because vesicle motion within pollen tubes reveals important information about vesicle function and interactions. Conventional vesicle tracking is based on spatiotemporal image analysis, which requires high-quality images and vesicles with constant velocity. For in vivo tracking, vesicles may disappear in some frames, and image sequences may have spatial and temporal distortions, which hamper vesicle tracking for broader applications. In this paper, we studied intracellular motion during pollen tube growth with an optical flow method. Streaming images from confocal and optical microscopes were recorded to study the intracellular motion of vesicles of different size. Local motion for each vesicle was detected using a local displacement vector field. The displacement from two adjacent frames was then calculated. The flow field shows information such as the dynamics of vesicle secretion, endocytosis, exocytosis, and cytoskeletal stability. Vesicles from different regions inside the tube were tracked simultaneously with a Kanade-Lucas-Tomasi (KLT) feature matching algorithm. The spatial and temporal characteristics of intracellular vesicles were evaluated. The proposed methods can be of great use for studying the dynamics of fluorescently tagged particles in biological systems.
keywords: {Electron tubes;Optical imaging;Tracking;Videos;Optical filters;Biomedical optical imaging;Optical recording},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989410&isnumber=7988677

Z. Li, P. Moran, Q. Dong, R. J. Shaw and K. Hauser, "Development of a tele-nursing mobile manipulator for remote care-giving in quarantine areas," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3581-3586.
doi: 10.1109/ICRA.2017.7989411
Abstract: During outbreaks of contagious diseases, healthcare workers are at high risk for infection due to routine interaction with patients, handling of contaminated materials, and challenges associated with safely removing protective gear. This poses an opportunity for the use of remote-controlled robots that could perform common nursing duties inside hazardous clinical areas, thereby minimizing the exposure of healthcare workers to contagions and other biohazards. This paper describes the development of the prototype system Tele-Robotic Intelligent Nursing Assistant (TRINA), which consists of a mobile manipulator robot, a human operator's console, and operator assistance algorithms which automate or partially-automate tedious and error-prone tasks. Using off-the-shelf robotic and sensing components, total hardware costs are kept under $75,000. The system's capabilities for performing standard nursing tasks are evaluated in the simulation laboratory of a nursing school.
keywords: {Medical services;Robot sensing systems;Robot kinematics;Collision avoidance;Mobile communication;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989411&isnumber=7988677

L. Zhang, M. Ye, P. Giataganas, M. Hughes and G. Yang, "Autonomous scanning for endomicroscopic mosaicing and 3D fusion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3587-3593.
doi: 10.1109/ICRA.2017.7989412
Abstract: Robot-assisted minimally invasive surgery can benefit from the automation of common, repetitive or well-defined but ergonomically difficult tasks. One such task is the scanning of a pick-up endomicroscopy probe over a complex, undulating tissue surface to enhance the effective field-of-view through video mosaicing. In this paper, the da Vinci® surgical robot, through the dVRK framework, is used for autonomous scanning and 2D mosaicing over a user-defined region of interest. To achieve the level of precision required for high quality mosaic generation, which relies on sufficient overlap between consecutive image frames, visual servoing is performed using a combination of a tracking marker attached to the probe and the endomicroscopy images themselves. The resulting sub-millimetre accuracy of the probe motion allows for the generation of large mosaics with minimal intervention from the surgeon. Images are streamed from the endomicroscope and overlaid live onto the surgeons view, while 2D mosaics are generated in real-time, and fused into a 3D stereo reconstruction of the surgical scene, thus providing intuitive visualisation and fusion of the multi-scale images. The system therefore offers significant potential to enhance surgical procedures, by providing the operator with cellular-scale information over a larger area than could typically be achieved by manual scanning.
keywords: {Probes;Trajectory;Three-dimensional displays;Robots;Surface reconstruction;Cameras;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989412&isnumber=7988677

J. Sikorski, I. Dawson, A. Denasi, E. E. G. Hekman and S. Misra, "Introducing BigMag — A novel system for 3D magnetic actuation of flexible surgical manipulators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3594-3599.
doi: 10.1109/ICRA.2017.7989413
Abstract: Magnetic interaction can be utilized for remote actuation of surgical manipulators. However, platforms currently available for that purpose have limited workspaces, inadequate field strength or very low bandwidth of the electrical subsystem. In this paper, we present BigMag, a novel platform capable of magnetic steering of continuum manipulators for medical purposes. BigMag comprises of 6 mobile coils and is capable of generating the fields of at least 40 mT in any direction at every point of its workspace. Moreover, we introduce a mathematical model for 3D mobile coil arrays. Each coil is modelled using finite element data adjusted by measurement-based correction, (a maximum observed mean error between the model and the prediction of 3.36 ± 5.62%). The model for a full system is validated in two tasks. In the first task, the system executes a prescribed rotating field (mean error between the model and measurement of 7.51% and minimum R2 of 0.964). The second task tests the estimation of the field for known 3D trajectories (minimum R2 of 0.967). The investigation concludes with a demonstration of BigMag capabilities in actuation of magnetic catheters in confined spaces usinguser-controlled steering.
keywords: {Coils;Manipulators;Mathematical model;Mobile communication;Magnetic hysteresis;Three-dimensional displays;Bandwidth},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989413&isnumber=7988677

T. Greigarn, R. Jackson, T. Liu and M. C. Çavuşoğlu, "Experimental validation of the pseudo-rigid-body model of the MRI-actuated catheter," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3600-3605.
doi: 10.1109/ICRA.2017.7989414
Abstract: An MRI-actuated catheter is a novel robotic catheter system that utilizes the MRI for both remote steering and visualization for catheter ablation of atrial fibrillation. Planning and control of the catheter requires a sufficiently fast yet accurate model of the catheter. The pseudo-rigid-body (PRB) model offers a reasonable trade-off between speed and accuracy by approximating the continuum catheter as rigid links connected by flexible joints, thus reducing the infinite degrees of freedom of the continuum mechanism to a finite one. In this paper, a PRB model of the MRI-actuated catheter is validated experimentally by comparing the deflections of the PRB model with the deflections of the catheter prototype.
keywords: {Catheters;Load modeling;Mathematical model;Optimization;Robots;Magnetic resonance imaging;Numerical models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989414&isnumber=7988677

R. C. Luo, C. P. Tsai and K. C. Hsieh, "Robot assisted tapping control for therapeutical percussive massage applications," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3606-3611.
doi: 10.1109/ICRA.2017.7989415
Abstract: The objective of this paper is to present a percussive massage based on robotic tapping motion, and it is also the first paper to discuss the massage technique for this kind. The tapping motion is different from the common contact motion, it satisfies with the short-time contact on human muscles, and the robot end-effector itself has an initial velocity and acceleration to make an impulse contact. After contacting with human muscles, the robot manipulator stops and end-effector repeatedly performs the tapping motion. To tackle with the tapping motion problems, we utilize the online trajectory generator (OTG) based on the impedance control, which ensures the safety of human without any possible accident which can hurt human. We implement the tapping motion with a dual arm robot developed at the iCeiRA lab in NTU. By the Cartesian space teach function and the concept of virtual point, the tapping force and contact position can be changed adaptively to meet different needs.
keywords: {Force;Acceleration;Manipulators;Muscles;Trajectory;Impedance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989415&isnumber=7988677

B. Dahroug, B. Tamadazte and N. Andreff, "Visual servoing controller for time-invariant 3D path following with remote centre of motion constraint," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3612-3618.
doi: 10.1109/ICRA.2017.7989416
Abstract: The Remote Centre of Motion (RCM) is an essential movement for most of the medical robotic systems during the minimal invasive surgeries. In literature, there are many references which had analysed the techniques for modelling the problem of RCM constraint. However, only very few have discussed the RCM with Path Following Controller which ensures the complexity of surgical tasks. Therefore, this article is focusing on presenting the Task Priority Controller. Such task controller deploys exteroceptive sensor (visual servoing scheme) in order that the surgical tool follows the reference path while maintaining the RCM constraints. The experimental results showed good performance of the proposed controller.
keywords: {Tools;Mathematical model;Trajectory tracking;Visual servoing;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989416&isnumber=7988677

S. Bargoti and J. Underwood, "Deep fruit detection in orchards," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3626-3633.
doi: 10.1109/ICRA.2017.7989417
Abstract: An accurate and reliable image based fruit detection system is critical for supporting higher level agriculture tasks such as yield mapping and robotic harvesting. This paper presents the use of a state-of-the-art object detection framework, Faster R-CNN, in the context of fruit detection in orchards, including mangoes, almonds and apples. Ablation studies are presented to better understand the practical deployment of the detection network, including how much training data is required to capture variability in the dataset. Data augmentation techniques are shown to yield significant performance gains, resulting in a greater than two-fold reduction in the number of training images required. In contrast, transferring knowledge between orchards contributed to negligible performance gain over initialising the Deep Convolutional Neural Network directly from ImageNet features. Finally, to operate over orchard data containing between 100-1000 fruit per image, a tiling approach is introduced for the Faster R-CNN framework. The study has resulted in the best yet detection performance for these orchards relative to previous works, with an F1-score of > 0.9 achieved for apples and mangoes.
keywords: {Object detection;Image color analysis;Training;Land vehicles;Robot sensing systems;Computer vision},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989417&isnumber=7988677

T. Mueller-Sim, M. Jenkins, J. Abel and G. Kantor, "The Robotanist: A ground-based agricultural robot for high-throughput crop phenotyping," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3634-3639.
doi: 10.1109/ICRA.2017.7989418
Abstract: The established processes for measuring physiological and morphological traits (phenotypes) of crops in outdoor test plots are labor intensive and error-prone. Low-cost, reliable, field-based robotic phenotyping will enable geneticists to more easily map genotypes to phenotypes, which in turn will improve crop yields. In this paper, we present a novel robotic ground-based platform capable of autonomously navigating below the canopy of row crops such as sorghum or corn. The robot is also capable of deploying a manipulator to measure plant stalk strength and gathering phenotypic data with a modular array of non-contact sensors. We present data obtained from deployments to Sorghum bicolor test plots at various sites in South Carolina, USA.
keywords: {Robot sensing systems;Navigation;Agriculture;Cameras;Payloads},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989418&isnumber=7988677

J. Chen and S. Shen, "Improving octree-based occupancy maps using environment sparsity with application to aerial robot navigation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3656-3663.
doi: 10.1109/ICRA.2017.7989419
Abstract: In this paper, we present an improved octree-based mapping framework for autonomous navigation of mobile robots. Octree is best known for its memory efficiency for representing large-scale environments. However, existing implementations, including the state-of-the-art OctoMap [1], are computationally too expensive for online applications that require frequent map updates and inquiries. Utilizing the sparse nature of the environment, we propose a ray tracing method with early termination for efficient probabilistic map update. We also propose a divide-and-conquer volume occupancy inquiry method which serves as the core operation for generation of free-space configurations for optimization-based trajectory generation. We experimentally demonstrate that our method maintains the same storage advantage of the original OctoMap, but being computationally more efficient for map update and occupancy inquiry. Finally, by integrating the proposed map structure in a complete navigation pipeline, we show autonomous quadrotor flight through complex environments.
keywords: {Octrees;Navigation;Robot sensing systems;Ray tracing;Three-dimensional displays;Planning;Complexity theory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989419&isnumber=7988677

R. Kurazume, Y. Pyo, K. Nakashima, A. Kawamura and T. Tsuji, "Feasibility study of IoRT platform “Big Sensor Box”," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3664-3671.
doi: 10.1109/ICRA.2017.7989420
Abstract: This paper proposes new software and hardware platforms named ROS-TMS and Big Sensor Box, respectively, for an informationally structured environment. We started the development of a management system for an informationally structured environment named Town Management System (TMS) in the Robot Town Project in 2005. Since then we have been continuing our efforts to improve performance and to enhance TMS functions. Recently, we launched a new version of TMS named ROS-TMS, which resolves some critical problems in TMS by adopting the Robot Operating System (ROS) and utilizing the high scalability and numerous resources of ROS. In this paper, we first discuss the structure of a software platform for the informationally structured environment and describe in detail our latest system, ROS-TMS version 4.0. Next, we introduce a hardware platform for the informationally structured environment named Big Sensor Box, in which a variety of sensors are embedded and service robots are operated according to the structured information under the management of ROS-TMS. Robot service experiments including a fetch-and-give task and autonomous control of a wheelchair robot are also conducted in Big Sensor Box.
keywords: {Service robots;Cameras;Databases;Robot vision systems;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989420&isnumber=7988677

T. Le, S. Gibb, N. Pham, H. M. La, L. Falk and T. Berendsen, "Autonomous robotic system using non-destructive evaluation methods for bridge deck inspection," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3672-3677.
doi: 10.1109/ICRA.2017.7989421
Abstract: Bridge condition assessment is important to maintain the quality of highway roads for public transport. Bridge deterioration with time is inevitable due to aging material, environmental wear and in some cases, inadequate maintenance. Non-destructive evaluation (NDE) methods are preferred for condition assessment for bridges, concrete buildings, and other civil structures. Some examples of NDE methods are ground penetrating radar (GPR), acoustic emission, and electrical resistivity (ER). NDE methods provide the ability to inspect a structure without causing any damage to the structure in the process. In addition, NDE methods typically cost less than other methods, since they do not require inspection sites to be evacuated prior to inspection, which greatly reduces the cost of safety related issues during the inspection process. In this paper, an autonomous robotic system equipped with three different NDE sensors is presented. The system employs GPR, ER, and a camera for data collection. The system is capable of performing real-time, cost-effective bridge deck inspection, and is comprised of a mechanical robot design and machine learning and pattern recognition methods for automated steel rebar picking to provide realtime condition maps of the corrosive deck environments.
keywords: {Bridges;Ground penetrating radar;Inspection;Robot sensing systems;Erbium},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989421&isnumber=7988677

M. Nakajima et al., "High-precision microinjection of microbeads into C. elegans trapped in a suction microchannel," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3678-3683.
doi: 10.1109/ICRA.2017.7989422
Abstract: This study presents the high-precision microinjection of fluorescent micro-gel beads into Caenorhabditis elegans trapped in a suction microchannel. In our previous works, we demonstrated survival microinjection by a conventional micromanipulation technique. However, the focal planes differed between the tip of the microinjection tool and the target axon inside the C. elegans body. To resolve this problem, we here propose a suction microchannel that traps C. elegans during the microinjection operation. The focal plane of the target nerve axon matches that of the fluorescent microbead in the microinjection tool, enabling high-precision microinjection into the interior of the C. elegans body under a microscopic view. In an experimental evaluation, the positioning accuracy of the injection into C. elegans was within the target accuracy (15 μm). The head-flrst navigation alignment of C. elegans along the microchannel was controlled by electrotaxis. Injection of the fluorescent micro-gel bead into the C. elegans body was quantitatively confirmed by confocal microscopy.
keywords: {Microchannels;Microinjection;Axons;Tools;Microscopy;Fluorescence;Silicon},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989422&isnumber=7988677

J. Kwak, C. Lee, J. Kim, S. Kim and S. Oh, "Wire-tension control using Compact Planetary geared Elastic Actuator," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3684-3689.
doi: 10.1109/ICRA.2017.7989423
Abstract: The tension control of wires can benefit from Series Elastic Actuator (SEA), which is a potential emerging actuator system. In this paper, it is verified that the tension of wires can be successfully controlled by a novel SEA, called Compact Planetary-geared Elastic Actuator (cPEA), which incorporates a planetary gear and a spring to achieve precise force sensing and compactness at the same time. The design of model-based tension control and impedance compensator using cPEA is introduced, and the experiments that show the effectiveness of the proposed control are provided.
keywords: {Wires;Impedance;Gears;Actuators;Force;Springs;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989423&isnumber=7988677

U. Jeong and K. -J. Cho, "A feasibility study on tension control of Bowden-cable based on a dual-wire scheme," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3690-3695.
doi: 10.1109/ICRA.2017.7989424
Abstract: A critical issue for Bowden-cable transmission is bending-dependent hysteresis that degrades control performance and limits the application. The relationship between input and output of the Bowden-cable varies with the changing bending angle of the cable. This paper proposes a novel method that can compensate the varying hysteresis of the Bowden-cable using an embedded auxiliary wire, called a sensing wire. The accumulated bend angle of the Bowden-cable can be estimated by measuring the displacement change of the sensing wire and the input tension of the actuation wire. The estimated bending angle of the sheath can be used to compensate the hysteresis of the Bowden-cable with a feedforward control scheme, even though it is subject to the varying shape of the Bowden-cable. The proposed system has a simple and fully embedded design inside the sheath and does not require any external shape sensor or output tension sensor, which keeps the size and complexity of the system low. The results show that the control error of output tension decreased from 4.22 N to 0.69 N when the bend angle of the Bowden-cable changes from 0° to 560°.
keywords: {Wires;Robot sensing systems;Friction;Hysteresis;Shape;Estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989424&isnumber=7988677

W. -B. Lee, S. -D. Lee and J. -B. Song, "Design of a 6-DOF collaborative robot arm with counterbalance mechanisms," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3696-3701.
doi: 10.1109/ICRA.2017.7989425
Abstract: Most collaborative robots use high-power motors for a good weight-to-payload ratio, thus leading to not only an increase in manufacturing cost but also possibility of injury at a collision between a human and a robot. To maintain high-performance with low-power driving units, a spring-based counterbalance mechanism (CBM) and a robot arm based on these CBMs were developed in our previous study. In this study, a 6-DOF collaborative robot equipped with a multi-DOF CBM is proposed. A double parallelogram linkage and a slider-crank mechanism are employed for a compact and durable design of a multi-DOF CBM. Unlike the previous prototypes in which some portions of CBMs were protruded out of the robot body due to their large volume, the proposed CBMs can be embedded inside the robot links. The performance of the developed CBM and collaborative robot were verified based on simulations using dynamic simulation software. Simulation results show that the proposed CBMs can effectively reduce the joint torques required to operate the robot. This reduction in the torque enables low-power motors to be used in a collaborative robot, thus significantly improving collision safety and energy efficiency.
keywords: {Couplings;Torque;Collaboration;Collision avoidance;Springs;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989425&isnumber=7988677

Y. Hirata, R. Shirai and K. Kosuge, "Position and orientation control of passive wire-driven motion support system using servo brakes," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3702-3707.
doi: 10.1109/ICRA.2017.7989426
Abstract: Wire-driven haptic devices can easily achieve highspeed operation because of the low inertia of light and thin wires. Therefore, it is expected to be widely used as a motion support system in fields such as sports training. However, usually these wires are driven by controlling each wire's tension using servo motors, which raises concerns about the safety in human-robot interaction. Thus, we propose to support the user by controlling servo brakes instead of motors, which can ensure safety. In this paper, we introduce a passive wire-driven system without any motors for realistic motion support in sports training. The system can measure the user motion and support the user while following a target form by a novel passive control method considering the orientation as well as the position using 7 wires' lengths and the brake tensions. We also conduct error evaluation experiments and show that a tennis beginner using this system can accurately follow the target form.
keywords: {Wires;Brakes;Servomotors;Haptic interfaces;Training;Force;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989426&isnumber=7988677

Y. Song and D. Luchtenburg, "Using compliant leg design for impact attenuation of airdrop landings of quadruped robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3708-3713.
doi: 10.1109/ICRA.2017.7989427
Abstract: Most airdropped cargo use a combination of one or more parachutes and an impact attenuation system to land safely. The latter adds cost, weight and complexity. However, by using their legs for impact attenuation, airdropped quadruped robots may avoid the need for such a system. In this paper, various leg configurations for attenuating impact of airborne landings were studied and tested. Using simple lumped element models for simulation and analysis, a quadruped robot with a three-segment leg was designed and built. This model was validated with experiments with a small scale 20 cm-tall test robot. During the experiments, the test robot experienced 7.7 × 10 m/s2 or 7.9 g-acceleration when dropped from height of 37.85 cm. This result is much better than the result of 1.4 × 102 m/s2 or 14.7g-acceleration when dropped at 10% of the original height with the same robot equipped with rigid legs. Such compliant leg design could be potentially used for impact attenuation of airdrop landings of robots five times larger.
keywords: {Legged locomotion;Springs;Attenuation;Knee;Acceleration;Servomotors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989427&isnumber=7988677

M. Usman, B. Suthar, H. Seong, E. Hawkes, I. Gaponov and J. -H. Ryu, "Passive returning mechanism for twisted string actuators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3714-3719.
doi: 10.1109/ICRA.2017.7989428
Abstract: The twisted string actuator is an actuator that is gaining popularity in various engineering and robotics and applications. However, the fundamental limitation of actuators of this type is the uni-directional action, meaning that the actuator can contract but requires external power to return to its initial state. This paper proposes 2 novel passive extension mechanisms based on buckling effect to solve the uni-directional issue of the twisted string actuator. The proposed mechanisms are mechanically simple and compact and provide a nearly-constant extension force throughout the operation range. The constant force can fully extend the twisted string actuator with minimal loss of force during contraction. The designed mechanisms are evaluated in a series of practical tests, and their performances are compared and discussed.
keywords: {Force;Springs;Electron tubes;Actuators;Rubber;Robots;Contracts},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989428&isnumber=7988677

S. Abdolshah, D. Zanotto, G. Rosati and S. Agrawal, "Performance evaluation of a new design of cable-suspended camera system," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3728-3733.
doi: 10.1109/ICRA.2017.7989429
Abstract: Adaptive cable-driven parallel robots can adjust the position of one or more pulley blocks to optimize performance within a given workspace. Because of their augmented kinematic redundancy, adaptive systems have several advantages over their traditional counterparts featuring the same numbers of cables. In this paper, we explore the application of adaptive cable-driven robots to cable-suspended camera systems. Performance of the traditional and of the adaptive designs are analyzed, using dexterity and stiffness as performance metrics. Results show superior performance of the adaptive design compared to the traditional system. An illustrative design problem for adaptive cable-suspended camera systems is also presented and solved.
keywords: {Cameras;Indexes;Adaptive systems;Mechanical cables;Pulleys;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989429&isnumber=7988677

G. Huskic, S. Buck and A. Zell, "Path following control of skid-steered wheeled mobile robots at higher speeds on different terrain types," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3734-3739.
doi: 10.1109/ICRA.2017.7989430
Abstract: A new nonlinear control law for path following with skid-steered mobile robots is proposed. A terrain dependent kinematic model is utilized in path coordinates, and the kinematic parameters are experimentally evaluated. A kinematic path following control is developed using the Lyapunov approach. A separate linear velocity control is then proposed, taking reachable curvatures and actuator saturation into account. The proposed approach is experimentally evaluated in different terrain scenarios, and compared with two other state-of-the-art algorithms. The skid-steered vehicle used for the experiments is the Robotnik Summit XL, a well known commercial mobile robot.
keywords: {Kinematics;Wheels;Mobile robots;Velocity control;Actuators;Convergence},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989430&isnumber=7988677

J. Huh, B. Lee and D. D. Lee, "Adaptive motion planning with high-dimensional mixture models," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3740-3747.
doi: 10.1109/ICRA.2017.7989431
Abstract: This paper presents a novel adaptive approach to fast sampling-based motion planning by learning models of collision and collision-free regions in configuration spaces in an online manner. The proposed approach incrementally learns Gaussian Mixture Models (GMMs) for collision detection in high dimensional configuration spaces. In practical applications for robotic manipulation, the representation of collision and collision-free regions in configuration space can change due to relative motion between the robot base and workspace. We show how to rapidly adapt to such changes by using inverse kinematics to transform the parameters of the Gaussian mixture model to new configurations. The transformed model is initially used as a prior and then continually updated and refined as the RRT planning algorithm proceeds in real-time. This approach is extremely computationally efficient, and our proposed method is compared with traditional sampling-based planning methods on a number of experimental robot arm planning scenarios.
keywords: {Planning;Collision avoidance;Adaptation models;Manipulators;Predictive models;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989431&isnumber=7988677

R. Zhao and S. Ratchev, "On-line trajectory planning with time-variant motion constraints for industrial robot manipulators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3748-3753.
doi: 10.1109/ICRA.2017.7989432
Abstract: An on-line trajectory generation algorithm with time-variant kinematic motion constraints is presented in this paper. The algorithm is an extension of a class of trajectory planning method which is applicable with constant kinematic motion constraints only. The extended approach allows the abrupt change in the value of the physical robot constraints(jerk, acceleration, and velocity) at any time instant and keeps these constraints bounded during the trajectory parameter adaptation. Short computation time enables the real-time usage of the proposed algorithm so that it can update the trajectory at any time taking into account the current robot motion limits. It allows sensor integration in low-level robot motion control, that is, making robots have the capability of reacting to unforeseen sensor events in real time. Simulation results are summarized in the paper.
keywords: {Trajectory;Acceleration;Robot sensing systems;Kinematics;Service robots;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989432&isnumber=7988677

Z. Wang, S. Jegelka, L. P. Kaelbling and T. Lozano-Pérez, "Focused model-learning and planning for non-Gaussian continuous state-action systems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3754-3761.
doi: 10.1109/ICRA.2017.7989433
Abstract: We introduce a framework for model learning and planning in stochastic domains with continuous state and action spaces and non-Gaussian transition models. It is efficient because (1) local models are estimated only when the planner requires them; (2) the planner focuses on the most relevant states to the current planning problem; and (3) the planner focuses on the most informative and/or high-value actions. Our theoretical analysis shows the validity and asymptotic optimality of the proposed approach. Empirically, we demonstrate the effectiveness of our algorithm on a simulated multi-modal pushing problem.
keywords: {Planning;Computational modeling;Stochastic processes;Aerospace electronics;Robots;Dynamic programming;Heuristic algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989433&isnumber=7988677

H. L. Chiang, B. HomChaudhuri, A. P. Vinod, M. Oishi and L. Tapia, "Dynamic risk tolerance: Motion planning by balancing short-term and long-term stochastic dynamic predictions," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3762-3769.
doi: 10.1109/ICRA.2017.7989434
Abstract: Identifying collision-free paths over long time windows in environments with stochastically moving obstacles is difficult, in part because long-term predictions of obstacle positions typically have low fidelity, and the region of possible obstacle occupancy is typically large. As a result, planning methods that are restricted to identifying paths with a low probability of collision may not be able to find a valid path. However, allowing paths with a higher probability of collision may limit detection of imminent collisions. In this paper, we present Dynamic Risk Tolerance (DRT), a framework that dynamically evaluates risk tolerance, a function which is formulated as a time-varying upper bound on the acceptable likelihood of collision for a given path. DRT is implemented with forward stochastic reachable sets to predict the exact distribution of obstacles in a scalable manner over an arbitrarily long time window. In effect, DRT identifies actions that balance risks posed by both near and far obstacles. We empirically compare DRT to other state of the art methods that are capable of generating real-time solutions in highly crowded environments, and demonstrate the success rates for DRT that is 46% higher than the best performing comparison method, in the most difficult problem tested.
keywords: {Collision avoidance;Planning;Vehicle dynamics;Robots;Aerodynamics;Monte Carlo methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989434&isnumber=7988677

S. Choudhury, O. Salzman, S. Choudhury and S. S. Srinivasa, "Densification strategies for anytime motion planning over large dense roadmaps," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3770-3777.
doi: 10.1109/ICRA.2017.7989435
Abstract: We consider the problem of computing shortest paths in a dense motion-planning roadmap G. We assume that n, the number of vertices of G, is very large. Thus, using any path-planning algorithm that directly searches G, running in O(VlogV + E) ≈ O(n2) time, becomes unacceptably expensive. We are therefore interested in anytime search to obtain successively shorter feasible paths and converge to the shortest path in G. Our key insight is to provide existing path-planning algorithms with a sequence of increasingly dense subgraphs of G. We study the space of all (r-disk) subgraphs of G. We then formulate and present two densification strategies for traversing this space which exhibit complementary properties with respect to problem difficulty. This inspires a third, hybrid strategy which has favourable properties regardless of problem difficulty. This general approach is then demonstrated and analyzed using the specific case where a low-dispersion deterministic sequence is used to generate the samples used for G. Finally we empirically evaluate the performance of our strategies for random scenarios in ℝ2 and ℝ4 and on manipulation planning problems for a 7 DOF robot arm, and validate our analysis.
keywords: {Planning;Dispersion;Approximation algorithms;Visualization;Image edge detection;Search problems;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989435&isnumber=7988677

G. Francis, L. Ott and F. Ramos, "Stochastic functional gradient for motion planning in continuous occupancy maps," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3778-3785.
doi: 10.1109/ICRA.2017.7989436
Abstract: Safe path planning is a crucial component in autonomous robotics. The many approaches to find a collision free path can be categorically divided into trajectory optimizers and sampling-based methods. When planning using occupancy maps, the sampling-based approach is the prevalent method. The main drawback of such techniques is that the reasoning about the expected cost of a plan is limited to the search heuristic used by each method. We introduce a novel planning method based on trajectory optimization to plan safe and efficient paths in continuous occupancy maps. We extend the expressiveness of the state-of-the-art functional gradient optimization methods by devising a stochastic gradient update rule to optimize a path represented as a Gaussian process. This approach avoids the need to commit to a specific resolution of the path representation, whether spatial or parametric. We utilize a continuous occupancy map representation in order to define our optimization objective, which enables fast computation of occupancy gradients. We show that this approach is essential in order to ensure convergence to the optimal path, and present results and comparisons to other planning methods in both simulation and with real laser data. The experiments demonstrate the benefits of using this technique when planning for safe and efficient paths in continuous occupancy maps.
keywords: {Planning;Optimization;Trajectory;Robots;Kernel;Gaussian processes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989436&isnumber=7988677

K. Elimelech and V. Indelman, "Consistent sparsification for efficient decision making under uncertainty in high dimensional state spaces," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3786-3791.
doi: 10.1109/ICRA.2017.7989437
Abstract: In this paper we introduce a novel approach for efficient decision making under uncertainty and belief space planning, in high dimensional state spaces. While recently developed methods focus on sparsifying the inference process, the sparsification here is done in the context of efficient decision making, with no impact on the state inference. By identifying state variables which are uninvolved in the decision, we generate a sparse version of the state's information matrix, to be used in the examination of candidate actions. This sparse approximation is action-consistent, i.e. has no influence on the action selection. Overall we manage to maintain the same quality of solution, while reducing the computational complexity of the problem. The approach is put to the test in a SLAM simulation, where a significant improvement in runtime is achieved. Nevertheless, the method is generic, and not tied to a specific type of problem.
keywords: {Decision making;Sparse matrices;Covariance matrices;Uncertainty;Jacobian matrices;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989437&isnumber=7988677

D. Guo, H. Wang, W. Chen, M. Liu, Z. Xia and K. K. Leang, "A unified leader-follower scheme for mobile robots with uncalibrated on-board camera," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3792-3797.
doi: 10.1109/ICRA.2017.7989438
Abstract: This paper studies the problem of image-based leader-follower formation control for mobile robots, where the controller is designed independently of the leader's motion. An adaptive control scheme, which is suitable for both omnidirectional and perspective cameras, is proposed. The proposed approach avoids the need for accurate calibration of the extrinsic parameters of the omnidirectional camera as well as the intrinsic and extrinsic parameters of perspective camera. Additionally, the coefficients of the plane where the feature point moves relative to the camera frame can be uncertain. These uncertain constant parameters are estimated using an adaptive estimator. Uniform Semi-global Practical Asymptotic Stability (USPAS) of the system is shown using the Lyapunov approach. Experimental results are presented to demonstrate the effectiveness of the proposed control scheme.
keywords: {Cameras;Robot vision systems;Kinematics;Mobile robots;Calibration;Automation;Adaptive control;mobile robot;visual servoing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989438&isnumber=7988677

E. Marchand and F. Chaumette, "Visual servoing through mirror reflection," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3798-3804.
doi: 10.1109/ICRA.2017.7989439
Abstract: Apart the use of catadioptric cameras, only few visual servoing works exploit the use of mirror. Such a configuration is however interesting since it allows to overpass the limited camera field of view. Based on the known projection equations involved in such a system, this paper introduces the theoretical background that allows the use of planar mirror for visual servoing in different configurations. Limitations intrinsic to such systems, such as the number of d.o.f actually controllable, is then discussed. Experiments using a mirror mounted on the end-effector of a 6 d.o.f robot validate the proposed approach.
keywords: {Mirrors;Cameras;Visual servoing;Manganese;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989439&isnumber=7988677

P. A. Patlan-Rosales and A. Krupa, "A robotic control framework for 3-D quantitative ultrasound elastography," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3805-3810.
doi: 10.1109/ICRA.2017.7989440
Abstract: In this paper we present a novel approach to track and explore stiff tissues within 3-D ultrasound volumes acquired by a medical 3-D ultrasound probe mounted on a six degrees of freedom robotic arm. Autonomous palpation and on-line elastography process are implemented to estimate the elastic property of the tissues (strain) in a volume of interest (VoI) indicated by the user. The compression motion, required for the elastography, is performed by controlling the force applied by the ultrasound probe to the tissues. A visual servoing control for centering a rigid tissue (target) inside the field of view (FoV) of the ultrasound probe is established to always maintain the target visible. Additionally, rotations around the contact point between the tissue and the ultrasound probe are teleoperated through a haptic device handled by the user in order to allow exploration of the target surrounding areas. Results show a stable system that can be used in the future for diagnosis of diseases or tumor location.
keywords: {Probes;Ultrasonic imaging;Strain;Force;Robots;Elastography;Radio frequency},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989440&isnumber=7988677

P. Vicente, L. Jamone and A. Bernardino, "Towards markerless visual servoing of grasping tasks for humanoid robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3811-3816.
doi: 10.1109/ICRA.2017.7989441
Abstract: Vision-based grasping for humanoid robots is a challenging problem due to a multitude of factors. First, humanoid robots use an “eye-to-hand” kinematics configuration that, on the contrary to the more common “eye-in-hand” configuration, demands a precise estimate of the position of the robot's hand. Second, humanoid robots have a long kinematic chain from the eyes to the hands, prone to accumulate the calibration errors of the kinematics model, which offsets the measured hand-to-object relative pose from the real one. In this paper, we propose a method able to solve these two issues jointly. A robust pose estimation of the robot's hand is achieved via a 3D model-based stereo-vision algorithm, using an edge-based distance transform metric and synthetically generated images of a robot's arm-hand internal computer-graphics model (kinematics and appearance). Then, a particle-based optimization method adapts on-line the robot's internal model to match the real and the synthetically generated images, effectively compensating the kinematics calibration errors. We evaluate the proposed approach using a position-based visual-servoing method on the iCub robot, showing the importance of the continuous visual feedback in humanoid grasping tasks.
keywords: {Kinematics;Grasping;Visualization;Solid modeling;Humanoid robots;Calibration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989441&isnumber=7988677

A. Saxena, H. Pandya, G. Kumar, A. Gaud and K. M. Krishna, "Exploring convolutional networks for end-to-end visual servoing," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3817-3823.
doi: 10.1109/ICRA.2017.7989442
Abstract: Present image based visual servoing approaches rely on extracting hand crafted visual features from an image. Choosing the right set of features is important as it directly affects the performance of any approach. Motivated by recent breakthroughs in performance of data driven methods on recognition and localization tasks, we aim to learn visual feature representations suitable for servoing tasks in unstructured and unknown environments. In this paper, we present an end-to-end learning based approach for visual servoing in diverse scenes where the knowledge of camera parameters and scene geometry is not available a priori. This is achieved by training a convolutional neural network over color images with synchronised camera poses. Through experiments performed in simulation and on a quadrotor, we demonstrate the efficacy and robustness of our approach for a wide range of camera poses in both indoor as well as outdoor environments.
keywords: {Cameras;Visual servoing;Visualization;Feature extraction;Optical imaging;Jacobian matrices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989442&isnumber=7988677

B. Pfrommer, N. Sanket, K. Daniilidis and J. Cleveland, "PennCOSYVIO: A challenging Visual Inertial Odometry benchmark," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3847-3854.
doi: 10.1109/ICRA.2017.7989443
Abstract: We present PennCOSYVIO, a new challenging Visual Inertial Odometry (VIO) benchmark with synchronized data from a VI-sensor (stereo camera and IMU), two Project Tango hand-held devices, and three GoPro Hero 4 cameras. Recorded at UPenn's Singh center, the 150m long path of the hand-held rig crosses from outdoors to indoors and includes rapid rotations, thereby testing the abilities of VIO and Simultaneous Localization and Mapping (SLAM) algorithms to handle changes in lighting, different textures, repetitive structures, and large glass surfaces. All sensors are synchronized and intrinsically and extrinsically calibrated. We demonstrate the accuracy with which ground-truth poses can be obtained via optic localization off of fiducial markers. The data set can be found at https://daniilidis-group.github.io/penncosyvio/.
keywords: {Cameras;Benchmark testing;Visualization;Simultaneous localization and mapping;Global Positioning System;Calibration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989443&isnumber=7988677

C. Gao and R. Harle, "MSGD: Scalable back-end for indoor magnetic field-based GraphSLAM," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3855-3862.
doi: 10.1109/ICRA.2017.7989444
Abstract: Simultaneous Localisation and Mapping (SLAM) systems that recover the trajectory of a robot or mobile device are characterised by a front-end and back-end. The front-end uses sensor observations to identify loop closures; the back-end optimises the estimated trajectory to be consistent with these closures. The GraphSLAM framework formulates the back-end problem as a graph-based optimisation on a pose graph. This paper describes a back-end system optimised for very dense sequence-based loop closures. This arises when the frontend generates magnetic loop closures, among other things. Magnetic measurements are fast varying, which is good for localisation, but the requirement for high sampling rates (50 Hz+) produces many more loop closures than conventional systems. To date, however, there is no study optimising GraphSLAM back-end for sequence-based magnetic loop closures. Hence we introduce a novel variant of the Stochastic Gradient Descent-based SLAM algorithm called MSGD (Magnetic-SGD). We use high-accuracy groundtruth system and extensive real datasets to evaluate MSGD against state-of-the-art back-end algorithms. We demonstrate MSGD is at least as good as the best competitor algorithm in terms of quality, while being faster and more scalable.
keywords: {Simultaneous localization and mapping;Trajectory;Algorithm design and analysis;Estimation;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989444&isnumber=7988677

P. Schmuck and M. Chli, "Multi-UAV collaborative monocular SLAM," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3863-3870.
doi: 10.1109/ICRA.2017.7989445
Abstract: With systems performing Simultaneous Localization And Mapping (SLAM) from a single robot reaching considerable maturity, the possibility of employing a team of robots to collaboratively perform a task has been attracting increasing interest. Promising great impact in a plethora of tasks ranging from industrial inspection to digitization of archaeological structures, collaborative scene perception and mapping are key in efficient and effective estimation. In this paper, we propose a novel, centralized architecture for collaborative monocular SLAM employing multiple small Unmanned Aerial Vehicles (UAVs) to act as agents. Each agent is able to independently explore the environment running limited-memory SLAM onboard, while sending all collected information to a central server, a ground station with increased computational resources. The server manages the maps of all agents, triggering loop closure, map fusion, optimization and distribution of information back to the agents. This allows an agent to incorporate observations from others in its SLAM estimates on the fly. We put the proposed framework to the test employing a nominal keyframe-based monocular SLAM algorithm, demonstrating the applicability of this system in multi-UAV scenarios.
keywords: {Simultaneous localization and mapping;Servers;Collaboration;Cameras;Computer architecture;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989445&isnumber=7988677

S. Yang and S. Scherer, "Direct monocular odometry using points and lines," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3871-3877.
doi: 10.1109/ICRA.2017.7989446
Abstract: Most visual odometry algorithm for a monocular camera focuses on points, either by feature matching, or direct alignment of pixel intensity, while ignoring a common but important geometry entity: edges. In this paper, we propose an odometry algorithm that combines points and edges to benefit from the advantages of both direct and feature based methods. It works better in texture-less environments and is also more robust to lighting changes and fast motion by increasing the convergence basin. We maintain a depth map for the keyframe then in the tracking part, the camera pose is recovered by minimizing both the photometric error and geometric error to the matched edge in a probabilistic framework. In the mapping part, edge is used to speed up and increase stereo matching accuracy. On various public datasets, our algorithm achieves better or comparable performance than state-of-the-art monocular odometry methods. In some challenging texture-less environments, our algorithm reduces the state estimation error over 50%.
keywords: {Image edge detection;Cameras;Three-dimensional displays;Uncertainty;Mathematical model;Robustness;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989446&isnumber=7988677

J. Dong, J. G. Burnham, B. Boots, G. Rains and F. Dellaert, "4D crop monitoring: Spatio-temporal reconstruction for agriculture," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3878-3885.
doi: 10.1109/ICRA.2017.7989447
Abstract: Autonomous crop monitoring at high spatial and temporal resolution is a critical problem in precision agriculture. While Structure from Motion and Multi-View Stereo algorithms can finely reconstruct the 3D structure of a field with low-cost image sensors, these algorithms fail to capture the dynamic nature of continuously growing crops. In this paper we propose a 4D reconstruction approach to crop monitoring, which employs a spatio-temporal model of dynamic scenes that is useful for precision agriculture applications. Additionally, we provide a robust data association algorithm to address the problem of large appearance changes due to scenes being viewed from different angles at different points in time, which is critical to achieving 4D reconstruction. Finally, we collected a high-quality dataset with ground-truth statistics to evaluate the performance of our method. We demonstrate that our 4D reconstruction approach provides models that are qualitatively correct with respect to visual appearance and quantitatively accurate when measured against the ground truth geometric properties of the monitored crops.
keywords: {Agriculture;Image reconstruction;Simultaneous localization and mapping;Three-dimensional displays;Monitoring;Cameras;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989447&isnumber=7988677

L. Carlone and S. Karaman, "Attention and anticipation in fast visual-inertial navigation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3886-3893.
doi: 10.1109/ICRA.2017.7989448
Abstract: Visual attention is the cognitive process that allows humans to parse a large amount of sensory data by selecting relevant information and filtering out irrelevant stimuli. This papers develops a computational approach for visual attention in robots. We consider a Visual-Inertial Navigation (VIN) problem in which a robot needs to estimate its state using an on-board camera and an inertial sensor. The robot can allocate limited resources to VIN, due to time and energy constraints. Therefore, we answer the following question: under limited resources, what are the most relevant visual cues to maximize the performance of visual-inertial navigation? Our approach has four key features. First, it is task-driven, in that the selection of the visual cues is guided by a metric quantifying the task performance. Second, it exploits the notion of anticipation, since it uses a simplified model for forward-simulation of robot dynamics, predicting the utility of a set of visual cues over a time horizon. Third, it is efficient and easy to implement, since it leads to a greedy algorithm for the selection of the most relevant visual cues. Fourth, it provides formal performance guarantees: we leverage submodularity to prove that the greedy selection cannot be far from the optimal (combinatorial) selection. Simulations and real experiments on agile micro aerial vehicles show that our approach leads to dramatic improvements in the VIN performance. In the easy scenarios, our approach outperforms the state of the art in terms of localization errors. In the most challenging scenarios, it enables accurate visual-inertial navigation while the state of the art fails to track robot's motion during aggressive maneuvers.
keywords: {Visualization;Measurement;Robot sensing systems;Navigation;Covariance matrices;Time factors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989448&isnumber=7988677

Z. Zhang, C. Forster and D. Scaramuzza, "Active exposure control for robust visual odometry in HDR environments," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3894-3901.
doi: 10.1109/ICRA.2017.7989449
Abstract: We propose an active exposure control method to improve the robustness of visual odometry in HDR (high dynamic range) environments. Our method evaluates the proper exposure time by maximizing a robust gradient-based image quality metric. The optimization is achieved by exploiting the photometric response function of the camera. Our exposure control method is evaluated in different real world environments and outperforms the built-in auto-exposure function of the camera. To validate the benefit of our approach, we adapt a state-of-the-art visual odometry pipeline (SVO) to work with varying exposure time and demonstrate improved performance using our exposure control method in challenging HDR environments.
keywords: {Measurement;Cameras;Image quality;Feature extraction;Robustness;Visualization;Brightness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989449&isnumber=7988677

P. P. Neumann, H. Kohlhoff, D. Hüllmann, A. J. Lilienthal and M. Kluge, "Bringing Mobile Robot Olfaction to the next dimension — UAV-based remote sensing of gas clouds and source localization," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3910-3916.
doi: 10.1109/ICRA.2017.7989450
Abstract: This paper introduces a novel robotic platform for aerial remote gas sensing. Spectroscopic measurement methods for remote sensing of selected gases lend themselves for use on mini-copters, which offer a number of advantages for inspection and surveillance. No direct contact with the target gas is needed and thus the influence of the aerial platform on the measured gas plume can be kept to a minimum. This allows to overcome one of the major issues with gas-sensitive mini-copters. On the other hand, remote gas sensors, most prominently Tunable Diode Laser Absorption Spectroscopy (TDLAS) sensors have been too bulky given the payload and energy restrictions of mini-copters. Here, we introduce and present the Unmanned Aerial Vehicle for Remote Gas Sensing (UAV-REGAS), which combines a novel lightweight TDLAS sensor with a 3-axis aerial stabilization gimbal for aiming on a versatile hexacopter. The proposed system can be deployed in scenarios that cannot be addressed by currently available robots and thus constitutes a significant step forward for the field of Mobile Robot Olfaction (MRO). It enables tomographic reconstruction of gas plumes and a localization of gas sources. We also present first results showing the gas sensing and aiming capabilities under realistic conditions.
keywords: {Measurement by laser beam;Gas detectors;Robot sensing systems;Laser beams;Payloads},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989450&isnumber=7988677

R. D'Sa et al., "Design and experiments for a transformable solar-UAV," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3917-3923.
doi: 10.1109/ICRA.2017.7989451
Abstract: Aerial robotic platforms are an increasingly sought-after solution for a variety of sensing, monitoring, and transportation challenges. However, as invaluable as unmanned aerial vehicles (UAVs) have been for these applications, fixed-wing and multi-rotor systems each have individual limitations. Fixed-wing UAVs are generally capable of high-altitude surveillance and long flight times, while quad-rotors are most effective when used for their maneuverability and close-quarters surveying. This paper improves upon the prototypes discussed in [1] by creating a series of three next-generation prototypes to isolate the aspects of solar powered fixed-wing flight, quad-rotor flight, and transformation modes of the SUAV:Q platform. Improvements to the transformation mechanism, airframe design, variable pitch propulsion system, and custom-designed power electronics are presented along with validation of the designs through empirical testing.
keywords: {Fasteners;Prototypes;Servomotors;Aircraft;Propellers;Stability analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989451&isnumber=7988677

X. Lyu, H. Gu, Y. Wang, Z. Li, S. Shen and F. Zhang, "Design and implementation of a quadrotor tail-sitter VTOL UAV," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3924-3930.
doi: 10.1109/ICRA.2017.7989452
Abstract: We present the design and implementation of a quadrotor tail-sitter Vertical Take-Off and Landing (VTOL) Unmanned Aerial Vehicle (UAV). The VTOL UAV combines the advantage of a quadrotor, vertical take-off and landing and hovering at a stationary point, with that of a fixed-wing, efficient level flight. We describe our vehicle design with special considerations on fully autonomous operation in a real outdoor environment where the wind is present. The designed quadrotor tail-sitter UAV has insignificant vibration level and achieves stable hovering and landing performance when a cross wind is present. Wind tunnel test is conducted to characterize the full envelope aerodynamics of the aircraft, based on which a flight controller is designed, implemented and tested. MATLAB simulation is presented and shows that our vehicle can achieve a continuous transition from hover flight to level flight. Finally, both indoor and outdoor flight experiments are conducted to verify the performance of our vehicle and the designed controller.
keywords: {Aircraft;Unmanned aerial vehicles;Aerodynamics;Vibrations;Atmospheric modeling;Mathematical model;Aerospace control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989452&isnumber=7988677

R. Bähnemann, M. Burri, E. Galceran, R. Siegwart and J. Nieto, "Sampling-based motion planning for active multirotor system identification," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3931-3938.
doi: 10.1109/ICRA.2017.7989453
Abstract: This paper reports on an algorithm for planning trajectories that allow a multirotor micro aerial vehicle (MAV) to quickly identify a set of unknown parameters. In many problems like self calibration or model parameter identification some states are only observable under a specific motion. These motions are often hard to find, especially for inexperienced users. Therefore, we consider system model identification in an active setting, where the vehicle autonomously decides what actions to take in order to quickly identify the model. Our algorithm approximates the belief dynamics of the system around a candidate trajectory using an extended Kalman filter (EKF). It uses sampling-based motion planning to explore the space of possible beliefs and find a maximally informative trajectory within a user-defined budget. We validate our method in simulation and on a real system showing the feasibility and repeatability of the proposed approach. Our planner creates trajectories which reduce model parameter convergence time and uncertainty by a factor of four.
keywords: {Trajectory;Solid modeling;Robots;Planning;Uncertainty;Covariance matrices;Calibration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989453&isnumber=7988677

S. Verling, T. Stastny, G. Bättig, K. Alexis and R. Siegwart, "Model-based transition optimization for a VTOL tailsitter," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3939-3944.
doi: 10.1109/ICRA.2017.7989454
Abstract: This paper addresses the problem of trajectory optimization for the transition of a Vertical Take-off and Landing (VTOL) tailsitter Unmanned Aerial Vehicle (UAV). The proposed strategy performs a model based optimization, where the model represents the closed-loop dynamics of the UAV with low-level control, ensuring attitude stabilization over the whole trajectory. We discuss the design of an optimization framework, vehicle modeling, and elaborate on the cost function construction. An additional feedback gain is implemented on the throttle channel with altitude discrepancies as its input to provide some level of robustness to wind disturbances. The overall approach is verified in simulation and experimental results with a focus on optimization of the back-transition (cruise-to-hover) of the Wingtra S100 VTOL tailsitter.
keywords: {Optimization;Mathematical model;Unmanned aerial vehicles;Attitude control;Data models;Propellers;Aircraft},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989454&isnumber=7988677

Y. Demitrit, S. Verling, T. Stastny, A. Melzer and R. Siegwart, "Model-based wind estimation for a hovering VTOL tailsitter UAV," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3945-3952.
doi: 10.1109/ICRA.2017.7989455
Abstract: To many unmanned aerial vehicle (UAV) designs, the lack of information about the wind speed and direction is a limiting factor in achieving robust outdoor flight. This paper addresses the problem of wind estimation onboard a hovering vertical take-off and landing (VTOL) tailsitter UAV. The proposed estimation framework makes use of the standard onboard sensor suite: inertial measurement unit (IMU), global positioning system (GPS) and a magnetometer. No additional airspeed sensor is needed. As a result, the autopilot is provided with an estimate of the wind velocity vector in the horizontal (north-east) plane. An aerodynamic model of the vehicle has been derived and used in a Kalman filter framework to estimate the horizontal wind velocity vector in real-time. The wind estimator has been implemented onboard the UAVs autopilot and validated in real flight. As a result, we successfully obtain the direction and speed of the wind with an estimation accuracy close to the accuracy range of the ground truth measurement. Furthermore, the derived grey-box model allows to generalise the framework to different airframes.
keywords: {Wind speed;Velocity measurement;Mathematical model;Estimation;Atmospheric modeling;Propellers;Unmanned aerial vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989455&isnumber=7988677

A. Spek and T. Drummond, "Joint pose and principal curvature refinement using quadrics," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3968-3975.
doi: 10.1109/ICRA.2017.7989456
Abstract: In this paper we present a novel joint approach for optimising surface curvature and pose alignment. We present two implementations of this joint optimisation strategy, including a fast implementation that uses two frames and an offline multi-frame approach. We demonstrate an order of magnitude improvement in simulation over state of the art dense relative point-to-plane Iterative Closest Point (ICP) pose alignment using our dense joint frame-to-frame approach and show comparable pose drift to dense point-to-plane ICP bundle adjustment using low-cost depth sensors. Additionally our improved joint quadric based approach can be used to more accurately estimate surface curvature on noisy point clouds than previous approaches.
keywords: {Iterative closest point algorithm;Computational modeling;Optimization;Three-dimensional displays;Jacobian matrices;Sensors;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989456&isnumber=7988677

M. Dzitsiuk, J. Sturm, R. Maier, L. Ma and D. Cremers, "De-noising, stabilizing and completing 3D reconstructions on-the-go using plane priors," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3976-3983.
doi: 10.1109/ICRA.2017.7989457
Abstract: Creating 3D maps on robots and other mobile devices has become a reality in recent years. Online 3D reconstruction enables many exciting applications in robotics and AR/VR gaming. However, the reconstructions are noisy and generally incomplete. Moreover, during online reconstruction, the surface changes with every newly integrated depth image which poses a significant challenge for physics engines and path planning algorithms. This paper presents a novel, fast and robust method for obtaining and using information about planar surfaces, such as walls, floors, and ceilings as a stage in 3D reconstruction based on Signed Distance Fields (SDFs). Our algorithm recovers clean and accurate surfaces, reduces the movement of individual mesh vertices caused by noise during online reconstruction and fills in the occluded and unobserved regions. We implemented and evaluated two different strategies to generate plane candidates and two strategies for merging them. Our implementation is optimized to run in real-time on mobile devices such as the Tango tablet. In an extensive set of experiments, we validated that our approach works well in a large number of natural environments despite the presence of significant amount of occlusion, clutter and noise, which occur frequently. We further show that plane fitting enables in many cases a meaningful semantic segmentation of real-world scenes.
keywords: {Three-dimensional displays;Surface reconstruction;Image reconstruction;Solid modeling;Real-time systems;Robots;Mobile handsets},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989457&isnumber=7988677

W. Luan, Y. Yang, C. Fermüller and J. S. Baras, "Fast task-specific target detection via graph based constraints representation and checking," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3984-3991.
doi: 10.1109/ICRA.2017.7989458
Abstract: We present a framework for fast target detection in real-world robotics applications. Considering that an intelligent agent attends to a task-specific object target during execution, our goal is to detect the object efficiently. We propose the concept of early recognition, which influences the candidate proposal process to achieve fast and reliable detection performance. To check the target constraints efficiently, we put forward a novel policy which generates a sub-optimal checking order, and we prove that it has bounded time cost compared to the optimal checking sequence, which is not achievable in polynomial time. Experiments on two different scenarios: 1) rigid object and 2) non-rigid body part detection validate our pipeline. To show that our method is widely applicable, we further present a human-robot interaction system based on our non-rigid body part detection.
keywords: {Object detection;Proposals;Pipelines;Image segmentation;Computer vision;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989458&isnumber=7988677

M. Jaimez, C. Kerl, J. Gonzalez-Jimenez and D. Cremers, "Fast odometry and scene flow from RGB-D cameras based on geometric clustering," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 3992-3999.
doi: 10.1109/ICRA.2017.7989459
Abstract: In this paper we propose an efficient solution to jointly estimate the camera motion and a piecewise-rigid scene flow from an RGB-D sequence. The key idea is to perform a two-fold segmentation of the scene, dividing it into geometric clusters that are, in turn, classified as static or moving elements. Representing the dynamic scene as a set of rigid clusters drastically accelerates the motion estimation, while segmenting it into static and dynamic parts allows us to separate the camera motion (odometry) from the rest of motions observed in the scene. The resulting method robustly and accurately determines the motion of an RGB-D camera in dynamic environments with an average runtime of 80 milliseconds on a multi-core CPU. The code is available for public use/test.
keywords: {Cameras;Motion segmentation;Estimation;Image segmentation;Robustness;Dynamics;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989459&isnumber=7988677

G. Izatt, G. Mirano, E. Adelson and R. Tedrake, "Tracking objects with point clouds from vision and touch," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4000-4007.
doi: 10.1109/ICRA.2017.7989460
Abstract: We present an object-tracking framework that fuses point cloud information from an RGB-D camera with tactile information from a GelSight contact sensor. GelSight can be treated as a source of dense local geometric information, which we incorporate directly into a conventional point-cloud-based articulated object tracker based on signed-distance functions. Our implementation runs at 12 Hz using an online depth reconstruction algorithm for GelSight and a modified second-order update for the tracking algorithm. We present data from hardware experiments demonstrating that the addition of contact-based geometric information significantly improves the pose accuracy during contact, and provides robustness to occlusions of small objects by the robot's end effector.
keywords: {Robot sensing systems;Cameras;Geometry;Three-dimensional displays;Optimization;Iterative closest point algorithm},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989460&isnumber=7988677

K. Wu, X. Li, R. Ranasinghe, G. Dissanayake and Y. Liu, "RISAS: A novel rotation, illumination, scale invariant appearance and shape feature," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4008-4015.
doi: 10.1109/ICRA.2017.7989461
Abstract: This paper presents a novel appearance and shape feature, RISAS, which is robust to viewpoint, illumination, scale and rotation variations. RISAS consists of a keypoint detector and a feature descriptor both of which utilise texture and geometric information present in the appearance and shape channels. A novel response function based on the surface normals is used in combination with the Harris corner detector for selecting keypoints in the scene. A strategy that uses the depth information for scale estimation and background elimination is proposed to select the neighbourhood around the keypoints in order to build precise invariant descriptors. Proposed descriptor relies on the ordering of both grayscale intensity and shape information in the neighbourhood. Comprehensive experiments which confirm the effectiveness of the proposed RGB-D feature when compared with CSHOT [1] and LOIND[2] are presented. Furthermore, we highlight the utility of incorporating texture and shape information in the design of both the detector and the descriptor by demonstrating the enhanced performance of CSHOT and LOIND when combined with RISAS detector.
keywords: {Detectors;Shape;Robustness;Three-dimensional displays;Feature extraction;Histograms;Lighting},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989461&isnumber=7988677

J. Mirabel and F. Lamiraux, "Manipulation planning: Addressing the crossed foliation issue," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4032-4037.
doi: 10.1109/ICRA.2017.7989462
Abstract: This paper deals with manipulation planning. First, we propose a new tool called the constraint graph to describe the various motion constraints relative to a manipulation planning problem. Then, we describe a problem arising for some manipulation planning problems called the crossed foliation issue. We propose a extension of RRT algorithm that explores the leaves of the foliations generated by motion constraints and that solves the crossed foliation problem. Finally, we show a wide variety of problem that our approach can solve.
keywords: {Grippers;Robots;Planning;Manifolds;Space exploration;Vegetation;Conferences},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989462&isnumber=7988677

M. Bonilla, L. Pallottino and A. Bicchi, "Noninteracting constrained motion planning and control for robot manipulators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4038-4043.
doi: 10.1109/ICRA.2017.7989463
Abstract: In this paper we present a novel geometric approach to motion planning for constrained robot systems. This problem is notoriously hard, as classical sampling-based methods do not easily apply when motion is constrained in a zero-measure submanifold of the configuration space. Based on results on the functional controllability theory of dynamical systems, we obtain a description of the complementary spaces where rigid body motions can occur, and where interaction forces can be generated, respectively. Once this geometric setting is established, the motion planning problem can be greatly simplified. Indeed, we can relax the geometric constraint, i.e., replace the lower-dimensional constraint manifold with a full-dimensional boundary layer. This in turn allows us to plan motion using state-of-the-art methods, such as RRT*, on points within the boundary layer, which can be efficiently sampled. On the other hand, the same geometric approach enables the design of a completely decoupled control scheme for interaction forces, so that they can be regulated to zero (or any other desired value) without interacting with the motion plan execution. A distinguishing feature of our method is that it does not use projection of sampled points on the constraint manifold, thus largely saving in computational time, and guaranteeing accurate execution of the motion plan. An explanatory example is presented, along with an experimental implementation of the method on a bimanual manipulation workstation.
keywords: {Planning;Robots;Manifolds;Aerospace electronics;Force;Jacobian matrices;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989463&isnumber=7988677

M. Toussaint and M. Lopes, "Multi-bound tree search for logic-geometric programming in cooperative manipulation domains," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4044-4051.
doi: 10.1109/ICRA.2017.7989464
Abstract: Joint symbolic and geometric planning is one of the core challenges in robotics. We address the problem of multi-agent cooperative manipulation, where we aim for jointly optimal paths for all agents and over the full manipulation sequence. This joint optimization problem can be framed as a logic-geometric program. Existing solvers lack several features (such as consistently handling kinematic switches) and efficiency to handle the cooperative manipulation domain. We propose a new approximate solver scheme, combining ideas from branch-and-bound and MCTS and exploiting multiple levels of bounds to better direct the search. We demonstrate the method in a scenario where a Baxter robot needs to help a human to reach for objects.
keywords: {Kinematics;Optimization;Planning;Aerospace electronics;Programming;Robots;Search problems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989464&isnumber=7988677

M. Gualtieri, J. Kuczynski, A. M. Shultz, A. Ten Pas, R. Platt and H. Yanco, "Open world assistive grasping using laser selection," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4052-4057.
doi: 10.1109/ICRA.2017.7989465
Abstract: Many people with motor disabilities are unable to complete activities of daily living (ADLs) without assistance. This paper describes a complete robotic system developed to provide mobile grasping assistance for ADLs. The system is comprised of a robot arm from a Rethink Robotics Baxter robot mounted to an assistive mobility device, a control system for that arm, and a user interface with a variety of access methods for selecting desired objects. The system uses grasp detection to allow previously unseen objects to be picked up by the system. The grasp detection algorithms also allow for objects to be grasped in cluttered environments. We evaluate our system in a number of experiments on a large variety of objects. Overall, we achieve an object selection success rate of 88% and a grasp detection success rate of 90% in a non-mobile scenario, and success rates of 89% and 72% in a mobile scenario.
keywords: {Lasers;Robot sensing systems;Manipulators;Motorcycles;Grasping;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989465&isnumber=7988677

C. Pérez-D'Arpino and J. A. Shah, "C-LEARN: Learning geometric constraints from demonstrations for multi-step manipulation in shared autonomy," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4058-4065.
doi: 10.1109/ICRA.2017.7989466
Abstract: Learning from demonstrations has been shown to be a successful method for non-experts to teach manipulation tasks to robots. These methods typically build generative models from demonstrations and then use regression to reproduce skills. However, this approach has limitations to capture hard geometric constraints imposed by the task. On the other hand, while sampling and optimization-based motion planners exist that reason about geometric constraints, these are typically carefully hand-crafted by an expert. To address this technical gap, we contribute with C-LEARN, a method that learns multi-step manipulation tasks from demonstrations as a sequence of keyframes and a set of geometric constraints. The system builds a knowledge base for reaching and grasping objects, which is then leveraged to learn multi-step tasks from a single demonstration. C-LEARN supports multi-step tasks with multiple end effectors; reasons about SE(3) volumetric and CAD constraints, such as the need for two axes to be parallel; and offers a principled way to transfer skills between robots with different kinematics. We embed the execution of the learned tasks within a shared autonomy framework, and evaluate our approach by analyzing the success rate when performing physical tasks with a dual-arm Optimas robot, comparing the contribution of different constraints models, and demonstrating the ability of C-LEARN to transfer learned tasks by performing them with a legged dual-arm Atlas robot in simulation.
keywords: {Planning;Solid modeling;Knowledge based systems;Grasping;Hidden Markov models;End effectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989466&isnumber=7988677

J. Z. Woodruff and K. M. Lynch, "Planning and control for dynamic, nonprehensile, and hybrid manipulation tasks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4066-4073.
doi: 10.1109/ICRA.2017.7989467
Abstract: In this paper we propose a method for motion planning and feedback control of hybrid, dynamic, and non-prehensile manipulation tasks. We outline five subproblems to address this: determining a set of manipulation primitives, choosing a sequence of tasks, picking transition states, motion planning for each individual primitive, and stabilizing each mode using feedback control. We apply the framework to plan a sequence of motions for manipulating a block with a planar 3R manipulator. We demonstrate preliminary experimental results for a block resting on the manipulator with a desired goal state on a ledge outside of the robot's workspace. The planned primitives reorient the block using a series of fixed, rolling, and sliding contact modes, and throw it to the goal state.
keywords: {Manipulator dynamics;Planning;Dynamics;Aerospace electronics;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989467&isnumber=7988677

S. Kim and M. Likhachev, "Parts assembly planning under uncertainty with simulation-aided physical reasoning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4074-4081.
doi: 10.1109/ICRA.2017.7989468
Abstract: Parts assembly, in a broad sense, is to make multiple objects to be in specific relative poses in contact with each other. One of the major reasons that make it difficult is uncertainty. Because parts assembly involves physical contact between objects, it requires higher precision than other manipulation tasks like collision avoidance. The key idea of this paper is to use simulation-aided physical reasoning while planning with the goal of finding a robust motion plan for parts assembly. Specifically, in the proposed approach, a) uncertainty between object poses is represented as a distribution of particles, b) the motion planner estimates the transition of particles for unit actions (motion primitives) through physics-based simulation, and c) the performance of the planner is sped up using Multi-Heuristic A* (MHA*) search that utilizes multiple inadmissible heuristics that lead to fast uncertainty reduction. To demonstrate the benefits of our framework, motion planning and physical robot experiments for several parts assembly tasks are provided.
keywords: {Uncertainty;Robots;Tools;Planning;Grippers;Cognition;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989468&isnumber=7988677

M. Murooka, S. Nozawa, Y. Kakiuchi, K. Okada and M. Inaba, "Feasibility evaluation of object manipulation by a humanoid robot based on recursive estimation of the object's physical properties," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4082-4089.
doi: 10.1109/ICRA.2017.7989469
Abstract: Whole-body manipulation is necessary for a humanoid robot to achieve tasks such as carrying large objects. One difficulty for achieving a whole-body manipulation is that the robot needs to select the appropriate operation from a list of candidates, such as lifting, pushing, and tilting. The appropriate operation depends upon the target object's physical properties, including its mass, center of mass, and friction coefficient, which are difficult to measure directly. In order to select the appropriate manipulation motion online, we propose a method of estimating the object's physical properties and evaluating the feasibility of the object operation. We calculate the likelihood of the object's physical properties from sensor information during manipulation and update these properties' probabifity distribution periodically based on Bayesian methods. The operational feasibility probability is evaluated by physics-based stability determination, allowing the robot to perform manipulation tasks by selecting the appropriate operation. We show the effectiveness of the proposed method by an experiment in which a life-sized humanoid robot carries a large object.
keywords: {Force;Robot sensing systems;Estimation;Humanoid robots;Robot kinematics;Friction;Dexterous Manipulation;Probability and Statistical Methods;Calibration and Identification;Dual Arm Manipulation;Humanoid Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989469&isnumber=7988677

M. Cognetti, D. De Simone, F. Patota, N. Scianca, L. Lanari and G. Oriolo, "Real-time pursuit-evasion with humanoid robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4090-4095.
doi: 10.1109/ICRA.2017.7989470
Abstract: We consider a pursuit-evasion problem between humanoids. In our scenario, the pursuer enters the safety area of the evader headed for collision, while the latter executes a fast evasive motion. Control schemes are designed for both the pursuer and the evader. They are structurally identical, although the objectives are different: the pursuer tries to align its direction of motion with the line-of-sight to the evader, whereas the evader tries to move in a direction orthogonal to the line-of-sight to the pursuer. At the core of the control scheme is a maneuver planning module which makes use of closed-form expressions exclusively. This allows its use in a replanning framework, where each robot updates its motion plan upon completion of a step to account for the perceived motion of the other. Simulation and experimental results on NAO humanoids reveal an interesting asymptotic behavior which was predicted using unicycle as template models for trajectory generation.
keywords: {Trajectory;Safety;Real-time systems;Planning;Robot sensing systems;Humanoid robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989470&isnumber=7988677

H. Sadeghian, C. Ott, G. Garofalo and G. Cheng, "Passivity-based control of underactuated biped robots within hybrid zero dynamics approach," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4096-4101.
doi: 10.1109/ICRA.2017.7989471
Abstract: The concept of hybrid zero dynamics is a promising approach for designing exponentially stabilizing controllers for dynamic walking with some degrees of underactuation. By this approach a feedback controller is designed such that a stable periodic orbit, within an invariant submanifold for the hybrid closed-loop system is created. This is usually achieved through an exponentially fast dynamics transverse to the zero dynamics manifold and the stability properties of such periodic orbit is then transferred to the full-order dynamic system. In this paper a passivity-based controller for a planar biped with one degree of underactuation is designed. By this approach we aim to preserve the natural dynamics of the system in the transverse dynamics (i.e. the dynamics transverse to the zero dynamics manifold) in contrast to the common input-output linearization method which cancels these dynamics. A Lyapunov stability analysis of the full-order system based on the conditional stability theorem is presented. By this analysis, the asymptotic stability of the periodic orbit in lower dimensional state space is extended to the full dimensional space. The results of the analysis are verified by simulation on a seven-link biped robot walking with zero ankle torque in sagittal plane.
keywords: {Legged locomotion;Aerodynamics;Manifolds;Foot;Convergence;Orbits},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989471&isnumber=7988677

M. Rijnen et al., "Control of humanoid robot motions with impacts: Numerical experiments with reference spreading control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4102-4107.
doi: 10.1109/ICRA.2017.7989472
Abstract: This work explores the stabilization of desired dynamic motion tasks involving hard impacts at non-negligible speed for humanoid robots. To this end, a so-called reference spreading hybrid control law is designed showing promising results in simulation. The simulations are performed employing a dynamical model of an existing humanoid robot and impacts are assumed to be inelastic. The desired motion task consists of having the robot balancing on one foot while repeatedly making and breaking contact with a wall by means of one hand. The simulation results illustrate that the considered controller is suited to control humanoid robot motions with impacts.
keywords: {Humanoid robots;Trajectory;Dynamics;Tracking;Monitoring},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989472&isnumber=7988677

G. Mesesan, J. Englsberger, B. Henze and C. Ott, "Dynamic multi-contact transitions for humanoid robots using Divergent Component of Motion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4108-4115.
doi: 10.1109/ICRA.2017.7989473
Abstract: This paper presents a new method for planning and controlling dynamic multi-contact motions for humanoid robots. Our motion planner takes a sequence of multi-contact stances and generates closed-form reference trajectories for the robot center of mass (CoM) position, velocity, and acceleration, based on the concept of Divergent Component of Motion (DCM). The timing of the contact transitions and the end-effector trajectories are automatically computed such that the motion is feasible with respect to kinematic and dynamic constraints. We verify the constraints using a simplified model of the robot to achieve a very fast planner that finds a feasible solution within a few seconds. The reference trajectories serve as inputs to a passivity-based whole-body controller which includes a DCM controller for tracking the CoM trajectory. We demonstrate the robustness of our approach in simulation and experiments with the humanoid robot TORO.
keywords: {Trajectory;Humanoid robots;Aerodynamics;Force;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989473&isnumber=7988677

H. Atsuta, H. Nozaki and T. Sugihara, "Smooth-path-tracking control of a biped robot at variable speed based on dynamics morphing," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4116-4121.
doi: 10.1109/ICRA.2017.7989474
Abstract: This paper extends the longitudinal walking controller of biped robots proposed by one of the authors to walking along a smooth curved path. The previous controller defined in a fixed inertial frame is redesigned with respect to a moving frame attached to the center of mass (COM) of the robot in order to achieve walking along an arc. As a result, it is found that a desired position of the zero-moment point (ZMP) can be determined only from the local curvature of the referential path besides the state of the robot with respect to the moving frame. Thus, it is directly applicable to walking along an arbitrary smooth path including straight walk. In addition to the extension of the ZMP manipulation, techniques of foot control consistent with COM movement and automatic update of the referential COM position are fully extended to curved walk. The idea was examined through computer simulations to show responsiveness to updates of motion references and robustness against external disturbances.
keywords: {Legged locomotion;Foot;Oscillators;Robot kinematics;Trajectory;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989474&isnumber=7988677

Y. Hu and K. Mombaur, "Influence of compliance modulation on human locomotion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4130-4137.
doi: 10.1109/ICRA.2017.7989475
Abstract: Compliance is an important feature of human locomotion, where many studies have focused on the identification of stiffness parameters in order to build new machines, and stiffness is often assumed to be constant. However, it has been shown that during human walking, stiffness profiles are not constant in time and have high modulations in particular when changing walking phases. In order to understand how the constant stiffness assumption influences the walking gait and how much modulation is needed in walking mechanisms to reproduce natural gaits, in this work we focus on the analysis of joint and bi-articular stiffness profiles modulation and the influence of these modulations on the walking motions in different walking environments, i.e. level ground, slope and stairs. The analysis is carried out on periodic steps from motion capture data. mapped on a 14 segments human model with spring damper systems.
keywords: {Legged locomotion;Modulation;Foot;Springs;Hip;Knee;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989475&isnumber=7988677

Z. Bing, L. Cheng, K. Huang, M. Zhou and A. Knoll, "CPG-based control of smooth transition for body shape and locomotion speed of a snake-like robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4146-4153.
doi: 10.1109/ICRA.2017.7989476
Abstract: In this paper, a lightweight central pattern generator(CPG) model is designed for a snake-like robot, to achieve smooth transition of body shape and locomotion speed. First, based on the convergence behavior of the gradient system, a lightweight CPG model with fast computing time is designed and compared with other widely adopted CPG models. Then, the body shape and locomotion speed transitions in rolling gait are simulated based on the proposed CPG model. Compared with the sinusoid-based method, a smooth transition process can be achieved, without generating undesired movement or abnormal torque. Finally, extensive prototype experiments are conducted to demonstrate that the CPG-based control can effectively ensure smooth transition process and avoid abnormal torque, when the body shape and locomotion speed are changed.
keywords: {Robots;Mathematical model;Shape;Torque;Three-dimensional displays;Computational modeling;Oscillators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989476&isnumber=7988677

H. Guo, J. Zhang, T. Wang, Y. Li, J. Hong and Y. Li, "Design and control of an inchworm-inspired soft robot with omega-arching locomotion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4154-4159.
doi: 10.1109/ICRA.2017.7989477
Abstract: This paper presents an inchworm inspired soft robot composed of the soft body, the front foot as well as the back foot. Compared to the traditional inchworm-type robot consisting of rigid components, the driven mode for the soft robot is more simple. The soft robot inspired by the inchworm has higher locomotion efficiency than the other bionic soft robot. The main idea of this paper is to imitate the “Ω” motion shape of biology inchworm based on a silicone square tube with strain-limiting layers. Besides, each foot of the robot made through 3D printing technology together with metal sheet can produce different friction coefficients to achieve the anchor-motion movement. Then, the robot realizes an inchworm-like locomotion under certain actuation patterns. Experimental results show that the proposed robot has excellent performance.
keywords: {Robots;Pneumatic systems;Actuators;Foot;Shape;Limiting;Electron tubes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989477&isnumber=7988677

H. Vejdani, D. Boerma, S. M. Swartz and K. S. Breuer, "Guidelines for the design and control of bio-inspired hovering robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4160-4166.
doi: 10.1109/ICRA.2017.7989478
Abstract: We study the dynamics of hovering mechanisms inspired by hummingbirds and bats to extract practical guidelines for the design and control of aerial robots. Using a dynamical model that incorporates wing flapping, pronation and folding, we determine the parameters for which hovering is possible. We show that the pronation angle (rotational degree of freedom for the wing about its span) significantly effects energy consumption of the system and demonstrate an optimal wing-beat frequency that minimizes the average power consumption. Furthermore, we show that increased body rotational inertia can significantly increase the energy consumption of hovering and can lead to implausible hovering trajectories. Last, we show that a bat-inspired hovering mechanism that allows for wing folding can generate plausible hovering behavior for larger aerial systems.
keywords: {Aerodynamics;Drag;Robots;Insects;Strips;Energy consumption;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989478&isnumber=7988677

A. R. Chowdhury, A. Vibhute, G. S. Soh, S. H. Foong and K. L. Wood, "Implementing caterpillar inspired roll control of a spherical robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4167-4174.
doi: 10.1109/ICRA.2017.7989479
Abstract: This paper presents a novel caterpillar inspired rolling gait generation and control mechanism of a spherical robot. The research investigates efficient locomotory rolling gaits of Pleurotya caterpillar in unstructured environment. A similar rhythmic rolling pattern is produced for the spherical robot locomotion. A synergetically combined feedforward - feedback control strategy is further proposed. The feedforward component is generated from centrally connected pattern generators (CPGs)in conjunction with nonlinear robot dynamics. A nonlinear integral sliding mode (ISMC) feedback method regulates these rhythmic patterns to adjust robot stability and robustness in the presence of parameter uncertainties and external disturbances. The proposed control strategy is developed, implemented and tested for the spherical robot on both smooth and irregular surfaces. The robot performance is quantified by measuring the stability in roll angle and wheel velocities. Experimental results show that proposed novel strategy is efficient in producing a stable rolling gait and robust control of a spherical robot on different types of surface conditions.
keywords: {Wheels;Mobile robots;Friction;Dynamics;Robot kinematics;Feedforward neural networks;Pleurotya caterpillar;Biomimetics;Spherical Robot;Rolling gait;Central Pattern Generator (CPG);Rolling friction;Integral sliding mode (ISMC) Control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989479&isnumber=7988677

B. Kwak and J. Bae, "Design of hair-like appendages and their coordination inspired by water beetles for steady swimming on the water surface," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4175-4180.
doi: 10.1109/ICRA.2017.7989480
Abstract: Locomotion of water beetles have been widely studied in biology owing to their remarkable swimming skills. Here, we investigated the coordination between the two pairs of legs to achieve steady swimming with novel hair-like appendages. Some design considerations and a fabrication of the hair-like appendages, which can passively adjust their projected area to obtain net thrust, are proposed. As do water beetles in nature, the coordination between the two pairs of legs were considered to achieve steady swimming without jerky motion by varying the beating frequency and phase of the legs. To verify the functionality of the hair-like appendages and their coordinations, six different types of appendages were fabricated, and two robots (one with single pair and the other with two pairs of legs) were built. Locomotion of the robots were compared through experiments, and steady swimming was achievable by properly coordinating the two-pairs of legs without sacrificing the swmming speed.
keywords: {Legged locomotion;Hair;Robot kinematics;Flexible printed circuits;Fabrication;Aluminum},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989480&isnumber=7988677

T. D. Niehues, R. J. King, A. D. Deshpande and S. Keller, "Development and validation of modeling framework for interconnected tendon networks in robotic and human fingers," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4181-4186.
doi: 10.1109/ICRA.2017.7989481
Abstract: The primary contribution of this work is the development of a generalized modeling methodology for complex tendon systems toward a long-term goal of modeling the mechanical structure of the human finger. The key feature of this model is its ability to predict how muscle forces will transmit through an interconnected tendon network based on tendon kinematics and the current joint posture, so that the transformation from input muscle forces to output joint torques and fingertip forces is accurately represented. The feasibility of this model is evaluated by using a tendon-driven robotic finger testbed. Moreover, we utilize the validated model to explore unique features of the extensor mechanism.
keywords: {Tendons;Muscles;Joining processes;Force;Computational modeling;Predictive models;Electronics packaging},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989481&isnumber=7988677

N. M. Cahill, Y. Ren and T. G. Sugar, "Mechanical specialization of robotic limbs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4187-4192.
doi: 10.1109/ICRA.2017.7989482
Abstract: In this paper we introduce a design framework that permits task-specific complex geometries in robotic limbs with the minimal power consumption. Additionally we present a optimal gear ratio selection algorithm with realistic constraints, which we use as a subroutine within the geometry optimization. As a case study we optimize the a spatial, hybrid parallel-serial robotic limb structure with a large set of geometric parameters. Optimal design with respect to this mechanism produces three locally optimal families of designs. These are analyzed rigorously and a best design was chosen. A prototype has been constructed from the chosen design family, proving that the approach is practical. This serves as evidence that the design optimization method is an effective tool to minimize the electrical cost of a given task, and thus specialize the design.
keywords: {Legged locomotion;Optimization;Gears;Torque;DC motors;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989482&isnumber=7988677

N. L. Rodas, J. Bert, D. Visvikis, M. de Mathelin and N. Padoy, "Pose optimization of a C-arm imaging device to reduce intraoperative radiation exposure of staff and patient during interventional procedures," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4200-4207.
doi: 10.1109/ICRA.2017.7989483
Abstract: Minimally-invasive (MI) procedures are becoming more popular and frequent due to their benefits such as reduced patient trauma and hospitalization time. However, several common types of MI interventions are performed under X-ray guidance, which exposes both patients and staff to harmful ionizing radiation. Radiation exposure has therefore become a major concern for the medical community. Yet, few efforts to actively reduce it by exploiting the robotic capabilities of the devices present in the surgical suite have been performed. The propagation of radiation highly depends on the X-ray source positioning. Hence, we propose an approach to optimize the imaging device's pose in order to reduce the exposure to radiation of both patient and staff, while preserving the visibility of the targeted anatomical structure in the acquired image. Our method is based on the optimization of a cost function, which takes the current context and device parameters into account to compute the overall radiation exposure. It relies on GPU-accelerated Monte Carlo methods to simulate radiation propagation and performs the optimization in quasi real-time. When evaluated on a set of standard imaging configurations, our approach is able to recommend a device's pose in a few seconds, for which the delivered dose is reduced. Such an approach can contribute to lower the probability of appearance and severity of long-term negative effects due to radiation exposure and improve overall radiation safety.
keywords: {Imaging;X-ray imaging;Robots;Optimization;Safety;Kinematics;Performance evaluation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989483&isnumber=7988677

F. Zhang, Z. Yan and Z. Du, "Preoperative planning for the multi-arm surgical robot using PSO-GP-based performance optimization," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4208-4214.
doi: 10.1109/ICRA.2017.7989484
Abstract: For the robotically-assisted minimally invasive surgery, preoperative planning is essential towards assisting surgeons to prepare the intervention and to decide the best access to the surgical site. Many recent studies in preoperative planning have focused on the pose selection of the robot and the port placement. However, as such techniques cannot evaluate the performance of the multi-arm cooperation, their applications are constrained in real practise with multi-arm surgical robots. In this paper, the surgical workspace is divided and the subspaces are assigned with different weights to reflect the internal differences within the surgical workspace. We propose three metrics to evaluate the performance of the multi-arm surgical robot: Global Isotropy Index (GII) to measure the dexterity of one single robot arm; Cooperation Capability Index (CCI) to reflect the performance of the multi-arm cooperation; Minimum Distance Index (MDI) to describe the collision avoidance of the robotic arms. We also propose a combination of Particle Swarm Optimization (PSO) and Gaussian Process (GP) to locate the port placement and robot positioning. The proposed integrated PSO-GP-based optimization strategy is implemented on a three-arm surgical robot. Two sets of experiments are carried out to validate our method. The results demonstrate that the performance optimization strategy based on PSO-GP is capable of guiding surgeons to plan an intervention with the multi-arm surgical robot.
keywords: {Manipulators;Medical robotics;Surgery;Collision avoidance;Indexes;Instruments},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989484&isnumber=7988677

A. Acemoglu and L. S. Mattos, "Magnetic laser scanner for endoscopic microsurgery," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4215-4220.
doi: 10.1109/ICRA.2017.7989485
Abstract: Scanning lasers increase the quality of the laser microsurgery enabling fast tissue ablation with less thermal damage. However, the possibility to perform scanning laser microsurgery in confined workspaces is restricted by the large size of currently available actuators, which are typically located outside the patient and require direct line-of-sight to the microsurgical area. Here, a magnetic scanner tool is designed to allow endoscopic scanning laser microsurgery. The tool consists of two miniature electromagnetic coil pairs and permanent magnets attached to a flexible optical fiber. The actuation mechanism is based on the interaction between the electromagnetic field and the permanent magnets. Controlled and high-speed laser scanning is achieved by bending of the optical fiber with magnetic torque. Results demonstrate the achievement of a 3×3 mm2 scanning range within the laser spot is controlled with 35μm precision. The system is also capable of automatically executing high-speed laser scanning operations over customized trajectories with a root-mean-squared-error (RMSE) in the order of 75μm. Furthermore, it can be teleoperated in real-time using any appropriate user interface device. This new technology enables laser scanning in narrow and difficult to reach workspaces, promising to bring the benefits of scanning laser microsurgery to laparoscopic or even flexible endoscopic procedures. In addition, the same technology can be potentially used for optical fiber based imaging, enabling for example the creation of new family of scanning endoscopic OCT or hyperspectral probes.
keywords: {Laser ablation;Tools;Surgery;Magnetic moments;Magnetic resonance imaging;Electromagnetics;Scanning Laser;Magnetic Actuation;Laser Microsurgery;Endoscopic Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989485&isnumber=7988677

K. Chandrasekaran, A. Sathuluri and A. Thondiyath, "MagNex — Expendable robotic surgical tooltip," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4221-4226.
doi: 10.1109/ICRA.2017.7989486
Abstract: This paper presents the design of a single use disposable compliant surgical tooltip for a tele-operated surgical robot. The proposed design aims at mitigating bio-fouling of surgical tools. By implementing a monolithic design for surgical tooltip, the cleaning and sterilization processes needed after every surgery for traditional surgical robotic tools is considerably simplified. The proposed design has 3 degrees of freedom (DOF) with a modified serpentine joint for enhanced buckling strength and off-axis stiffness. A magnetic force based coupling is proposed as a means of transferring power through a hermetic barrier to maneuver the tooltip. The tooltip is thus coupled through a hermetically sealed tool shaft preventing biological material from entering the tool shaft. By having a pluggable tooltip, modularity is also achieved by interchangeable tooltip instead of replacing the whole tool during surgery. A prototype of the proposed design is developed and its functional performance is validated. Owing to the magnetic nexus which forms the magnetic coupling, the tool is named MagNex.
keywords: {Tools;Magnetic flux;Magnetic separation;Shafts;Robots;Magnetic domains;Couplings},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989486&isnumber=7988677

A. R. Yazdanpanah, X. Liu and J. Tan, "Modeling and analysis of a laparoscopic camera's interaction with abdomen tissue," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4227-4232.
doi: 10.1109/ICRA.2017.7989487
Abstract: Robotic camera systems have recently drawn attention in minimally invasive surgeries(MIS). Control and manipulation of these systems during traversing abdominal cavity is associated with camera-tissue interaction. This paper demonstrates a theoretical and experimental analysis of a wireless laparoscopic camera's interaction with abdominal wall during MIS. A mechanical model is developed to represent the behavior of abdominal wall bulk tissue by considering skin, fat, muscle and connective tissues layers which predicts behavior of the tissue during interaction with laparoscopic camera. The model was implemented in ABAQUS to analyze the camera-tissue interaction and find interaction forces generated during contact and motion with different linear and rotational speeds. Simulations were validated by experiments on porcine tissue which can be used for proper control of insertable camera. A noninvasive method is proposed to measure the mechanical properties of each patient's abdominal wall tissue at start of MIS in order to tune the control system to optimize the interaction depth and opposite forces. This method features preventing overload damage and camera fall during MIS.
keywords: {Cameras;Robot vision systems;Force;Abdomen;Creep;Surgery},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989487&isnumber=7988677

G. Gras et al., "Implicit gaze-assisted adaptive motion scaling for highly articulated instrument manipulation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4233-4239.
doi: 10.1109/ICRA.2017.7989488
Abstract: Traditional robotic surgical systems rely entirely on robotic arms to triangulate articulated instruments inside the human anatomy. This configuration can be ill-suited for working in tight spaces or during single access approaches, where little to no triangulation between the instrument shafts is possible. The control of these instruments is further obstructed by ergonomic issues: The presence of motion scaling imposes the use of clutching mechanics to avoid the workspace limitations of master devices, and forces the user to choose between slow, precise movements, or fast, less accurate ones. This paper presents a bi-manual system using novel self-triangulating 6-degrees-of-freedom (DoF) tools through a flexible elbow, which are mounted on robotic arms. The control scheme for the resulting 9-DoF system is detailed, with particular emphasis placed on retaining maximum dexterity close to joint limits. Furthermore, this paper introduces the concept of gaze-assisted adaptive motion scaling. By combining eye tracking with hand motion and instrument information, the system is capable of inferring the user's destination and modifying the motion scaling accordingly. This safe, novel approach allows the user to quickly reach distant locations while retaining full precision for delicate manoeuvres. The performance and usability of this adaptive motion scaling is evaluated in a user study, showing a clear improvement in task completion speed and in the reduction of the need for clutching.
keywords: {Instruments;Manipulators;Tools;Surgery;Kinematics;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989488&isnumber=7988677

A. Mitrevski, A. Kuestenmacher, S. Thoduka and P. G. Plöger, "Improving the reliability of service robots in the presence of external faults by learning action execution models," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4256-4263.
doi: 10.1109/ICRA.2017.7989489
Abstract: While executing actions, service robots may experience external faults because of insufficient knowledge about the actions' preconditions. The possibility of encountering such faults can be minimised if symbolic and geometric precondition models are combined into a representation that specifies how and where actions should be executed. This work investigates the problem of learning such action execution models and the manner in which those models can be generalised. In particular, we develop a template-based representation of execution models, which we call δ models, and describe how symbolic template representations and geometric success probability distributions can be combined for generalising the templates beyond the problem instances on which they are created. Our experimental analysis, which is performed with two physical robot platforms, shows that δ models can describe execution-specific knowledge reliably, thus serving as a viable model for avoiding the occurrence of external faults.
keywords: {Data models;Reliability;Service robots;Search problems;Prediction algorithms;Cognition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989489&isnumber=7988677

A. Causo, P. Z. Win, P. S. Guo and I. -. Chen, "Deploying social robots as teaching aid in pre-school K2 classes: A proof-of-concept study," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4264-4269.
doi: 10.1109/ICRA.2017.7989490
Abstract: This paper describes the outcome of a pilot study of deploying humanoid social robots as a teaching aid in preschool classroom. Sixteen K2 students each from two pre-schools were recruited to test commercially available robots, Pepper and Nao. The robots were assigned to different schools and were programmed to deliver 6 lessons over a span of 3 months. To assess the deployment and the performance of the children, we used Likert-scale based survey to record our observations. One of the survey forms used was TEPI, which measures the performance of the children's behavior based on three major criteria. The TEPI data gathered suggests that during the lessons children display desirable behavior such as critical thinking, imagination and creativity, and social interaction and independence. We also observed classroom atmosphere, classroom management, and class behavior during the lessons. Data from the survey highlights the potential benefits and the challenges of deploying robots as a teaching aid in a real classroom setting.
keywords: {Education;Atmosphere;Robot sensing systems;Creativity;Tools;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989490&isnumber=7988677

D. Nyga, M. Picklum, S. Koralewski and M. Beetz, "Instruction completion through instance-based learning and semantic analogical reasoning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4270-4277.
doi: 10.1109/ICRA.2017.7989491
Abstract: As autonomous, mobile robots are increasingly entering our everyday lives and the tasks they are to perform are getting continuously more complex and versatile, instructing robots by means of natural-language commands becomes more and more important. Such instructions, stated by humans and originally intended for human use, are typically formulated very vaguely and lack critical information about how to perform particular actions. Probabilistic relational models have shown promise in filling in missing information pieces that have been omitted in such instructions. However, the enormous size of these models and the computational expense in learning and reasoning often impedes their practical applicability to real-world domains. In this work, we propose a novel instance-based learning approach towards building up knowledge bases for instruction completion, which combines probabilistic methods with semantic analogical reasoning. Probabilistic reasoning is employed to build up a knowledge base of natural-language instruction sheets, while instruction completion can be achieved through fast database queries. We showcase the scalabilty of our approach by building up a KB of more than 100,000 instruction steps that have been mined from the wikihow.com web site and which are publicly accessible from within the Prac [21] natural-language interpreter.
keywords: {Cognition;Probabilistic logic;Robots;Semantics;Computational modeling;Knowledge based systems;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989491&isnumber=7988677

D. Nyga, M. Picklum and M. Beetz, "What no robot has seen before — Probabilistic interpretation of natural-language object descriptions," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4278-4285.
doi: 10.1109/ICRA.2017.7989492
Abstract: We investigate the task of recognizing objects of daily use in human environments purely based on object descriptions given in natural language. In particular, we present an approach to transform phrases stated in natural language that describe such objects by their visual appearance into formal, semantic representations of their perceptual characteristics, which in turn can be used in a robot perception system in order to identify objects that the robot has never encountered before. To this end, we learn probabilistic first-order knowledge bases from encyclopedic articles and online dictionaries, which contain textual descriptions of a vast amount of everyday objects. We demonstrate the applicability of the approach on a robotic system in a proof-of-concept evaluation on a selected set of object descriptions acquired from the internet.
keywords: {Robots;Semantics;Image color analysis;Object recognition;Probabilistic logic;Natural languages;Taxonomy},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989492&isnumber=7988677

L. Moriello, L. Biagiotti, C. Melchiorri and A. Paoli, "Control of liquid handling robotic systems: A feed-forward approach to suppress sloshing," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4286-4291.
doi: 10.1109/ICRA.2017.7989493
Abstract: This paper presents a feed-forward approach to reduce sloshing dynamics in liquid handling robotic systems. According to our solution, the dynamics of a liquid into an open vessel manipulated by a robot can be described by means of a spherical pendulum mechanical model. By doing this, the sloshing problem can be addressed as a vibration suppression problem for a second order system. More in details, the pendulum model is utilized to tune an exponential filter which shapes the reference trajectory for the robot, thus achieving a sloshing-free motion of the liquid inside the vessel.
keywords: {Liquids;Service robots;Vibrations;Trajectory;Dynamics;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989493&isnumber=7988677

K. Ma, L. Liu and G. S. Sukhatme, "Informative planning and online learning with sparse Gaussian processes," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4292-4298.
doi: 10.1109/ICRA.2017.7989494
Abstract: A big challenge in environmental monitoring is the spatiotemporal variation of the phenomena to be observed. To enable persistent sensing and estimation in such a setting, it is beneficial to have a time-varying underlying environmental model. Here we present a planning and learning method that enables an autonomous marine vehicle to perform persistent ocean monitoring tasks by learning and refining an environmental model. To alleviate the computational bottleneck caused by large-scale data accumulated, we propose a framework that iterates between a planning component aimed at collecting the most information-rich data, and a sparse Gaussian Process learning component where the environmental model and hyperparameters are learned online by taking advantage of only a subset of data that provides the greatest contribution. Our simulations with ground-truth ocean data shows that the proposed method is both accurate and efficient.
keywords: {Data models;Planning;Training;Computational modeling;Robot sensing systems;Predictive models;Kernel},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989494&isnumber=7988677

S. Gunn, P. B. Luh, X. Lu and B. Hotaling, "Optimizing guidance for an active shooter event," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4299-4304.
doi: 10.1109/ICRA.2017.7989495
Abstract: It is unclear what triggers the behavior of active shooters, but their consequences are severe. There is opportunity to implement an automated response system capable of delivery guidance to evacuees' to aide people to safety. Optimizing guidance delivery is challenging because active shooter incidents evolve quickly and are unpredictable. In this paper, we develop a new problem formulation specific for active shooter events by utilizing the structure of each room. To effectively solve this problem, a divide-and-conquer approach is deployed to split evacuees into groups. The egress routes are decomposed and coordinated for each group are optimized using stochastic dynamic programming. Numerical testing and simulation show our solution with a safe room the solution fast relevant to shooting events and effectively.
keywords: {Buildings;Optimization;Mathematical model;Computational modeling;Law enforcement;Stress;Probabilistic logic},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989495&isnumber=7988677

J. D. Carrico, K. J. Kim and K. K. Leang, "3D-printed ionic polymer-metal composite soft crawling robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4313-4320.
doi: 10.1109/ICRA.2017.7989496
Abstract: This paper presents the design, fabrication, modeling, and performance characterization of a new 3D-printed ionic polymer-metal composite (IPMC) soft crawling robot. First, a precursor to an ionomeric polymer material (Nafion) is used to 3D print modular leg and body sections to create a caterpillar-like robot. Then, the printed components are activated, plated with electrodes, assembled together to create the robot from smart electroactive polymer material. The 3D-printed robot exploits the unique capabilities of IPMC materials; specifically, the actuation of the hydrated 3D-printed leg and body sections can be controlled by applying a voltage signal. In particular, the IPMC legs can grip and the body sections can expand and contract, allowing the robot to propel itself forward and backward. The newly-developed 3D-printing process and the robot design and modeling process are described. Experimental results are presented that show the prototype robot moving along a tube like a caterpillar or inchworm.
keywords: {Legged locomotion;Polymers;Electrodes;Actuators;Robot sensing systems;Three-dimensional printing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989496&isnumber=7988677

C. -J. Peng et al., "A versatile conducting interpenetrating polymer network for sensing and actuation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4321-4325.
doi: 10.1109/ICRA.2017.7989497
Abstract: This work deals with a Conducting-Interpenetrating Polymer Network (C-IPN). The C-IPN exhibits very interesting and promising properties which can make it suitable for applications in robotics as a tool to perform tasks in the fields of manipulation, grasping or force measurement. It is known in the literature that such C-IPN may be actuated and bended to interact with other objects. Some of them can also be used as sensors to characterize the interaction. In this paper, we show that actuation and sensing can be performed at the same time. Moreover, we propose analytical models which can be useful for future work to process the C-IPN output and to control them. All results are verified with experimental data.
keywords: {Electrodes;Actuators;Polymers;Mathematical model;DC motors;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989497&isnumber=7988677

L. Hines, K. Petersen and M. Sitti, "Asymmetric stable deformations in inflated dielectric elastomer actuators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4326-4331.
doi: 10.1109/ICRA.2017.7989498
Abstract: Robotic systems that are soft or incorporate soft actuators are well suited for operation in unstructured environments and for safe interactions with fragile objects. The majority, however, are tethered or burdened with bulky payloads of pumps and compressors. In a recent article we presented a sealed, inflated actuator composed of fluidically connected membrane dielectric elastomer actuators capable of large, repeatable, and stable deformations. Each membrane could switch between two identical volumes, and maintain its shape when an applied voltage was removed. Here we extend our previous work by simulating and demonstrating asymmetric stable deformations. In an experimental two-membrane setup, the membranes experience large and significantly different area strains of >100% and >550% when transitioning between stable states. With the addition of more membranes, this asymmetry can increase the number of discrete stable membrane sizes, allowing more complex control when later implemented in a mechanism.
keywords: {Actuators;Robots;Switches;Shape;Compressors;Strain;Dielectrics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989498&isnumber=7988677

F. Chen et al., "Networked soft actuators with large deformations," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4332-4337.
doi: 10.1109/ICRA.2017.7989499
Abstract: Soft actuators play an important role in producing motions in soft robots, and dielectric elastomers have shown great promise because of their considerable voltage-induced deformation. In particular, air-filled dielectric elastomer actuators have been well studied, where the air inside provides prestretches to improve the actuation range. This paper proposes a network of inflated dielectric elastomer actuators, interconnected via a chamber, with the advantages to be highly deformable and continuously controllable. Theoretical analyses show that the networked design is able to largely postpone the occurrence of material failures of the actuators, resulting in a large and continuous actuation range for their control. We further carried out experiments for validation, and the results were largely in line with the theoretical predictions. These findings essentially provide insight into developing networked soft actuators, for achieving large actuation capability.
keywords: {Actuators;Dielectrics;Aerospace electronics;Electromagnetic interference;Shape;Service robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989499&isnumber=7988677

J. O. Alcaide, L. Pearson and M. E. Rentschler, "Design, modeling and control of a SMA-actuated biomimetic robot with novel functional skin," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4338-4345.
doi: 10.1109/ICRA.2017.7989500
Abstract: Traditional colonoscopy requires highly trained personnel to be performed. Additionally, current devices may cause discomfort and carry the risk of perforating the bowel wall. In this paper, a soft three modular section robot is designed, modeled, controlled and tested. Each of the robotic sections has three degrees of freedom, one translation and two rotations. The robot uses a peristaltic motion to translate, inspired by the motion generated by the bowel. The robot uses nine independently controlled Shape Memory Alloy (SMA) springs as its actuators and a novel silicone rubber skin provides the passive recovery force to expand the springs to their original state. It also incorporates three air tubes, one for each section, to provide forced convection reducing the cooling time of the SMA springs. A parametric study on the skin curvature and thickness using Finite Element Analysis (FEA) is performed to maximize traction while providing enough recovery force. A multi-input multi-output (MIMO) controller based on fuzzy control is designed and implemented for each of the sections allowing the robot to achieve any orientation between −90° and +90° in both pitch and roll in less than 4 seconds with near zero steady state error. Both the peristaltic motion and the orientability of the robot are tested. The robot is able to perform a peristaltic motion with maximum speed of 4 mm/s (24 cm/min) and an average speed of 2.2 cm/min. Each section is also able to follow, with less than 2% overshoot and near zero steady-state error, periodic multi-input squared signals of 25° of amplitude.
keywords: {Springs;Robots;Skin;Force;Actuators;Wires;Temperature measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989500&isnumber=7988677

M. Duduta, D. R. Clarke and R. J. Wood, "A high speed soft robot based on dielectric elastomer actuators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4346-4351.
doi: 10.1109/ICRA.2017.7989501
Abstract: A multilayer fabrication method has been used to create crawling soft robots based on dielectric elastomer actuators. These actuators are created without the need for pre-stretch, eliminating the need for rigid components. A four-legged, multi-gait capable crawler can be fabricated in a matter of hours and shows promise for future untethered systems. Studies on inchworm robots show them to be the fastest dielectric elastomer actuator-based systems reported to date, capable of traveling faster than 1 body length/second for the best elastomer available. Most importantly, the devices are primarily soft and deformable, with few rigid attachments.
keywords: {Actuators;Legged locomotion;Nonhomogeneous media;Fabrication;Force;Electrodes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989501&isnumber=7988677

K. P. Becker, N. W. Bartlett, M. J. D. Malley, P. M. Kjeer and R. J. Wood, "Tunable friction through constrained inflation of an elastomeric membrane," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4352-4357.
doi: 10.1109/ICRA.2017.7989502
Abstract: Many areas of robotics, particularly locomotion and grasping, can benefit from the ability to modulate friction on surfaces that come into contact with objects in the environment. Previous research has tried to address the challenge of tunable friction; however, those efforts only provide modest gains or are difficult to integrate. We propose a tunable friction mechanism that relies on pneumatic actuation and is easily integrated into pre-existing soft actuators. We characterize the performance of our friction mechanism with quantitative force data for varying preload forces, substrate materials, and inflation pressures. Testing results show that our tunable friction mechanism achieves an order of magnitude differentiation in friction forces between high and low friction states. We demonstrate its potential application in a one degree-of-freedom soft crawler and a soft gripper with actuatable finger friction pads. The crawler successfully propelled itself forward by leveraging asymmetric strokes and the gripper achieved a factor of five differentiation of grip force between engaged and disengaged states of the friction tuning mechanism.
keywords: {Friction;Force;Substrates;Tuning;Force measurement;Testing;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989502&isnumber=7988677

D. Schneider, E. Schömer and N. Wolpert, "Collision detection for 3D rigid body motion planning with narrow passages," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4365-4370.
doi: 10.1109/ICRA.2017.7989503
Abstract: In sampling-based 3D rigid body motion planning one of the major subroutines is collision detection. Especially for problems with narrow passages many samples have to be checked by a collision detection algorithm. In this application, the runtime of the motion planning algorithm is dominated by collision detection and the samples have the very specific characteristic that many of them are in collision and have small penetration volumes. In our work, we introduce a data structure and an algorithm that makes use of this characteristic by combining well-known data structures like a distance field and an octree with the swap algorithm by Llanas et al. For 3D rigid body motion planning with narrow passages, our approach achieves a speedup of up to 5.0 compared to well-established collision detection libraries like the Proximity Query Package (PQP) and the Flexible Collision Library (FCL).
keywords: {Collision avoidance;Planning;Algorithms;Data structures;Acceleration;Three-dimensional displays;Image edge detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989503&isnumber=7988677

R. Burger, M. Bharatheesha, M. van Eert and R. Babuška, "Automated tuning and configuration of path planning algorithms," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4371-4376.
doi: 10.1109/ICRA.2017.7989504
Abstract: A large number of novel path planning methods for a wide range of problems have been described in literature over the past few decades. These algorithms can often be configured using a set of parameters that greatly influence their performance. In a typical use case, these parameters are only very slightly tuned or even left untouched. Systematic approaches to tune parameters of path planning algorithms have been largely unexplored. At the same time, there is a rising interest in the planning and robotics communities regarding the real world application of these theoretically developed and simulation-tested planning algorithms. In this work, we propose the use of Sequential Model-based Algorithm Configuration (SMAC) tools to address these concerns. We show that it is possible to improve the performance of a planning algorithm for a specific problem without the need of in-depth knowledge of the algorithm itself. We compare five planners that see a lot of practical usage on three typical industrial pick-and-place tasks to demonstrate the effectiveness of the method.
keywords: {Planning;Tuning;Robots;Algorithm design and analysis;Software algorithms;Prediction algorithms;Software},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989504&isnumber=7988677

R. Nakamura and A. Amino, "Perfect tracking control using a phase plane for a wheeled inverted pendulum under hardware constraints," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4377-4382.
doi: 10.1109/ICRA.2017.7989505
Abstract: A wheeled inverted pendulum cannot balance without control, and it is important to save motion in a control range. In some situations, however, to avoid a collision, the maximum acceleration and deceleration must be applied. A motion-planning method for a wheeled inverted pendulum (“body” hereafter)-which uses full performance from all attitudes under hardware constraints-was developed. The developed method involves two steps. First, a linear combination of zeroth to fourth differentials of parameters based on the motion equation of a wheeled inverted pendulum is obtained. Second, the arbitrary attitude of the wheeled inverted pendulum and hardware constraints are expressed on a phase plane containing angular rate of body motion and an angular inclination of the body. By executing these two steps, a motion plan can be expressed on the phase plane. A simulation based on a model confirmed that the movement plan formulated by this technique can be followed with no error.
keywords: {Wheels;Torque;Robots;Hardware;Acceleration;Mathematical model;Tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989505&isnumber=7988677

M. J. Kuhlman, M. W. Otte, D. Sofge and S. K. Gupta, "Maximizing mutual information for multipass target search in changing environments," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4383-4390.
doi: 10.1109/ICRA.2017.7989506
Abstract: Motion planning for multi-target autonomous search requires efficiently gathering as much information over an area as possible with an imperfect sensor. In disaster scenarios and contested environments the spatial connectivity may unexpectedly change (due to aftershock, avalanche, flood, building collapse, adversary movements, etc.) and the flight envelope may evolve as a known function of time to ensure rescue worker safety or to facilitate other mission goals. Algorithms designed to handle both expected and unexpected changes must: (1) reason over a sufficiently long time horizon to respect expected changes, and (2) replan quickly in response to unexpected changes. These ambitions are hindered by the submodularity property of mutual information, which makes optimal solutions NP-hard to compute. We present an algorithm for autonomous search in changing environments that uses a variety of techniques to improve both the speed and time horizon, including using e-admissible heuristics to speed up the search.
keywords: {Robot sensing systems;Mutual information;Computational modeling;Planning;Target tracking;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989506&isnumber=7988677

L. He, J. Pan and D. Manocha, "Efficient multi-agent global navigation using interpolating bridges," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4391-4398.
doi: 10.1109/ICRA.2017.7989507
Abstract: We present a novel approach for collision-free global navigation for continuous-time multi-agent systems with general linear dynamics. Our approach is general and can be used to perform collision-free navigation in 2D and 3D workspaces with narrow passages and crowded regions. As part of pre-computation, we compute multiple bridges in the narrow or tight regions in the workspace using kinodynamic RRT algorithms. Our bridge has certain geometric properties that enable us to calculate a collision-free trajectory for each agent using simple interpolation at runtime. Moreover, we combine interpolated bridge trajectories with local multi-agent navigation algorithms to compute global collision-free paths for each agent. The overall approach combines the performance benefits of coupled multi-agent algorithms with the precomputed trajectories of the bridges to handle challenging scenarios. In practice, our approach can perform global navigation for tens to hundreds of agents on a single CPU core in 2D and 3D workspaces.
keywords: {Bridges;Trajectory;Navigation;Two dimensional displays;Three-dimensional displays;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989507&isnumber=7988677

C. Cunningham, J. Amato, H. L. Jones and W. L. Whittaker, "Accelerating energy-aware spatiotemporal path planning for the lunar poles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4399-4406.
doi: 10.1109/ICRA.2017.7989508
Abstract: Future robotic missions to the poles of the Moon and Mercury will face challenges not encountered by current and prior planetary rover missions. Careful energy-aware spatiotemporal path planning will be required to accomplish mission objectives at high cadence under changing illumination conditions. With attention to landing site and time, such spatiotemporal path planning may enable extended missions on order of months that would not otherwise be possible. This work presents improvements in energy-aware spatiotemporal path planning for multiple waypoints to significantly reduce planning time. A time-compression technique is used to simplify planning in areas where changes occur infrequently. Consideration of end-goal reachability reduces the search space. Finally, heuristics that use pre-computation with static obstacles speed up the search.
keywords: {Planning;Hazards;Lighting;Path planning;Spatiotemporal phenomena;Moon;Space vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989508&isnumber=7988677

M. Deremetz, R. Lenain, B. Thuilot and V. Rousseau, "Adaptive trajectory control of off-road mobile robots: A multi-model observer approach," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4407-4413.
doi: 10.1109/ICRA.2017.7989509
Abstract: In this paper, the problems associated with accurate path tracking control in off-road conditions is addressed with model-based adaptive control. In particular, the estimation of grip conditions is investigated through the derivation of a new observer and by gathering kinematic and dynamic models into a single framework. This new reference point employs a unique observer regardless of the velocity of the robots. Previous approaches necessitated the switching of models depending upon the phenomena encountered as well as robot dynamics. The observer proposed here allows an accurate and reactive estimation of sliding. This permits to feed relevantly a control law based on an extended kinematic model, enabling accurate path tracking, even in harsh conditions and when facing significant dynamic effects such as spin around.
keywords: {Kinematics;Observers;Mobile robots;Adaptation models;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989509&isnumber=7988677

O. Arslan and D. E. Koditschek, "Smooth extensions of feedback motion planners via reference governors," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4414-4421.
doi: 10.1109/ICRA.2017.7989510
Abstract: In robotics, it is often practically and theoretically convenient to design motion planners for approximate low-order (e.g., position-or velocity-controlled) robot models first, and then adapt such reference planners to more accurate high-order (e.g., force/torque-controlled) robot models. In this paper, we introduce a novel provably correct approach to extend the applicability of low-order feedback motion planners to high-order robot models, while retaining stability and collision avoidance properties, as well as enforcing additional constraints that are specific to the high-order models. Our smooth extension framework leverages the idea of reference governors to separate the issues of stability and constraint satisfaction, affording a bidirectionally coupled robot-governor system where the robot ensures stability with respect to the governor and the governor enforces state (e.g., collision avoidance) and control (e.g., actuator limits) constraints. We demonstrate example applications of our framework for augmenting path planners and vector field planners to the second-order robot dynamics.
keywords: {Robots;Collision avoidance;Navigation;Stability analysis;Asymptotic stability;Dynamics;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989510&isnumber=7988677

C. Liu et al., "Set space visual servoing of a 6-DOF manipulator," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4422-4428.
doi: 10.1109/ICRA.2017.7989511
Abstract: This article develops a set space visual servoing method that is quiet different from state-of-the-art approaches. Our approach does not require complex image processing techniques for the extraction, matching and tracking of image features. Instead, it only requires a simple matching algorithm and builds visual errors in set space. Each error is mainly related to one degree of freedom of the camera; therefore, we can design a decoupled control law. This control law is robust and does not require calibrated inner parameters of the camera. Our approach has been validated in 4-degree-of-freedom (DOF) visual servoing simulations with common image patterns and 6-DOF visual servoing experiments with specific image patterns. These visual servoing tasks are properly achieved even when partial occlusions occur.
keywords: {Visual servoing;Visualization;Cameras;Feature extraction;Aerospace electronics;Algorithm design and analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989511&isnumber=7988677

L. Chen, F. Zhou, Y. Shen, X. Tian, H. Ling and Y. Chen, "Illumination insensitive efficient second-order minimization for planar object tracking," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4429-4436.
doi: 10.1109/ICRA.2017.7989512
Abstract: Tracking for planar objects is an important issue to vision-based robotic applications. In direct visual tracking (DVT) methods, the similarity between two images is often measured through the sum of squared differences (SSD) especially with the efficient second-order minimization (ESM) due to its simplicity and efficiency. However, SSD-based ESM is not robust to illumination changes since it is usually built upon the brightness constancy assumption. Contrast to image brightness, gradient orientations (GO) are invariant to both linear and non-linear illumination changes as verified in practice. Based on GO, we propose an illumination insensitive ESM method for planar object tracking in this paper. In order to introduce GO into the ESM, we generalized the original ESM formulas for multi-dimensional features. In addition, a denoising method based on the Perona-Malik function and a mask image were suggested to improve GO's robustness against image noise and low texture. Our experimental results on dataset for planar objects with illumination changes and a benchmark dataset confirm the proposed method is robust to illumination variations and capable to deal with the general tracking challenges.
keywords: {Lighting;Robustness;Jacobian matrices;Visualization;Brightness;Minimization;Object tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989512&isnumber=7988677

W. Huang, J. Gu, X. Ma and Y. Li, "Correlation filter-based self-paced object tracking," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4437-4442.
doi: 10.1109/ICRA.2017.7989513
Abstract: Object tracking is an important capability for robots tasked with interacting with humans and the environment, and it enables robots to manipulate objects. In object tracking, selecting samples to learn a robust and efficient appearance model is a challenging task. Model learning determines both the strategy and frequency of model updating, which concerns many details that can affect the tracking results. In this paper, we propose an object tracking approach by formulating a new objective function that integrates the learning paradigm of self-paced learning into object tracking such that reliable samples can be automatically selected for model learning. Sample weights and model parameters can be learned by minimizing this single objective function under the framework of kernelized correlation filters. Moreover, a real-valued error-tolerant self-paced function with a constraint vector is proposed to combine prior knowledge, i.e., the characteristics of object tracking, with information learned during tracking. We demonstrate the robustness and efficiency of our object tracking approach on a recent object tracking benchmark data set: OTB 2013.
keywords: {Object tracking;Linear programming;Reliability;Robots;Correlation;Computational modeling;Minimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989513&isnumber=7988677

X. Wang, M. O'Brien, C. Xiang, B. Xu and H. Najjaran, "Real-time visual tracking via robust Kernelized Correlation Filter," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4443-4448.
doi: 10.1109/ICRA.2017.7989514
Abstract: There has been an increasing interest in the use of correlation filters for visual object tracking due to their impressive tracking performance. However, existing correlation filter based tracking methods, such as Struck and Kernelized Correlation Filter (KCF), cannot always solve tracking problems in complicated conditions such as heavy occlusion and aggressive motion. In this paper, we proposed a real-time visual tracker via a robust KCF. We start by implementing a search window alignment, based on a motion model with uncertainty, which increases the tracking accuracy for fast moving targets and reduces the padding value to accelerate tracking speed. Next, we establish a combined confidence measurement including occlusion information, which is utilized for robust updating. Then we apply an adaptive Kalman filter to improve the tracking accuracy. Qualitative and quantitative experimental results show that the proposed algorithm outperforms the state-of-the-art methods such as KCF and Struck.
keywords: {Conferences;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989514&isnumber=7988677

F. Bonnet, L. Cazenille, A. Gribovskiy, J. Halloy and F. Mondada, "Multi-robot control and tracking framework for bio-hybrid systems with closed-loop interaction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4449-4456.
doi: 10.1109/ICRA.2017.7989515
Abstract: Bio-mimetic robots can interact with groups of animals in bio-hybrid systems to study their behaviour by producing calibrated stimuli and by analysing their responses. Integrating a group of robots into a group of animals to mimic their behaviour is challenging, both in terms of robotic hardware design and robot control. In particular, the robots must be able to react in real-time to the animal changes of behaviour. This implies the need to adequately track and identify animal behaviour. In this paper, we present a novel framework to control several bio-mimetic robots to integrate into groups of fish. Our framework is able to track the position of the fish and robots in real-time. The robots are driven by a bio-mimetic model of fish behaviour from the literature. We show that our multi-robot system can successfully integrate into groups of fish with closed-loop interactions between the robots and the fish.
keywords: {Software;Collision avoidance;Mobile robots;Cats;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989515&isnumber=7988677

M. J. Islam and J. Sattar, "Mixed-domain biological motion tracking for underwater human-robot interaction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4457-4464.
doi: 10.1109/ICRA.2017.7989516
Abstract: We present a novel algorithm for an autonomous underwater robot to visually detect and follow its companion human diver. Using both spatial-domain and frequency-domain features pertaining to human swimming patterns, we devise an algorithm to visually detect the position and swimming direction of the diver. Our algorithm is unique in the way that it allows detection of arbitrary motion directions, in addition to keeping track of a diver's position through the image sequence over time. A Hidden Markov Model (HMM)-based approach prunes the search-space of all potential trajectories relying on image intensities in the spatial-domain. A diver's motion signature is subsequently detected in a sequence of non-overlapping image subwindows exhibiting human swimming patterns. The pruning step ensures efficient computation by avoiding exponentially large search-spaces, whereas the frequency-domain detection allows us to detect the diver's position and motion direction accurately. Experimental validation of the proposed approach is presented on datasets collected from open-water and closed-water environments.
keywords: {Tracking;Trajectory;Frequency-domain analysis;Hidden Markov models;Robots;Unmanned underwater vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989516&isnumber=7988677

A. Z. Zhu, N. Atanasov and K. Daniilidis, "Event-based feature tracking with probabilistic data association," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4465-4470.
doi: 10.1109/ICRA.2017.7989517
Abstract: Asynchronous event-based sensors present new challenges in basic robot vision problems like feature tracking. The few existing approaches rely on grouping events into models and computing optical flow after assigning future events to those models. Such a hard commitment in data association attenuates the optical flow quality and causes shorter flow tracks. In this paper, we introduce a novel soft data association modeled with probabilities. The association probabilities are computed in an intertwined EM scheme with the optical flow computation that maximizes the expectation (marginalization) over all associations. In addition, to enable longer tracks we compute the affine deformation with respect to the initial point and use the resulting residual as a measure of persistence. The computed optical flow enables a varying temporal integration different for every feature and sized inversely proportional to the length of the flow. We show results in egomotion and very fast vehicle sequences and we show the superiority over standard frame-based cameras.
keywords: {Optical imaging;Optical sensors;Cameras;Spatiotemporal phenomena;Computational modeling;Integrated optics;Optical computing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989517&isnumber=7988677

M. Rünz and L. Agapito, "Co-fusion: Real-time segmentation, tracking and fusion of multiple objects," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4471-4478.
doi: 10.1109/ICRA.2017.7989518
Abstract: In this paper we introduce Co-Fusion, a dense SLAM system that takes a live stream of RGB-D images as input and segments the scene into different objects (using either motion or semantic cues) while simultaneously tracking and reconstructing their 3D shape in real time. We use a multiple model fitting approach where each object can move independently from the background and still be effectively tracked and its shape fused over time using only the information from pixels associated with that object label. Previous attempts to deal with dynamic scenes have typically considered moving regions as outliers, and consequently do not model their shape or track their motion over time. In contrast, we enable the robot to maintain 3D models for each of the segmented objects and to improve them over time through fusion. As a result, our system can enable a robot to maintain a scene description at the object level which has the potential to allow interactions with its working environment; even in the case of dynamic scenes.
keywords: {Three-dimensional displays;Motion segmentation;Real-time systems;Solid modeling;Tracking;Image segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989518&isnumber=7988677

E. I. Farhi and V. Indelman, "Towards efficient inference update through planning via JIP — Joint inference and belief space planning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4479-4486.
doi: 10.1109/ICRA.2017.7989519
Abstract: Inference and decision making under uncertainty are essential in numerous robotics problems. In recent years, the similarities between inference and control triggered much work, from developing unified computational frameworks to pondering about the duality between the two. In spite of the aforementioned efforts, inference and control, as well as inference and belief space planning (BSP) are still treated as two separate processes. In this paper we propose a novel approach that utilizes the similarities between inference and BSP and make the key observation that inference can be efficiently updated using the precursory planning stage, thus paving the way towards a joint inference and BSP paradigm. We develop four different methods that implement our novel approach under simplifying assumptions and validate them in the context of autonomous navigation in unknown environment. Results indicate that not only our methods improve running time by at least two orders of magnitude, compared to iSAM2 paradigm, they also found to be less sensitive to state dimensionality and loop closures.
keywords: {Planning;Decision making;Jacobian matrices;Aerospace electronics;Uncertainty;Robots;Current measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989519&isnumber=7988677

S. Pathak, A. Thomas and V. Indelman, "Nonmyopic data association aware belief space planning for robust active perception," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4487-4494.
doi: 10.1109/ICRA.2017.7989520
Abstract: One key assumption of Belief Space Planning (BSP) is that the data association is known perfectly. In this paper, we relax this assumption in the context of non-myopic planning as well as belief being a Gaussian Mixture Model (GMM). Interestingly, explicit reasoning about the data association within the belief enables our framework to have parsimonious data association, thereby resulting in a scalable solution compared with na&#x00EF;ve permutational approaches. Unlike in some of the recent approaches where the number of components in a GMM belief can only be reduced, in our approach this can also go up such as due to perceptual aliasing present in the environment. Furthermore, our approach naturally integrates with inference, providing a unified framework for robust passive and active perception. We demonstrate key aspects of our approach and its comparison with the state of the art on a general abstract domain as well as in a real robot setup.
keywords: {Planning;Robot sensing systems;Robustness;Uncertainty;Linear programming},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989520&isnumber=7988677

K. Yousif, Y. Taguchi and S. Ramalingam, "MonoRGBD-SLAM: Simultaneous localization and mapping using both monocular and RGBD cameras," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4495-4502.
doi: 10.1109/ICRA.2017.7989521
Abstract: RGBD SLAM systems have shown impressive results, but the limited field of view (FOV) and depth range of typical RGBD cameras still cause problems for registering distant frames. Monocular SLAM systems, in contrast, can exploit wide-angle cameras and do not have the depth range limitation, but are unstable for textureless scenes. We present a SLAM system that uses both an RGBD camera and a wide-angle monocular camera for combining the advantages of the two sensors. Our system extracts 3D point features from RGBD frames and 2D point features from monocular frames, which are used to perform both RGBD-to-RGBD and RGBD-to-monocular registration. To compensate for different FOV and resolution of the cameras, we generate multiple virtual images for each wide-angle monocular image and use the feature descriptors computed on the virtual images to perform the RGBD-to-monocular matches. To compute the poses of the frames, we construct a graph where nodes represent RGBD and monocular frames and edges denote the pairwise registration results between the nodes. We compute the global poses of the nodes by first finding the minimum spanning trees (MSTs) of the graph and then pruning edges that have inconsistent poses due to possible mismatches using the MST result. We finally run bundle adjustment on the graph using all the consistent edges. Experimental results show that our system registers a larger number of frames than using only an RGBD camera, leading to larger-scale 3D reconstruction.
keywords: {Cameras;Simultaneous localization and mapping;Feature extraction;Three-dimensional displays;Robot vision systems;Image edge detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989521&isnumber=7988677

A. Pumarola, A. Vakhitov, A. Agudo, A. Sanfeliu and F. Moreno-Noguer, "PL-SLAM: Real-time monocular visual SLAM with points and lines," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4503-4508.
doi: 10.1109/ICRA.2017.7989522
Abstract: Low textured scenes are well known to be one of the main Achilles heels of geometric computer vision algorithms relying on point correspondences, and in particular for visual SLAM. Yet, there are many environments in which, despite being low textured, one can still reliably estimate line-based geometric primitives, for instance in city and indoor scenes, or in the so-called “Manhattan worlds”, where structured edges are predominant. In this paper we propose a solution to handle these situations. Specifically, we build upon ORB-SLAM, presumably the current state-of-the-art solution both in terms of accuracy as efficiency, and extend its formulation to simultaneously handle both point and line correspondences. We propose a solution that can even work when most of the points are vanished out from the input images, and, interestingly it can be initialized from solely the detection of line correspondences in three consecutive frames. We thoroughly evaluate our approach and the new initialization strategy on the TUM RGB-D benchmark and demonstrate that the use of lines does not only improve the performance of the original ORB-SLAM solution in poorly textured frames, but also systematically improves it in sequence frames combining points and lines, without compromising the efficiency.
keywords: {Simultaneous localization and mapping;Three-dimensional displays;Cameras;Trajectory;Pipelines;Real-time systems;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989522&isnumber=7988677

L. Contreras and W. Mayol-Cuevas, "O-POCO: Online point cloud compression mapping for visual odometry and SLAM," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4509-4514.
doi: 10.1109/ICRA.2017.7989523
Abstract: This paper presents O-POCO, a visual odometry and SLAM system that makes online decisions regarding what to map and what to ignore. It takes a point cloud from classical SfM and aims to sample it on-line by selecting map features useful for future 6D relocalisation. We use the camera's traveled trajectory to compartamentalize the point cloud, along with visual and spatial information to sample and compress the map. We propose and evaluate a number of different information layers such as the descriptor information's relative entropy, map-feature occupancy grid, and the point cloud's geometry error. We compare our proposed system against both SfM, and online and offline ORB-SLAM using publicly available datasets in addition to our own. Results show that our online compression strategy is capable of outperforming the baseline even for conditions when the number of features per key-frame used for mapping is four times less.
keywords: {Cameras;Three-dimensional displays;Trajectory;Visualization;Simultaneous localization and mapping;Splines (mathematics);Cams},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989523&isnumber=7988677

K. Yousif, Y. Taguchi, S. Ramalingam and A. Bab-Hadiashar, "ROS2D: Image feature detector using rank order statistics," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4515-4522.
doi: 10.1109/ICRA.2017.7989524
Abstract: We present a new image feature detection method. Our method selects features based on segmenting points with high local intensity variations across different scales using a robust rank order statistics approach. Our method produces a large number of repeatable features that are invariant to several image transformations such as rotation, scaling, viewpoint, and lighting variations. We show the advantages of our feature in comparison to other existing features using the Oxford dataset. We also show that, when used in monocular and stereo SLAM systems, our feature outperforms SIFT in terms of the pose estimation accuracy using several public datasets including the KITTI dataset.
keywords: {Feature extraction;Three-dimensional displays;Detectors;Kernel;Image segmentation;Robustness;Lighting},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989524&isnumber=7988677

S. Park, T. Schöps and M. Pollefeys, "Illumination change robustness in direct visual SLAM," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4523-4530.
doi: 10.1109/ICRA.2017.7989525
Abstract: Direct visual odometry and Simultaneous Localization and Mapping (SLAM) methods determine camera poses by means of direct image alignment. This optimizes a photometric cost term based on the Lucas-Kanade method. Many recent works use the brightness constancy assumption in the alignment cost formulation and therefore cannot cope with significant illumination changes. Such changes are especially likely to occur for loop closures in SLAM. Alternatives exist which attempt to match images more robustly. In our paper, we perform a systematic evaluation of real-time capable methods. We determine their accuracy and robustness in the context of odometry and of loop closures, both on real images as well as synthetic datasets with simulated lighting changes. We find that for real images, a Census-based method outperforms the others. We make our new datasets available online.
keywords: {Lighting;Robustness;Measurement;Optimization;Simultaneous localization and mapping;Brightness;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989525&isnumber=7988677

N. Tazhigaliyeva et al., "Cyrillic manual alphabet recognition in RGB and RGB-D data for sign language interpreting robotic system (SLIRS)," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4531-4536.
doi: 10.1109/ICRA.2017.7989526
Abstract: Deaf-mute communities around the world experience a need in effective human-robot interaction system that would act as an interpreter in public places such as banks, hospitals, or police stations. The focus of this work is to address the challenges presented to hearing-impaired people by developing an interpreting robotic system required for effective communication in public places. To this end, we utilize a previously developed neural network-based learning architecture to recognize Cyrillic manual alphabet, which is used for fingerspelling in Kazakhstan. In order to train and test the performance of the recognition system, we collected four datasets comprising of static and motion RGB and RGB-D data of 33 manual gestures. After applying them to standard machine learning algorithms as well as to our previously developed learning-based method, we achieved an average accuracy of 93% for a complete alphabet recognition by modeling motion depth data.
keywords: {Assistive technology;Gesture recognition;Manuals;Sensors;Image segmentation;Humanoid robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989526&isnumber=7988677

T. S. Lembono, J. E. Low, L. S. T. Win, S. Foong and U. -X. Tan, "Orientation filter and angular rates estimation in monocopter using accelerometers and magnetometer with the Extended Kalman Filter," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4537-4543.
doi: 10.1109/ICRA.2017.7989527
Abstract: In monocopter flight, two important parameters are required for control: angular rates and heading direction. Small monocopters fly at a very high speed (more than 600rpm), which can be out of the typical gyroscope limit. Very high speed gyroscopes do exist, but the price is high and it can only measure a single axis rotation. This paper presents an alternative approach to measure angular rates by using three accelerometers. The readings of the accelerometers are subtracted to calculate the angular rates in all three axes (x, y, and z). This paper also proposes to use the Extended Kalman Filter (EKF) to estimate the heading direction based on the magnetometer reading and the angular rates. The angular rates direction is used as the vertical direction reference. The proposed method has been applied on two setups: DC Motor setup (for quantifying the method's performance) and Monocopter setup. In the DC Motor setup, the motor encoder is used as the ground truth for the heading direction. The result is compared with the usual method of using only the magnetometer to obtain the heading direction of monocopters. The EKF result is more accurate and stable even in the presence of strong magnetic disturbances. In addition, the angle of attack and the coning angle can also be determined by the proposed method.
keywords: {Accelerometers;Magnetometers;Kalman filters;Gyroscopes;Earth;Magnetic separation;Gravity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989527&isnumber=7988677

T. Liu and S. Shen, "High altitude monocular visual-inertial state estimation: Initialization and sensor fusion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4544-4551.
doi: 10.1109/ICRA.2017.7989528
Abstract: Obtaining reliable state estimates at high altitude but GPS-denied environments, such as between high-rise buildings or in the middle of deep canyons, is known to be challenging, due to the lack of direct distance measurements. Monocular visual-inertial systems provide a possible way to recover the metric distance through proper integration of visual and inertial measurements. However, the nonlinear optimization problem for state estimation suffers from poor numerical conditioning or even degeneration, due to difficulties in obtaining observations of visual features with sufficient parallax, and the excessive period of inertial measurement integration. In this paper, we propose a spline-based high altitude estimator initialization method for monocular visual-inertial navigation system (VINS) with special attention to the numerical issues. Our formulation takes only inertial measurements that contain sufficient excitation, and drops uninformative measurements such as those obtained during hovering. In addition, our method explicitly reduces the number of parameters to be estimated in order to achieve earlier convergence. Based on the initialization results, a complete closed-loop system is constructed for high altitude navigation. Extensive experiments are conducted to validate our approach.
keywords: {Cameras;Visualization;Robot vision systems;Splines (mathematics);Tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989528&isnumber=7988677

Z. Yang, F. Gao and S. Shen, "Real-time monocular dense mapping on aerial robots using visual-inertial fusion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4552-4559.
doi: 10.1109/ICRA.2017.7989529
Abstract: In this work, we present a solution to real-time monocular dense mapping. A tightly-coupled visual-inertial localization module is designed to provide metric and high-accuracy odometry. A motion stereo algorithm is proposed to take the video input from one camera to produce local depth measurements with semi-global regularization. The local measurements are then integrated into a global map for noise filtering and map refinement. The global map obtained is able to support navigation and obstacle avoidance for aerial robots through our indoor and outdoor experimental verification. Our system runs at 10Hz on an Nvidia Jetson TX1 by properly distributing computation to CPU and GPU. Through onboard experiments, we demonstrate its ability to close the perception-action loop for autonomous aerial robots. We release our implementation as open-source software1.
keywords: {Cameras;Real-time systems;Graphics processing units;Unmanned aerial vehicles;Visualization;Optimization;Algorithm design and analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989529&isnumber=7988677

L. Teixeira and M. Chli, "Real-time local 3D reconstruction for aerial inspection using superpixel expansion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4560-4567.
doi: 10.1109/ICRA.2017.7989530
Abstract: On the quest of automating the navigation of challenging and promising Robotics platforms such as small Unmanned Aerial Vehicles (UAVs), the community has been increasingly active in developing perception capabilities able to run onboard such platforms in real-time. Despite that vision-based techniques have been at the heart of recent advancements, the realistic employment onboard UAVs is still in its infancy. Inspired by some of the most recent breakthroughs in online dense scene estimation and borrowing fundamental concepts from Computer Vision, in this work we propose a new pipeline for real-time, local scene reconstruction using a single camera for aerial navigation. Aiming for denser scene estimation than traditional feature-based maps with the ability to run onboard a small UAV in real-time, the proposed approach is demonstrated to achieve unprecedented performance producing rich maps of the camera's workspace, timely enough to serve in obstacle avoidance and real-time interaction of a robot with its direct surroundings. Evaluation on benchmarking datasets and on challenging aerial footage captured with a UAV featuring a conventional camera, reveals dramatic speed-ups, as well as denser and more accurate local reconstructions with respect to the state of the art.
keywords: {Cameras;Simultaneous localization and mapping;Real-time systems;Estimation;Pipelines;Image reconstruction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989530&isnumber=7988677

C. Papachristos, S. Khattak and K. Alexis, "Uncertainty-aware receding horizon exploration and mapping using aerial robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4568-4575.
doi: 10.1109/ICRA.2017.7989531
Abstract: This paper presents a novel path planning algorithm for autonomous, uncertainty-aware exploration and mapping of unknown environments using aerial robots. The proposed planner follows a two-step, receding horizon, belief space-based approach. At first, in an online computed tree the algorithm finds the branch that optimizes the amount of space expected to be explored. The first viewpoint configuration of this branch is selected, but the path towards it is decided through a second planning step. Within that, a new tree is sampled, admissible branches arriving at the reference viewpoint are found and the robot belief about its state and the tracked landmarks of the environment is propagated. The branch that minimizes the expected localization and mapping uncertainty is selected, the corresponding path is executed by the robot and the whole process is iteratively repeated. The proposed planner is capable of running online onboard a small aerial robot and its performance is evaluated using experimental studies in a challenging environment.
keywords: {Planning;Uncertainty;Collision avoidance;Unmanned aerial vehicles;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989531&isnumber=7988677

S. J. Lee and H. J. Kim, "Autonomous swing-angle estimation for stable slung-load flight of multi-rotor UAVs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4576-4581.
doi: 10.1109/ICRA.2017.7989532
Abstract: This paper presents a practical swing-angle estimation method for slung load operations of the multi-rotor unmanned aerial vehicle (UAV), which is essential to maintain the safety during the operation. In order not to rely on extra sensors for monitoring the swing angle, the proposed method in this paper offers an autonomous swing-angle estimation using only an inertial measurement unit (IMU) and a single load cell attached to the slung load. The disturbance observer (DOB) derived external force estimation is performed to estimate the swing angle. The unique structure of the proposed DOB-based disturbance force estimation technique utilizes the IMU data only. Both simulation and actual experiment are performed to validate the feasibility of the proposed algorithm.
keywords: {Force;Mathematical model;Estimation;Unmanned aerial vehicles;Load modeling;Acceleration;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989532&isnumber=7988677

M. Corah and N. Michael, "Active estimation of mass properties for safe cooperative lifting," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4582-4587.
doi: 10.1109/ICRA.2017.7989533
Abstract: This work considers estimation of mass parameters for multi-robot coordinated lifting in the context of coordinated aerial manipulation, and develops strategies for active parameter estimation for cooperative manipulation tasks through an information-theoretic framework. The active sensing problem is formulated based on application of increasing forces to the object and detection of small motions that occur when the center of pressure exits the convex hull formed by existing contacts. In order to enable identification of informative actions, we develop and employ a closed-form solution of Cauchy-Schwarz quadratic mutual information (Ics) for non-parametric filters. The evaluation considers iterative selection from a finite set of measurements and demonstrates that choosing measurements to maximize Ics significantly improves the convergence rate of the parameter estimates compared to random and cyclic selection methods. This approach is extended to consider actuator constraints and feasible lifting configurations and achieves an 80% success rate in formation of feasible lifting configurations compared to a 53% baseline performance.
keywords: {Estimation;Robot sensing systems;Integrated circuits;Force;Force measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989533&isnumber=7988677

F. Tung and J. J. Little, "MF3D: Model-free 3D semantic scene parsing," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4596-4603.
doi: 10.1109/ICRA.2017.7989534
Abstract: We present a novel model-free method for online 3D semantic scene parsing from video sequences. MF3D (Model-Free 3D) is different from conventional methods for 3D scene parsing in that voxel labelling is approached via search-based label transfer instead of discriminative classification. This non-parametric approach makes MF3D easy to scale with an online growth in the database, as no model re-training is required with the addition of new examples or categories. Experimental results on the KITTI benchmark demonstrate that our model-free approach enables accurate online 3D scene parsing while retaining extensibility to new categories. In addition, we show that unsupervised binary encoding (hashing) techniques can be easily incorporated into our framework for scalability to larger databases.
keywords: {Three-dimensional displays;Semantics;Solid modeling;Labeling;Databases;Two dimensional displays;Surface reconstruction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989534&isnumber=7988677

C. Ye, Y. Yang, R. Mao, C. Fermüller and Y. Aloimonos, "What can i do around here? Deep functional scene understanding for cognitive robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4604-4611.
doi: 10.1109/ICRA.2017.7989535
Abstract: For robots that have the capability to interact with the physical environment through their end effectors, understanding the surrounding scenes is not merely a task of image classification or object recognition. To perform actual tasks, it is critical for the robot to have a functional understanding of the visual scene. Here, we address the problem of localization and recognition of functional areas in an arbitrary indoor scene, formulated as a two-stage deep learning based detection pipeline. A new scene functionality testing-bed, which is compiled from two publicly available indoor scene datasets, is used for evaluation. Our method is evaluated quantitatively on the new dataset, demonstrating the ability to perform efficient recognition of functional areas from arbitrary indoor scenes. We also demonstrate that our detection model can be generalized to novel indoor scenes by cross validating it with images from two different datasets.
keywords: {Visualization;Image color analysis;Computer vision;Pipelines;Ontologies;Biological neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989535&isnumber=7988677

F. Ziaeetabar, E. E. Aksoy, F. Wörgötter and M. Tamosiunaite, "Semantic analysis of manipulation actions using spatial relations," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4612-4619.
doi: 10.1109/ICRA.2017.7989536
Abstract: Recognition of human manipulation actions together with the analysis and execution by a robot is an important issue. Also, perception of spatial relationships between objects is central to understanding the meaning of manipulation actions. Here we would like to merge these two notions and analyze manipulation actions using symbolic spatial relations between objects in the scene. Specifically, we define procedures for extraction of symbolic human-readable relations based on Axis Aligned Bounding Box object models and use sequences of those relations for action recognition from image sequences. Our framework is inspired by the so called Semantic Event Chain framework, which analyzes touching and un-touching events of different objects during the manipulation. However, our framework uses fourteen spatial relations instead of two. We show that our relational framework is able to differentiate between more manipulation actions than the original Semantic Event Chains. We quantitatively evaluate the method on the MANIAC dataset containing 120 videos of eight different manipulation actions and obtain 97% classification accuracy which is 12 % more as compared to the original Semantic Event Chains.
keywords: {Robots;Semantics;Cognition;Three-dimensional displays;Videos;Image segmentation;Visualization;Spatial relations;manipulation actions;semantic analysis;action semantics;action classification},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989536&isnumber=7988677

O. H. Jafari, O. Groth, A. Kirillov, M. Y. Yang and C. Rother, "Analyzing modular CNN architectures for joint depth prediction and semantic segmentation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4620-4627.
doi: 10.1109/ICRA.2017.7989537
Abstract: This paper addresses the task of designing a modular neural network architecture that jointly solves different tasks. As an example we use the tasks of depth estimation and semantic segmentation given a single RGB image. The main focus of this work is to analyze the cross-modality influence between depth and semantic prediction maps on their joint refinement. While most of the previous works solely focus on measuring improvements in accuracy, we propose a way to quantify the cross-modality influence. We show that there is a relationship between final accuracy and cross-modality influence, although not a simple linear one. Hence a larger cross-modality influence does not necessarily translate into an improved accuracy. We find that a beneficial balance between the cross-modality influences can be achieved by network architecture and conjecture that this relationship can be utilized to understand different network design choices. Towards this end we propose a Convolutional Neural Network (CNN) architecture that fuses the state-of-the-art results for depth estimation and semantic labeling. By balancing the cross-modality influences between depth and semantic prediction, we achieve improved results for both tasks using the NYU-Depth v2 benchmark.
keywords: {Semantics;Image segmentation;Estimation;Computer vision;Labeling;Computer architecture;Network architecture},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989537&isnumber=7988677

J. McCormac, A. Handa, A. Davison and S. Leutenegger, "SemanticFusion: Dense 3D semantic mapping with convolutional neural networks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4628-4635.
doi: 10.1109/ICRA.2017.7989538
Abstract: Ever more robust, accurate and detailed mapping using visual sensing has proven to be an enabling factor for mobile robots across a wide variety of applications. For the next level of robot intelligence and intuitive user interaction, maps need to extend beyond geometry and appearance - they need to contain semantics. We address this challenge by combining Convolutional Neural Networks (CNNs) and a state-of-the-art dense Simultaneous Localization and Mapping (SLAM) system, ElasticFusion, which provides long-term dense correspondences between frames of indoor RGB-D video even during loopy scanning trajectories. These correspondences allow the CNN's semantic predictions from multiple view points to be probabilistically fused into a map. This not only produces a useful semantic 3D map, but we also show on the NYUv2 dataset that fusing multiple predictions leads to an improvement even in the 2D semantic labelling over baseline single frame predictions. We also show that for a smaller reconstruction dataset with larger variation in prediction viewpoint, the improvement over single frame segmentation increases. Our system is efficient enough to allow real-time interactive use at frame-rates of ≈25Hz.
keywords: {Semantics;Simultaneous localization and mapping;Three-dimensional displays;Geometry;Two dimensional displays;Labeling;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989538&isnumber=7988677

C. De Alvis, L. Ott and F. Ramos, "Online learning for scene segmentation with laser-constrained CRFs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4639-4643.
doi: 10.1109/ICRA.2017.7989539
Abstract: Scene understanding is a crucial requirement for robot navigation. Conditional Random Fields (CRF) are commonly used to solve the scene labelling problem since they represent contextual information efficiently and provide efficient inference methods. However, when a robot navigates through an unknown environment, it is often necessary to adjust the parameters of the CRF online to maintain the same level of accuracy under changes no predicted during the training phase. Online parameter learning can be challenging since ground truth information is not available for newly encountered scenes. To address this issue, this paper proposes a stochastic gradient descent (SGD) method to learn the parameters of a constrained CRF (cCRF) in an online fashion. By leveraging the information from laser scans and image data the complexity of the labelling problem can be significantly reduced. The parameters are estimated by optimising a novel loss function that takes into account highly confident labels as a reference while eliminating the need for manual labelling. These labels are obtained purely based on the information from camera and laser sensors, in a self-supervised manner. Sensor data is pre-processed using methods such as convolutional nets, discriminant analysis, and Euclidean distance based clustering to extract reference labels. We show that this online parameter learning is robust to changes in the data distribution by selecting the learning rate appropriately. Experimental results are presented on the KITTI data set demonstrating the benefits of online CRF training.
keywords: {Labeling;Sensors;Stochastic processes;Robots;Navigation;Training;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989539&isnumber=7988677

A. Valada, J. Vertens, A. Dhall and W. Burgard, "AdapNet: Adaptive semantic segmentation in adverse environmental conditions," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4644-4651.
doi: 10.1109/ICRA.2017.7989540
Abstract: Robust scene understanding of outdoor environments using passive optical sensors is a onerous and essential task for autonomous navigation. The problem is heavily characterized by changing environmental conditions throughout the day and across seasons. Robots should be equipped with models that are impervious to these factors in order to be operable and more importantly to ensure safety in the real-world. In this paper, we propose a novel semantic segmentation architecture and the convoluted mixture of deep experts (CMoDE) fusion technique that enables a multi-stream deep neural network to learn features from complementary modalities and spectra, each of which are specialized in a subset of the input space. Our model adaptively weighs class-specific features of expert networks based on the scene condition and further learns fused representations to yield robust segmentation. We present results from experimentation on three publicly available datasets that contain diverse conditions including rain, summer, winter, dusk, fall, night and sunset, and show that our approach exceeds the state-of-the-art. In addition, we evaluate the performance of autonomously traversing several kilometres of a forested environment using only the segmentation for perception.
keywords: {Convolution;Kernel;Robustness;Robots;Semantics;Benchmark testing;Image segmentation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989540&isnumber=7988677

W. Ma, J. Li, F. Niu, B. Ouyang, H. Ji and D. Sun, "A robust control scheme for 3D manipulation of a microparticle with electromagnetic coil system," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4660-4665.
doi: 10.1109/ICRA.2017.7989541
Abstract: Electromagnetically actuated microparticles can be widely applied in the field of biomedicine, for its advantages of minimally invasive feature and approachability to complex microenvironments. In this paper, we propose a robust feedback control approach for precise 3D manipulation of a microparticle actuated by a self-constructed electromagnetic coil system. Model uncertainties, environmental disturbances as well as actuator energy loss problem are all taken into account in the controller design. It is shown that this proposed control scheme can enable the entire system to maintain the input-to-state stability in presence of various perturbations. Experimental results have demonstrated the effectiveness of the proposed control approach. Success of the current study will benefit the precise motion control with high throughput in applications of the targeted material delivery.
keywords: {Uncertainty;Three-dimensional displays;Electromagnetics;Magnetic fields;Robustness;Stability analysis;Magnetic forces},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989541&isnumber=7988677

E. Amanov, J. Granna and J. Burgner-Kahrs, "Toward improving path following motion: Hybrid continuum robot design," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4666-4672.
doi: 10.1109/ICRA.2017.7989542
Abstract: Continuum manipulators possess the ability to travel on nonlinear paths and avoid obstacles in confined environments. A variety of designs were proposed for several applications, such as minimally invasive surgery or inspections and maintenance in hazardous spaces. While hyperredundant robots can follow a path on the large scale, path following behavior on small the scale is still a challenge. Only a limited number of paths can be followed by small continuum robots due to design constraints such as fixed curvatures or fixed segment lengths. For most applications, continuum robot parameters have to be optimized and selected according to specific task and design constraints. This is time consuming and limits the utilization of the manipulator to specific application scenarios. In this work, we propose a hybrid continuum robot design to overcome these disadvantages and offer a universal tool which is able to follow any constant curvature path. The design is comprised of a telescopic composition of several tendon driven patterned elastic tubes. Each one can be translated and bent independently. With this design we achieve improved path deviation errors (max 0.6 mm) in comparison to previously proposed continuum robots in simulation. We prove the path following behavior on random paths with a two segment prototype robot with overall outer diameter of 6 mm in an experimental setup with average path deviation errors lower than 5 mm.
keywords: {Electron tubes;Tendons;Manipulators;Motion segmentation;Shape;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989542&isnumber=7988677

M. C. Koval, M. Klingensmith, S. S. Srinivasa, N. S. Pollard and M. Kaess, "The manifold particle filter for state estimation on high-dimensional implicit manifolds," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4673-4680.
doi: 10.1109/ICRA.2017.7989543
Abstract: We estimate the state of a noisy robot arm and underactuated hand using an implicit Manifold Particle Filter (MPF) informed by contact sensors. As the robot touches the world, its state space collapses to a contact manifold that we represent implicitly using a signed distance field. This allows us to extend the MPF to higher (six or more) dimensional state spaces. Earlier work, which explicitly represents the contact manifold, was only capable of scaling to three dimensions. Through a series of experiments, we show that the implicit MPF converges faster and is more accurate than a conventional particle filter during periods of persistent contact. We present three methods of drawing samples from an implicit contact manifold, and compare them in experiments.
keywords: {Robot sensing systems;Manifolds;Particle filters;Noise measurement;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989543&isnumber=7988677

J. E. King, V. Ranganeni and S. S. Srinivasa, "Unobservable Monte Carlo planning for nonprehensile rearrangement tasks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4681-4688.
doi: 10.1109/ICRA.2017.7989544
Abstract: In this work, we present an anytime planner for creating open-loop trajectories that solve rearrangement planning problems under uncertainty using nonprehensile manipulation. We first extend the Monte Carlo Tree Search algorithm to the unobservable domain. We then propose two default policies that allow us to quickly determine the potential to achieve the goal while accounting for the contact that is critical to rearrangement planning. The first policy uses a learned model generated from a set of user demonstrations. This model can be quickly queried for a sequence of actions that attempts to create contact with objects and achieve the goal. The second policy uses a heuristically guided planner in a subspace of the full state space. Using these goal informed policies, we are able to find initial solutions to the problem quickly, then continuously refine the solutions as time allows. We demonstrate our algorithm on a 7 degree-of-freedom manipulator moving objects on a table.
keywords: {Robots;Planning;Monte Carlo methods;Trajectory;Uncertainty;Physics;History},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989544&isnumber=7988677

J. Leitner et al., "The ACRV picking benchmark: A robotic shelf picking benchmark to foster reproducible research," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4705-4712.
doi: 10.1109/ICRA.2017.7989545
Abstract: Robotic challenges like the Amazon Picking Challenge (APC) or the DARPA Challenges are an established and important way to drive scientific progress. They make research comparable on a well-defined benchmark with equal test conditions for all participants. However, such challenge events occur only occasionally, are limited to a small number of contestants, and the test conditions are very difficult to replicate after the main event. We present a new physical benchmark challenge for robotic picking: the ACRV Picking Benchmark. Designed to be reproducible, it consists of a set of 42 common objects, a widely available shelf, and exact guidelines for object arrangement using stencils. A well-defined evaluation protocol enables the comparison of complete robotic systems - including perception and manipulation - instead of sub-systems only. Our paper also describes and reports results achieved by an open baseline system based on a Baxter robot.
keywords: {Benchmark testing;Robot kinematics;Protocols;Service robots;Standards;Australia},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989545&isnumber=7988677

O. Kroemer and G. S. Sukhatme, "Feature selection for learning versatile manipulation skills based on observed and desired trajectories," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4713-4720.
doi: 10.1109/ICRA.2017.7989546
Abstract: For a manipulation skill to be applicable to a wide range of scenarios, it must generalize between different objects and object configurations. Robots should therefore learn skills that adapt to features describing the objects being manipulated. Most of these object features will however be irrelevant for generalizing the skill and, hence, the robot should select a small set of relevant features for adapting the skill. We use a framework for learning versatile manipulation skills that adapt to a sparse set of object features. Skills are initially learned from demonstrations and subsequently improved using reinforcement learning. The robot also learns a meta prior over the features' relevances to guide the feature selection process. In this paper, we explore using either desired trajectories or observed trajectories for selecting the relevant features. The framework was evaluated on placing, tilting, and wiping tasks. The evaluations showed that using the desired trajectories to select the relevant features lead to better skill learning performance.
keywords: {Robots;Trajectory;Feature extraction;Shape;Three-dimensional displays;Learning (artificial intelligence);Input variables},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989546&isnumber=7988677

S. Nobili, R. Scona, M. Caravagna and M. Fallon, "Overlap-based ICP tuning for robust localization of a humanoid robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4721-4728.
doi: 10.1109/ICRA.2017.7989547
Abstract: State estimation techniques for humanoid robots are typically based on proprioceptive sensing and accumulate drift over time. This drift can be corrected using exteroceptive sensors such as laser scanners via a scene registration procedure. For this procedure the common assumption of high point cloud overlap is violated when the scenario and the robot's point-of-view are not static and the sensor's field-of-view (FOV) is limited. In this paper we focus on the localization of a robot with limited FOV in a semi-structured environment. We analyze the effect of overlap variations on registration performance and demonstrate that where overlap varies, outlier filtering needs to be tuned accordingly. We define a novel parameter which gives a measure of this overlap. In this context, we propose a strategy for robust non-incremental registration. The pre-filtering module selects planar macro-features from the input clouds, discarding clutter. Outlier filtering is automatically tuned at run-time to allow registration to a common reference in conditions of non-uniform overlap. An extensive experimental demonstration is presented which characterizes the performance of the algorithm using two humanoids: the NASA Valkyrie, in a laboratory environment, and the Boston Dynamics Atlas, during the DARPA Robotics Challenge Finals.
keywords: {Three-dimensional displays;Iterative closest point algorithm;Robot sensing systems;Humanoid robots;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989547&isnumber=7988677

X. Xiao, O. Ma and F. Asano, "Control walking speed by approximate-kinetic-model-based self-adaptive control on underactuated compass-like bipedal walker," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4729-4734.
doi: 10.1109/ICRA.2017.7989548
Abstract: This paper proposes an approximate-kinetic-model-based self-adaptive (AKS) control system to rapidly generate target walking speed by an underactuated compasslike bipedal walker. First, a model of the underactuated compass-like bipedal walker is built, and an open-loop system is introduced and analysed as the prototype of AKS system. Second, the control law of AKS is described in detail. The dynamic updating of trajectory is proposed and the calculation of control parameters by an approximate linearized model is analysed. Finally, simulations are conducted, and thus the capability of disturbance rejection and versatility is tested. As a conclusion, target walking speeds with 4∼6% steady-state error can be generated rapidly and steadily. Limit cycle walker can obviously improve the capability of handling disturbance and various tasks by AKS control system.
keywords: {Legged locomotion;Trajectory;Mathematical model;Limit-cycles;Analytical models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989548&isnumber=7988677

J. H. Kim, J. Lee and Y. Oh, "Stability regions for standing balance of biped humanoid robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4735-4740.
doi: 10.1109/ICRA.2017.7989549
Abstract: Based on the liner inverted pendulum model (LIPM) for the dynamics of biped humanoid robots, an analytical method for computing stability regions relevant to standing balance of the biped humanoid robots is introduced in this paper. More precisely, two types of the stability regions are discussed in this paper with the consideration of that the zero moment point (ZMP) should be located in the supporting region to guarantee stable standing of the biped humanoid robots. First, assuming no external disturbances affecting the motion of the biped humanoid robots, the set of the initial values of the center of mass (CoM) position and velocity with which the location of the ZMP is limited to be inside the supporting region can be explicitly obtained by solving a finite number of linear inequalities. Second, two admissible sets of external force disturbances (impulse and finite energy) with which the ZMP does not deviate from the supporting region are characterized by solving finite number of linear inequalities or the discrete-time Lyapunov equation, respectively. The validity and effectiveness of the analytical method proposed in this paper are verified through a simulation result.
keywords: {Humanoid robots;Stability analysis;Force;Two dimensional displays;Mathematical model;Pathology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989549&isnumber=7988677

P. Ferrari, M. Cognetti and G. Oriolo, "Humanoid whole-body planning for loco-manipulation tasks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4741-4746.
doi: 10.1109/ICRA.2017.7989550
Abstract: We consider the problem of planning whole-body motions for humanoids that must execute loco-manipulation tasks, i.e., manipulation tasks that implicitly require a locomotion phase. The proposed planner builds a tree in configuration-time space by concatenating feasible, collision-free whole-body motions that realize a succession of CoM movement primitives and, at the same time, the assigned manipulation task. To obtain fluid, natural motions we identify three zones of operation, i.e, locomotion, loco-manipulation and manipulation, and we carefully design a mechanism that allows to synchronize the two tasks. The proposed method has been implemented in V-REP for the NAO humanoid and successfully tested in various scenarios of increasing complexity.
keywords: {Planning;Kinematics;Synchronization;Trajectory;Robot kinematics;Humanoid robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989550&isnumber=7988677

M. X. Grey, A. D. Ames and C. K. Liu, "Footstep and motion planning in semi-unstructured environments using randomized possibility graphs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4747-4753.
doi: 10.1109/ICRA.2017.7989551
Abstract: Traversing environments with arbitrary obstacles poses significant challenges for bipedal robots. In some cases, whole body motions may be necessary to maneuver around an obstacle, but most existing footstep planners can only select from a discrete set of predetermined footstep actions; they are unable to utilize the continuum of whole body motion that is truly available to the robot platform. Existing motion planners that can utilize whole body motion tend to struggle with the complexity of large-scale problems. We introduce a planning method, called the “Randomized Possibility Graph”, which uses high-level approximations of constraint manifolds to rapidly explore the “possibility” of actions, thereby allowing lower-level motion planners to be utilized more efficiently. We demonstrate simulations of the method working in a variety of semi-unstructured environments. In this context, “semi-unstructured” means the walkable terrain is flat and even, but there are arbitrary 3D obstacles throughout the environment which may need to be stepped over or maneuvered around using whole body motions.
keywords: {Manifolds;Planning;Navigation;Legged locomotion;Shape;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989551&isnumber=7988677

J. Vorndamme, M. Schappler and S. Haddadin, "Collision detection, isolation and identification for humanoids," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4754-4761.
doi: 10.1109/ICRA.2017.7989552
Abstract: High-performance collision handling, which is divided into the five phases detection, isolation, estimation, classification and reaction, is a fundamental robot capability for safe and sensitive operation/interaction in unknown environments. For complex humanoid robots collision handling is obviously significantly more complex than for classical static manipulators. In particular, the robot stability during the collision reaction phase has to be carefully designed and relies on high fidelity contact information that is generated during the first three phases. In this paper, a unified realtime algorithm is presented for determining unknown contact forces and contact locations for humanoid robots based on proprioceptive sensing only, i.e. joint position, velocity and torque, as well as force/torque sensing along the structure. The proposed scheme is based on nonlinear model-based momentum observers that are able to recover the unknown contact forces and the respective locations. The dynamic loads acting on internal force/torque sensors are also corrected based on a novel nonlinear compensator. The theoretical capabilities of the presented methods are evaluated in simulation with the Atlas robot. In summary, we propose a full solution to the problem of collision detection, collision isolation and collision identification for the general class of humanoid robots.
keywords: {Collision avoidance;Robot sensing systems;Humanoid robots;Robot kinematics;Acceleration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989552&isnumber=7988677

V. Samy, K. Bouyarmane and A. Kheddar, "QP-based adaptive-gains compliance control in humanoid falls," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4762-4767.
doi: 10.1109/ICRA.2017.7989553
Abstract: We address the problem of humanoid falling with a decoupled strategy consisting of a pre-impact and a postimpact stage. In the pre-impact stage, geometrical reasoning allows the robot to choose appropriate impact points in the surrounding environment and to adopt a posture to reach them while avoiding impact-singularities and preparing for the postimpact. The surrounding environment can be unstructured and may contain cluttered obstacles. The post-impact stage uses a quadratic program controller that adapts on-line the joint proportional-derivative (PD) gains to make the robot compliant-to absorb impact and post-impact dynamics, which lowers possible damage risks. This is done by a new approach incorporating the stiffness and damping gains directly as decision variables in the QP along with the usually-considered variables of joint accelerations and contact forces. Constraints of the QP prevent the motors from reaching their torque limits during the fall. Several experiments on the humanoid robot HRP-4 in a full-dynamics simulator are presented and discussed.
keywords: {Robot kinematics;Humanoid robots;Trajectory;Green products;Damping;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989553&isnumber=7988677

T. Otani et al., "Angular momentum compensation in yaw direction using upper body based on human running," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4768-4775.
doi: 10.1109/ICRA.2017.7989554
Abstract: Humans utilize their torsos and arms while running to compensate for the angular momentum generated by the lower-body movement during the flight phase. To enable this capability in a humanoid robot, the robot should have human-like mass, a center of mass position, and inertial moment of each link. To mimic this characteristic, we developed an angular momentum control method using a humanoid upper body based on human motion. In this method, the angular momentum generated by the movement of the humanoid lower body is calculated, and the torso and arm motions are calculated to compensate for the angular momentum of the lower body. We additionally developed the humanoid upper-body mechanism that mimics the human link length and mass property by using carbon fiber reinforced plastic and a symmetric structure. As a result, the developed humanoid robot could generate almost the same angular momentum as that of human through human-like running motion. Furthermore, when suspended in midair, the humanoid robot produced the angular momentum compensation in the yaw direction.
keywords: {Legged locomotion;Torso;Humanoid robots;Shoulder;Robot kinematics;Elbow},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989554&isnumber=7988677

Y. Yamada, H. Sawada, T. Kubota and T. Nakamura, "Blade-type crawler vehicle with gyro wheel for stably traversing uneven terrain at high speed," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4776-4781.
doi: 10.1109/ICRA.2017.7989555
Abstract: Unmanned rescue, observation, and/or research vehicles with high terrain adaptability, high speed, and high reliability are needed in difficult-to-reach locations. However, for most vehicles, high performance over rough terrain reduces the travel speed and/or requires complex mechanisms. We have developed a blade-type crawler robot with a very simple and reliable mechanism, which traverses uneven terrain at high speed. Moreover, the gyro wheel design stabilizes the success of this approach in improving the motion, ensuring robust traversal. The improvement in traveling speed and robustness over uneven terrain by our approach was confirmed by experiment.
keywords: {Crawlers;Wheels;Blades;Torque;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989555&isnumber=7988677

Y. Chen, S. Le, Q. C. Tan, O. Lau, F. Wan and C. Song, "A lobster-inspired robotic glove for hand rehabilitation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4782-4787.
doi: 10.1109/ICRA.2017.7989556
Abstract: This paper presents preliminary results of the design, development, and evaluation of a hand rehabilitation glove fabricated using lobster-inspired hybrid design with rigid and soft components for actuation. Inspired by the bending abdomen of lobsters, hybrid actuators are built with serially jointed rigid shells actuated by pressurized soft chambers inside to generate bending motions. Such bio-inspiration absorbs features from the classical rigid-bodied robotics with precisely-defined motion generation, as well as the emerging soft robotics with light-weight, physically safe, and adaptive actuation. The fabrication procedure is described, followed by experiments to mechanically characterize these actuators. Finally, an open-palm glove design integrated with these hybrid actuators are presented for a qualitative case study. A hand rehabilitation system is developed by learning patterns of the sEMG signals from the users forearm to train the assistive glove for hand rehabilitation exercises.
keywords: {Actuators;Force;Fabrication;Motion segmentation;Three-dimensional displays;Soft robotics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989556&isnumber=7988677

C. Gehring, C. Dario Bellicoso, P. Fankhauser, S. Coros and M. Hutter, "Quadrupedal locomotion using trajectory optimization and hierarchical whole body control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4788-4794.
doi: 10.1109/ICRA.2017.7989557
Abstract: Quadrupedal locomotion can be described as a constrained optimization problem that is very hard to solve due to the high dimensional, nonlinear and non-smooth system dynamics. In this paper, we propose a formulation that can be solved within few seconds using sequential quadratic programming. This method considers only a simplified model that just sufficiently represents the system dynamics. The output is a very coarse plan, which can be accurately and robustly followed on a real system using hierarchical whole-body control combined with inverted pendulum-based reactive stepping. Using the fully torque controllable quadrupedal robot ANYmal, we present successful experiments for walking, trotting, and gait transitions even under substantial external disturbances.
keywords: {Legged locomotion;Tracking;Optimization;Planning;Trajectory;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989557&isnumber=7988677

X. Jia, Z. Chen, J. M. Petrosino, W. R. Hamel and M. Zhang, "Biological undulation inspired swimming robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4795-4800.
doi: 10.1109/ICRA.2017.7989558
Abstract: Aquatic animal movement results from a complex balance between muscular actuation, swimmer's inertia, damping, and stiffness; as well as, the effects from the fluid environment. Most aquatic animals utilize undulatory propulsion methods during swimming. Propulsion mode transition involves a variation of these parameters, and to better investigate the variation of these parameters during propulsion mode switching, and provide guidance for swimming robot design, we studied propulsion mechanism of undulation locomotion by combining biological investigation, mathematical simulation and experimental validation. A modular robot platform, with assembling function, was built based on the obtained biological features to realize the corresponding propulsion methods. Then a modular dynamic modeling method was proposed to simulate robot locomotion using a CPG based algorithm and a PD control method, further revealing the underlying mechanism for undulatory locomotion. Finally, experiments were conducted using the robotic platform to validate the found conclusions as well as enhance the propulsion mechanism of undulatory motion, providing a generic guidance for swimming robot design.
keywords: {Legged locomotion;Servomotors;Robot kinematics;Aquatic robots;Electronic mail;Head},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989558&isnumber=7988677

X. Wang and T. Geng, "Introducing rotary force to a template model can explain human compliant slope walking," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4801-4806.
doi: 10.1109/ICRA.2017.7989559
Abstract: Like level-ground walking, biological experiments have shown that humans largely maintain compliant leg behavior during slope walking, which greatly reduces the mechanical cost of transportation. Nowadays biped robots are becoming more and more functional on irregular terrains, yet no theoretical model can describe explicitly the cause of the characteristic ground reaction force (GRF) patterns observed in human slope walking. To fill the knowledge gap, this study extended Geyer's template biped level-ground walking model to explaining the slope walking GRF. By comparing the current Geyer's model with the human slope walking data, it was reasoned out that only using radial force from the legs could not account for the shifted anterior-posterior (AP) GRF without breaking the compliant leg behavior in the normal direction. With introducing the leg rotary force, the extended Geyer's model was then able to address the shifted AP GRF effectively. For legged robotics, this study primarily suggests that letting the leg rotary force collaborate with the compliant leg behaviour can improve the agility and energy-efficiency of dynamic walking on irregular terrains.
keywords: {Legged locomotion;Force;Biological system modeling;Data models;Springs;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989559&isnumber=7988677

S. Guitron, A. Guha, S. Li and D. Rus, "Autonomous locomotion of a miniature, untethered origami robot using hall effect sensor-based magnetic localization," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4807-4813.
doi: 10.1109/ICRA.2017.7989560
Abstract: Autonomous control of magnetically-actuated miniature robots enables greater versatility and complexity in function but has so far been a challenge to implement. In this paper, we present closed-loop position feedback control of a miniature origami robot utilizing its integrated magnet and an array of Hall effect sensors, enabling the robot's actuation, detection, and locomotion to be initiated from outside its body. An array of 33 Hall effect sensors arranged in repeated triangles cover a range of 60 mm by 75 mm, enabling position detection of the robot with average error of 0.995±0.520 mm. The robot's speed response to applied magnetic field was characterized, and a controller was designed to actuate the robot dependably. We demonstrate autonomous movement of the robot along preplanned paths and the viability of magnetic detection and actuation.
keywords: {Magnetic sensors;Robot sensing systems;Sensor arrays;Hall effect;Magnetic resonance imaging},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989560&isnumber=7988677

P. M. Loschak, A. Değirmenci and R. D. Howe, "Predictive filtering in motion compensation with steerable cardiac catheters," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4830-4836.
doi: 10.1109/ICRA.2017.7989561
Abstract: Robotic cardiac catheterization using ultrasound (US) imaging catheters provides real time imaging from within the heart while reducing the difficulty in manually steering a four degree-of-freedom (4-DOF) catheter. Accurate robotic catheter navigation in the heart is challenging due to a variety of disturbances including cyclical physiological motions, such as respiration. In this work we compensate for respiratory motion by using an Extended Kalman Filter (EKF) to predict target motion and by applying the predictions to steer the US imaging catheter. The system performance was measured in bench top experiments with phantom vasculature. The robotic system with predictive filtering tracked cyclically moving targets with 1.59 mm and 0.72° mean error. Accurately tracking moving structures can improve intra-procedural treatments and visualization.
keywords: {Catheters;Target tracking;Motion compensation;Imaging;Robots;Heart},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989561&isnumber=7988677

C. Chautems and B. J. Nelson, "The tethered magnet: Force and 5-DOF pose control for cardiac ablation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4837-4842.
doi: 10.1109/ICRA.2017.7989562
Abstract: Cardiac arrhythmias are commonly treated by minimally invasive catheter ablation. Because of challenges in precisely manipulating the distal end of the catheter, several magnetic manipulation systems (MMS) have been developed to aid in steering the tip inside the heart. Due to the relative stiffness of catheters, magnetic gradients that create forces acting on the catheter tip position are limited in their effectiveness and are typically ignored. This dramatically limits the tip orientations possible at any specified position in the workspace. Replacing the flexible catheter tip by a string-like tether and replacing multiple magnets by a single magnet allows the ablation tool to be positioned at any location with essentially any orientation. In addition to the five pose degrees of freedom, the tension on the tether can also be controlled. During an ablation procedure, the distal end of the tethered magnet is placed in contact with the heart wall. Extending the tether after tip contact transfers the tension on the tether to a force at the contact point. The contact force can then be precisely controlled and is no longer dependent on catheter bending radius and insertion length, as is the case with current catheter steering systems. The kinematics of a tethered magnet is modeled and tested inside a clinical MMS called the Aeon Phocus. This demonstrates the feasibility of magnetic field gradient control in a medically certified system currently in clinical use.
keywords: {Saturation magnetization;Magnetic moments;Magnetic separation;Catheters;Electromagnets;Gravity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989562&isnumber=7988677

S. L. Charreyron, B. Zeydan and B. J. Nelson, "Shared control of a magnetic microcatheter for vitreoretinal targeted drug delivery," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4843-4848.
doi: 10.1109/ICRA.2017.7989563
Abstract: Retinal diseases including age-related macular degeneration and diabetic retinopathy are leading causes of visual impairment and a growing medical crisis worldwide. As a result, new therapies and methods of safely delivering these new therapies can be of significant benefit to society. In this paper, we present a proof-of-concept for performing drug delivery using flexible magnetic microcatheters. The potential benefits of these catheters are that they are safer to use than existing rigid vitreoretinal tools, are precisely manipulable, and can be used to deliver lower dosages of therapeutic agents to precisely targeted locations on the retina with higher efficacy. The task of positioning the catheter tip is shared between a human operator and a control algorithm, which have complementary skills and can separately address different aspects of the overall task. The system was tested in an eye-phantom by an untrained operator with a 93% success rate in reaching 43 target points uniformly dispersed over the retina.
keywords: {Retina;Catheters;Micromagnetics;Visualization;Tools;Drugs;Magnetic resonance imaging},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989563&isnumber=7988677

P. Moreira, K. J. Boskma and S. Misra, "Towards MRI-guided flexible needle steering using fiber Bragg grating-based tip tracking," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4849-4854.
doi: 10.1109/ICRA.2017.7989564
Abstract: The use of magnetic resonance (MR) images for needle-based interventions offers several advantages over other types of imaging modalities (e.g., high tissue contrast and no radiation). However, MR-guided interventions face challenges related to electromagnetic compatibility of medical devices and real-time tracking of surgical instruments. This work presents a flexible needle steering system that combines an MR-compatible robot and a Fiber Bragg Grating (FBG)-based needle tip tracker. The MR images are used to localize obstacles and targets, while the FBG sensors provide strain measurements for online estimation of the needle tip position. A pre-operative planner defines the needle entry point and desired path, while a model predictive controller calculates the needle rotation during the insertion. To the best of the authors knowledge, this is the first work that fuses MR images and FBG-based tracking to steer a flexible needle in closed-loop inside the MR bore. The system is validated by steering a bevel-tipped flexible needle towards a physical target in gelatin phantoms and biological tissues. The needle reaches the target in all trials with an average targeting error of 2.76 mm. Disregarding the target displacement during the insertion, the average targeting error drops to 1.74 mm. The preliminary results demonstrate the feasibility of combining MR images and FBG-based needle tip tracking to steer a flexible needle in clinical procedures. In order to move towards to a clinically-relevant application, the design of a flexible Nitinol biopsy needle is also presented and evaluated by experiments in a prostate of a bull. The flexible needle presented a curvature 2.5 times larger than a conventional biopsy needle while maintaining the ability to collect tissue samples.
keywords: {Needles;Robots;Fiber gratings;Sensors;Biopsy;Target tracking},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989564&isnumber=7988677

B. Wehbe, M. Hildebrandt and F. Kirchner, "Experimental evaluation of various machine learning regression methods for model identification of autonomous underwater vehicles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4885-4890.
doi: 10.1109/ICRA.2017.7989565
Abstract: In this work we investigate the identification of a motion model for an autonomous underwater vehicle by applying different machine learning (ML) regression methods. By using the data collected from the robot's on-board navigation sensors, we train the regression models to learn the damping term which is regarded as one of the most uncertain components of the motion model. Four regression techniques are investigated namely, artificial neural networks, support vector machines, kernel ridge regression, and Gaussian processes regression. The performance of the identified models is tested through real experimental scenarios performed with the AUV Leng. The novelty of this work is the identification of an underwater vehicle's motion model, for the first time, through machine learning methods by using the robot's onboard sensory data. Results show that the damping model learned with nonlinear methods yield better estimates than the simplified linear and quadratic model which is identified with least-squares technique.
keywords: {Damping;Kernel;Sensors;Data models;Support vector machines;Navigation;Underwater vehicles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989565&isnumber=7988677

J. Elsdon and Y. Demiris, "Assisted painting of 3D structures using shared control with a hand-held robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4891-4897.
doi: 10.1109/ICRA.2017.7989566
Abstract: We present a shared control method of painting 3D geometries, using a handheld robot which has a single autonomously controlled degree of freedom. The user scans the robot near to the desired painting location, the single movement axis moves the spray head to achieve the required paint distribution. A simultaneous simulation of the spraying procedure is performed, giving an open loop approximation of the current state of the painting. An online prediction of the best path for the spray nozzle actuation is calculated in a receding horizon fashion. This is calculated by producing a map of the paint required in the 2D space defined by nozzle position on the gantry and the time into the future. A directed graph then extracts its edge weights from this paint density map and Dijkstra's algorithm is then used to find the candidate for the most effective path. Due to the heavy parallelisation of this approach and the majority of the calculations taking place on a GPU we can run the prediction loop in 32.6ms for a prediction horizon of 1 second, this approach is computationally efficient, outperforming a greedy algorithm. The path chosen by the proposed method on average chooses a path in the top 15% of all paths as calculated by exhaustive testing. This approach enables development of real time path planning for assisted spray painting onto complicated 3D geometries. This method could be applied to applications such as assistive painting for people with disabilities, or accurate placement of liquid when large scale positioning of the head is too expensive.
keywords: {Paints;Painting;Automobiles;Service robots;Three-dimensional displays;Path planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989566&isnumber=7988677

J. Wang, S. Bai and B. Englot, "Underwater localization and 3D mapping of submerged structures with a single-beam scanning sonar," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4898-4905.
doi: 10.1109/ICRA.2017.7989567
Abstract: We present a novel approach to perform underwater simultaneous localization and mapping (SLAM) using a small inspection-class remotely operated vehicle (ROV) equipped with a single-beam scanning sonar, amidst high levels of noise present in the sonar data, and in the absence of inertial/odometry measurements. Features are extracted from hierarchically grouped clusters of sonar returns, data association is performed via the iterative joint compatibility test, and the vehicle's trajectory and map are estimated using incremental smoothing and mapping (iSAM). The resulting point clouds derived from the ROV's sonar are used to produce Gaussian process occupancy maps, which interpolate among gaps in the acoustic range data to produce descriptive 3D maps of submerged structures. The proposed localization and mapping approach is demonstrated using data gathered in two harbor environments in close proximity to piers and seawalls.
keywords: {Sonar measurements;Feature extraction;Simultaneous localization and mapping;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989567&isnumber=7988677

A. Kalmbach, Y. Girdhar, H. M. Sosik and G. Dudek, "Phytoplankton hotspot prediction with an unsupervised spatial community model," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4906-4913.
doi: 10.1109/ICRA.2017.7989568
Abstract: Many interesting natural phenomena are sparsely distributed and discrete. Locating the hotspots of such sparsely distributed phenomena is often difficult because their density gradient is likely to be very noisy. We present a novel approach to this search problem, where we model the co-occurrence relations between a robot's observations with a Bayesian nonparametric topic model. This approach makes it possible to produce a robust estimate of the spatial distribution of the target, even in the absence of direct target observations. We apply the proposed approach to the problem of finding the spatial locations of the hotspots of a specific phytoplankton taxon in the ocean. We use classified image data from Imaging FlowCytobot (IFCB), which automatically measures individual microscopic cells and colonies of cells. Given these individual taxon-specific observations, we learn a phytoplankton community model that characterizes the co-occurrence relations between taxa. We present experiments with simulated robot missions drawn from real observation data collected during a research cruise traversing the US Atlantic coast. Our results show that the proposed approach outperforms nearest neighbor and k-means based methods for predicting the spatial distribution of hotspots from in-situ observations.
keywords: {Data models;Computational modeling;Robots;Oceans;Training;Predictive models;Sea measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989568&isnumber=7988677

K. Nelson and K. Mohseni, "An artificial fish lateral line sensory system composed of modular pressure sensor blocks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4914-4919.
doi: 10.1109/ICRA.2017.7989569
Abstract: The lateral line sensory system found in fish and other aquatic organisms is believed to aid in various behavioral activities such as station keeping and wall detection. This paper presents results for an artificial lateral line designed for use in an underwater vehicle. Algorithms for leveraging this system to estimate hydrodynamic forces and for wall detection are presented and experimentally validated. Three sensor setups were built, two with fixed sensor positions and one with a novel, modular sensor block approach. The modular realization allows for flexibility in testing and can be integrated into the control system of the autonomous underwater vehicle built by our group. These lateral line sensory systems were experimentally validated and the results are presented.
keywords: {Force;Pressure sensors;Estimation;Hydrodynamics;Robot sensing systems;Three-dimensional displays;Testing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989569&isnumber=7988677

N. R. Rypkema, E. M. Fischell and H. Schmidt, "One-way travel-time inverted ultra-short baseline localization for low-cost autonomous underwater vehicles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4920-4926.
doi: 10.1109/ICRA.2017.7989570
Abstract: This paper presents an acoustic localization system for small and low-cost autonomous underwater vehicles (AUVs). Accurate and robust localization for low-cost AUVs would lower the barrier toward multi-AUV research in river and ocean environments. However, these AUVs introduce size, power, and cost constraints that prevent the use of conventional AUV sensors and acoustic positioning systems, adding great difficulty to the problem of underwater localization. Our system uses a single acoustic transmitter placed at a reference point and is acoustically passive on the AUV, reducing cost and power use, and enabling multi-AUV localization. The AUV has an ultra-short baseline (USBL) receiver array that uses one-way travel-time (OWTT) and phased-array beamforming to calculate range, azimuth, and inclination to the transmitter, providing an instantaneous estimate of the vehicle location. This estimate is fed to a particle filter and graph-based smoothing algorithm to generate a consistent AUV trajectory. We describe the complete processing pipeline of our system, and present results based on experiments using a low-cost AUV. To the authors' knowledge, this work constitutes the first practical demonstration of the feasibility of OWTT inverted USBL navigation for AUVs.
keywords: {Acoustics;Sonar equipment;Array signal processing;Global Positioning System;Acoustic arrays;Data acquisition},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989570&isnumber=7988677

Y. Yang and G. Huang, "Acoustic-inertial underwater navigation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4927-4933.
doi: 10.1109/ICRA.2017.7989571
Abstract: In this paper, we introduce a novel acoustic-inertial navigation system (AINS) for Autonomous Underwater Vehicles (AUVs). We are aiming to reduce the cost and latency of current underwater navigation systems that typically employ high-accuracy and thus high-cost inertial sensors. In particular, the proposed approach efficiently fuses the acoustic observations from a 2D imaging sonar and the inertial measurements from a MEMS inertial measurement unit (IMU) within a tightly-coupled EKF framework, while having no need to keep the acoustic features in the state vector. As a result, the computational complexity of the proposed AINS is independent from the scale of the operating environment. Moreover, we develop an acoustic feature linear triangulation to provide accurate initial estimates for iterative solvers, and perform an in-depth observability analysis to investigate the effects of sensor motion on the triangulation. Additionally, since it is challenging to perform a priori sensor extrinsic calibration underwater, we advocate to calibrate IMU-sonar online. The proposed AINS has been validated extensively in Monte-Carlo simulations.
keywords: {Silicon;Sonar measurements;Acoustics;Sonar navigation;Sensors;Acoustic measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989571&isnumber=7988677

K. Qin and D. A. Shell, "Robots going round the bend — A comparative study of estimators for anticipating river meanders," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4934-4940.
doi: 10.1109/ICRA.2017.7989572
Abstract: Marine robots and unmanned surface vehicles will increasingly be deployed in rivers and riverine environments. The structure produced by flowing waters may be exploited for purposes of estimation, planning, and control. This paper adopts a widely acknowledged model for the geometry of watercourse channels, namely sine-generated curves, as a basis for estimators that predict the shape of the yet unseen portion of the river. Predictions of this sort help a robot anticipate the future, for example, in throttling speeds as it rounds a bend. After examining how to reparameterize standard filters to incorporate this model, we compare the performance of three Gaussian filters and show that nonideality and theoretical challenges (of non-linearity, multi-modality/periodicity) degrade the performance of standard Kalman filters severely, but can be successfully mitigated by imposing an interval constraint. Thereafter, we present results of a constrained interval Kalman filter on data from three natural rivers. The results we report show the effectiveness of our method on the estimation of meander parameters. The results we report, including data from simulation, from maps, and from GPS tracks of a boat on the Colorado river, show the effectiveness of our method on the estimation of meander parameters.
keywords: {Rivers;Kalman filters;Robots;Estimation;Biological system modeling;Standards;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989572&isnumber=7988677

J. Li, G. Zhong, H. Yin, M. He, Y. Tan and Z. Li, "Position control of a robot finger with variable stiffness actuated by shape memory alloy," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4941-4946.
doi: 10.1109/ICRA.2017.7989573
Abstract: The purpose of this research is to present a new method to achieve precise position tracking control for robot finger with variable stiffness mechanism. First, the variable stiffness design of the finger which is actuated by SMA-3 fibers is presented. Then, the relationship between the variation of pulling force ΔF of the bending robot finger and input voltage of SMA-3 is established. In addition, the relationship between the pulling force F and the input voltage of SMA-2 wire is established as well. Therefore, a control method based on these models for the position tracking of robot finger with variable stiffness characteristics is proposed. The experimental results show that the proposed method has better performance than traditional PID control when the stiffness changed by heating current, resulting in a reduction of maximum error by 86%.
keywords: {Three-dimensional displays;Conferences;Automation;Fingers;SMA actuator;variable stiffness;robot finger},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989573&isnumber=7988677

C. Zhang, W. Wang, N. Xi, Y. Wang and L. Liu, "Control of cardiomyocyte contraction for actuation of bio-syncretic robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4947-4952.
doi: 10.1109/ICRA.2017.7989574
Abstract: Bio-syncretic robots, consisting of living biological materials and traditional electromechanical systems, have attracted lots of attention due to the potentialities of self-sensing, self-actuation and self-repairing with intrinsic safety and high energy conversion efficiency. However, most of current researches focus on the movement of the devices, and have ignored the study on the control of actuation unit “cells”, which is as important as motors for traditional electromechanical robots. In this work, the effects of cell culturing time, seeding concentration and functional drugs (cytochalasin and adrenalin) on contractile frequency and force strength of cardiomyocytes have been studied using scanning ion conductance microscope (SICM) and arrays of micro-pillars made of PDMS. This work will lay the foundation for the further study of quantitatively control of bio-syncretic robots actuated by cardiomyocytes and is also meaningful for the development of cytology, medicine, and clinical science.
keywords: {Robots;Force;Muscles;Actuators;Force measurement;Automation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989574&isnumber=7988677

A. Rodríguez, E. Coevoet and C. Duriez, "Real-time simulation of hydraulic components for interactive control of soft robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4953-4958.
doi: 10.1109/ICRA.2017.7989575
Abstract: In this work we propose a new method for online motion planning in the task-space for hydraulic actuated soft robots. Our solution relies on the interactive resolution of an inverse kinematics problem, that takes into account the properties (mass, stiffness) of the deformable material used to build the robot. An accurate modeling of the mechanical behavior of hydraulic components is based on a novel GPU parallel method for the real-time computation of fluid weight distribution. The efficiency of the method is further increased by a novel GPU parallel leveraging mechanism. Our complete solution has been integrated within the open-source SOFA framework. In our results, we validate our simulation with a fabricated silicone cylinder and we demonstrate the usage of our approach for direct control of hydraulic soft robots.
keywords: {Robots;Hydraulic systems;Computational modeling;Instruction sets;Cavity resonators;Graphics processing units;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989575&isnumber=7988677

J. Hughes and F. Iida, "Localized differential sensing of soft deformable surfaces," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4959-4964.
doi: 10.1109/ICRA.2017.7989576
Abstract: There is an increasing interest in the use of soft technologies for robotic application, however, the lack of advanced sensory motor capabilities is currently a significant limitation. Sensing of soft robots, in particular, is still not fully understood and methods by which a large deformable continuum body can be effectively sensed without loosing the intrinsic soft body dynamics are limited. This paper proposes a novel soft body sensing method, localized differential sensing, whereby the sensing of localized deformation on a large soft structure can be achieved with a pair of strain sensors. The design principles for this method are given. To demonstrate this sensing method Conductive Thermoplastic Elastomer (CTPE) is used for the sensing of deformation of soft body structures. A feasibility study of the approach is also presented, with strain sensors incorporated into the universal gripper to allow detection of grasped objects.
keywords: {Strain;Robot sensing systems;Resistance;Morphology;Sensitivity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989576&isnumber=7988677

V. Wall, G. Zöller and O. Brock, "A method for sensorizing soft actuators and its application to the RBO hand 2," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4965-4970.
doi: 10.1109/ICRA.2017.7989577
Abstract: The compliance of soft actuators makes manipulation safer and simplifies control. But their high flexibility also makes sensorization challenging. From the large space of possible deformations not all are equally important. We present a method for sensorization of soft actuators that, for a given application, finds an effective layout from a set of sensors. It starts from a redundant sensor layout and iteratively reduces the number of sensors. Applying the method to the PneuFlex actuators of the RBO Hand 2, we identify a layout of four liquid metal strain sensors and one pressure sensor to predict actuator deformation in three dimensions: flexional, lateral, and twist. Finally, the layout is used to build a sensorized RBO Hand 2. It can detect passive shape adaptation while grasping and reveals failure cases during manipulation, e.g. slipping fingers while opening a door.
keywords: {Actuators;Layout;Robot sensing systems;Capacitive sensors;Grasping;Metals},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989577&isnumber=7988677

A. Stilli, L. Grattarola, H. Feldmann, H. A. Wurdemann and K. Althoefer, "Variable Stiffness Link (VSL): Toward inherently safe robotic manipulators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4971-4976.
doi: 10.1109/ICRA.2017.7989578
Abstract: Nowadays, the field of industrial robotics focuses particularly on collaborative robots that are able to work closely together with a human worker in an inherently safe way. To detect and prevent harmful collisions, a number of solutions both from the actuation and sensing sides have been suggested. However, due to the rigid body structures of the majority of systems, the risk of harmful collisions with human operators in a collaborative environment remains. In this paper, we propose a novel concept for a collaborative robot made of Variable Stiffness Links (VSLs). The idea is to use a combination of silicone based structures and fabric materials to create stiffness-controllable links that are pneumatically actuated. According to the application, it is possible to change the stiffness of the links by varying the value of pressure inside their structure. Moreover, the pressure readings from the pressure sensors inside the regulators can be utilised to detect collisions between the manipulator body and a human worker, for instance. A set of experiments are performed with the aim to assess the performance of the VSL when embedded in a robotic manipulator. The effects of different loads and pressures on the workspace of the manipulator are evaluated together with the efficiency of the collision detection control system and hardware.
keywords: {Collision avoidance;Manipulators;Robot sensing systems;Service robots;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989578&isnumber=7988677

V. A. Ho, H. Yamashita, Z. Wang, S. Hirai and K. Shibuya, "Morphological computation in tactile sensing: The role of wrinkle," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4977-4984.
doi: 10.1109/ICRA.2017.7989579
Abstract: This paper presents a new approach for active tactile sensation that utilizes soft morphological computation. This work is inspired by human finger's wet-induced wrinkles, which appear after a long time soaking in water, and has been indicated as an efficient means for enhancement of gripping in wet environment. We created a tactile sensing system that is an integration of actuation (pneumatic actuator) and sensing elements (strain gauges). This device can change its morphology so that the posture of embedded sensing elements can vary, then generate different responses depending on the sensing tasks. As a result, this device can actively select its sensing functions depending on different sensing tasks. In this paper, the sensing device is both sensitive to indentation contact and sliding action on its surface by using only one type of strain gauge. This preliminary work is an example of soft morphological control in sensing, and expected to open a new trend in development of tactile sensing system.
keywords: {Robot sensing systems;Skin;Strain measurement;Morphology;Surface morphology},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989579&isnumber=7988677

J. P. King, L. E. Valle, N. Pol and Y. Park, "Design, modeling, and control of pneumatic artificial muscles with integrated soft sensing," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4985-4990.
doi: 10.1109/ICRA.2017.7989580
Abstract: Presented are techniques for designing, modeling, and control of reliable pneumatic artificial muscle actuators with integrated low profile sensors for position feedback. The sensor is fabricated through a three-dimensional manufacturing process based on a modified lathe approach for controlling viscous and viscoelastic materials as well as on direct writing of liquid metal. Next, a new precision pneumatic muscle design and its integration with the sensor is illustrated. A theoretical model and experimental characterization of the muscle-sensor package are presented with high correlation and repeatability. Finally, a position feedback sliding mode controller is implemented with a position error of <;0.9% of maximum muscle contraction.
keywords: {Muscles;Sensor phenomena and characterization;Resistance;Robot sensing systems;Electrical resistance measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989580&isnumber=7988677

O. Arslan, K. Berntorp and P. Tsiotras, "Sampling-based algorithms for optimal motion planning using closed-loop prediction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4991-4996.
doi: 10.1109/ICRA.2017.7989581
Abstract: Motion planning under differential constraints is one of the canonical problems in robotics. State-of-the-art methods evolve around kinodynamic variants of popular sampling-based algorithms, such as Rapidly-exploring Random Trees (RRTs). However, there are still challenges remaining, for example, how to include complex dynamics while guaranteeing optimality. If the open-loop dynamics are unstable, exploration by random sampling in control space becomes inefficient. We describe CL-RRT#, which leverages ideas from the RRT# algorithm and a variant of the RRT algorithm, which generates trajectories using closed-loop prediction. Planning with closed-loop prediction allows us to handle complex unstable dynamics and avoids the need to find computationally hard steering procedures. The search technique presented in the RRT# algorithm allows us to improve the solution quality by searching over alternative reference trajectories. We show the benefits of the proposed approach on an autonomous-driving scenario.
keywords: {Trajectory;Data structures;Heuristic algorithms;Planning;Aerospace electronics;Prediction algorithms;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989581&isnumber=7988677

S. Arora and S. Scherer, "Randomized algorithm for informative path planning with budget constraints," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 4997-5004.
doi: 10.1109/ICRA.2017.7989582
Abstract: Maximizing information gathered within a budget is a relevant problem for information gathering tasks for robots with cost or operating time constraints. This problem is also known as the informative path planning (IPP) problem or correlated orienteering. It can be formalized as that of finding budgeted routes in a graph such that the reward collected by the route is maximized, where the reward at nodes can be dependent. Unfortunately, the problem is NP-Hard and the state of the art methods are too slow to even present an approximate solution online. Here we present Randomized Anytime Orienteering (RAOr) algorithm that provides near optimal solutions while demonstrably converging to an efficient solution in runtimes that allows the solver to be run online. The key idea of our approach is to pose orienteering as a combination of a Constraint Satisfaction Problem and a Traveling Salesman Problem. This formulation allows us to restrict the search space to routes that incur minimum distance to visit a set of selected nodes, and rapidly search this space using random sampling. The paper provides the analysis of asymptotic near-optimality, convergence rates for RAOr algorithms, and present strategies to improve anytime performance of the algorithm. Our experimental results suggest an improvement by an order of magnitude over the state of the art methods in relevant simulation and in real world scenarios.
keywords: {Traveling salesman problems;Robot sensing systems;Approximation algorithms;Space exploration;Algorithm design and analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989582&isnumber=7988677

Y. -Y. Lin, C. -C. Ni, N. Lei, X. David Gu and J. Gao, "Robot Coverage Path planning for general surfaces using quadratic differentials," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5005-5011.
doi: 10.1109/ICRA.2017.7989583
Abstract: Robot Coverage Path planning (i.e., the process of providing full coverage of a given domain by one or multiple robots) is a classical problem in the field of robotics and motion planning. The goal of such planning is to provide nearly full coverage while also minimize duplicately visited area. In this paper, we focus on the scenario of path planning on general surface, including planar domains with complex topology, complex terrain, and general surface in 3D space. Our approach described in this paper adopts a natural, intrinsic and global parametrization of the surface for robot path planning, namely the holomorphic quadratic differentials. We give each point on the surface a uv-coordinates naturally represented by a complex number, except for a small number of zero points (singularities). We show that natural, efficient robot paths can be obtained by using such coordinate systems. The method is based on intrinsic geometry and thus can be adapted to general surface exploration in 3D.
keywords: {Trajectory;Robot kinematics;Surface treatment;Three-dimensional displays;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989583&isnumber=7988677

C. Choi and E. Frazzoli, "Torque efficient motion through singularity," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5012-5018.
doi: 10.1109/ICRA.2017.7989584
Abstract: Constraint on the actuation and power resources is often the critical limiting factor for a robot to perform desired tasks. Increasing torque and energy capacity may be a solution, but is seldom viable for robots already built. An attractive alternative is to carefully generate motion trajectories that maximally leverages upon the limited torque and energy resources. In this endeavor, singularity, which is deemed undesirable due to lose of manipulability, could be utilized to an advantage. This paper presents analysis of force and momentum generated through contact in relation to the singularity. The analysis shows that a motion at or near singularity not only maximally leverages the torque limits to generate forces in quasi-static motions, but is also optimally energy efficient for dynamical motion when it comes to momentum generation. Based on a simplified model, we discuss mechanical advantage aspects of a robotic leg and describe range of feasible forces that can be generated together with directions in which singular position becomes minimum torque configuration. Then we define stroke motion and establish upper bounds on the momentum generated through contact. Collinear stroke, where motion is along a straight line, is examined with respect to singularity.
keywords: {Torque;Force;Legged locomotion;Knee;Hip;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989584&isnumber=7988677

B. Ichter, E. Schmerling, A. Agha-mohammadi and M. Pavone, "Real-time stochastic kinodynamic motion planning via multiobjective search on GPUs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5019-5026.
doi: 10.1109/ICRA.2017.7989585
Abstract: In this paper we present the PUMP (Parallel Uncertainty-aware Multiobjective Planning) algorithm for addressing the stochastic kinodynamic motion planning problem, whereby one seeks a low-cost, dynamically-feasible motion plan subject to a constraint on collision probability (CP). To ensure exhaustive evaluation of candidate motion plans (as needed to tradeoff the competing objectives of performance and safety), PUMP incrementally builds the Pareto front of the problem, accounting for the optimization objective and an approximation of CP. This is performed by a massively parallel multiobjective search, here implemented with a focus on GPUs. Upon termination of the exploration phase, PUMP searches the Pareto set of motion plans to identify the lowest cost solution that is certified to satisfy the CP constraint (according to an asymptotically exact estimator). We introduce a novel particle-based CP approximation scheme, designed for efficient GPU implementation, which accounts for dependencies over the history of a trajectory execution. We present numerical experiments for quadrotor planning wherein PUMP identifies solutions in ~100 ms, evaluating over one hundred thousand partial plans through the course of its exploration phase. The results show that this multiobjective search achieves a lower motion plan cost, for the same CP constraint, compared to a safety buffer-based search heuristic and repeated RRT trials.
keywords: {Trajectory;Planning;Uncertainty;Safety;Optimization;Approximation algorithms;Monte Carlo methods},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989585&isnumber=7988677

N. M. Stiffler, A. Kolling and J. M. O'Kane, "Persistent pursuit-evasion: The case of the preoccupied pursuer," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5027-5034.
doi: 10.1109/ICRA.2017.7989586
Abstract: We consider a visibility-based pursuit-evasion problem in which a single robot with an omnidirectional but unreliable sensor moving through an environment must systematically search that environment to detect an unpredictably moving target. A common assumption in visibility-based pursuit-evasion is that the sensors used to detect the evader are perfectly reliable. That is, any evader that moves within view of the pursuer for any interval of time will be detected. This assumption is problematic because, when implemented on real sensor systems, such plans cannot account for the possibility of short-term false negative errors in evader detection. This paper addresses this limitation by introducing a model based on the idea of pessimal unoccluded distance to reason about the degree of plausibility that the evader may be concealed within each occluded region. We describe a decomposition of the environment that fully characterizes the opportune moment for an evader to take advantage of sensor error. Furthermore, we present a complete algorithm that solves the active problem of planning a search for a pursuer which maximizes the distance that the evader must travel through the pursuer robot's sensor footprint.
keywords: {Robot sensing systems;Search problems;Surveillance;Trajectory;Games},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989586&isnumber=7988677

A. Spielberg, B. Araki, C. Sung, R. Tedrake and D. Rus, "Functional co-optimization of articulated robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5035-5042.
doi: 10.1109/ICRA.2017.7989587
Abstract: We present parametric trajectory optimization, a method for simultaneously computing physical parameters, actuation requirements, and robot motions for more efficient robot designs. In this scheme, robot dimensions, masses, and other physical parameters are solved for concurrently with traditional motion planning variables, including dynamically consistent robot states, actuation inputs, and contact forces. Our method requires minimal user domain knowledge, requiring only a coarse guess of the target robot configuration sequence and a parameterized robot topology as input. We demonstrate our results on four simulated robots, one of which we physically fabricated in order to demonstrate physical consistency. We demonstrate that by optimizing robot body parameters alongside robot trajectories, motion planning problems which would otherwise be infeasible can be made feasible, and actuation requirements can be significantly reduced.
keywords: {Legged locomotion;Trajectory optimization;Dynamics;Heuristic algorithms;Actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989587&isnumber=7988677

D. M. Bodily, T. F. Allen and M. D. Killpack, "Motion planning for mobile robots using inverse kinematics branching," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5043-5050.
doi: 10.1109/ICRA.2017.7989588
Abstract: A novel algorithm for planning robotic manipulation tasks is presented in which the base position and joint motions of a robot are simultaneously optimized to follow a smooth desired end-effector trajectory. During the optimization routine, the manipulator's base position and joint motions are planned simultaneously by strategically moving a set of virtual robot arms (each representing a single configuration in a sequence) branching from a common base to a number of assigned target poses associated with a task. Additional goals (e.g. collision avoidance) and hard constraints, including joint limits are also incorporated. The optimization problem at the core of this method is a quadratic program, allowing constrained high-dimensional problems to be solved in very little time. This method has successfully planned motions allowing an 8-DOF manipulator to paint walls, and has proven to be highly efficient and scalable in practice.
keywords: {Kinematics;Planning;End effectors;Trajectory;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989588&isnumber=7988677

J. Zhang and S. Singh, "Enabling aggressive motion estimation at low-drift and accurate mapping in real-time," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5051-5058.
doi: 10.1109/ICRA.2017.7989589
Abstract: We present a data processing pipeline to online estimate ego-motion and build a map of the traversed environment, leveraging data from a 3D laser, a camera, and an IMU. Different from traditional methods that use a Kalman filter or factor-graph optimization, the proposed method employs a sequential, multi-layer processing pipeline, solving for motion from coarse to fine. The resulting system enables high-frequency, low-latency ego-motion estimation, along with dense, accurate 3D map registration. Further, the system is capable of handling sensor degradation by automatic reconfiguration bypassing failure modules. Therefore, it can operate in the presence of highly dynamic motion as well as in dark, texture-less, and structure-less environments. During experiments, the system demonstrates 0.22% of relative position drift over 9.3km of navigation and robustness w.r.t aggressive motion such as highway speed driving (up to 33m/s).
keywords: {Lasers;Cameras;Optimization;Three-dimensional displays;Visualization;Measurement by laser beam;Motion estimation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989589&isnumber=7988677

Y. Liao, L. Huang, Y. Wang, S. Kodagoda, Y. Yu and Y. Liu, "Parse geometry from a line: Monocular depth estimation with partial laser observation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5059-5066.
doi: 10.1109/ICRA.2017.7989590
Abstract: Many standard robotic platforms are equipped with at least a fixed 2D laser range finder and a monocular camera. Although those platforms do not have sensors for 3D depth sensing capability, knowledge of depth is an essential part in many robotics activities. Therefore, recently, there is an increasing interest in depth estimation using monocular images. As this task is inherently ambiguous, the data-driven estimated depth might be unreliable in robotics applications. In this paper, we have attempted to improve the precision of monocular depth estimation by introducing 2D planar observation from the remaining laser range finder without extra cost. Specifically, we construct a dense reference map from the sparse laser range data, redefining the depth estimation task as estimating the distance between the real and the reference depth. To solve the problem, we construct a novel residual of residual neural network, and tightly combine the classification and regression losses for continuous depth estimation. Experimental results suggest that our method achieves considerable promotion compared to the state-of-the-art methods on both NYUD2 and KITTI, validating the effectiveness of our method on leveraging the additional sensory information. We further demonstrate the potential usage of our method in obstacle avoidance where our methodology provides comprehensive depth information compared to the solution using monocular camera or 2D laser range finder alone.
keywords: {Estimation;Lasers;Two dimensional displays;Neural networks;Robot sensing systems;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989590&isnumber=7988677

D. Zermas, I. Izzat and N. Papanikolopoulos, "Fast segmentation of 3D point clouds: A paradigm on LiDAR data for autonomous vehicle applications," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5067-5073.
doi: 10.1109/ICRA.2017.7989591
Abstract: The recent activity in the area of autonomous vehicle navigation has initiated a series of reactions that stirred the automobile industry, pushing for the fast commercialization of this technology which, until recently, seemed futuristic. The LiDAR sensor is able to provide a detailed understanding of the environment surrounding the vehicle making it useful in a plethora of autonomous driving scenarios. Segmenting the 3D point cloud that is provided by modern LiDAR sensors, is the first important step towards the situational assessment pipeline that aims for the safety of the passengers. This step needs to provide accurate segmentation of the ground surface and the obstacles in the vehicle's path, and to process each point cloud in real time. The proposed pipeline aims to solve the problem of 3D point cloud segmentation for data received from a LiDAR in a fast and low complexity manner that targets real world applications. The two-step algorithm first extracts the ground surface in an iterative fashion using deterministically assigned seed points, and then clusters the remaining non-ground points taking advantage of the structure of the LiDAR point cloud. Our proposed algorithms outperform similar approaches in running time, while producing similar results and support the validity of this pipeline as a segmentation tool for real world applications.
keywords: {Three-dimensional displays;Laser radar;Clustering algorithms;Surface treatment;Autonomous vehicles;Automobiles;Pipelines},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989591&isnumber=7988677

R. Sagawa, R. Furukawa, A. Matsumoto and H. Kawasaki, "Learning-based feature extraction for active 3D scan with reducing color crosstalk of multiple pattern projections," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5074-5080.
doi: 10.1109/ICRA.2017.7989592
Abstract: 3D reconstruction methods based on active stereo technique have been widely used for many practical systems. Many of these systems are configured with a single camera and a single projector. Since such systems can only capture one side of the target object, several attempts have been conducted to enlarge the captured area, especially multi-projector systems attract many researchers. For multi-projector based systems, overlap between multiple pattern projections is a serious problem. Even if different color channels are used for each projector, complete separation is not possible because of color crosstalks. Another open problem is decoding errors of the projected patterns, which causes a failure on extracting positional information of the projected pattern form the captured image. Among several reasons for such errors, color crosstalks are crucial because their features are similar to the main signal and difficult to be decomposed. In this paper, we solve these problems by utilizing machine learning techniques where a convolutional neural network is trained to extract low dimensional pattern features for each projector. In addition, it is trained to suppress the color crosstalks from different projectors. Using this new technique, we succeeded in reconstructing 3D shapes from images where multiple patterns are overlapped.
keywords: {Image color analysis;Cameras;Feature extraction;Crosstalk;Three-dimensional displays;Shape;Pattern matching},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989592&isnumber=7988677

M. Wang, D. Su, L. Shi, Y. Liu and J. V. Miro, "Real-time 3D human tracking for mobile robots with multisensors," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5081-5087.
doi: 10.1109/ICRA.2017.7989593
Abstract: Acquiring the accurate 3-D position of a target person around a robot provides fundamental and valuable information that is applicable to a wide range of robotic tasks, including home service, navigation and entertainment. This paper presents a real-time robotic 3-D human tracking system which combines a monocular camera with an ultrasonic sensor by the extended Kalman filter (EKF). The proposed system consists of three sub-modules: monocular camera sensor tracking model, ultrasonic sensor tracking model and multi-sensor fusion. An improved visual tracking algorithm is presented to provide partial location estimation (2-D). The algorithm is designed to overcome severe occlusions, scale variation, target missing and achieve robust re-detection. The scale accuracy is further enhanced by the estimated 3-D information. An ultrasonic sensor array is employed to provide the range information from the target person to the robot and Gaussian Process Regression is used for partial location estimation (2-D). EKF is adopted to sequentially process multiple, heterogeneous measurements arriving in an asynchronous order from the vision sensor and the ultrasonic sensor separately. In the experiments, the proposed tracking system is tested in both simulation platform and actual mobile robot for various indoor and outdoor scenes. The experimental results show the superior performance of the 3-D tracking system in terms of both the accuracy and robustness.
keywords: {Target tracking;Visualization;Cameras;Acoustics;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989593&isnumber=7988677

B. Yang, P. Lancaster and J. R. Smith, "Pre-touch sensing for sequential manipulation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5088-5095.
doi: 10.1109/ICRA.2017.7989594
Abstract: The primary focus of this work is to examine how robots can achieve more robust sequential manipulation through the use of pre-touch sensors. The utility of close-range proximity sensing is evaluated through a robotic system that uses a new optical time-of-flight pre-touch sensor to complete a highly precise and sequential task - solving the Rubik's cube. The techniques used in this task are then extended to a more general framework in which ICP is used to match pre-touch data to a reference model, demonstrating that even simple pre-touch scans can be used to recover the pose of common objects that require sequential manipulation.
keywords: {Optical sensors;Cameras;Robot vision systems;Tactile sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989594&isnumber=7988677

V. K. Viswanathan et al., "AUV motion-planning for photogrammetric reconstruction of marine archaeological sites," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5096-5103.
doi: 10.1109/ICRA.2017.7989595
Abstract: This paper presents a method for constructing 3D maps of marine archaeological sites using deployments of Autonomous Underwater Vehicles (AUV) equipped with sonar and cameras. The method requires multiple AUV missions in which the first mission directs the AUV to conduct a high altitude lawnmower scan over the area to create a course bathymetry map using sonar. Subsequent AUV missions then direct the AUV to make low altitude fly-overs just above the wreck with the goal of obtaining camera images from multiple viewpoints of the wreck to enable offboard 3D mapping via photogrammetric reconstruction. This approach uses a coarse map generated after the first mission to construct AUV paths that attempt to maximize information gain, i.e. maximize the number of viewpoints of the wreck within a time limit. Presented is a motion planner derived from Rapidly-Exploring Random Trees (RRT) that have sampling strategies modified for this problem. Specifically, the random node selection and new node generation are designed to consider the kinematics of an AUV and the information gain associated with each flyover. Simulation results demonstrate improvements of up to 152% when these sampling strategies are used. Experiment results, involving deployments for mapping two known wrecks located along the coast of Malta, validate the system's ability to construct 3D maps and associated visualizations.
keywords: {Sonar;Three-dimensional displays;Trajectory;Planning;Cameras;Image reconstruction;Heuristic algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989595&isnumber=7988677

W. Dong and V. Isler, "A novel method for the extrinsic calibration of a 2-D laser-rangefinder & a camera," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5104-5109.
doi: 10.1109/ICRA.2017.7989596
Abstract: We present a novel method for extrinsically calibrating a camera and a 2-D Laser Rangefinder (LRF) whose beams are invisible from the camera image. We show that point-to-plane constraints from a single observation of a V-shaped calibration pattern composed of two non-coplanar triangles suffice to uniquely constrain the relative pose between two sensors. Next, we present an approach to obtain solutions using point-to-plane constraints from single or multiple observations. Along the way, we also show that previous solutions, in contrast to our method, have inherent ambiguities and therefore must rely on a good initial estimate. Real and synthetic experiments validate our method and show that it achieves better accuracy than previous methods.
keywords: {Calibration;Cameras;Lasers;Measurement by laser beam;Three-dimensional displays;Laser beams;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989596&isnumber=7988677

M. Hsiao, E. Westman, G. Zhang and M. Kaess, "Keyframe-based dense planar SLAM," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5110-5117.
doi: 10.1109/ICRA.2017.7989597
Abstract: In this work, we develop a novel keyframe-based dense planar SLAM (KDP-SLAM) system, based on CPU only, to reconstruct large indoor environments in real-time using a hand-held RGB-D sensor. Our keyframe-based approach applies a fast dense method to estimate odometry, fuses depth measurements from small baseline images, extracts planes from the fused depth map, and optimizes the poses of the keyframes and landmark planes in a global factor graph using incremental smoothing and mapping (iSAM). Using the fast odometry estimation, correct plane correspondences may be found projectively, and the pose of each frame can be estimated accurately even without sufficient planes to fully constrain the 6 degree-of-freedom transformation. The depth map generated from the local fusion process generates higher quality reconstructions and plane segmentations by eliminating noise. Moreover, explicitly modeling plane landmarks in the fully probabilistic global optimization significantly reduces the drift that plagues other dense SLAM algorithms. We test our system on standard RGB-D benchmarks as well as additional indoor environments, demonstrating its state-of-the-art performance as a real-time dense 3D SLAM algorithm, without the use of GPU.
keywords: {Simultaneous localization and mapping;Real-time systems;Three-dimensional displays;Optimization;Cameras;Indoor environments;Graphics processing units},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989597&isnumber=7988677

D. Massiceti, A. Krull, E. Brachmann, C. Rother and P. H. S. Torr, "Random forests versus Neural Networks — What's best for camera localization?," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5118-5125.
doi: 10.1109/ICRA.2017.7989598
Abstract: This work addresses the task of camera localization in a known 3D scene given a single input RGB image. State-of-the-art approaches accomplish this in two steps: firstly, regressing for every pixel in the image its 3D scene coordinate and subsequently, using these coordinates to estimate the final 6D camera pose via RANSAC. To solve the first step. Random Forests (RFs) are typically used. On the other hand. Neural Networks (NNs) reign in many dense regression tasks, but are not test-time efficient. We ask the question: which of the two is best for camera localization? To address this, we make two method contributions: (1) a test-time efficient NN architecture which we term a ForestNet that is derived and initialized from a RF, and (2) a new fully-differentiable robust averaging technique for regression ensembles which can be trained end-to-end with a NN. Our experimental findings show that for scene coordinate regression, traditional NN architectures are superior to test-time efficient RFs and ForestNets, however, this does not translate to final 6D camera pose accuracy where RFs and ForestNets perform slightly better. To summarize, our best method, a ForestNet with a robust average, which has an equivalent fast and lightweight RF, improves over the state-of-the-art for camera localization on the 7-Scenes dataset [1]. While this work focuses on scene coordinate regression for camera localization, our innovations may also be applied to other continuous regression tasks.
keywords: {Radio frequency;Cameras;Artificial neural networks;Three-dimensional displays;Training;Vegetation;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989598&isnumber=7988677

L. Platinsky, A. J. Davison and S. Leutenegger, "Monocular visual odometry: Sparse joint optimisation or dense alternation?," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5126-5133.
doi: 10.1109/ICRA.2017.7989599
Abstract: Real-time monocular SLAM is increasingly mature and entering commercial products. However, there is a divide between two techniques providing similar performance. Despite the rise of ‘dense’ and ‘semi-dense’ methods which use large proportions of the pixels in a video stream to estimate motion and structure via alternating estimation, they have not eradicated feature-based methods which use a significantly smaller amount of image information from keypoints and retain a more rigorous joint estimation framework. Dense methods provide more complete scene information, but in this paper we focus on how the amount of information and different optimisation methods affect the accuracy of local motion estimation (monocular visual odometry). This topic becomes particularly relevant after the recent results from a direct sparse system. We propose a new method for fairly comparing the accuracy of SLAM frontends in a common setting. We suggest computational cost models for an overall comparison which indicates that there is relative parity between the approaches at the settings allowed by current serial processors when evaluated under equal conditions.
keywords: {Simultaneous localization and mapping;Optimization;Estimation;Cameras;Feature extraction;Visualization;Image reconstruction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989599&isnumber=7988677

J. Briales and J. Gonzalez-Jimenez, "Initialization of 3D pose graph optimization using Lagrangian duality," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5134-5139.
doi: 10.1109/ICRA.2017.7989600
Abstract: Pose Graph Optimization (PGO) is the de facto choice to solve the trajectory of an agent in Simultaneous Localization and Mapping (SLAM). The Maximum Likelihood Estimation (MLE) for PGO is a non-convex problem for which no known technique is able to guarantee a globally optimal solution under general conditions. In recent years, Lagrangian duality has proved suitable to provide good, frequently tight relaxations of the hard PGO problem through convex Semidefinite Programming (SDP). In this work, we build from the state-of-the-art Lagrangian relaxation [1] and contribute a complete recovery procedure that, given the (tractable) optimal solution of the relaxation, provides either the optimal MLE solution if the relaxation is tight, or a remarkably good feasible guess if the relaxation is non-tight, which occurs in specially challenging PGO problems (very noisy observations, low graph connectivity, etc.). In the latter case, when used for initialization of local iterative methods, our approach outperforms other state-of-the-art approaches converging to better solutions. We support our claims with extensive experiments.
keywords: {Maximum likelihood estimation;Optimization;Three-dimensional displays;Symmetric matrices;Simultaneous localization and mapping;Rendering (computer graphics)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989600&isnumber=7988677

K. A. Skinner, E. Iscar and M. Johnson-Roberson, "Automatic color correction for 3D reconstruction of underwater scenes," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5140-5147.
doi: 10.1109/ICRA.2017.7989601
Abstract: Mapping of underwater environments is a critical task for a range of activities from monitoring coral reef habitats to surveying submerged archaeological sites. While recent advances in methods for terrestrial mapping can achieve dense 3D reconstructions of scenes in real-time, there remains the challenge of transferring these methods to the underwater domain due to characteristic effects on propagation of light through the water column that violate the brightness constancy constraint used in terrestrial techniques. Current state-of-the-art methods for underwater 3D reconstruction exploit a physical model of light propagation underwater to account for such range-dependent effects as scattering and attenuation; however, these methods necessitate careful calibration of attenuation coefficients required by the physical model, or rely on rough estimates of these coefficients from prior lab experiments. The main contribution of this paper is to develop a novel method to achieve simultaneous estimation of attenuation coefficients for color correction during structure recovery of an underwater scene by integrating this estimation directly into the bundle adjustment step, which performs non-linear optimization. To validate the proposed method, an artificial scene is submerged in a pure water tank and surveyed with a stereo camera platform to simulate an underwater robotic survey in a controlled environment. The target structure is imaged in air with an RGB-D sensor to provide ground truth structure and color, and a color calibration board is place in the scene for further reference. Results show that the proposed method can automatically estimate a water-column aware model for color correction of underwater images simultaneously to 3D reconstruction of the submerged scene.
keywords: {Attenuation;Three-dimensional displays;Cameras;Image color analysis;Image reconstruction;Scattering;Solid modeling;Underwater 3D reconstruction;bundle adjustment;stereo vision},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989601&isnumber=7988677

J. Kim, Y. Latif and I. Reid, "RRD-SLAM: Radial-distorted rolling-shutter direct SLAM," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5148-5154.
doi: 10.1109/ICRA.2017.7989602
Abstract: In this paper, we present a monocular direct semi-dense SLAM (Simultaneous Localization And Mapping) method that can handle both radial distortion and rolling-shutter distortion. Such distortions are common in, but not restricted to, situations when an inexpensive wide-angle lens and a CMOS sensor are used, and leads to significant inaccuracy in the map and trajectory estimates if not modeled correctly. The apparent naive solution of simply undistorting the images using pre-calibrated parameters does not apply to this case since rows in the undistorted image are no longer captured at the same time. To address this we develop an algorithm that incorporates radial distortion into an existing state-of-the-art direct semi-dense SLAM system that takes rolling-shutters into account. We propose a method for finding the generalized epipolar curve for each rolling-shutter radially distorted image. Our experiments demonstrate the efficacy of our approach and compare it favorably with the state-of-the-art in direct semi-dense rolling-shutter SLAM.
keywords: {Distortion;Cameras;Simultaneous localization and mapping;Splines (mathematics);Lenses;Optical distortion;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989602&isnumber=7988677

K. J. Wu, C. X. Guo, G. Georgiou and S. I. Roumeliotis, "VINS on wheels," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5155-5162.
doi: 10.1109/ICRA.2017.7989603
Abstract: In this paper, we present a vision-aided inertial navigation system (VINS) for localizing wheeled robots. In particular, we prove that VINS has additional unobservable directions, such as the scale, when deployed on a ground vehicle that is constrained to move along straight lines or circular arcs. To address this limitation, we extend VINS to incorporate low-frequency wheel-encoder data, and show that the scale becomes observable. Furthermore, and in order to improve the localization accuracy, we introduce the manifold-(m)VINS that exploits the fact that the vehicle moves on an approximately planar surface. In our experiments, we first show the performance degradation of VINS due to special motions, and then demonstrate that by utilizing the additional sources of information, our system achieves significantly higher positioning accuracy, while operating in real-time on a commercial-grade mobile device.
keywords: {Acceleration;Mobile robots;Observability;Wheels;Noise measurement;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989603&isnumber=7988677

R. Codd-Downey and M. Jenkin, "On the utility of additional sensors in aquatic simultaneous localization and mapping," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5163-5168.
doi: 10.1109/ICRA.2017.7989604
Abstract: Simultaneous Localization and Mapping (SLAM) is a key stepping stone on the road to truly autonomous robots. SLAM is of particular importance to robots with large motion estimation problems, such as robots operating on the surface of aquatic GPS-denied environments where a paucity of local landmarks complicates SLAM and accurate navigation. Visual sensors have proven to be an effective tool for SLAM generally and have wide applicability, but is vision enough to solve SLAM in this environment, and how important are other sensors including a compass and water column depth to solve SLAM for an aquatic surface vehicle? Here we show that more sensors are almost always helpful in terms of improving SLAM performance in such a situation but that a compass is a particularly useful sensor for SLAM for autonomous surface vehicles; suggesting that a compass is a worthwhile investment for such a robot, and that compass alternatives should be considered when operating an autonomous vehicle in environments that are both GPS and compass-denied.
keywords: {Simultaneous localization and mapping;Compass;Sonar;Visualization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989604&isnumber=7988677

M. Kuang, J. Zhu, W. Wang and Y. Tang, "Flight controller design and demonstration of a thrust-vectored tailsitter," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5169-5174.
doi: 10.1109/ICRA.2017.7989605
Abstract: This paper discusses the design and control methods of a thrust-vectored tailsitter that combines the advantages of both fixed wing and rotary wing systems. Separable takeoff bracket and controllable forward landing are implemented to reduce the flight weight and mitigate the effects of crosswinds. A six-degrees-of-freedom model especially for this tailsitter is then proposed to describe the dynamics of the whole system. Attitude representation based on horizontal /vertical Euler angles is presented to avoid the problem of singularity. Attitude and altitude controllers that switch between horizontal and vertical modes are used. In these controllers linear/constant acceleration approximation and filtered feed-forward acceleration algorithm are implemented. Effectiveness and reliability of the proposed control methods are demonstrated and evaluated by experimental results of the whole flight envelope.
keywords: {Aircraft;Attitude control;Propellers;Switches;Aerodynamics;Angular velocity},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989605&isnumber=7988677

M. Zhao, K. Kawasaki, X. Chen, S. Noda, K. Okada and M. Inaba, "Whole-body aerial manipulation by transformable multirotor with two-dimensional multilinks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5175-5182.
doi: 10.1109/ICRA.2017.7989606
Abstract: In this paper, we introduce the achievement of the aerial manipulation by using the whole body of a transformable aerial robot, instead of attaching an additional manipulator. The aerial robot in our work is composed by two-dimensional multilinks which enable a stable aerial transformation and can be employed as an entire gripper. We propose a planning method to find the optimized grasping form for the multilinks while they are on the air, which is based on the original planar enveloping algorithm, along with the optimization of the internal force and joint torque for the force-closure. We then propose the aerial approach and grasp motion strategy, which is devoted to the determination of the form and position of the aerial robot to approach and grasp effectively the object from the air. Finally we present the experimental results of the aerial manipulation which involves grasping, carrying and dropping different types of object. These results validate the performance of aerial grasping based on our proposed whole-body grasp planning and motion control method.
keywords: {Unmanned aerial vehicles;Grasping;Planning;Manipulators;Grippers;Propellers;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989606&isnumber=7988677

Q. Li, J. Qian, Z. Zhu, X. Bao, M. K. Helwa and A. P. Schoellig, "Deep neural networks for improved, impromptu trajectory tracking of quadrotors," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5183-5189.
doi: 10.1109/ICRA.2017.7989607
Abstract: Trajectory tracking control for quadrotors is important for applications ranging from surveying and inspection, to film making. However, designing and tuning classical controllers, such as proportional-integral-derivative (PID) controllers, to achieve high tracking precision can be time-consuming and difficult, due to hidden dynamics and other non-idealities. The Deep Neural Network (DNN), with its superior capability of approximating abstract, nonlinear functions, proposes a novel approach for enhancing trajectory tracking control. This paper presents a DNN-based algorithm as an add-on module that improves the tracking performance of a classical feedback controller. Given a desired trajectory, the DNNs provide a tailored reference input to the controller based on their gained experience. The input aims to achieve a unity map between the desired and the output trajectory. The motivation for this work is an interactive “fly-as-you-draw” application, in which a user draws a trajectory on a mobile device, and a quadrotor instantly flies that trajectory with the DNN-enhanced control system. Experimental results demonstrate that the proposed approach improves the tracking precision for user-drawn trajectories after the DNNs are trained on selected periodic trajectories, suggesting the method's potential in real-world applications. Tracking errors are reduced by around 40-50% for both training and testing trajectories from users, highlighting the DNNs' capability of generalizing knowledge.
keywords: {Trajectory;Training;Trajectory tracking;Feedback control;Artificial neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989607&isnumber=7988677

M. Ryll et al., "6D physical interaction with a fully actuated aerial robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5190-5195.
doi: 10.1109/ICRA.2017.7989608
Abstract: This paper presents the design, control, and experimental validation of a novel fully-actuated aerial robot for physically interactive tasks, named Tilt-Hex. We show how the Tilt-Hex, a tilted-propeller hexarotor is able to control the full pose (position and orientation independently) using a geometric control, and to exert a full-wrench (force and torque independently) with a rigidly attached end-effector using an admittance control paradigm. An outer loop control governs the desired admittance behavior and an inner loop based on geometric control ensures pose tracking. The interaction forces are estimated by a momentum based observer. Control and observation are made possible by a precise control and measurement of the speed of each propeller. An extensive experimental campaign shows that the Tilt-Hex is able to outperform the classical underactuated multi-rotors in terms of stability, accuracy and dexterity and represent one of the best choice at date for tasks requiring aerial physical interaction.
keywords: {Unmanned aerial vehicles;Propellers;Robots;Force;Admittance;Observers;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989608&isnumber=7988677

M. Gassner, T. Cieslewski and D. Scaramuzza, "Dynamic collaboration without communication: Vision-based cable-suspended load transport with two quadrotors," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5196-5202.
doi: 10.1109/ICRA.2017.7989609
Abstract: Transport of objects is a major application in robotics nowadays. While ground robots can carry heavy payloads for long distances, they are limited in rugged terrains. Aerial robots can deliver objects in arbitrary terrains; however they tend to be limited in payload. It has been previously shown that, for heavy payloads, it can be beneficial to carry them using multiple flying robots. In this paper, we propose a novel collaborative transport scheme, in which two quadrotors transport a cable-suspended payload at accelerations that exceed the capabilities of previous collaborative approaches, which make quasi-static assumptions. Furthermore, this is achieved completely without explicit communication between the collaborating robots, making our system robust to communication failures and making consensus on a common reference frame unnecessary. Instead, they only rely on visual and inertial cues obtained from on-board sensors. We implement and validate the proposed method on a real system.
keywords: {Payloads;Force;Robot sensing systems;Trajectory;Collaboration;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989609&isnumber=7988677

A. Franchi and A. Mallet, "Adaptive closed-loop speed control of BLDC motors with applications to multi-rotor aerial vehicles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5203-5208.
doi: 10.1109/ICRA.2017.7989610
Abstract: This paper introduces the adaptive bias and adaptive gain (ABAG) algorithm for closed-loop electronic speed control (ESC) of the brushless direct current (BLDC) motors typically used to spin the propellers in multi-rotor aerial robots. The ABAG algorithm is adaptive and robust in the sense that it does not require the knowledge of any mechanical/electrical parameter of the motor/propeller group and that neither a pre-calibration nor the knowledge of the feedforward/nominal input is needed. The ABAG algorithm is amenable to an extremely low complexity implementation. We experimentally prove that it can run in 27.5 μs on a 8 MHz microcontroller with no floating point unit and limited arithmetic capabilities allowing only 8-bit additions, subtractions and multiplications. Besides the controller implementation we present a self-contained open source software architecture that handles the entire speed control process, including clock synchronization, and over-current and blockage safeties. The excellent performance and robustness of ABAG are shown by experimental tests and aerial physical interaction experiments.
keywords: {Propellers;Rotors;Velocity control;Robot sensing systems;Permanent magnet motors;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989610&isnumber=7988677

D. R. McArthur, A. B. Chowdhury and D. J. Cappelleri, "Design of the I-BoomCopter UAV for environmental interaction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5209-5214.
doi: 10.1109/ICRA.2017.7989611
Abstract: This paper presents the design of the Interacting-BoomCopter (I-BoomCopter) unmanned aerial vehicle (UAV), designed specifically for environmental interactions. The novel design consists of a horizontally mounted four-blade reversible propeller on a front boom that is attached to a standard tri-rotor UAV configuration. A custom end-effector and force sensor is placed at the end of the front boom for autonomous pushing and pulling interaction tasks. The modeling of the new platform is presented and two prototype versions built, flight tested, and characterized. Finally, the efficacy of the new platform for environmental interactions is evaluated with an autonomous door opening task and a teleoperated door opening and door closing task.
keywords: {Propellers;Prototypes;Rotors;Unmanned aerial vehicles;Acceleration;Dynamics;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989611&isnumber=7988677

D. Hall, F. Dayoub, J. Kulk and C. McCool, "Towards unsupervised weed scouting for agricultural robotics," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5223-5230.
doi: 10.1109/ICRA.2017.7989612
Abstract: Weed scouting is an important part of modern integrated weed management but can be time consuming and sparse when performed manually. Automated weed scouting and weed destruction has typically been performed using classification systems able to classify a set group of species known a priori. This greatly limits deployability as classification systems must be retrained for any field with a different set of weed species present within them. In order to overcome this limitation, this paper works towards developing a clustering approach to weed scouting which can be utilized in any field without the need for prior species knowledge. We demonstrate our system using challenging data collected in the field from an agricultural robotics platform. We show that considerable improvements can be made by (i) learning low-dimensional (bottleneck) features using a deep convolutional neural network to represent plants in general and (ii) tying views of the same area (plant) together. Deploying this algorithm on in-field data collected by AgBotII, we are able to successfully cluster cotton plants from grasses without prior knowledge or training for the specific plants in the field.
keywords: {Robots;Clustering algorithms;Image segmentation;Image color analysis;Feature extraction;Neural networks;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989612&isnumber=7988677

J. -H. Kim, Y. Sung and B. Y. Lattimer, "Bayesian estimation based real-time fire-heading in smoke-filled indoor environments using thermal imagery," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5231-5236.
doi: 10.1109/ICRA.2017.7989613
Abstract: This paper presents a fire heading estimation for solving the autonomous navigation problem of a firefighting robot in smoke-filled indoor fire environment. In smoke-filled fire environments, firefighters and firefighting robots experience difficulty maintaining direction while finding the fire source. To solve this, the statistical texture features in thermal images were analyzed and fused by using Bayesian estimation to compute the vertical and horizontal fire heading. For its validation, a large-scaled test-bed was built with a hallway and two rooms, with one of the rooms having a real size fire generating dense and dark smoke. The proposed method probabilistically computed the fire-heading toward the entrance of the hallway then guided the robot to the room with the actual fire, all while navigating in a smoke-filled situation. The experimental results have demonstrated the effectiveness of this method in indoor fire environments.
keywords: {Fires;Robots;Estimation;Feature extraction;Bayes methods;Reflection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989613&isnumber=7988677

M. Fehr et al., "TSDF-based change detection for consistent long-term dense reconstruction and dynamic object discovery," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5237-5244.
doi: 10.1109/ICRA.2017.7989614
Abstract: Robots that are operating for extended periods of time need to be able to deal with changes in their environment and represent them adequately in their maps. In this paper, we present a novel 3D reconstruction algorithm based on an extended Truncated Signed Distance Function (TSDF) that enables to continuously refine the static map while simultaneously obtaining 3D reconstructions of dynamic objects in the scene. This is a challenging problem because map updates happen incrementally and are often incomplete. Previous work typically performs change detection on point clouds, surfels or maps, which are not able to distinguish between unexplored and empty space. In contrast, our TSDF-based representation naturally contains this information and thus allows us to more robustly solve the scene differencing problem. We demonstrate the algorithms performance as part of a system for unsupervised object discovery and class recognition. We evaluated our algorithm on challenging datasets that we recorded over several days with RGB-D enabled tablets. To stimulate further research in this area, all of our datasets are publicly available3.
keywords: {Three-dimensional displays;Heuristic algorithms;Robots;Computational modeling;Geometry;Image reconstruction;Detection algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989614&isnumber=7988677

D. Honegger, T. Sattler and M. Pollefeys, "Embedded real-time multi-baseline stereo," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5245-5250.
doi: 10.1109/ICRA.2017.7989615
Abstract: Dense depth map estimation from stereo cameras has many applications in robotic vision, e.g., obstacle detection, especially when performed in real-time. The range in which depth values can be accurately estimated is usually limited for two-camera stereo setups due to the fixed baseline between the cameras. In addition, two-camera setups suffer from wrong depth estimates caused by local minima in the matching cost functions. Both problems can be alleviated by adding more cameras as this creates multiple baselines of different lengths and since multi-image matching leads to unique minima. However, using more cameras usually comes at an increase in run-time. In this paper, we present a novel embedded system for multi-baseline stereo. By exploiting the parallelization capabilities within FPGAs, we are able to estimate a depth map from multiple cameras in real-time. We show that our approach requires only little more power and weight compared to a two-camera stereo system. At the same time, we show that our system produces significantly better depth maps and is able to handle occlusion of some cameras, resulting in the redundancy typically desired for autonomous vehicles. Our system is small in size and leight-weight and can be employed even on a MAV platform with very strict power, weight, and size requirements.
keywords: {Cameras;Field programmable gate arrays;Real-time systems;Robot vision systems;Distortion;Lenses},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989615&isnumber=7988677

C. V. Nguyen, M. Milford and R. Mahony, "3D tracking of water hazards with polarized stereo cameras," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5251-5257.
doi: 10.1109/ICRA.2017.7989616
Abstract: Current self-driving car systems operate well in sunny weather but struggle in adverse conditions. One of the most commonly encountered adverse conditions involves water on the road caused by rain, sleet, melting snow or flooding. While some advances have been made in using conventional RGB camera and LIDAR technology for detecting water hazards, other sources of information such as polarization offer a promising and potentially superior approach to this problem in terms of performance and cost. In this paper, we present a novel stereo-polarization system for detecting and tracking water hazards based on polarization and color variation of reflected light, with consideration of the effect of polarized light from sky as function of reflection and azimuth angles. To evaluate this system, we present a new large `water on road' datasets spanning approximately 2 km of driving in various on-road and off-road conditions and demonstrate for the first time reliable water detection and tracking over a wide range of realistic car driving water conditions using polarized vision as the primary sensing modality. Our system successfully detects water hazards up to more than 100m. Finally, we discuss several interesting challenges and propose future research directions for further improving robust autonomous car perception in hazardous wet conditions using polarization sensors.
keywords: {Sun;Cameras;Hazards;Image color analysis;Mathematical model;Azimuth;Scattering},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989616&isnumber=7988677

B. J. Meyer and T. Drummond, "Improved semantic segmentation for robotic applications with hierarchical conditional random fields," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5258-5265.
doi: 10.1109/ICRA.2017.7989617
Abstract: Conventional approaches to semantic segmentation are inappropriate for robotic applications, as they focus on pixel-level performance and give little significance to spurious object detections. This paper presents a region-based conditional random field model for semantic segmentation that focuses on object-level performance, recognising that in a robotics context, false object detections can have costly consequences. We show how optimising at the semantic region-level results in significantly fewer false positive object detections than conventional approaches. We further show how both object and pixel-level performance can be improved over conventional methods by combining region random fields with dense pixel random fields in a hierarchical manner. An object-aware performance metric is introduced that heavily penalises false positive and false negative object detections, as appropriate for robotic applications. Our approach is evaluated on the challenging NYU v2 and Pascal VOC datasets, outperforming comparable conventional methods in terms of object and pixel-level performance.
keywords: {Semantics;Robots;Image segmentation;Object detection;Labeling;Context modeling;Measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989617&isnumber=7988677

R. Dubé, D. Dugas, E. Stumm, J. Nieto, R. Siegwart and C. Cadena, "SegMatch: Segment based place recognition in 3D point clouds," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5266-5272.
doi: 10.1109/ICRA.2017.7989618
Abstract: Place recognition in 3D data is a challenging task that has been commonly approached by adapting image-based solutions. Methods based on local features suffer from ambiguity and from robustness to environment changes while methods based on global features are viewpoint dependent. We propose SegMatch, a reliable place recognition algorithm based on the matching of 3D segments. Segments provide a good compromise between local and global descriptions, incorporating their strengths while reducing their individual drawbacks. SegMatch does not rely on assumptions of `perfect segmentation', or on the existence of `objects' in the environment, which allows for reliable execution on large scale, unstructured environments. We quantitatively demonstrate that SegMatch can achieve accurate localization at a frequency of 1Hz on the largest sequence of the KITTI odometry dataset. We furthermore show how this algorithm can reliably detect and close loops in real-time, during online operation. In addition, the source code for the SegMatch algorithm is made publicly available.
keywords: {Three-dimensional displays;Feature extraction;Histograms;Shape;Image segmentation;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989618&isnumber=7988677

P. Falco, S. Lu, A. Cirillo, C. Natale, S. Pirozzi and D. Lee, "Cross-modal visuo-tactile object recognition using robotic active exploration," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5273-5280.
doi: 10.1109/ICRA.2017.7989619
Abstract: In this work, we propose a framework to deal with cross-modal visuo-tactile object recognition. By cross-modal visuo-tactile object recognition, we mean that the object recognition algorithm is trained only with visual data and is able to recognize objects leveraging only tactile perception. The proposed cross-modal framework is constituted by three main elements. The first is a unified representation of visual and tactile data, which is suitable for cross-modal perception. The second is a set of features able to encode the chosen representation for classification applications. The third is a supervised learning algorithm, which takes advantage of the chosen descriptor. In order to show the results of our approach, we performed experiments with 15 objects common in domestic and industrial environments. Moreover, we compare the performance of the proposed framework with the performance of 10 humans in a simple cross-modal recognition task.
keywords: {Visualization;Three-dimensional displays;Object recognition;Robot sensing systems;Training;Histograms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989619&isnumber=7988677

A. Giusti, J. Malzahn, N. G. Tsagarakis and M. Althoff, "Combined inverse-dynamics/passivity-based control for robots with elastic joints," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5281-5288.
doi: 10.1109/ICRA.2017.7989620
Abstract: We consider the global tracking control problem of robots with elastic joints. Even if joint elasticity introduces beneficial features for modern applications which require physically resilient and safer robots that can interact with the environment or humans, it challenges the achievable control performance. We propose a novel controller which combines the benefits of two approaches: the intrinsic robustness to model uncertainty from passivity-based control and the implementation efficiency of inverse-dynamics control schemes using a modern recursive algorithm. The novel controller is applied to an elastic-joint reconfigurable robotic arm using a recently proposed framework for on-the-fly control design. Simulation and experimental results validate our proposed approach.
keywords: {Manipulators;Computational modeling;Elasticity;Robustness;Trajectory tracking;Numerical models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989620&isnumber=7988677

L. Biagiotti, L. Moriello and C. Melchiorri, "Feedforward control of Variable Stiffness Joints robots for vibrations suppression," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5289-5294.
doi: 10.1109/ICRA.2017.7989621
Abstract: This paper presents a new feedforward controller based on a continuous-time finite impulse response filter, designed to minimize the vibrations that usually affect robot manipulators with elastic joints. In particular, Variable Stiffness Joints (VSJ) robots are considered, since they are usually characterized by a very low level of damping which makes the problem of the oscillations quite important. The proposed approach allows to simplify the overall control structure of VSJ robots, which is based on a decentralized control of each servomotor, imposing the desired position and the desired stiffness at each joint, and on a novel feedforward control, filtering the reference signals. After analyzing some of the filter properties and the method for the parameters choice, experimental results on a VSJ robot demonstrate the importance of the proposed filtering action for minimizing vibrations and oscillations.
keywords: {Vibrations;Feedforward neural networks;Manipulators;Damping;Oscillators;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989621&isnumber=7988677

A. Doerr, D. Nguyen-Tuong, A. Marco, S. Schaal and S. Trimpe, "Model-based policy search for automatic tuning of multivariate PID controllers," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5295-5301.
doi: 10.1109/ICRA.2017.7989622
Abstract: PID control architectures are widely used in industrial applications. Despite their low number of open parameters, tuning multiple, coupled PID controllers can become tedious in practice. In this paper, we extend PILCO, a model-based policy search framework, to automatically tune multivariate PID controllers purely based on data observed on an otherwise unknown system. The system's state is extended appropriately to frame the PID policy as a static state feedback policy. This renders PID tuning possible as the solution of a finite horizon optimal control problem without further a priori knowledge. The framework is applied to the task of balancing an inverted pendulum on a seven degree-of-freedom robotic arm, thereby demonstrating its capabilities of fast and data-efficient policy learning, even on complex real world problems.
keywords: {Tuning;PD control;PI control;Computational modeling;Data models;State feedback;Process control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989622&isnumber=7988677

A. Radulescu, I. Havoutis, D. G. Caldwell and C. Semini, "Whole-body trajectory optimization for non-periodic dynamic motions on quadrupedal systems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5302-5307.
doi: 10.1109/ICRA.2017.7989623
Abstract: Autonomous legged robots will be required to handle a wide range of tasks in complex environments. While a lot of research has focused on developing their abilities for periodic locomotion tasks, less effort has been invested in devising generalized strategies for dynamic, non-periodic movements. Motion design approaches are frequently enlisted in the form of teleoperation or predefined heuristics in such scenarios. We employ a realistic simulation of the hydraulically actuated HyQ2Max quadrupedal system for investigations on two distinctive tasks: rearing and posture recovery. We present a whole-body optimization methodology for non-periodic tasks on quadrupedal systems. This approach delivers solutions involving multiple contacts without the need for predefined feet placements. The results obtained show the potential of optimization approaches for motion synthesis in the context of complex tasks.
keywords: {Legged locomotion;Cost function;Kernel;Trajectory;Dynamics;optimization;parametrized policy;multi-legged systems;switching contacts;non-periodic movements;quadruped;posture recovery;whole-body trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989623&isnumber=7988677

A. W. Winkler, F. Farshidian, M. Neunert, D. Pardo and J. Buchli, "Online walking motion and foothold optimization for quadruped locomotion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5308-5313.
doi: 10.1109/ICRA.2017.7989624
Abstract: We present an algorithm that generates walking motions for quadruped robots without the use of an explicit footstep planner by simultaneously optimizing over both the Center of Mass (CoM) trajectory and the footholds. Feasibility is achieved by imposing stability constraints on the CoM related to the Zero Moment Point and explicitly enforcing kinematic constraints between the footholds and the CoM position. Given a desired goal state, the problem is solved online by a Nonlinear Programming solver to generate the walking motion. Experimental trials show that the algorithm is able to generate walking gaits for multiple steps in milliseconds that can be executed on a real quadruped robot.
keywords: {Legged locomotion;Optimization;Force;Acceleration;Trajectory;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989624&isnumber=7988677

V. R. Desaraju and N. Michael, "Leveraging experience for computationally efficient adaptive nonlinear model predictive control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5314-5320.
doi: 10.1109/ICRA.2017.7989625
Abstract: This work presents Experience-driven Predictive Control (EPC) as a fast technique for solving nonlinear model predictive control (NMPC) problems with uncertain system dynamics. EPC leverages an affine dynamics model that is updated online via Locally Weighted Projection Regression (LWPR) to capture nonlinearities, uncertainty, and changes in the system dynamics. This model enables the NMPC problem to be re-cast as a quadratic program (QP). The QP can then be solved via multi-parametric techniques to generate a mapping from state, reference, and dynamics model to a locally optimal, affine feedback control law. These mappings, in conjunction with the basis functions learned via LWPR, define a notion of experience for the controller as they capture the full input-output relationship for previous actions the controller has taken. The resulting experience database allows EPC to avoid solving redundant optimization problems, and as it is constructed online, enables the system to operate more efficiently over time. We demonstrate the performance of EPC through a set of hardware-in-the-loop simulation studies of a quadrotor micro air vehicle that is subjected to unmodeled exogenous perturbations.
keywords: {Adaptation models;Predictive models;Vehicle dynamics;Computational modeling;Nonlinear dynamical systems;Predictive control;System dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989625&isnumber=7988677

H. Zhang, B. Cheng and J. Zhao, "Extended tau theory for robot motion control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5321-5326.
doi: 10.1109/ICRA.2017.7989626
Abstract: Biologists proposed the tau theory to explain how animals control their motion using visual feedback for different tasks including landing and perching. Tau theory is based on a concept called time-to-contact, which is the required time to contact an object if the current velocity is maintained. Recently, tau theory has been applied to control robots' motion for similar tasks such as perching, docking, braking, or landing. However, existing tau theory can only work for the case with zero contact velocity. Some tasks such as perching actually require a non-zero contact velocity to make gripping mechanisms work. To address this problem, we extend the tau theory by proposing a two-stage strategy in one dimensional space to generate the reference trajectory for time-to-contact. Moreover, we propose a new coupling strategy to deal with the motion in three dimensional space. Simulation results demonstrate the effectiveness of proposed two-stage and coupling strategies. Moreover, we leverage a featureless method to estimate the time-to-contact from image sequences and implement it on a mobile robot platform. Experimental results also demonstrate that the non-zero contact velocity can be accomplished using onboard vision feedback. The research presented in this paper can be readily applied to control the motion of flying robots for perching with visual feedback.
keywords: {Trajectory;Animals;Estimation;Mobile robots;Optical imaging;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989626&isnumber=7988677

M. Panzirsch, R. Balachandran, J. Artigas, C. Riecke, M. Ferre and A. Albu-Schaeffer, "Haptic intention augmentation for cooperative teleoperation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5335-5341.
doi: 10.1109/ICRA.2017.7989627
Abstract: Multiple robotic agents, autonomous or teleoperated, can be employed to synergise and cooperate to achieve a common objective more effectively. Tasks using robotic manipulators can be eased and improved in terms of reliability, adaptability and ergonomics via robot cooperation. In spite of visual and haptic feedback, cooperative telemanipulation of multiple robots by distant operators can still be challenging due to practical limitations in synchronisation and supervision. This paper presents a new control approach for haptic intention augmentation between two human operators handling objects via teleoperation in a cooperative manner. The force feedback to each operator is enhanced by information on the motion intention of the other operator observed by a force sensor at the input devices. Besides on-ground experiments, an experiment is presented that involves the cooperative teleoperation of an on-ground robot by a cosmonaut on the International Space Station and another distant operator on ground.
keywords: {Force;Delay effects;Force feedback;Robot kinematics;Aerospace electronics;teleoperation;haptic augmentation;operator intention;cooperation;ISS;time delay},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989627&isnumber=7988677

N. Pedemonte, F. Abi-Farraj and P. R. Giordano, "Visual-based shared control for remote telemanipulation with integral haptic feedback," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5342-5349.
doi: 10.1109/ICRA.2017.7989628
Abstract: Nowadays, one of the largest environmental challenges that European countries must face consists in dealing with the past half century of nuclear waste. In order to optimize maintenance costs, nuclear waste must be sorted, segregated and stored according to its radiation level. Towards this end, in [1] we have recently proposed a visual-based shared control architecture meant to facilitate a human operator in controlling two remote robotic arms (one equipped with a gripper and another with a camera) during remote manipulation tasks of nuclear waste via a master device. The operator could then receive force cues informative of the feasibility of her/his motion commands during the task execution. The strategy presented in [1], albeit effective, suffers however from a locality issue since the operator can only provide instantaneous velocity commands (in a suitable task space), and receive instantaneous force feedback cues. On the other hand, the ability to `steer' a whole future trajectory in task space, and to receive a corresponding integral force feedback along the whole planned trajectory (because of any constraint of the considered system), could significantly enhance the operator's performance, especially when dealing with complex manipulation tasks. The aim of this work is to then extend [1] towards a planning-based shared control architecture able to take into account the mentioned requirements. A human/hardware-in-the-loop experiment with simulated slave robots and a real master device is reported for demonstrating the feasibility and effectiveness of the proposed approach.
keywords: {Trajectory;Grippers;Cameras;Manipulators;Force feedback;Splines (mathematics)},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989628&isnumber=7988677

J. Ramos and S. Kim, "Improving humanoid posture Teleoperation by Dynamic Synchronization through operator motion anticipation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5350-5356.
doi: 10.1109/ICRA.2017.7989629
Abstract: This paper presents the ongoing work towards enabling robots to achieve highly dynamic behavior through full-body teleoperation. Human operator and robot slave have independent balance controllers that interact with each other during the experiments. First we present a compliant balancing controller that regulates the feet contact forces in order to mitigate external disturbances and maintain balance. Next, by estimating the forces that the operator exerts over its own Center of Mass to generate movement, the Dynamic Synchronization Force Scaling controller allows the robot to anticipate human motion during posture tracking. This strategy requires reduced control gains for state tracking when compared to purely reactive controllers, resulting in an inherently more stable system. Results show a considerable reduction of the position tracking overshoot along with substantial reduction of required error-based control forces.
keywords: {Legged locomotion;Dynamics;Foot;Force;Robot kinematics;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989629&isnumber=7988677

A. Namiki, Y. Matsumoto, T. Maruyama and Y. Liu, "Vision-based predictive assist control on master-slave systems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5357-5362.
doi: 10.1109/ICRA.2017.7989630
Abstract: In this paper, we propose a method for improving the maneuverability of master-slave systems. We aim at reproducing human skillfulness and dynamic performance in master-slave robots by using assist control for human operators. In this paper, we tackle a reaching task performed by a master-slave robot and propose an operation assist algorithm based on visual feedback control. The algorithm consists of visual object recognition for a slave robot, prediction of the operator's motion by a particle filter, estimation of the operator's intention, and operation assistance of the reaching motion. We verified the validity of the proposed system in experiments.
keywords: {Robots;Visualization;Estimation;Acceleration;Predictive models;Trajectory;Feedback control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989630&isnumber=7988677

C. P. Quintero, M. Dehghan, O. Ramirez, M. H. Ang and M. Jagersand, "Flexible virtual fixture interface for path specification in tele-manipulation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5363-5368.
doi: 10.1109/ICRA.2017.7989631
Abstract: We present the design and implementation of a flexible force-vision-based interface; allowing local operators to visually specify a path constraint to a remote robot manipulator in an on-line fashion during the teleoperation. Using bilateral and unilateral configurations, we compare our system to direct teleoperation through user studies. Three performance metrics (smoothness, error and execution time) and a subjective evaluation (NASA TLX) were used to quantify user performance. The trials show that our system outperforms direct teleoperation and reduces cognitive load. Our findings show that the performance of a unilateral teleop configuration with visual-force constraints surpass a bilateral teleop configuration in terms of displacement error and variance, as well as allowing users to complete tasks faster and with a smoother trajectory.
keywords: {Force;Three-dimensional displays;Visualization;Robot sensing systems;Robot kinematics;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989631&isnumber=7988677

S. Wang, X. Zuo, R. Wang, F. Cheng and R. Yang, "A generative human-robot motion retargeting approach using a single depth sensor," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5369-5376.
doi: 10.1109/ICRA.2017.7989632
Abstract: The goal of human-robot motion retargeting is to let a robot follow the movements performed by a human subject. This is traditionally achieved by applying the estimated poses from a human pose tracking system to a robot via explicit joint mapping strategies. In this paper, we present a novel approach that combine the human pose estimation and the motion retarget procedure in a unified generative framework. A 3D parametric human-robot model is proposed that has the specific joint and stability configurations as a robot while its shape resembles a human subject. Using a single depth camera to monitor human pose, we use its raw depth map as input and drive the human-robot model to fit the input 3D point cloud. The calculated joint angles of the fitted model can be applied onto the robots for retargeting. The robot's joint angles, instead of fitted individually, are fitted globally so that the transformed surface shape is as consistent as possible to the input point cloud. The robot configurations including its skeleton proportion, joint limitation, and DoF are enforced implicitly in the formulation. No explicit and pre-defined joints mapping strategies are needed. This framework is tested with both simulations and real robots that have different skeleton proportion and DoFs compared with human to show its effectiveness for motion retargeting.
keywords: {Robot sensing systems;Three-dimensional displays;Joints;Computational modeling;Solid modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989632&isnumber=7988677

C. Schultz, S. Gaurav, M. Monfort, L. Zhang and B. D. Ziebart, "Goal-predictive robotic teleoperation from noisy sensors," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5377-5383.
doi: 10.1109/ICRA.2017.7989633
Abstract: Robotic teleoperation from a human operator's pose demonstrations provides an intuitive and effective means of control that has been made feasible by improvements in sensor technologies in recent years. However, the imprecision of low-cost depth cameras and the difficulty of calibrating a frame of reference for the operator introduce inefficiencies in this process when performing tasks that require interactions with objects in the robot's workspace. We develop a goal-predictive teleoperation system that aids in “de-noising” the controls of the operator to be more goal-directed. Our approach uses inverse optimal control to predict the intended object of interaction from the current motion trajectory in real time and then adapts the degree of autonomy between the operator's demonstrations and autonomous completion of the predicted task. We evaluate our approach using the Microsoft Kinect depth camera as our input sensor to control a Rethink Robotics Baxter robot.
keywords: {Manipulators;Cameras;Robot vision systems;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989633&isnumber=7988677

C. Lin and Y. Liu, "Decentralized estimation and control for bilateral teleoperation of mobile robot network with task abstraction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5384-5391.
doi: 10.1109/ICRA.2017.7989634
Abstract: A decentralized bilateral teleoperation system is studied in this paper by using estimators with task abstraction. There is only a part of mobile robots in the multi-robot system can receive the human command via the master robot located in the local side. By exchanging information through a undirected and connected graph, mobile robots in the network have to estimate the human command and the global task function for the control of teleoperation. The control framework is more scalable and flexible that the size and formation of mobile robot network can be teleoperated. Stability analysis is presented and experimental results are illustrated to show the efficacy of the performance of the decentralized teleoperation system.
keywords: {Mobile robots;Robot kinematics;Manipulators;Receivers;Multi-robot systems;Estimation;decentralized control;multi-robot teleoperation;task abstraction;mobile robot network},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989634&isnumber=7988677

A. Shakoor, T. Luo, S. Chen, M. Xie, J. K. Mills and D. Sun, "A high-precision robot-aided single-cell biopsy system," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5397-5402.
doi: 10.1109/ICRA.2017.7989635
Abstract: In this paper, we present a precise robot-aided single-cell surgery system to perform single-cell biopsy for cells <25 μm in diameter. A microfluidic chip is designed to arrange upto 100 individual cells in an array. A micropipette mounted onto a 3-DOF micromanipulator and a computer mouse-operated high-precision XY stage is developed to perform high-precision and high-throughput single-cell biopsy. The system is evaluated experimentally by extracting two organelles from adherent cells patterned in a microfluidic chip. The fluorescent-labeled nucleus and mitochondria of human foreskin fibroblast cells are biopsied to demonstrate the capability of the proposed system. The survival rate of the semi-automated biopsy is 73% and 45% for mitochondrial and nucleus biopsies, respectively.
keywords: {Cells (biology);Biopsy;Microfluidics;Surgery;Glass;Biomembranes;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989635&isnumber=7988677

L. Yang, K. Youcef-Toumi and U. -X. Tan, "Detect-Focus-Track-Servo (DFTS): A vision-based workflow algorithm for robotic image-guided micromanipulation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5403-5408.
doi: 10.1109/ICRA.2017.7989636
Abstract: Robotic image-guided micromanipulation contributes towards the ease of operation, speed, accuracy, and repeatability in cell manipulation. However, such technology is not fully exploited because of the challenges in the integration of robotic modules with existing microscope systems, and the difficulty in incorporating robot assistance seamlessly into the workflow. In this paper, we propose a vision-based workflow algorithm termed Detect-Focus-Track-Servo (DFTS). It facilitates easy integration of robotic modules. It also supports user interactions while minimizing the need for manual intervention and disruption to workflow through automatic detection, focusing, tracking and servoing. Experimental results suggest satisfactory detection accuracy of 99.0 % at 70 μm tolerance. The robustness test suggests no difference in the accuracy under blurred and cluttered images. The self-focus algorithm is also demonstrated to bring the tip into focus consistently. The track-servo algorithm achieves low sub-pixel uncertainty. By proposing the DFTS workflow algorithm, we hope that the level of autonomy and ease of deployment in robot and vision modules for micromanipulation can be improved so as to open up new possibilities in the development of robotic image-guided cell manipulation.
keywords: {Microscopy;Tools;Tracking;Discrete Fourier transforms;Micromanipulators;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989636&isnumber=7988677

S. Mange, E. F. Helbling, N. Gravish and R. J. Wood, "An actuated gaze stabilization platform for a flapping-wing microrobot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5409-5414.
doi: 10.1109/ICRA.2017.7989637
Abstract: Onboard vision sensing is a current challenge in micro-scale robotics. Small flapping-wing robots such as the RoboBee present significant constraints on power, weight, and image quality for an onboard vision sensor. Here we report the integration of a 1 × 1 × 1.7 mm camera capable of video capture in flight. Inspired by gaze stabilization in insects, we designed and fabricated a one degree of freedom mechanism attached to the top of the RoboBee that achieves output angles of -41° to +60°. We perform open-loop roll maneuvers and demonstrate initial control of the gaze angle during flight. This represents the first use of a camera in free flight at this scale.
keywords: {Cameras;Actuators;Fasteners;Optical sensors;Robot vision systems;Fabrication},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989637&isnumber=7988677

J. Zhang, Z. Tu, F. Fei and X. Deng, "Geometric flight control of a hovering robotic hummingbird," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5415-5421.
doi: 10.1109/ICRA.2017.7989638
Abstract: Controlled hovering of motor driven flapping wing micro aerial vehicles (FWMAVs) is challenging due to its limited control authority, large inertia, vibration produced by wing strokes, and limited components accuracy due to fabrication methods. In this work, we present a hummingbird inspired FWMAV with 12 grams of weight and 20 grams of maximum lift. We present its full non-linear dynamic model including the full inertia tensor, non-linear input mapping, and damping effect from flapping counter torques (FCTs) and flapping counter forces (FCFs). We also present a geometric flight controller to ensure exponentially stable and globally exponential attractive properties. We experimentally demonstrated the vehicle lifting off and hover with attitude stabilization.
keywords: {Aerodynamics;Torque;Damping;Vehicle dynamics;Force;Robots;Radiation detectors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989638&isnumber=7988677

J. Zhang, F. Fei, Z. Tu and X. Deng, "Design optimization and system integration of robotic hummingbird," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5422-5428.
doi: 10.1109/ICRA.2017.7989639
Abstract: Flying animals with flapping wings may best exemplify the astonishing ability of natural selection on design optimization by excelling both stability and maneuverability at insect/hummingbird scale. Flapping Wing Micro Air Vehicle (FWMAV) holds great promise in bridging the performance gap between engineering system and their natural counterparts. Designing and constructing such a system is a challenging problem under stringent size, weight and power (SWaP) constraints. In this work, we presented a systematic approach for design optimization and integration for a hummingbird inspired FWMAV. Our formulation covers aspects of actuation, dynamics, flight stability and control, which was validated by experimental data for both rigid and flexible wings, ranging from low to high wing loading. The optimization yields prototypes with onboard sensors, electronics, and computation units. The prototype flaps at 30Hz to 40Hz, with 7.5 to 12 grams of system weight and 12 to 20 grams of maximum lift. Liftoff was demonstrated with added payloads. Flapping wing platforms with different requirements and scales can now be designed and optimized with minor modifications of proposed formulation.
keywords: {Gears;Prototypes;Springs;Design optimization;Vehicle dynamics;DC motors;System integration},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989639&isnumber=7988677

P. Kim, B. Coltin, O. Alexandrov and H. J. Kim, "Robust visual localization in changing lighting conditions," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5447-5452.
doi: 10.1109/ICRA.2017.7989640
Abstract: We present an illumination-robust visual localization algorithm for Astrobee, a free-flying robot designed to autonomously navigate on the International Space Station (ISS). Astrobee localizes with a monocular camera and a pre-built sparse map composed of natural visual features. Astrobee must perform tasks not only during the day, but also at night when the ISS lights are dimmed. However, the localization performance degrades when the observed lighting conditions differ from the conditions when the sparse map was built. We investigate and quantify the effect of lighting variations on visual feature-based localization systems, and discover that maps built in darker conditions can also be effective in bright conditions, but the reverse is not true. We extend Astrobee's localization algorithm to make it more robust to changing-light environments on the ISS by automatically recognizing the current illumination level, and selecting an appropriate map and camera exposure time. We extensively evaluate the proposed algorithm through experiments on Astrobee.
keywords: {Lighting;Visualization;Cameras;Brightness;Feature extraction;Robots;Vocabulary},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989640&isnumber=7988677

O. -O. Christidi-Loumpasefski, K. Nanos and E. Papadopoulos, "On parameter estimation of space manipulator systems using the angular momentum conservation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5453-5458.
doi: 10.1109/ICRA.2017.7989641
Abstract: To accomplish tasks with high accuracy, advanced control strategies that benefit from the knowledge of system parameters are required. However, during operation some of them may change, or be unknown. In this paper, a novel parameter estimation method is proposed, which is based on the conservation of the angular momentum of a space manipulator system in the free-floating mode. The estimated parameters are combinations of spacecraft, manipulator and payload parameters and render the system full dynamics identified and applicable to model-based control. The algorithm requires only measurements of joint angles and rates, and spacecraft attitude and angular velocity. No information about spacecraft and joint accelerations or joint torques, which include substantial noise, is required. Thus, in contrast to other methods using the equations of motion, the proposed method is insensitive to sensor noise. Moreover, it does not require the prior knowledge of any system parameters and can be applied to free-floating systems with more than one manipulators. The application of the proposed method is illustrated by a 3D example.
keywords: {Space vehicles;Manipulator dynamics;Dynamics;Mathematical model;Estimation;Accelerometers},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989641&isnumber=7988677

J. T. Karras et al., "Pop-up mars rover with textile-enhanced rigid-flex PCB body," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5459-5466.
doi: 10.1109/ICRA.2017.7989642
Abstract: This paper presents a novel manufacturing paradigm for constructing origami-inspired pop-up robots for future space exploration missions. The new approach uses a textile-enhanced rigid-flex printed circuit board (PCB) to implement a folding robot chassis using robust, spaceflight-tolerant materials, and integrates the robot electronics directly into the chassis for added compactness. The new approach also decouples the mechanical and electrical functions of the chassis flexures for improved kinematics and lifetime. This manufacturing paradigm was used to build PUFFER (Pop-Up Flat Folding Explorer Robot), a self-actuated pop-up rover being developed to provide a low-payload-cost mobility enhancement for future NASA missions.
keywords: {Robots;Prototypes;Copper;Robustness;Wheels;Couplings;Polyimides},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989642&isnumber=7988677

A. Parness, N. Abcouwer, C. Fuller, N. Wiltsie, J. Nash and B. Kennedy, "LEMUR 3: A limbed climbing robot for extreme terrain mobility in space," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5467-5473.
doi: 10.1109/ICRA.2017.7989643
Abstract: This paper introduces a new four-limbed robot, LEMUR 3, that has demonstrated climbing on cliff faces and smooth glass. Each limb on the robot consists of seven identical actuators in a serial chain. Each limb terminates in a single axis force sensor that allows various end effectors to be mounted and connected to the robot's power and communication system. Microspine grippers were used for climbing the rocky surface and gecko adhesive grippers were used for the glass solar panels. All other hardware and much of the software was common for the two demonstrations. The robot's mechanical, electrical, and software systems, various gripping devices, and field demonstrations are described. Limbed mobility is of interest to JPL and NASA because of its potential to access extreme terrain, including that on Mars and in microgravity environments.
keywords: {Grippers;Actuators;Shafts;Mobile robots;Torque;Gears},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989643&isnumber=7988677

B. Jenett and D. Cellucci, "A mobile robot for locomotion through a 3D periodic lattice environment," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5474-5479.
doi: 10.1109/ICRA.2017.7989644
Abstract: This paper describes a novel class of robots specifically adapted to climb periodic lattices, which we call “Relative Robots”. These robots use the regularity of the structure to simplify the path planning, align with minimal feedback, and reduce the number of degrees of freedom (DOF) required to locomote. They can perform vital inspection and repair tasks within the structure that larger truss construction robots could not perform without modifying the structure. We detail a specific type of relative robot designed to traverse a cuboctahedral (CubOct) cellular solids lattice, show how the symmetries of the lattice simplify the design, and test these design methodologies with a CubOct relative robot that traverses a 76.2 mm (3 in.) pitch lattice, MOJO (Multi-Objective JOurneying robot). We perform three locomotion tasks with MOJO: vertical climbing, horizontal climbing, and turning, and find that, due to changes in the orientation of the robot relative to the gravity vector, the success rate of vertical and horizontal climbing is significantly different.
keywords: {Lattices;Hip;Manipulators;Solids;Mobile robots;Geometry},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989644&isnumber=7988677

D. Hirano, H. Kato and N. Tanishima, "Caging-based grasp with flexible manipulation for robust capture of a free-floating target," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5480-5486.
doi: 10.1109/ICRA.2017.7989645
Abstract: This paper discusses robust capture of a free-floating target using a robotic arm. The position error resulting from sensor errors and time delay can cause undesired contact and unstable control. In this paper, we propose a caging-based rigid gripper and impedance control, which enables the robot to capture the target robustly without precise motion tracking and large force interaction. The performance of the proposed method is verified experimentally using an air-floating system that emulates planar microgravity motion.
keywords: {Grippers;Manipulators;Grasping;Force;Impedance;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989645&isnumber=7988677

C. Cunningham, M. Ono, I. Nesnas, J. Yen and W. L. Whittaker, "Locally-adaptive slip prediction for planetary rovers using Gaussian processes," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5487-5494.
doi: 10.1109/ICRA.2017.7989646
Abstract: This paper presents a method for predicting slip using Gaussian process regression. Slip models are learned for visually classified terrain types as a function of terrain geometry. Spatial correlations between terrain properties are leveraged for on-line slip model adaptation. Results show that regression-based modeling using in-situ rover data outperforms the state-of-practice, terrestrially-calibrated slip curves in both mean prediction and uncertainty bounds. Local adaptation improves slip prediction results, particularly in high-slip sand areas that pose the greatest threat to rovers. Slip estimates made using a visual classifier to identify terrain type are compared to estimates using on-line model selection with only proprioceptive slip measurements as inputs. The proprioceptive results nearly match the visual results, showing that this approach could work even when a visual classifier is not available.
keywords: {Visualization;Predictive models;Gaussian processes;Adaptation models;Computational modeling;Geometry;Data models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989646&isnumber=7988677

D. K. Shukla and K. Skonieczny, "Simple texture descriptors for classifying monochrome planetary rover terrains," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5495-5502.
doi: 10.1109/ICRA.2017.7989647
Abstract: Planetary rovers face mobility hazards associated with various classes of terrains they traverse: sand, bedrock, and rock-strewn terrain. This work develops visual classifiers for these 3 terrain types for single monochrome navigation images from the NASA Mars Exploration Rover missions. The classifiers are based primarily on visual texture, captured in histograms of edges filter responses at various scales and orientations. Monochrome image intensity is further used to distinguish between confusing rock and bedrock cases. Three approaches are investigated: a gradient-based simplified HOG descriptor, a simplified GIST descriptor, and MR8 textons. Local rotational invariance is implemented in each approach, as validation tests demonstrate its benefit to performance. K-Nearest Neighbors is used for the final classification. No major differences in performance are observed between the three approaches, leading to the adoption of the HOG approach due to its lower computational complexity and thus highest applicability to planetary missions. Final tests demonstrate an accuracy between 70% and 93% (81% average) for the 3-way classification using the simplified HOG descriptor.
keywords: {Gabor filters;Histograms;Training;Image edge detection;Filter banks;Visualization;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989647&isnumber=7988677

J. D. Greer, T. K. Morimoto, A. M. Okamura and E. W. Hawkes, "Series pneumatic artificial muscles (sPAMs) and application to a soft continuum robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5503-5510.
doi: 10.1109/ICRA.2017.7989648
Abstract: We describe a new series pneumatic artificial muscle (sPAM) and its application as an actuator for a soft continuum robot. The robot consists of three sPAMs arranged radially around a tubular pneumatic backbone. Analogous to tendons, the sPAMs exert a tension force on the robot's pneumatic backbone, causing bending that is approximately constant curvature. Unlike a traditional tendon driven continuum robot, the robot is entirely soft and contains no hard components, making it safer for human interaction. Models of both the sPAM and soft continuum robot kinematics are presented and experimentally verified. We found a mean position accuracy of 5.5 cm for predicting the end-effector position of a 42 cm long robot with the kinematic model. Finally, closed-loop control is demonstrated using an eye-in-hand visual servo control law which provides a simple interface for operation by a human. The soft continuum robot with closed-loop control was found to have a step-response rise time and settling time of less than two seconds.
keywords: {Robots;Pneumatic systems;Actuators;Visualization;Polyethylene;Structural rings;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989648&isnumber=7988677

M. C. Yuen, H. Tonoyan, E. L. White, M. Telleria and R. K. Kramer, "Fabric sensory sleeves for soft robot state estimation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5511-5518.
doi: 10.1109/ICRA.2017.7989649
Abstract: In this paper, we describe the fabrication and testing of a stretchable fabric sleeve with embedded elastic strain sensors for state reconstruction of a soft robotic joint. The strain sensors are capacitive and composed of graphite-based conductive composite electrodes and a silicone elastomer dielectric. The sensors are screenprinted directly into the fabric sleeve, which contrasts the approach of pre-fabricating sensors and subsequently attaching them to a host. We demonstrate the capabilities of the sensor-embedded fabric sleeve by determining the joint angle and end effector position of a soft pneumatic joint with similar accuracy to a traditional IMU. Furthermore, we show that the sensory sleeve is capable of capturing more complex material states, such as fabric buckling and non-constant curvatures along linkages and joints.
keywords: {Robot sensing systems;Fabrics;Electrodes;Capacitive sensors;Couplings;soft material robotics;hydraulic/pneumatic actuators;flexible robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989649&isnumber=7988677

H. Choi, P. Jung, K. Jung and K. Kong, "Design and fabrication of a soft three-axis force sensor based on radially symmetric pneumatic chambers," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5519-5524.
doi: 10.1109/ICRA.2017.7989650
Abstract: In applications of human-robot interactions, accurate measurement of interactive forces between the human and the robot plays a significant role. Such sensors should not only be accurate and reliable, but also be soft enough to guarantee the safe and compliant human-robot interaction. In this aspect, pneumatic sensors with soft air chambers have often been utilized as a soft force measurement system. Although such a sensor system provides a good compliance and softness, however, it measures only a lumped force acting on the chamber, because the measurement of the pneumatic sensor is the pressure change in the air chamber. For the measurement of multi-dimensional interaction forces with high softness and compliance, a three-axis force measurement system is devised by arranging three air chambers in a radially symmetric pattern. Each air chamber embeds a pneumatic sensor, and the pressure changes in the three air chambers are measured in order to distinguish the direction of the applied force. By decoupling the sensor signals from the three pneumatic sensors, the three-dimensional force components can be calculated accurately. Consequently, the proposed sensor system is able to measure the three-axis forces while maintaining the great softness and compliance provided by the soft air chambers. The design, the fabrication method, and the verification of the proposed method are introduced in this paper.
keywords: {Force measurement;Force;Sensor systems;Pressure measurement;Rubber;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989650&isnumber=7988677

N. Farrow, L. McIntire and N. Correll, "Functionalized textiles for interactive soft robotics," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5525-5531.
doi: 10.1109/ICRA.2017.7989651
Abstract: We use a conductive fabric substrate as a building material for a soft sensor to extend the functionality of soft actuators. We use PCB etching techniques to apply a pattern to the fabric, yielding distinct conductive surfaces within the same textile. We connect these via flexible wire bus embedded in silicone, terminating in a flexible PCB. We show how touch and metal objects can be localized along the length of the composite fabric strip. We demonstrate an example soft robotic application, by replacing the constraint layer component in a PneuFlex-style soft actuator with the self contained sensing strip. We show that the augmented composite actuator is able to interact with conductive objects in the environment using a capacitive touch sensing with applications in grasping and human-robot interaction.
keywords: {Fabrics;Robot sensing systems;Wires;Strips;Actuators;Capacitance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989651&isnumber=7988677

D. Drotman, S. Jadhav, M. Karimi, P. de Zonia and M. T. Tolley, "3D printed soft actuators for a legged robot capable of navigating unstructured terrain," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5532-5538.
doi: 10.1109/ICRA.2017.7989652
Abstract: Soft robots have recently demonstrated impressive abilities to adapt to objects and their environment with limited sensing and actuation. However, mobile soft robots are typically fabricated using laborious molding processes that result in limited actuated degrees of freedom and hence limited locomotion capabilities. In this paper, we present a 3D printed robot with bellowed soft legs capable of rotation about two axes. This allows our robot to navigate rough terrain that previously posed a significant challenge to soft robots. We present models and FEM simulations for the soft leg modules and predict the robot locomotion capabilities. We use finite element analysis to simulate the actuation characteristics of these modules. We then compared the analytical and computational results to experimental results with a tethered prototype. The experimental soft robot is capable of lifting its legs 5.3 cm off the ground and is able to walk at speeds up to 20 mm/s (0.13 bl/s). This work represents a practical approach to the design and fabrication of functional mobile soft robots.
keywords: {Actuators;Legged locomotion;Bellows;Geometry;Force;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989652&isnumber=7988677

D. Bruder, A. Sedal, J. Bishop-Moser, S. Kota and R. Vasudevan, "Model based control of fiber reinforced elastofluidic enclosures," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5539-5544.
doi: 10.1109/ICRA.2017.7989653
Abstract: Fiber-Reinforced Elastofluidic Enclosures (FREEs), are a subset of pneumatic soft robots with an asymmetric continuously deformable skin that are able to generate a wide range of deformations and forces, including rotation and screw motions. Though these soft robots are able to generate a variety of motions, simultaneously controlling their end effector rotation and position has remained challenging due to the lack of a simple model. This paper presents a model that establishes a relationship between the pressure, torque due to axial loading, and axial rotation to enable a model-driven open-loop control for FREEs. The modeling technique relies on describing force equilibrium between the fiber, fluid, and an elastomer model which is computed via system identification. The model is experimentally tested as these variables are changed, illustrating that it provides good agreement with the real system. To further illustrate the potential of the model, a precision open-loop control experiment of opening a rotational combination lock is presented2.
keywords: {Force;Computational modeling;Load modeling;Mathematical model;Robots;Loading;Optical fiber devices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989653&isnumber=7988677

L. O. Tiziani, T. W. Cahoon and F. L. Hammond, "Sensorized pneumatic muscle for force and stiffness control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5545-5552.
doi: 10.1109/ICRA.2017.7989654
Abstract: This paper presents the design and experimental validation of a soft pneumatic artificial muscle with position and force sensing capabilities. Conductive liquid-based soft sensors are embedded in a fiber-reinforced contractile actuator to measure two modes of deformation - axial strain and diametral expansion - which, together, are used to determine the stroke length and contractile force generated under internal pressure. We validate the proposed device by using data from the embedded sensors to estimate the force output of the actuator at fixed lengths and the stiffness and force output of a one degree-of-freedom hinge joint driven by an antagonist pair of the sensorized pneumatic muscles.
keywords: {Muscles;Finite element analysis;Optical fiber sensors;Bladder;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989654&isnumber=7988677

M. Bjelonic, T. Homberger, N. Kottege, P. Borges, M. Chli and P. Beckerle, "Autonomous navigation of hexapod robots with vision-based controller adaptation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5561-5568.
doi: 10.1109/ICRA.2017.7989655
Abstract: This work introduces a novel hybrid control architecture for a hexapod platform (Weaver), making it capable of autonomously navigating in uneven terrain. The main contribution stems from the use of vision-based exteroceptive terrain perception to adapt the robot's locomotion parameters. Avoiding computationally expensive path planning for the individual foot tips, the adaptation controller enables the robot to reactively adapt to the surface structure it is moving on. The virtual stiffness, which mainly characterizes the behavior of the legs' impedance controller is adapted according to visually perceived terrain properties. To further improve locomotion, the frequency and height of the robot's stride are similarly adapted. Furthermore, novel methods for terrain characterization and a keyframe based visual-inertial odometry algorithm are combined to generate a spatial map of terrain characteristics. Localization via odometry also allows for autonomous missions on variable terrain by incorporating global navigation and terrain adaptation into one control architecture. Autonomous runs on a testbed with variable terrain types illustrate that adaptive stride and impedance behavior decreases the cost of transport by 30 % compared to a non-adaptive approach and simultaneously increases body stability (up to 88 % on even terrain and by 54 % on uneven terrain). Weaver is able to freely explore outdoor environments as it is completely free of external tethers, as shown in the experiments.
keywords: {Legged locomotion;Weaving;Foot;Trajectory;Impedance;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989655&isnumber=7988677

S. Hayat, E. Yanmaz, T. X. Brown and C. Bettstetter, "Multi-objective UAV path planning for search and rescue," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5569-5574.
doi: 10.1109/ICRA.2017.7989656
Abstract: We propose a multi-objective optimization algorithm to allocate tasks and plan paths for a team of UAVs. The UAVs must find a target in a bounded area and then continuously communicate the target information to the ground personnel. Our genetic algorithm approach aims to minimize the mission completion time, which includes the time to find the target (area coverage) and the time to setup a communication path (network connectivity). We evaluate strategies using a data mule, a relay chain, and a novel hybrid approach to communicate with the ground personnel. The algorithm can be tuned to prioritize coverage or connectivity, depending on the mission demands. Simulation results show reduced overall mission completion times (up to 65%), with more improvement as the UAV density increases.
keywords: {Relays;Time factors;Unmanned aerial vehicles;Monitoring;Algorithm design and analysis;Path planning;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989656&isnumber=7988677

B. Araki, J. Strang, S. Pohorecky, C. Qiu, T. Naegeli and D. Rus, "Multi-robot path planning for a swarm of robots that can both fly and drive," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5575-5582.
doi: 10.1109/ICRA.2017.7989657
Abstract: The multi-robot path planning problem has been extensively studied for the cases of flying and driving vehicles. However, path planning for the case of vehicles that can both fly and drive has not yet been considered. Driving robots, while stable and energy efficient, are limited to mostly flat terrain. Quadcopters, on the other hand, are agile and highly mobile but have low energy efficiency and limited battery life. Combining a quadcopter with a driving mechanism presents a path planning challenge by enabling the selection of paths based off of both time and energy consumption. In this paper, we introduce a framework for multi-robot path planning for a swarm of flying-and-driving vehicles. By putting a lightweight driving platform on a quadcopter, we create a robust vehicle with an energy efficient driving mode and an agile flight mode. We extend two algorithms, priority planning with Safe Interval Path Planning and a multi-commodity network flow ILP, to accommodate multimodal locomotion, and we show that these algorithms can indeed plan collision-free paths for flying-and-driving vehicles on 3D graphs. Finally, we demonstrate that our system is able to plan paths and control the motions of 8 of our vehicles in a miniature town.
keywords: {Robot kinematics;Path planning;Collision avoidance;Planning;Batteries;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989657&isnumber=7988677

M. Rafieisakhaei, S. Chakravorty and P. R. Kumar, "MT-LQG: Multi-agent planning in belief space via trajectory-optimized LQG," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5583-5590.
doi: 10.1109/ICRA.2017.7989658
Abstract: Belief space planning is concerned with the problem of finding the control policy under process and measurement uncertainties. Formulated as a stochastic control problem, the solution of a general Decentralized Partially Observed Markov Decision Process (Dec-POMDP) is a collection of feedback policies for individual agents, maximizing a joint value function. In this paper, we design (m) number of Linear Quadratic Gaussian (LQG) policies for (m) number of agents maximizing the joint performance of the team. Casting the problem as a NonLinear Program (NLP), we propose a framework that reduces the optimization dimension from ((mn)2 + mn) to (mn) with (n) referring to the dimension of each individual agent's state space. As a result, the proposed method reduces the formidable generic Dec-POMDP to a computationally tractable multi-agent planning under uncertainty. Our results in 2D and 3D environments demonstrate the performance of the algorithm and its ability to predict and avoid inter-agent collisions.
keywords: {Trajectory;Aerospace electronics;Uncertainty;Planning;Search problems;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989658&isnumber=7988677

E. Huang, M. Mukadam, Z. Liu and B. Boots, "Motion planning with graph-based trajectories and Gaussian process inference," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5591-5598.
doi: 10.1109/ICRA.2017.7989659
Abstract: Motion planning as trajectory optimization requires generating trajectories that minimize a desired objective function or performance metric. Finding a globally optimal solution is often intractable in practice: despite the existence of fast motion planning algorithms, most are prone to local minima, which may require re-solving the problem multiple times with different initializations. In this work we provide a novel motion planning algorithm, GPMP-GRAPH, that considers a graph-based initialization that simultaneously explores multiple homotopy classes, helping to contend with the local minima problem. Drawing on previous work to represent continuous-time trajectories as samples from a Gaussian process (GP) and formulating the motion planning problem as inference on a factor graph, we construct a graph of interconnected states such that each path through the graph is a valid trajectory and efficient inference can be performed on the collective factor graph. We perform a variety of benchmarks and show that our approach allows the evaluation of an exponential number of trajectories within a fraction of the computational time required to evaluate them one at a time, yielding a more thorough exploration of the solution space and a higher success rate.
keywords: {Planning;Inference algorithms;Gaussian processes;Sparse matrices;Trajectory optimization;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989659&isnumber=7988677

R. Liu, C. Yuen, T. Do, D. Jiao, X. Liu and U. Tan, "Cooperative relative positioning of mobile users by fusing IMU inertial and UWB ranging information," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5623-5629.
doi: 10.1109/ICRA.2017.7989660
Abstract: Relative positioning between multiple mobile users is essential for many applications, such as search and rescue in disaster areas or human social interaction. Inertial-measurement unit (IMU) is promising to determine the change of position over short periods of time, but it is very sensitive to error accumulation over long term run. By equipping the mobile users with ranging unit, e.g. ultra-wideband (UWB), it is possible to achieve accurate relative positioning by trilateration-based approaches. As compared to vision or laser-based sensors, the UWB does not need to be with in line-of-sight and provides accurate distance estimation. However, UWB does not provide any bearing information and the communication range is limited, thus UWB alone cannot determine the user location without any ambiguity. In this paper, we propose an approach to combine IMU inertial and UWB ranging measurement for relative positioning between multiple mobile users without the knowledge of the infrastructure. We incorporate the UWB and the IMU measurement into a probabilistic-based framework, which allows to cooperatively position a group of mobile users and recover from positioning failures. We have conducted extensive experiments to demonstrate the benefits of incorporating IMU inertial and UWB ranging measurements.
keywords: {Distance measurement;Sensors;Position measurement;Mobile communication;Atmospheric measurements;Particle measurements;Motion measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989660&isnumber=7988677

L. Payá, W. Mayol, S. Cebollada and O. Reinoso, "Compression of topological models and localization using the global appearance of visual information," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5630-5637.
doi: 10.1109/ICRA.2017.7989661
Abstract: In this work, a clustering approach to obtain compact topological models of an environment is developed and evaluated. The usefulness of these models is tested by studying their utility to solve the robot localization problem subsequently. Omnidirectional visual information and global appearance descriptors are used both to create and compress the models and to estimate the position of the robot. Comparing to the methods based on the extraction and description of landmarks, global appearance approaches permit building models that can be handled and interpreted more intuitively and using relatively straightforward algorithms to estimate the position of the robot. The proposed algorithms are tested with a set of panoramic images captured with a catadioptric vision sensor in a large environment under real working conditions. The results show that it is possible to compress substantially the visual information contained in topological models to arrive to a balance between the computational cost and the accuracy of the localization process.
keywords: {Visualization;Clustering algorithms;Computational modeling;Robots;Image coding;Histograms;Sparse matrices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989661&isnumber=7988677

L. Meier, D. Honegger, V. Vilhjalmsson and M. Pollefeys, "Real-time stereo matching failure prediction and resolution using orthogonal stereo setups," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5638-5643.
doi: 10.1109/ICRA.2017.7989662
Abstract: Estimating the depth from two images with a baseline has a well-known regular problem: When a line is parallel to the epipolar geometry it is not possible to estimate the depth from pixels on this line. Moreover, the classic measure for the certainty of the depth estimate fails as well: The matching score between the template and any pixel on the epipolar line is perfect. This results for common scenes in incorrect matches with very high confidence, some even resistant to left-right image checks. It is straightforward to try to address this by adding a second stereo head in a perpendicular direction. However, it is nontrivial to identify the failure and fuse the two depth maps in a real-time system. A simple weighted average will alleviate the problem but still result in a very large error in the depth map. Our contributions are: 1) We derive a model to predict the failure of stereo by leveraging the matching scores and 2) we propose a combined cost function to fuse two depth maps from orthogonal stereo heads using the failure prediction, matching score and consistency. We show the resulting system in real-time operation on a low-latency system in indoor, urban and natural environments.
keywords: {Field programmable gate arrays;Cameras;Real-time systems;Geometry;Correlation;Head;Reliability},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989662&isnumber=7988677

J. Wu, L. Ma and X. Hu, "Delving deeper into convolutional neural networks for camera relocalization," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5644-5651.
doi: 10.1109/ICRA.2017.7989663
Abstract: Convolutional Neural Networks (CNNs) have been applied to camera relocalization, which is to infer the pose of the camera given a single monocular image. However, there are still many open problems for camera relocalization with CNNs. We delve into the CNNs for camera relocalization. First, a variant of Euler angles named Euler6 is proposed to represent orientation. Then a data augmentation method named pose synthesis is designed to reduce spsarsity of poses in the whole pose space to cope with overfitting in training. Third, a multi-task CNN named BranchNet is proposed to deal with the complex coupling of orientation and translation. The network consists of several shared convolutional layers and splits into two branches which predict orientation and translation, respectively. Experiments on the 7Scenes dataset show that incorporating these techniques one by one into an existing model PoseNet always leads to better results. Together these techniques reduce the orientation error by 15.9% and the translation error by 38.3% compared to the state-of-the-art model Bayesian PoseNet. We implement BranchNet on an Intel NUC mobile platform and reach a speed of 43 fps, which meets the real-time requirement of many robotic applications.
keywords: {Cameras;Training;Quaternions;Robot vision systems;Bayes methods;Feature extraction;Neural networks},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989663&isnumber=7988677

C. Raposo and J. P. Barreto, "Using 2 point+normal sets for fast registration of point clouds with small overlap," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5652-5658.
doi: 10.1109/ICRA.2017.7989664
Abstract: Global 3D point cloud registration has been solved by finding putative matches between the point clouds for establishing alignment hypotheses. A naive approach would try to perform exhaustive search of triplets with a cubic runtime complexity in the number of data points. Super4PCS reduces this complexity to linear by making use of sets of 4 coplanar points. This paper proposes 2-Point-Normal Sets (2PNS), a new global 3D registration approach that advances Super4PCS by using 2 points and their normals for generating alignment hypotheses. The dramatic improvement in the complexity of 2PNS when compared to Super4PCS is demonstrated by the experiments that show speed-ups of two orders of magnitude in noise-free datasets and up to 5.2× in Kinect scans, while improving robustness and alignment accuracy, even in datasets with overlaps as low as 5%.
keywords: {Three-dimensional displays;Complexity theory;Robustness;Iterative closest point algorithm;Runtime;Estimation;Object detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989664&isnumber=7988677

S. Dogru and L. Marques, "Shape reconstruction using a mobile robot for demining and UXO classification," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5659-5665.
doi: 10.1109/ICRA.2017.7989665
Abstract: Metal detectors are widely used to detect and localize land mines, as well as metallic clutter that causes many false alarms. These false alarms are handled by manual inspection with a prodder or using extra features like size and depth as well as fusion with other sensors like ground penetrating radar or chemical sensors. Directly shape itself has never been used, mainly due to infeasibility of the results of the few existing studies, which require controlled environments and dense sampling of the target objects. In this paper, we propose a new method for shape reconstruction that works with sparse data, and show its feasibility using field data collected by a mobile robot equipped with a commercial pulse induction metal detector carried by a custom 2DoF arm. This paper also describes the method employed to sweep natural terrains with the mobile manipulator and provides results of imaging a set of different metallic objects.
keywords: {Metals;Detectors;Shape;Manipulators;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989665&isnumber=7988677

A. K. Ushani, R. W. Wolcott, J. M. Walls and R. M. Eustice, "A learning approach for real-time temporal scene flow estimation from LIDAR data," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5666-5673.
doi: 10.1109/ICRA.2017.7989666
Abstract: Many autonomous systems require the ability to perceive and understand motion in a dynamic environment. We present a novel algorithm that estimates this motion from raw LIDAR data in real-time without the need for segmentation or model-based tracking. The sensor data is first used to construct an occupancy grid. The foreground is then extracted via a learned background filter. Using the filtered occupancy grid, raw scene flow between successive scans is computed. Finally, we incorporate these measurements in a filtering framework to estimate temporal scene flow. We evaluate our method on the KITTI dataset.
keywords: {Laser radar;Robot sensing systems;Three-dimensional displays;Real-time systems;Dynamics;Vehicle dynamics;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989666&isnumber=7988677

H. Mao, Z. Teng and J. Xiao, "Progressive object modeling with a continuum manipulator in unknown environments," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5674-5681.
doi: 10.1109/ICRA.2017.7989667
Abstract: It is important to enable a robot to manipulate a target object that has no 3-D model information and is situated in an environment with other unknown objects nearby. This poses an open problem of how to combine perception and manipulation to enable the robot to build an appearance-based model of the target object on the spot to facilitate further manipulation of the object while avoiding the other unknown obstacles in the way. In this paper, we introduce an approach to enable a continuum manipulator, which is apt to maneuver through a crowded environment, to gradually build a 3-D surface model of the target object by moving an RGB-D sensor around the object while also detecting and avoiding surrounding unknown obstacles. Our approach interleaves perception and manipulation such that perception guides the manipulator movement, which in turn allows more perception of the target object for object model building and further manipulator motion. Our approach is characterized by a progressive strategy to register RGB-D images of the target object to build and extend a partial model of the object and the corresponding motion planning strategy for the continuum robot to carry out model building and avoid obstacles at the same time. To demonstrate the effectiveness of our approach, experiments on progressive model building of real objects from real RGB-D images are conducted, where a simulated continuum robot plans and executes its motion to carry the RGB-D camera around a target object for taking those images in an augmented reality setting.
keywords: {Manipulators;Collision avoidance;Cameras;Robot vision systems;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989667&isnumber=7988677

L. Chen, L. Sun, T. Yang, L. Fan, K. Huang and Z. Xuanyuan, "RGB-T SLAM: A flexible SLAM framework by combining appearance and thermal information," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5682-5687.
doi: 10.1109/ICRA.2017.7989668
Abstract: Visual SLAM in low illumination scenes remains a considerably challenging task since the available amount of appearance information frequently stays insufficient. To tackle with this problem, we propose a novel SLAM framework by using both appearance information and thermal information, which possesses illumination-free recognizable contents, in a flexible manner. The key idea is to continuously update a RGB-T map, which contains both RGB and thermal map points to implement location and mapping. More specifically, in our SLAM system, we detect features in both RGB and thermal images and combine them together to update the RGB-T map and implement simultaneous location and mapping. Both quantitative and qualitative results demonstrate the effectiveness of our framework, especially under low illumination environments.
keywords: {Simultaneous localization and mapping;Cameras;Lighting;Feature extraction;Robot vision systems;Three-dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989668&isnumber=7988677

A. Khosravian, T. Chin, I. Reid and R. Mahony, "A discrete-time attitude observer on SO(3) for vision and GPS fusion," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5688-5695.
doi: 10.1109/ICRA.2017.7989669
Abstract: This paper proposes a discrete-time geometric attitude observer for fusing monocular vision with GPS velocity measurements. The observer takes the relative transformations obtained from processing monocular images with any visual odometry algorithm and fuses them with GPS velocity measurements. The objectives of this sensor fusion are twofold; first to mitigate the inherent drift of the attitude estimates of the visual odometry, and second, to estimate the orientation directly with respect to the North-East-Down frame. A key contribution of the paper is to present a rigorous stability analysis showing that the attitude estimates of the observer converge exponentially to the true attitude and to provide a lower bound for the convergence rate of the observer. Through experimental studies, we demonstrate that the observer effectively compensates for the inherent drift of the pure monocular vision based attitude estimation and is able to recover the North-East-Down orientation even if it is initialized with a very large attitude error.
keywords: {Cameras;Global Positioning System;Observers;Visualization;Velocity measurement;Stability analysis;Position measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989669&isnumber=7988677

J. Hidalgo-Carrió, D. Hennes, J. Schwendner and F. Kirchner, "Gaussian process estimation of odometry errors for localization and mapping," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5696-5701.
doi: 10.1109/ICRA.2017.7989670
Abstract: Since early in robotics the performance of odometry techniques has been of constant research for mobile robots. This is due to its direct influence on localization. The pose error grows unbounded in dead-reckoning systems and its uncertainty has negative impacts in localization and mapping (i.e. SLAM). The dead-reckoning performance in terms of residuals, i.e. the difference between the expected and the real pose state, is related to the statistical error or uncertainty in probabilistic motion models. A novel approach to model odometry errors using Gaussian processes (GPs) is presented. The methodology trains a GP on the residual between the non-linear parametric motion model and the ground truth training data. The result is a GP over odometry residuals which provides an expected value and its uncertainty in order to enhance the belief with respect to the parametric model. The localization and mapping benefits from a comprehensive GP-odometry residuals model. The approach is applied to a planetary rover in an unstructured environment. We show that our approach enhances visual SLAM by efficiently computing image frames and effectively distributing keyframes.
keywords: {Gaussian processes;Mobile robots;Mathematical model;Wheels;Simultaneous localization and mapping},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989670&isnumber=7988677

S. M. Siam and H. Zhang, "Fast-SeqSLAM: A fast appearance based place recognition algorithm," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5702-5708.
doi: 10.1109/ICRA.2017.7989671
Abstract: Loop closure detection or place recognition is a fundamental problem in robot simultaneous localization and mapping (SLAM). SeqSLAM is considered to be one of the most successful algorithms for loop closure detection as it has been demonstrated to be able to handle significant environmental condition changes including those due to illumination, weather, and time of the day. However, SeqSLAM relies heavily on exhaustive sequence matching, a computationally expensive process that prevents the algorithm from being used in dealing with large maps. In this paper, we propose Fast-SeqSLAM, an efficient version of SeqSLAM. Fast-SeqSLAM has a much reduced time complexity without degrading the accuracy, and this is achieved by using an approximate nearest neighbor (ANN) algorithm to match the current image with those in the robot map and extending the idea of SeqSLAM to greedily search a sequence of images that best match with the current sequence. We demonstrate the effectiveness of our Fast-SeqSLAM algorithm in appearance based loop closure detection.
keywords: {Sparse matrices;Approximation algorithms;Simultaneous localization and mapping;Time complexity;Image recognition;Image matching},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989671&isnumber=7988677

N. Weidner, S. Rahman, A. Q. Li and I. Rekleitis, "Underwater cave mapping using stereo vision," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5709-5715.
doi: 10.1109/ICRA.2017.7989672
Abstract: This paper presents a systematic approach for the 3-D mapping of underwater caves. Exploration of underwater caves is very important for furthering our understanding of hydrogeology, managing efficiently water resources, and advancing our knowledge in marine archaeology. Underwater cave exploration by human divers however, is a tedious, labor intensive, extremely dangerous operation, and requires highly skilled people. As such, it is an excellent fit for robotic technology, which has never before been addressed. In addition to the underwater vision constraints, cave mapping presents extra challenges in the form of lack of natural illumination and harsh contrasts, resulting in failure for most of the state-of-the-art visual based state estimation packages. A new approach employing a stereo camera and a video-light is presented. Our approach utilizes the intersection of the cone of the video-light with the cave boundaries: walls, floor, and ceiling, resulting in the construction of a wire frame outline of the cave. Successive frames are combined using a state of the art visual odometry algorithm while simultaneously inferring scale through the stereo reconstruction. Results from experiments at a cave, part of the Sistema Camilo, Quintana Roo, Mexico, validate our approach. The cave wall reconstruction presented provides an immersive experience in 3-D.
keywords: {Cameras;Lighting;Calibration;Visualization;Three-dimensional displays;Sonar navigation;Image edge detection},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989672&isnumber=7988677

S. Saeedi, L. Nardi, E. Johns, B. Bodin, P. H. J. Kelly and A. J. Davison, "Application-oriented design space exploration for SLAM algorithms," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5716-5723.
doi: 10.1109/ICRA.2017.7989673
Abstract: In visual SLAM, there are many software and hardware parameters, such as algorithmic thresholds and GPU frequency, that need to be tuned; however, this tuning should also take into account the structure and motion of the camera. In this paper, we determine the complexity of the structure and motion with a few parameters calculated using information theory. Depending on this complexity and the desired performance metrics, suitable parameters are explored and determined. Additionally, based on the proposed structure and motion parameters, several applications are presented, including a novel active SLAM approach which guides the camera in such a way that the SLAM algorithm achieves the desired performance metrics. Real-world and simulated experimental results demonstrate the effectiveness of the proposed design space and its applications.
keywords: {Simultaneous localization and mapping;Algorithm design and analysis;Measurement;Software algorithms;Space exploration;Hardware},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989673&isnumber=7988677

H. G. de Marina, Y. A. Kapitanyuk, M. Bronz, G. Hattenberger and M. Cao, "Guidance algorithm for smooth trajectory tracking of a fixed wing UAV flying in wind flows," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5740-5745.
doi: 10.1109/ICRA.2017.7989674
Abstract: This paper presents an algorithm for solving the problem of tracking smooth curves by a fixed wing unmanned aerial vehicle travelling with a constant airspeed and under a constant wind disturbance. The algorithm is based on the idea of following a guiding vector field which is constructed from the implicit function that describes the desired (possibly time-varying) trajectory. The output of the algorithm can be directly expressed in terms of the bank angle of the UAV in order to achieve coordinated turns. Furthermore, the algorithm can be tuned offline such that physical constraints of the UAV, e.g. the maximum bank angle, will not be violated in a neighborhood of the desired trajectory. We provide the corresponding theoretical convergence analysis and performance results from actual flights.
keywords: {Trajectory;Unmanned aerial vehicles;Atmospheric modeling;Algorithm design and analysis;Euclidean distance;Level set;Two dimensional displays},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989674&isnumber=7988677

A. Gawel et al., "Aerial picking and delivery of magnetic objects with MAVs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5746-5752.
doi: 10.1109/ICRA.2017.7989675
Abstract: Autonomous delivery of goods using a Micro Air Vehicle (MAV) is a difficult problem, as it poses high demand on the MAV's control, perception and manipulation capabilities. This problem is especially challenging if the exact shape, location and configuration of the objects are unknown. In this paper, we report our findings during the development and evaluation of a fully integrated system that is energy efficient and enables MAVs to pick up and deliver objects with partly ferrous surface of varying shapes and weights. This is achieved by using a novel combination of an electro-permanent magnetic gripper with a passively compliant structure and integration with detection, control and servo positioning algorithms. The system's ability to grasp stationary and moving objects was tested, as well as its ability to cope with different shapes of the object and external disturbances. We show that such a system can be successfully deployed in scenarios where an object with partly ferrous parts needs to be gripped and placed in a predetermined location.
keywords: {Grippers;Magnetic resonance imaging;Magnetosphere;Shape;Servomotors;Force;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989675&isnumber=7988677

M. Popović, G. Hitz, J. Nieto, I. Sa, R. Siegwart and E. Galceran, "Online informative path planning for active classification using UAVs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5753-5758.
doi: 10.1109/ICRA.2017.7989676
Abstract: In this paper, we introduce an informative path planning (IPP) framework for active classification using unmanned aerial vehicles (UAVs). Our algorithm uses a combination of global viewpoint selection and evolutionary optimization to refine the planned trajectory in continuous 3D space while satisfying dynamic constraints. Our approach is evaluated on the application of weed detection for precision agriculture. We model the presence of weeds on farmland using an occupancy grid and generate adaptive plans according to information-theoretic objectives, enabling the UAV to gather data efficiently. We validate our approach in simulation by comparing against existing methods, and study the effects of different planning strategies. Our results show that the proposed algorithm builds maps with over 50% lower entropy compared to traditional “lawnmower” coverage in the same amount of time. We demonstrate the planning scheme on a multirotor platform with different artificial farmland set-ups.
keywords: {Sensors;Optimization;Planning;Trajectory;Entropy;Three-dimensional displays;Heuristic algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989676&isnumber=7988677

B. T. Lopez and J. P. How, "Aggressive 3-D collision avoidance for high-speed navigation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5759-5765.
doi: 10.1109/ICRA.2017.7989677
Abstract: Autonomous robot navigation through unknown, cluttered environments at high-speeds is still an open problem. Quadrotor platforms with this capability have only begun to emerge with the advancements in light-weight, small form factor sensing and computing. Many of the existing platforms, however, require excessive computation time to perform collision avoidance, which ultimately limits the vehicle's top speed. This work presents an efficient perception and planning approach that significantly reduces the computation time by using instantaneous perception data for collision avoidance. Minimum-time, state and input constrained motion primitives are generated by sampling terminal states until a collision-free path is found. The worst case performance of the Triple Integrator Planner (TIP) is nearly an order of magnitude faster than the state-of-the-art. Experimental results demonstrate the algorithm's ability to plan and execute aggressive collision avoidance maneuvers in highly cluttered environments.
keywords: {Planning;Three-dimensional displays;Collision avoidance;Navigation;Robot sensing systems;Computational modeling;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989677&isnumber=7988677

A. Tagliabue, M. Kamel, S. Verling, R. Siegwart and J. Nieto, "Collaborative transportation using MAVs via passive force control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5766-5773.
doi: 10.1109/ICRA.2017.7989678
Abstract: This paper shows a strategy based on passive force control for collaborative object transportation using Micro Aerial Vehicles (MAVs), focusing on the transportation of a bulky object by two hexacopters. The goal is to develop a robust approach which does not rely on: (a) communication links between the MAVs, (b) the knowledge of the payload shape and (c) the position of grasping point. The proposed approach is based on the master-slave paradigm, in which the slave agent guarantees compliance to the external force applied by the master to the payload via an admittance controller. The external force acting on the slave is estimated using a non-linear estimator based on the Unscented Kalman Filter (UKF) from the information provided by a Visual-Inertial (VI) navigation system. Experimental results (online video [1]) demonstrate the performance of the force estimator and show the collaborative transportation of a 1.2 m long object.
keywords: {Force;Payloads;Torque;Transportation;Collaboration;Quaternions;Admittance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989678&isnumber=7988677

D. Falanga, E. Mueggler, M. Faessler and D. Scaramuzza, "Aggressive quadrotor flight through narrow gaps with onboard sensing and computing using active vision," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5774-5781.
doi: 10.1109/ICRA.2017.7989679
Abstract: We address one of the main challenges towards autonomous quadrotor flight in complex environments, which is flight through narrow gaps. While previous works relied on off-board localization systems or on accurate prior knowledge of the gap position and orientation in the world reference frame, we rely solely on onboard sensing and computing and estimate the full state by fusing gap detection from a single onboard camera with an IMU. This problem is challenging for two reasons: (i) the quadrotor pose uncertainty with respect to the gap increases quadratically with the distance from the gap; (ii) the quadrotor has to actively control its orientation towards the gap to enable state estimation (i.e., active vision). We solve this problem by generating a trajectory that considers geometric, dynamic, and perception constraints: during the approach maneuver, the quadrotor always faces the gap to allow state estimation, while respecting the vehicle dynamics; during the traverse through the gap, the distance of the quadrotor to the edges of the gap is maximized. Furthermore, we replan the trajectory during its execution to cope with the varying uncertainty of the state estimate. We successfully evaluate and demonstrate the proposed approach in many real experiments, achieving a success rate of 80% and gap orientations up to 45°. To the best of our knowledge, this is the first work that addresses and achieves autonomous, aggressive flight through narrow gaps using only onboard sensing and computing and without prior knowledge of the pose of the gap.
keywords: {Trajectory;State estimation;Cameras;Planning;Vehicle dynamics;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989679&isnumber=7988677

D. Held, Z. McCarthy, M. Zhang, F. Shentu and P. Abbeel, "Probabilistically safe policy transfer," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5798-5805.
doi: 10.1109/ICRA.2017.7989680
Abstract: Although learning-based methods have great potential for robotics, one concern is that a robot that updates its parameters might cause large amounts of damage before it learns the optimal policy. We formalize the idea of safe learning in a probabilistic sense by defining an optimization problem: we desire to maximize the expected return while keeping the expected damage below a given safety limit. We study this optimization for the case of a robot manipulator with safety-based torque limits. We would like to ensure that the damage constraint is maintained at every step of the optimization and not just at convergence. To achieve this aim, we introduce a novel method which predicts how modifying the torque limit, as well as how updating the policy parameters, might affect the robot's safety. We show through a number of experiments that our approach allows the robot to improve its performance while ensuring that the expected damage constraint is not violated during the learning process.
keywords: {Safety;Torque;Optimization;Training;Adaptation models;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989680&isnumber=7988677

M. Baum and O. Brock, "Achieving robustness by optimizing failure behavior," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5806-5811.
doi: 10.1109/ICRA.2017.7989681
Abstract: The most prominent criterion for learning of manipulation skills is the optimization of task success, modeled as expected reward or probability of success. This is sensible if we only want to optimize a single controller. But if learned manipulation primitives are used as modules in a larger system, then it is also important that their generated sensor traces facilitate recognition of action-outcomes. Optimization solely for expected success of a primitive does not guarantee this. We demonstrate a simple example for optimization of actions towards observability, combined with optimization for expected success. Our experiment is a manipulation task with a soft manipulator, where an action primitive is learned such that its generated sensor trace helps a classifier to distinguish task success and task failure. The experimental results indicate that adding auxiliary forces to the original manipulation primitive can indeed facilitate outcome recognition for manipulation tasks.
keywords: {Robot sensing systems;Planning;Robustness;Optimization;Estimation;Switches},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989681&isnumber=7988677

G. Zogopoulos-Papaliakos and K. J. Kyriakopoulos, "Generating semi-explicit DAEs with Structural Index 1 for fault diagnosis using structural analysis," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5812-5817.
doi: 10.1109/ICRA.2017.7989682
Abstract: Structural Analysis is a lucrative option for Fault Detection and Identification in Unmanned Aerial Vehicles (UAVs), because it handles detailed, large-scale mathematical models. It can be employed by an on-board flight computer to generate residual generators and implement automatic fault-detection. Contemporary algorithms applied on dynamic systems may yield residual generators which require the real-time solution of Differential-Algebraic Equation (DAE) systems. Depending on the form and differential index of each DAE system, its solution may not be possible exclusively by computational means. In this paper we explore the relation between Structural Analysis algorithms and the forms of DAE systems they produce, propose conditions under which all generated DAEs are Structural Index-1 and semi-explicit and provide a large-scale fixed-wing UAV model with that property.
keywords: {Mathematical model;Generators;Numerical models;Indexes;Fault diagnosis;Unmanned aerial vehicles;Heuristic algorithms},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989682&isnumber=7988677

S. Mayya and M. Egerstedt, "Safe open-loop strategies for handling intermittent communications in multi-robot systems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5818-5823.
doi: 10.1109/ICRA.2017.7989683
Abstract: In multi-robot systems where a central decision maker is specifying the movement of each individual robot, a communication failure can severely impair the performance of the system. This paper develops a motion strategy that allows robots to safely handle critical communication failures for such multi-robot architectures. For each robot, the proposed algorithm computes a time horizon over which collisions with other robots are guaranteed not to occur. These safe time horizons are included in the commands being transmitted to the individual robots. In the event of a communication failure, the robots execute the last received velocity commands for the corresponding safe time horizons leading to a provably safe open-loop motion strategy. The resulting algorithm is computationally effective and is agnostic to the task that the robots are performing. The efficacy of the strategy is verified in simulation as well as on a team of differential-drive mobile robots.
keywords: {Robot kinematics;Collision avoidance;Robot sensing systems;Approximation algorithms;Mobile robots;Safety},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989683&isnumber=7988677

D. M. Saxena, V. Kurtz and M. Hebert, "Learning robust failure response for autonomous vision based flight," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5824-5829.
doi: 10.1109/ICRA.2017.7989684
Abstract: The ability of autonomous mobile robots to react to and recover from potential failures of on-board systems is an important area of ongoing robotics research. With increasing emphasis on robust systems and long-term autonomy, mobile robots must be able to respond safely and intelligently to dangerous situations. Recent developments in computer vision have made autonomous vision based navigation possible. However, vision systems are known to be imperfect and prone to failure due to variable lighting, terrain changes, and other environmental variables. We describe a system for learning simple failure recovery maneuvers based on experience. This involves both recognizing when the vision system is prone to failure, and associating failures with appropriate responses that will most likely help the robot recover. We implement this system on an autonomous quadrotor and demonstrate that behaviors learned with our system are effective in recovering from situational perception failure, thereby improving reliability in cluttered and uncertain environments.
keywords: {Trajectory;Machine vision;Cameras;Mobile robots;Training;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989684&isnumber=7988677

G. Dicker, F. Chui and I. Sharf, "Quadrotor collision characterization and recovery control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5830-5836.
doi: 10.1109/ICRA.2017.7989685
Abstract: Collisions between quadrotor UAVs and the environment often occur, for instance, under faulty piloting, from wind gusts, or when obstacle avoidance fails. Airspace regulations are forcing drone companies to build safer drones; many quadrotor drones now incorporate propeller protection. However, propeller protected quadrotors still do not detect or react to collisions with objects such as walls, poles and cables. In this paper, we present a collision recovery pipeline which controls propeller protected quadrotors to recover from collisions. This pipeline combines concepts from impact dynamics, fuzzy logic, and aggressive quadrotor attitude control. The strategy is validated via a comprehensive Monte Carlo simulation of collisions against a wall, showing the feasibility of recovery from challenging collision scenarios. The pipeline is implemented on a custom experimental quadrotor platform, demonstrating feasibility of real-time performance and successful recovery from a range of pre-collision conditions. The ultimate goal of the research is to implement a general collision recovery solution as a safety feature for quadrotor flight controllers.
keywords: {Fuzzy logic;Propellers;Pipelines;Attitude control;Acceleration;Fuzzy sets;Collision avoidance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989685&isnumber=7988677

J. C. G. Higuera, D. Meger and G. Dudek, "Adapting learned robotics behaviours through policy adjustment," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5837-5843.
doi: 10.1109/ICRA.2017.7989686
Abstract: We present an approach to learning control policies for physical robots that achieves high efficiency by adjusting existing policies that have been learned on similar source systems, such as a similar robot with different physical parameters, or an approximate dynamics model simulator. This can be viewed as calibrating a policy learned on a source system, to match a desired behaviour in similar target systems. Our approach assumes that the trajectories described by the source robot are feasible on the target robot. By making this assumption, we only need to learn a mapping from the source robot state and action spaces to the target robot action space, which we call a policy adjustment model. We demonstrate our approach in simulation in the cart-pole balancing task and a two link double pendulum. We also validate our approach with a physical cart-pole system, where we adjust a learned policy under changes to the weight of the pole.
keywords: {Robots;Trajectory;Data models;Computational modeling;Supervised learning;Heuristic algorithms;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989686&isnumber=7988677

J. P. Wilson, C. M. Best and M. D. Killpack, "Variable stiffness adaptation to mitigate system failure in inflatable robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5844-5851.
doi: 10.1109/ICRA.2017.7989687
Abstract: Although inflatable soft robots are not yet a common robot platform, air leaking from the internal structure is a common and undesirable mode of failure for these platforms. In this paper we demonstrate a method to detect leaks in the structural chamber of an inflatable, pneumatically actuated robot. We then show that our method can adaptively lower commanded joint stiffness which slows the mass flow rate of the leak. This extends the operational life of the robot by decreasing long term error during operation by as much as 50% of the steady state error at the end effector when compared to the same leak if our adaptation method is not used. In future applications where we expect soft, inflatable robots to be useful, our methods can enable failure mitigation in resource-limited situations such as space exploration or disaster response.
keywords: {Actuators;Pneumatic systems;Bladder;Valves;Adaptive control;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989687&isnumber=7988677

S. M. Heydarabad, F. Milella, S. Davis and S. Nefiti-Meziani, "High-performing adaptive grasp for a robotic gripper using super twisting sliding mode control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5852-5857.
doi: 10.1109/ICRA.2017.7989688
Abstract: Grasping an object in the presence of unpredictable disturbances and with no previous knowledge of the geometry and mass distribution of it represents a significant challenge in Robotics. Also, grasping an object with sufficient force to prevent slippage, whilst not damaging or deforming the shape of the object proves to be still an intricate challenge despite the existence of a huge body of literature on robotic grasping. This paper addresses this challenge by evaluating the performance of a Super Twisting Sliding Mode Control (STSMC) designed for preventing slippage meanwhile causing minimum deformation to the grasped object. The performance of the STSMC is evaluated against the one of a First Order Sliding Mode Controller (FOSMC). Both controllers use grip force and slip feedback to counteract the slippage. Force and slip detection are provided by low-cost, off-the-shelf sensors. Experimental results presented in this paper, show that, when grasping objects, both controllers can robustly overcome external nonlinear disturbances, along with inaccuracies in the system model, preventing slippage and minimising deformation of objects. However, from these results, we observe that the STSMC not only, as expected, eliminates the major drawback of the FOSMC, which is chattering, but also provides more consistent and robust response in terms of slippage and gripping force.
keywords: {Force;Grippers;Sensors;Grasping;Friction;Fingers;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989688&isnumber=7988677

C. Huang, Y. Tung and T. Yeh, "Balancing control of a robot bicycle with uncertain center of gravity," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5858-5863.
doi: 10.1109/ICRA.2017.7989689
Abstract: In this research, a small humanoid robot and a bicycle of comparable size are constructed. Like the human rider, the robot is designed to pedal, balance and steer the bicycle. We particularly focus on the design of control system for the robot to balance and steer the bicycle using the handlebar. The control system is novel that it is capable of estimating the uncertain center of gravity of the robot-bicycle system and then incorporating such an estimation to enhance control performance. The control system design is based on a general control framework which can establish asymptotic stability under unknown measurement biases. The stability of the control system is theoretically proved and a systematic procedure to compute the control parameters is given. Both simulations and experiments verify that the proposed controller can automatically counteract the mass imbalance in the system and allow the robot to perform straight-line steering.
keywords: {Bicycles;Robots;Control systems;Asymptotic stability;Wheels;Estimation;Pollution measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989689&isnumber=7988677

Q. M. Ta and C. C. Cheah, "Simultaneous orientation and positioning control of a microscopic object using robotic tweezers," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5864-5869.
doi: 10.1109/ICRA.2017.7989690
Abstract: Existing control techniques for optical trapping of cells or micro-objects can only perform either positioning control or separate control of orientation and position in a sequential manner. In this paper, we propose a robotic control technique to achieve simultaneous orientation and positioning control of a microscopic object using multiple laser-driven fingertips and robotic motorized stage control. Several optically trapped micro-particles are first utilized as the laser-driven fingertips to grasp a target micro-object. Simultaneous control of the laser-driven fingertips and the robotic motorized stage is then performed to achieve the control objective, in which the target object is oriented to a desired angular position by controlling the laser-driven fingertips, and at the same time, it is manipulated to follow a desired trajectory by maneuvering the robotic stage. Rigorous mathematical formulation and solution are developed for simultaneous orientation and positioning control of a micro-object using optical tweezers.
keywords: {Robots;Laser beams;Biomedical optical imaging;Microscopy;Optical microscopy;Integrated optics;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989690&isnumber=7988677

Q. M. Ta and C. C. Cheah, "Coordinative optical manipulation of multiple microscopic objects using micro-hands with multiple fingertips," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5870-5875.
doi: 10.1109/ICRA.2017.7989691
Abstract: Current control techniques for optical manipulation of multiple micro-objects employ laser tweezers to directly trap and manipulate the target microscopic objects, and thus it is not capable of coordinating and manipulating micro-objects with arbitrary types in the micro-world, including large micro-objects, laser sensitive biological cells, or optically untrappable ones. In this paper, we propose a robotic control technique for optical manipulation of multiple microscopic objects by using micro-hands with multiple fingertips. In this control technique, several micro-hands are first formed by coordinating multiple optically trapped micro-particles that serve as the laser-driven fingertips, and then utilized for grasping and coordinative manipulation of multiple micro-objects. The proposed technique offers a robotic control framework for coordination and optical manipulation of multiple microscopic objects with arbitrary types in the micro-world, including large micro-objects, lasersensitive cells, or even untrappable microscopic objects.
keywords: {Laser beams;Biomedical optical imaging;Microscopy;Optical sensors;Integrated optics;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989691&isnumber=7988677

G. Garimella, M. Sheckells and M. Kobilarov, "Robust obstacle avoidance for aerial platforms using adaptive model predictive control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5876-5882.
doi: 10.1109/ICRA.2017.7989692
Abstract: This work addresses the problem of motion planning among obstacles for quadrotor platforms under external disturbances and with model uncertainty. A novel Nonlinear Model Predictive Control (NMPC) optimization technique is proposed which incorporates specified uncertainties into the planned trajectories. At the core of the procedure lies the propagation of model parameter uncertainty and initial state uncertainty as high-confidence ellipsoids in pose space. The quadrotor trajectories are then computed to avoid obstacles by a required safety margin, expressed as ellipsoid penetration while minimizing control effort and achieving a user-specified goal location. Combining this technique with online model identification results in robust obstacle avoidance behavior. Experiments in outdoor scenarios with virtual obstacles show that the quadrotor can avoid obstacles robustly, even under the influence of external disturbances.
keywords: {Trajectory;Uncertainty;Robustness;Collision avoidance;Computational modeling;Safety;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989692&isnumber=7988677

S. Singh, A. Majumdar, J. Slotine and M. Pavone, "Robust online motion planning via contraction theory and convex optimization," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5883-5890.
doi: 10.1109/ICRA.2017.7989693
Abstract: We present a framework for online generation of robust motion plans for robotic systems with nonlinear dynamics subject to bounded disturbances, control constraints, and online state constraints such as obstacles. In an offline phase, one computes the structure of a feedback controller that can be efficiently implemented online to track any feasible nominal trajectory. The offline phase leverages contraction theory and convex optimization to characterize a fixed-size “tube” that the state is guaranteed to remain within while tracking a nominal trajectory (representing the center of the tube). In the online phase, when the robot is faced with obstacles, a motion planner uses such a tube as a robustness margin for collision checking, yielding nominal trajectories that can be safely executed, i.e., tracked without collisions under disturbances. In contrast to recent work on robust online planning using funnel libraries, our approach is not restricted to a fixed library of maneuvers computed offline and is thus particularly well-suited to applications such as UAV flight in densely cluttered environments where complex maneuvers may be required to reach a goal. We demonstrate our approach through simulations of a 6-state planar quadrotor navigating cluttered environments in the presence of a cross-wind. We also discuss applications of our approach to Tube Model Predictive Control (TMPC) and compare the merits of our method with state-of-the-art nonlinear TMPC techniques.
keywords: {Electron tubes;Trajectory;Robustness;Planning;Tracking;Robots;Adaptive control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989693&isnumber=7988677

M. De Stefano, R. Balachandran, J. Artigas and C. Secchi, "Reproducing physical dynamics with hardware-in-the-loop simulators: A passive and explicit discrete integrator," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5899-5906.
doi: 10.1109/ICRA.2017.7989694
Abstract: In this paper we present a passive and reliable explicit discrete integrator, which allows to preserve the energy and dynamic properties of a physical body rendered on a hardware-in-the-loop simulator. Starting from the standard Euler integrator, we identify the energy generation that results from the integration process. This energy makes the time discrete dynamics deviate from the ideal one, resulting in position drifts or stability issues. By exploiting the time domain passivity approach, the simulated dynamics is reshaped in order to preserve its physical energy properties. The proposed integration method allows precise simulation of virtual bodies on industrial robot facilities. The method has been validated in simulation and experimentally tested on the DLR OOS-SIM facility.
keywords: {Service robots;Aerodynamics;Vehicle dynamics;Satellites;Standards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989694&isnumber=7988677

M. Hamaya, T. Matsubara, T. Noda, T. Teramae and J. Morimoto, "Learning task-parametrized assistive strategies for exoskeleton robots by multi-task reinforcement learning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5907-5912.
doi: 10.1109/ICRA.2017.7989695
Abstract: Recent studies suggest that reinforcement learning has great potential for generating assistive strategies in exoskeletons through physical interactions between a user and a robot. Previous methods focused on a task-specific assistive strategy, where for every single task (situation/context), the user needs to interact with a robot to learn an appropriate assistive strategy. Therefore, the learned strategies cannot be generalized for a new task. Since the sampling cost is expensive for such human-in-the-loop systems as exoskeletons, generalization must be enabled. In this paper, we propose to learn task-parametrized assistive strategies for exoskeleton robots. Our method employs an assistive strategy, which depends on the task parameter and the state variable, that can be learned from multiple sets of human-robot interaction data across different tasks and generalized even for an unseen task, given the task parameter without additional learning. To alleviate the user's burden in the learning process across multiple tasks, we exploit a data-efficient multi-task reinforcement learning framework. To verify the effectiveness of our method, we developed an experimental platform with an exoskeleton robot. We conducted a series of experiments whose experimental results show that our method can learn such a task-parametrized assistive strategy and be generalized for unseen tasks to reduce the user's electromyography signals (EMGs) during tasks.
keywords: {Exoskeletons;Learning (artificial intelligence);Electromyography;Robot kinematics;Training;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989695&isnumber=7988677

T. Sun, S. Nie, D. -Y. Yeung and S. Shen, "Gesture-based piloting of an aerial robot using monocular vision," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5913-5920.
doi: 10.1109/ICRA.2017.7989696
Abstract: Aerial robots are becoming popular among general public, and with the development of artificial intelligence (AI), there is a trend to equip aerial robots with a natural user interface (NUI). Hand/arm gestures are an intuitive way to communicate for humans, and various research works have focused on controlling an aerial robot with natural gestures. However, the techniques in this area are still far from mature. Many issues in this area have been poorly addressed, such as the principles of choosing gestures from the design point of view, hardware requirements from an economic point of view, considerations of data availability, and algorithm complexity from a practical perspective. Our work focuses on building an economical monocular system particularly designed for gesture-based piloting of an aerial robot. Natural arm gestures are mapped to rich target directions and convenient fine adjustment is achieved. Practical piloting scenarios, hardware cost and algorithm applicability are jointly considered in our system design. The entire system is successfully implemented in an aerial robot and various properties of the system are tested.
keywords: {Unmanned aerial vehicles;Gesture recognition;Algorithm design and analysis;Cameras;Robot vision systems;Hardware;Image color analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989696&isnumber=7988677

S. Penkov, A. Bordallo and S. Ramamoorthy, "Physical symbol grounding and instance learning through demonstration and eye tracking," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5921-5928.
doi: 10.1109/ICRA.2017.7989697
Abstract: It is natural for humans to work with abstract plans which are often an intuitive and concise way to represent a task. However, high level task descriptions contain symbols and concepts which need to be grounded within the environment if the plan is to be executed by an autonomous robot. The problem of learning the mapping between abstract plan symbols and their physical instances in the environment is known as the problem of physical symbol grounding. In this paper, we propose a framework for Grounding and Learning Instances through Demonstration and Eye tracking (GLIDE). We associate traces of task demonstration to a sequence of fixations which we call fixation programs and exploit their properties in order to perform physical symbol grounding. We formulate the problem as a probabilistic generative model and present an algorithm for computationally feasible inference over the proposed model. A key aspect of our work is that we estimate fixation locations within the environment which enables the appearance of symbol instances to be learnt. Instance learning is a crucial ability when the robot does not have any knowledge about the model or the appearance of the symbols referred to in the plan instructions. We have conducted human experiments and demonstrate that GLIDE successfully grounds plan symbols and learns the appearance of their instances, thus enabling robots to autonomously execute tasks in initially unknown environments.
keywords: {Grounding;Gaze tracking;Cameras;Three-dimensional displays;Glass;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989697&isnumber=7988677

R. Goljat, J. Babič, T. Petrič, L. Peternel and J. Morimoto, "Power-augmentation control approach for arm exoskeleton based on human muscular manipulability," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5929-5934.
doi: 10.1109/ICRA.2017.7989698
Abstract: The paper presents a novel control method for the arm exoskeletons that takes into account the muscular force manipulability of the human arm. In contrast to classical controllers that provide assistance without considering the biomechanical properties of the human arm, we propose a control method that takes into account the configuration of the arm and the direction of the motion to effectively compensate the anisotropic property of the muscular manipulability of the human arm. Consequently, the proposed control method effectively maintains a spherical endpoint manipulability in the entire workspace of the arm. As a result, the proposed method allows the human using the exoskeleton to efficiently perform tasks in arm configurations that are normally unsuitable due to the low manipulability. We evaluated the proposed approach by a preliminary experimental study where a subject wearing a 2 DOF arm-exoskeleton had to move a 4 kg weight between several locations. The results of our study demonstrate that the proposed approach effectively augments the ability of human motor control to perform tasks equally well in the whole arm workspace that include configurations with low intrinsic manipulability.
keywords: {Muscles;Force;Exoskeletons;Robots;Force measurement;Jacobian matrices;Torque measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989698&isnumber=7988677

J. Poon, Y. Cui, J. V. Miro, T. Matsubara and K. Sugimoto, "Local driving assistance from demonstration for mobility aids," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5935-5941.
doi: 10.1109/ICRA.2017.7989699
Abstract: Active assistive mobility systems are largely limited to a-priori mapped environments, whereas their reactive assistive counterparts are in general location independent and focus on the provision of collision avoidance in the immediate space surrounding the platform. This paper presents a framework capable of providing active short-term navigation, combining the intelligence of active assistance with the freedom of location independence. Demonstration data from an able expert while driving the mobility aid in a standard indoor setting is used off-line to learn reference behavioral models of navigation given perceptual information from the platform surroundings and the input controls exerted by the user while navigating. These serve as the foundation for on-line probabilistic short-term destination inference using the instantaneously available data from the user and on-board sensors. This is coupled with a real-time stochastic optimal path generation able to exploit the same short term demonstration paths from the expert with the belief they capture both the driver's awareness of the platform's physical geometry and appropriate behaviors for their surroundings. Experimental results with users of varying proficiency in a setting unvisited in training data show promise in using the framework in assisting users experiencing difficulty in safe power mobility aid use.
keywords: {Training data;Navigation;Data models;Laser beams;Sensors;Estimation;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989699&isnumber=7988677

D. A. Kurek and H. H. Asada, "The MantisBot: Design and impedance control of supernumerary robotic limbs for near-ground work," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5942-5947.
doi: 10.1109/ICRA.2017.7989700
Abstract: A novel wearable robotic device is developed to support the wearer when performing bi-manual tasks near the ground. The device is worn around the upper torso and has two Supernumerary Robotic Limbs (SRLs) that reach the ground when the wearer assumes a crawling-like position, such that neither of the wearer's natural arms are needed to support the body. Rather, both human hands can be engaged in executing a required task. Coordinating actuators at both robotic limbs, the wearer's body is supported stably with a desired impedance. As the wearer moves away from an equilibrium position, restoring forces designated by the impedance act on the wearer. First, the design concept of the SRLs for near-ground work is described, followed by a derivation of the control laws used to produce virtual impedance. A proof-of-concept prototype is then presented along with experimental verification of the derived control laws.
keywords: {Impedance;Robot kinematics;Springs;Prototypes;Actuators;Injuries;Wearable Robot;Supernumerary Robotic Limbs;Impedance Control;Human Augmentation;Body Support},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989700&isnumber=7988677

X. Yang, K. Sreenath and N. Michael, "A framework for efficient teleoperation via online adaptation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5948-5953.
doi: 10.1109/ICRA.2017.7989701
Abstract: We propose a task-independent adaptive teleoperation methodology that seeks to improve operator performance and efficiency by concurrently modeling user intent and adapting the set of available actions according to the predicted intent. User input selects a robot motion from a finite set of dynamically feasible and safe motions, represented as a motion primitive library. User intent is modeled as a probabilistic distribution with respect to future actions that represents the likelihood of action selection given recent user input, which can be formulated independent of task, environment, or user. As the intent model becomes increasingly confident, the action set is adapted in order to reduce the error between the intended and actual performance. Experimental evaluation of teleoperating a quadrotor for nonaggressive, single-intent maneuvers such as following a racetrack and conducting a free-hand helix motion shows improved performance, validating that the approach provides efficient adaptation towards achieving the user intent.
keywords: {Robots;Trajectory;Multiprotocol label switching;Adaptation models;Libraries;Vehicle dynamics;Atmospheric modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989701&isnumber=7988677

F. Parietti and H. H. Asada, "Independent, voluntary control of extra robotic limbs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5954-5961.
doi: 10.1109/ICRA.2017.7989702
Abstract: Most of the wearable robots today assist their users by acting in parallel or in series to their natural limbs. We propose a different approach to wearable robotics, consisting of devices that provide users with additional, independent robotic limbs. We present a wearable robot prototype that can achieve these goals with an extremely light weight apparatus. In order to control additional robotic limbs as if they were part of the user's body, we need voluntary signals that are independent of natural limb motions and comfortable to measure. One suitable solution - explored in this study - is the use of muscle activation signals generated by the torso. We hypothesize that a human is competent to move the extra limbs voluntarily and independently without interfering with the natural arms and legs. We developed a wearable suit to measure these signals, and we tested three possible real-time control strategies linking torso muscle contraction to the motions of two simulated extra limbs. The experimental data show that the velocity control strategy yields the highest motion accuracy, minimum muscular effort, maximum independence from the natural limbs and the fastest learning rate. This control strategy has then been applied to the control of the physical robot prototype, worn by human subjects. All of the subjects achieved accurate (normalized tracking error <; 0.5), independent (normalized natural arm motions <; 0.15) control of the extra limbs.
keywords: {Robots;Muscles;Torso;Electromyography;Sensors;Prototypes;Electrodes},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989702&isnumber=7988677

T. Seo, C. S. Casarez and R. S. Fearing, "High-rate controlled turning with a pair of miniature legged robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5962-5968.
doi: 10.1109/ICRA.2017.7989703
Abstract: Legged robots can explore unstructured environments more effectively than wheeled robots, but high turning rate tracking is still a challenging problem, particularly on varying surfaces. Previous steering methods with small robots have shown high turn rates, but usually only on a limited set of surfaces. This paper proposes a new method for steering a miniaturized legged robot by cooperation between two robots connected by a compliant joint, creating a 73 gram, 12 legged robot. Detailed design issues and an empirical verification are presented for several cooperation strategies, including changing velocities of the 4 sets of leg triples. The robots use their combined traction forces to turn at better than 50 degrees/sec at 1 m/sec on various surfaces. Closed-loop steering using a differential drive strategy is implemented on the connected robots to track a “figure 8” trajectory on a tile surface.
keywords: {Turning;Legged locomotion;Force;Dynamics;Wheels},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989703&isnumber=7988677

N. Doshi, K. Jayaram, B. Goldberg and R. J. Wood, "Phase control for a legged microrobot operating at resonance," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5969-5975.
doi: 10.1109/ICRA.2017.7989704
Abstract: We present an off-board phase estimator and controller for leg position near the resonance of the Harvard Ambulatory MicroRobot's (HAMR) two degree-of-freedom transmission. This control system is a first step towards leveraging the significant increase in stride length at transmission resonance for faster and more efficient locomotion. We experimentally characterize HAMR's transmission and determine that actuator phase is a sufficient proxy for leg phase across the range of useful operating frequencies (1-120Hz). An estimator is developed to determine actuator phase using off-board position sensors and it converges within a cycle on average. We also fit a nonlinear dynamic model of the transmission to the experimental data, and utilize the model to determine a suitable open-loop resonant leg trajectory and define feed forward control inputs. This resonant (100Hz) trajectory is theoretically 50% more efficient than pre-resonant high speed running trajectories. The controller converges to this trajectory in 0.05 ± 0.02 seconds (5.3 ± 2.4 cycles) in air, and in 0.05 ± 0.01 seconds (4.7 ± 0.6 cycles) under perturbations that approximate ground contact.
keywords: {Legged locomotion;Actuators;Trajectory;Resonant frequency;Heat-assisted magnetic recording;Frequency response;Resonance;Phase control;Dynamic modeling;Legged microrobots;Biologically Inspired Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989704&isnumber=7988677

I. S. M. Khalil et al., "Near-surface effects on the controlled motion of magnetotactic bacteria," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5976-5982.
doi: 10.1109/ICRA.2017.7989705
Abstract: Magnetotactic bacteria have the potential to controllably reach stagnant fluids inside the human body and achieve targeted drug delivery. In this application, motion of the magnetotactic bacteria is influenced by the near-surface effects such as the background flows and surface interactions. Here, we provide a hydrodynamic model of bipolarly-flagellated magnetotactic bacteria (Magnetospirillum gryphiswaldense strain MSR-1) based on the resistive-force theory to resemble the helical body and the two flagella bundles, and investigate their swimming characteristics in two environments, i.e., free-space and near flat walls. The free-space is studied using capillary tubes with depth of 200 μm, whereas the effect of the flat walls is investigated using microfluidic chips with depth of 5 μm. We find that the linear speeds of bacteria near- and far-surface are 36±16.4 μm/s (mean±s.d.) and 46±6.8 μm/s, respectively, whereas their respective angular velocities are 12.5±5.7 rad/s and 13.5±5.0 rad/s.
keywords: {Magnetic resonance imaging;Magnetic moments;Microorganisms;Immune system;Torque;Drag;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989705&isnumber=7988677

T. Sun et al., "Robotics-based micro-reeling of magnetic microfibers to fabricate helical structure for smooth muscle cells culture," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5983-5988.
doi: 10.1109/ICRA.2017.7989706
Abstract: Helical structure assembled by hydrogel microfibers is significant for culture of smooth muscle cells. However, the helical structure is only fabricated at the macroscale, while the fabrication of helical microstructure is still a challenge due to the lack of assembly method. In this paper, we propose a robotics-based assembly method to handle such challenge. An electromagnetic needle (EMN) is employed as end-effector to magnetically reel the microfiber encapsulating magnetic nanoparticles around a micropillar, and a dual-ring structure is designed to keep the microfiber being attracted at the EMN tip. For enhancing the stability of tip attraction, the manipulation mode of anticlockwise pushing microfiber is established. Moreover, the interaction mechanism between EMN tip and microfiber is analyzed by developing a static force model, and then the key condition of stably reeling microfiber is concluded. Furthermore, a robotics-based motion trajectory of EMN tip is planned to achieve a smooth reeling process. Based on such planning, the size of dual-ring structure is further optimized to improve the success rate of reeling. Finally, the helical microstructure with there-turn coils is successfully fabricated.
keywords: {Magnetic flux;Robots;Magnetic fields;Saturation magnetization;Microstructure;Microfluidics;Microchannels},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989706&isnumber=7988677

M. Grammatikopoulou and G. -Z. Yang, "Gaze contingent control for optical micromanipulation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5989-5995.
doi: 10.1109/ICRA.2017.7989707
Abstract: Optical Tweezers (OT) have the advantage of non-contact interaction with target objects such as cells, overcoming the pitfall of obstructive adhesion forces which are present in contact micromanipulation. It is also feasible to manipulate a number of small microparts simultaneously or 3D structures by using multiple laser traps. These capabilities give rise to the potential to develop a human-robot interface to facilitate microassembly tasks. This paper presents a gaze contingent control framework and a method for 3D orientation estimation for optical micromanipulation. The proposed strategy aims to use OT as an interactive microassembly platform. The framework comprises I) a strategy to recognize the operator's intentions in order to interactively place and reconfigure the optical traps using the operator's eye fixation point, II) haptic constraints generated from the user's eye gaze to assist positioning of the assembled microparts and III) a method for 3D orientation estimation. The performance of the proposed framework is assessed through a set of experiments comparing it to the standard OT user interface. Three-dimensional manipulation and orientation estimation of a non-spherical microstructure are also performed.
keywords: {Haptic interfaces;Charge carrier processes;Three-dimensional displays;Lasers;Optical imaging;Optical sensors;Optical buffering},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989707&isnumber=7988677

X. Liu et al., "Non-contact transportation and rotation of micro objects by vibrating glass needle circularly under water," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 5996-6001.
doi: 10.1109/ICRA.2017.7989708
Abstract: In micromanipulation, lots of methods have been developed to manipulate objects in microscale. However, few of them can be applied in both the transportation and the rotation of the micro objects. In this paper, we present a novel method to realize the non-contact transportation and rotation of the micro objects based on the vibration-induced swirl flow. A piezo actuator is set between the glass needle and a metal rod. The sine wave with controlled frequency and amplitude is input into the piezo actuator to drive the glass needle to move circularly, which is caused by resonance of the actuator and the metal rod. We place the glass needle under water and keep a limited distance to the bottom. The circular vibration of the glass needle can generate a swirl flow and low pressure around it. The low pressure can trap and transport the micro objects vertically to the glass needle, and the swirl flow can rotate the objects continuously. Finally, we realize the trap and rotation of micro object with only one piezo actuator. Experiments of transportation and rotation of microbeads are carried out, and the results demonstrate it is a simple, low-cost, effective micromanipulation method.
keywords: {Glass;Needles;Actuators;Vibrations;Metals;Transportation;Resonant frequency},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989708&isnumber=7988677

M. Power, S. Anastasova, S. Shanel and G. -Z. Yang, "Towards hybrid microrobots using pH- and photo-responsive hydrogels for cancer targeting and drug delivery," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6002-6007.
doi: 10.1109/ICRA.2017.7989709
Abstract: This work is towards targeted drug delivery using microrobots functionalized to navigate towards naturally occurring pH gradients caused by cancer cells, and to release a payload in response to a light stimulus. Stimuli-responsive microrobots for the localization of specific cell types and targeted drug delivery could provide a new and promising therapy to prevent and treat the spread of cancer. In this work, we present two novel biocompatible photoresists for the fabrication of hybrid microrobots using two-photon polymerization (TPP) for medical applications. One biomarker for cancerous cells is that they exhibit lower pH compared to surrounding healthy tissue. In this work, a pH-responsive resist was developed and demonstrated to automatically seek a low-pH solid in a microfluidic channel, simulating metastatic cells within a vessel. The second resist, a hydrogel-based photoresist, was created to contract in response to light. The two resists were combined together in a two-step printing process to create a microswimmer with potential for tumor localization and drug release capabilities in the human circulatory system.
keywords: {Resists;Robots;Fabrication;Cancer;Polymers;Navigation;Printing},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989709&isnumber=7988677

A. G. Dharmawan, H. H. Hariri, S. Foong, G. S. Soh and K. L. Wood, "Steerable miniature legged robot driven by a single piezoelectric bending unimorph actuator," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6008-6013.
doi: 10.1109/ICRA.2017.7989710
Abstract: In small mobile robots, decreasing the number of actuators is usually desirable to reduce the size and weight of the robot, but it is usually at the expense of the robot's degree of freedom (DOF). This work presents the development and preliminary experimental testing of a novel Legged Piezoelectric Miniature Robot (LPMR) driven only by a single piezoelectric unimorph actuator and yet fully capable of being maneuvered to move forward, turn right, or turn left. The underactuated motion is achieved by exploiting the bending vibration modes disparity of the piezoelectric actuator at different driving frequencies and designing specific positions of the robot's legs to generate a differential-drive-like mechanism. The speed of the robot can be controlled through regulating the magnitude of the applied voltage. The proposed underactuated system is experimentally verified and a preliminary characterization of the LPMR in terms of its forward and turning speed versus applied voltage and payload is investigated and reported.
keywords: {Legged locomotion;Aluminum;Resonant frequency;Force;Piezoelectric actuators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989710&isnumber=7988677

H. Inose et al., "Semi-endoskeleton-type waist assist AB-wear suit equipped with compressive force reduction mechanism," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6014-6019.
doi: 10.1109/ICRA.2017.7989711
Abstract: In recent years in Japan, over half of all workers suffered from lower back pain. This has become a social problem that needs to be addressed. To reduce its occurrence, we developed a flexible, high-output waist assist suit called “AB-Wear” in a previous study. The AB-Wear suit can assist human motion and reduce muscular fatigue of the waist. However, the assistive forces of the device generate compressive forces on the backbone, which have adverse effects on the body. Hence, in this study, we propose an exoskeleton-type AB-Wear equipped with a compressive force reduction mechanism, called “semi-endoskeleton-type AB-Wear”. This device has a reduction mechanism similar to a flexible flat spring behind the upper body. Because of this structure, this device can generate an effective assistive force. First, we explain the difference between the semi-endoskeleton-type AB-Wear and the previous device. Then, we model the semi-endoskeleton-type AB-Wear because the model is used for its operation. Moreover, its effectiveness is confirmed using musculoskeletal simulation. Finally it is evaluated by measuring surface electromyography (EMG) on a subject's body to confirm its effectiveness with a real body. The EMGs of the wearer with and without the suit are compared. The usefulness of the AB-Wear is confirmed by simulation and experiment.
keywords: {Force;Actuators;Muscles;Springs;Load modeling;Biological system modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989711&isnumber=7988677

H. Liang et al., "Estimation of EMG signal for shoulder joint based on EEG signals for the control of upper-limb power assistance devices," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6020-6025.
doi: 10.1109/ICRA.2017.7989712
Abstract: Brain-Machine Interface (BMI) has emerged as a powerful tool for assisting disabled people and for augmenting human performance. Up so far, no studies have succeeded in the power augmentation for the multi-DOFs robot based on EEG signals, especially for the complex shoulder joint. In this work, we propose an electromyography (EMG) estimation method based on electroencephalography (EEG) signals to realize the power assistance. The positions of the electrodes where the motion information of shoulder joint is effectively and exactly extracted are discussed, and a linear model that correlates the EMG to the EEG signal is constructed utilizing motion-related features extracted from multi-location EEG measurements. The constructed model is used to estimate the human muscular activity of shoulder joint from EEG using Principal Component Analysis (PCA) method. The proposed approach is experimentally verified, and an average correlation coefficients are as high as about 0.90 for different subjects are obtained between the estimated and the actually measured EMG signal. Our results suggest that the estimation of EMG based on EEG is feasible. This demonstrates the potential of using EEG signals to support human activities via brain-machine interface.
keywords: {Electroencephalography;Electromyography;Shoulder;Robots;Electrodes;Brain modeling;Principal component analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989712&isnumber=7988677

G. Chalvatzaki, X. S. Papageorgiou, C. S. Tzafestas and P. Maragos, "Comparative experimental validation of human gait tracking algorithms for an intelligent robotic rollator," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6026-6031.
doi: 10.1109/ICRA.2017.7989713
Abstract: Tracking human gait accurately and robustly constitutes a key factor for a smart robotic walker, aiming to provide assistance to patients with different mobility impairment. A context-aware assistive robot needs constant knowledge of the user's kinematic state to assess the gait status and adjust its movement properly to provide optimal assistance. In this work, we experimentally validate the performance of two gait tracking algorithms using data from elderly patients; the first algorithm employs a Kalman Filter (KF), while the second one tracks the user legs separately using two probabilistically associated Particle Filters (PFs). The algorithms are compared according to their accuracy and robustness, using data captured from real experiments, where elderly subjects performed specific walking scenarios with physical assistance from a prototype Robotic Rollator. Sensorial data were provided by a laser rangefinder mounted on the robotic platform recording the movement of the user's legs. The accuracy of the proposed algorithms is analysed and validated with respect to ground truth data provided by a Motion Capture system tracking a set of visual markers worn by the patients. The robustness of the two tracking algorithms is also analysed comparatively in a complex maneuvering scenario. Current experimental findings demonstrate the superior performance of the PFs in difficult cases of occlusions and clutter, where KF tracking often fails.
keywords: {Legged locomotion;Tracking;Lasers;Robot sensing systems;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989713&isnumber=7988677

F. Arrichiello, P. Di Lillo, D. Di Vito, G. Antonelli and S. Chiaverini, "Assistive robot operated via P300-based brain computer interface," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6032-6037.
doi: 10.1109/ICRA.2017.7989714
Abstract: In this paper we present an architecture for the operation of an assistive robot finally aimed at allowing users with severe motion disabilities to perform manipulation tasks that may help in daily-life operations. The robotic system, based on a lightweight robot manipulator, receives high level commands from the user through a Brain-Computer Interface based on P300 paradigm. The motion of the manipulator is controlled relying on a closed loop inverse kinematic algorithm that simultaneously manages multiple set-based and equality-based tasks. The software architecture is developed relying on widely used frameworks to operate BCIs and robots (namely, BCI2000 for the operation of the BCI and ROS for the control of the manipulator) integrating control, perception and communication modules developed for the application at hand. Preliminary experiments have been conducted to show the potentialities of the developed architecture.
keywords: {Manipulators;Graphical user interfaces;Mobile robots;Robot sensing systems;Computer architecture;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989714&isnumber=7988677

D. Tran et al., "A collaborative control framework for driver assistance systems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6038-6043.
doi: 10.1109/ICRA.2017.7989715
Abstract: This paper proposes a driver assistance system with a collaborative control framework between the human driver and a Collision Avoidance System (CAS) for vehicles on the road while considering the driver drowsiness status. Driver drowsiness detection is performed with two inputs: driver's facial data from a camera mounted in front of the driver and steering wheel data from the car controller system. We use the driver's drowsiness state as an input to the collaborative control framework in which the CAS algorithm runs in parallel with the human control and only intervenes under certain situations to assist the human driver. Experiments were performed on a simulated vehicle driving testbed to evaluate our drowsiness detection system and demonstrate the effectiveness of the proposed collaborative control framework.
keywords: {Collaboration;Automobiles;Roads;Wheels;Feature extraction;Autonomous automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989715&isnumber=7988677

W. Yu, A. Kapusta, J. Tan, C. C. Kemp, G. Turk and C. K. Liu, "Haptic simulation for robot-assisted dressing," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6044-6051.
doi: 10.1109/ICRA.2017.7989716
Abstract: There is a considerable need for assistive dressing among people with disabilities, and robots have the potential to fulfill this need. However, training such a robot would require extensive trials in order to learn the skills of assistive dressing. Such training would be time-consuming and require considerable effort to recruit participants and conduct trials. In addition, for some cases that might cause injury to the person being dressed, it is impractical and unethical to perform such trials. In this work, we focus on a representative dressing task of pulling the sleeve of a hospital gown onto a person's arm. We present a system that learns a haptic classifier for the outcome of the task given few (2-3) real-world trials with one person. Our system first optimizes the parameters of a physics simulator using real-world data. Using the optimized simulator, the system then simulates more haptic sensory data with noise models that account for randomness in the experiment. We then train hidden Markov Models (HMMs) on the simulated haptic data. The trained HMMs can then be used to classify and predict the outcome of the assistive dressing task based on haptic signals measured by a real robot's end effector. This system achieves 92.83% accuracy in classifying the outcome of the robot-assisted dressing task with people not included in simulation optimization. We compare our classifiers to those trained on real-world data. We show that the classifiers from our system can categorize the dressing task outcomes more accurately than classifiers trained on ten times more real data.
keywords: {Hidden Markov models;Robot sensing systems;Haptic interfaces;Robot kinematics;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989716&isnumber=7988677

M. Takeda, Y. Hirata, K. Kosuge, T. Katayama, Y. Mizuta and A. Koujina, "Human CoG estimation for assistive robots using a small number of sensors," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6052-6057.
doi: 10.1109/ICRA.2017.7989717
Abstract: Various assistive machines have been developed to prevent falling accidents of the elderly. In order to achieve advanced support using robot technology, it is important to acquire data or real-time state estimation of user's various motions. However, a lot of expensive and sophisticated sensors utilized to estimate user's state accurately are difficult to use in general households or institutions. In this article, we propose a method to estimate the user's state utilizing a few inexpensive and simple sensors. We focused on CoG (Center of Gravity) to estimate user's state, but when utilizing less sensors than required to calculate the human link model parameters, the position of CoG is underspecified. Then we considered the range of value of unknown parameters to calculate candidates of CoG. The range of CoG candidates can become narrow enough to estimate human state in real-time by properly selecting and placing the sensors. Therefore, the evaluation of CoG candidates allows us to determine where and which sensors to set when designing assistive robots. We firstly selected some sensors which can be generally found on assistive machines, and we created sets of measurements using the number of unknown parameters. From the result of the experiment using a motion capture system, we confirmed that the range of the candidates was considerably narrow when using some of the created measurement sets. We validated the proposed method to estimate user's CoG candidates by actually placing the sensors according to the designed measurement sets and confirmed that the CoG candidates corresponded to those obtained using the motion capture system.
keywords: {Legged locomotion;Robot sensing systems;Sensor systems;Motion measurement;Position measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989717&isnumber=7988677

Z. Erickson, A. Clegg, W. Yu, G. Turk, C. K. Liu and C. C. Kemp, "What does the person feel? Learning to infer applied forces during robot-assisted dressing," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6058-6065.
doi: 10.1109/ICRA.2017.7989718
Abstract: During robot-assisted dressing, a robot manipulates a garment in contact with a person's body. Inferring the forces applied to the person's body by the garment might enable a robot to provide more effective assistance and give the robot insight into what the person feels. However, complex mechanics govern the relationship between the robot's end effector and these forces. Using a physics-based simulation and data-driven methods, we demonstrate the feasibility of inferring forces across a person's body using only end effector measurements. Specifically, we present a long short-term memory (LSTM) network that at each time step takes a 9-dimensional input vector of force, torque, and velocity measurements from the robot's end effector and outputs a force map consisting of hundreds of inferred force magnitudes across the person's body. We trained and evaluated LSTMs on two tasks: pulling a hospital gown onto an arm and pulhng shorts onto a leg. For both tasks, the LSTMs produced force maps that were similar to ground truth when visualized as heat maps across the limbs. We also evaluated their performance in terms of root-mean-square error. Their performance degraded when the end effector velocity was increased outside the training range, but generalized well to limb rotations. Overall, our results suggest that robots could learn to infer the forces people feel during robot-assisted dressing, although the extent to which this will generalize to the real world remains an open question.
keywords: {Force;Clothing;End effectors;Force measurement;Estimation;Legged locomotion},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989718&isnumber=7988677

Y. Jiang, T. Li, L. Wang, F. Chen and Y. Wang, "Improving contour accuracy of a 2-DOF planar parallel kinematic machine by smart structure based compensation method," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6066-6072.
doi: 10.1109/ICRA.2017.7989719
Abstract: High contour accuracy is vital to the multi-axis motion system. Improvement in the contour accuracy of the parallel kinematic machine (PKM) has being a challenging issue in the process of its practical application. In analogy to the intelligent structure of the organisms, this paper proposes a smart structure based compensation (SSBC) method to improve the PKM's contour accuracy. Instead of adopting the advanced control strategies or improving the performances of machine's hardware, this method deals with the contouring issue through innovative mechanical design. The smart structures, which have the ability of perception and control, are introduced into the PKM's components to actively suppress their deformations and vibrations. Meanwhile, the accurate micro motions provided by the smart structure components can be used to compensate for the PKM's contour error caused by the uncoordinated control of the driving system just by using a simple control strategy. The implementation procedure of the SSBC method is first discussed in detail. A 2-DOF PKM is taken as the application object and the smart structures are introduced into its kinematic chains to control their axial deformations and internal forces. Then this PKM's kinematic error is reduced in advance to guarantee the result of the contour accuracy improvement. Finally, several experimental tests are performed to verify the effectiveness the proposed SSBC method in improving the PKM's contour accuracy. Except for the PKM, the SSBC method also provides a novel and effective way for the advanced multi-axis machines to improve their contour accuracies.
keywords: {Intelligent structures;Kinematics;Actuators;Intelligent sensors;Vibrations;Motion control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989719&isnumber=7988677

A. Koessler, A. Goldsztejn, S. Briot and N. Bouton, "Certified detection of parallel robot assembly mode under Type 2 singularity crossing trajectories," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6073-6079.
doi: 10.1109/ICRA.2017.7989720
Abstract: Increasing the size of operationnal workspace is one of the main problems parallel robots are faced with. Among all the proposed solutions to that, crossing Type 2 singularities using dedicated trajectory generation and multi-model controller has a great potential. Yet, this approach is not sufficient for the robot to operate autonomously, as assembly mode detection during the motion currently requires additional redundant information. To tackle this problem, we propose an algorithm based on Interval Analysis (IA) that is able to track the end-effector of the robot even under assembly mode change. IA-based solvers for the forward kinematic problem of parallel robots are well known, but they cannot be used under assembly mode change. Compared to those classical approaches, the major modification introduced is the tracking of end-effector velocity in addition to its pose. Using this new information of velocity, the algorithm is capable to monitor the assembly mode change of the robot happening when the singularities are crossed. The behavior and the reliability of this algorithm are analyzed experimentally on a five-bar planar parallel mechanism.
keywords: {Trajectory;Kinematics;Parallel robots;Robot kinematics;Mathematical model;Algorithm design and analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989720&isnumber=7988677

R. B. Hill, D. Six, A. Chriette, S. Briot and P. Martinet, "Crossing type 2 singularities of parallel robots without pre-planned trajectory with a virtual-constraint-based controller," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6080-6085.
doi: 10.1109/ICRA.2017.7989721
Abstract: The presence of Type 2 singularities in parallel robots severely affects their performances, mainly because the platform motion control is partially lost. It also leads to a size reduction of the operational workspace. Moreover, the dynamic model of the parallel mechanism degenerates and locally, the robot becomes underactuated in the singularity. It has been proven that it is possible to cross Type 2 singularities by respecting a dynamic criterion. Nevertheless, the controllers designed up to now require a pre-planned optimized trajectory including this criterion, and as a result, this strategy can only be used by qualified users. In order to avoid this drawback and to cross these types of singularities even if the trajectory is not pre-planned, this paper proposes a controller based on virtual constraints. Furthermore, the controller is integrated in a multi-control architecture in order to switch between a classical computed torque control far from the singularity and the virtual-constraint-based control law near to the singularity locus. Experimental results on a five-bar mechanism validated the automatic Type 2 singularity crossing.
keywords: {Parallel robots;Mathematical model;Trajectory;Kinematics;Matrices;Dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989721&isnumber=7988677

M. Bennehar, G. El-Ghazaly, A. Chemori and F. Pierrot, "A novel adaptive terminal sliding mode control for parallel manipulators: Design and real-time experiments," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6086-6092.
doi: 10.1109/ICRA.2017.7989722
Abstract: This paper deals with the design of a new robust adaptive controller for parallel manipulators based on sliding mode and modelbased adaptive control. More precisely, the proposed controller relies on continuous finite-time terminal sliding mode (TSM) control and the linear-in-the-parameters property of the inverse dynamics of the manipulator. The main motivation behind the proposed scheme is to improve the tracking performance of fast and accurate parallel manipulators while guaranteeing the closed-loop system's robustness. Based on the linear-in-the-parameters property of the inverse dynamics of the manipulator, an adaptive law is proposed in order to estimate in real-time the dynamic parameters of the manipulator. The proposed controller has the advantage of relying on the desired reference trajectories instead of measured ones which can improve its robustness and efficiency. To demonstrate the effectiveness of the proposed controller, real-time experiments are conducted on a four-degree-of-freedom parallel manipulator called Veloce.
keywords: {Manipulator dynamics;Uncertainty;Kinematics;Dynamics;Robustness},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989722&isnumber=7988677

P. Tempel, P. -E. Herve, O. Tempier, M. Gouttefarde and A. Pott, "Estimating inertial parameters of suspended cable-driven parallel robots — Use case on CoGiRo," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6093-6098.
doi: 10.1109/ICRA.2017.7989723
Abstract: Model based open-loop and closed-loop control systems make use of the system's inertial parameters. Unfortunately, not all of these values can be determined analytically nor can they be obtained from simple measurements. Established experiments for inertial parameters estimation have been applied to serial and parallel rigid-link manipulators, yet in very few cases to cable-driven parallel robots. Due to their kinematic properties and their unique setup, cable robots are more sensitive to incorrect estimates of the inertial parameters making it important to obtain such quantities through experiments. In this work, we assess the topic of inertial parameter identification of a parallel flexible-link manipulator exemplified by the suspended cable-driven parallel robot CoGIRo. Identification equations are derived from Newton-Euler equations of motion of an arbitrary point fixed to a rigid-body. Laboratory experiments for identification of the inertial parameters are then introduced and results are presented. Within the limitations of the sensors and data acquisition methods, reasonable results have been obtained, thereby validating the procedure for suspended cable-driven parallel robots.
keywords: {Mathematical model;Gravity;Parallel robots;Manipulators;Kinematics;Mobile communication},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989723&isnumber=7988677

C. Wu, G. Yang, C. -Y. Chen, S. Liu and T. Zheng, "Kinematic design of a novel 4-DOF parallel manipulator," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6099-6104.
doi: 10.1109/ICRA.2017.7989724
Abstract: A new four degrees-of-freedom (DOF) parallel manipulator that can produce 3-DOF translations and 1-DOF rotation (3T1R), has been proposed in this paper. It has two identical limbs connected to the moving platform through passive revolute joints, and each limb has two identical branches driven by a pair of base mounted collinear prismatic joints. Due to such a unique “4-2-1” kinematic structure, the 4-DOF parallel manipulator has the advantages of simple kinematics, large workspace, high speed, and high positioning accuracy. These advantages make it an appropriate candidate for high-speed and high-precision pick-and-place operations. To validate the proposed parallel manipulator design, mobility analysis is conducted based on the screw theory. Other critical design analysis issues, such as displacement, singularity, and workspace analyses, have been addressed in details.
keywords: {Kinematics;Fasteners;Manipulators;Automation;Connectors;Service robots;4-DOF parallel manipulator;Schonflies motions;kinematics;workspace;singularity analysis},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989724&isnumber=7988677

V. Prabakaran, M. R. Elara, T. Pathmakumar and S. Nansai, "hTetro: A tetris inspired shape shifting floor cleaning robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6105-6112.
doi: 10.1109/ICRA.2017.7989725
Abstract: This research work presents the development of a novel tetris inspired reconfigurable floor cleaning robot - hTetro, utilizing the hinged dissection theory of polyominoes. The developed robot platform is capable of transforming between any of the seven set of one-sided tetromino morphologies according to the perceived environment with an objective of maximizing the coverage area. Experiments were performed across two different settings to systematically compare the coverage area performance of the developed hTetro robot and a commercially available fixed morphology robot platform. Results indicate significantly higher coverage area performance in the case of hTetro due to its ability to assume optimal morphology in relation to navigating environment.
keywords: {Cleaning;Floors;Morphology;Robot sensing systems;Shape;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989725&isnumber=7988677

A. Abbas and J. Zhao, "A physics based model for twisted and coiled actuator," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6121-6126.
doi: 10.1109/ICRA.2017.7989726
Abstract: This paper presents the static and dynamic modeling for a recently discovered artificial muscle-twisted and coiled actuator (TCA). This actuator can generate large force and displacement; moreover, it is low-cost, easy to fabricate, and customizable. Since the discovery of TCA, it has been widely adopted for various robotic applications. Nevertheless, theoretical models to describe the static performance and dynamic response are underexplored. In this paper, we aim to model the statics and dynamics for TCA from physics perspective. Specifically, the developed model utilizes parameters related to the working principle and material properties of the actuator. Experiments are conducted to verify the proposed model, and the results demonstrate that the proposed model can predict the static performance and dynamic response for the actuator. Given the wide applications of TCA in robotics, the developed model will enable closed-loop control of robotic systems with TCAs to achieve precise motion.
keywords: {Force;Actuators;Torque;Dynamics;Muscles;Robots;Temperature},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989726&isnumber=7988677

H. Jiang et al., "A two-level approach for solving the inverse kinematics of an extensible soft arm considering viscoelastic behavior," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6127-6133.
doi: 10.1109/ICRA.2017.7989727
Abstract: Soft compliant materials and novel actuation mechanisms ensure flexible motions and high adaptability for soft robots, but also increase the difficulty and complexity of constructing control systems. In this work, we provide an efficient control algorithm for a multi-segment extensible soft arm in 2D plane. The algorithm separate the inverse kinematics into two levels. The first level employs gradient descent to select optimized arm's pose (from task space to configuration space) according to designed cost functions. With consideration of viscoelasticity, the second level utilizes neural networks to figure out the pressures from each segment's pose (from configuration space to actuation space). In experiments with a physical prototype, the control accuracy and effectiveness are validated, where the control algorithm is further improved by an optional feedback strategy.
keywords: {Aerospace electronics;Kinematics;Neural networks;Manipulators;Algorithm design and analysis;Cost function},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989727&isnumber=7988677

A. L. Orekhov, V. A. Aloi and D. C. Rucker, "Modeling parallel continuum robots with general intermediate constraints," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6142-6149.
doi: 10.1109/ICRA.2017.7989728
Abstract: Parallel continuum robots consist of a parallel arrangement of flexible legs and are dexterous, compliant, and easily miniaturized for minimally invasive surgery. By design, parallel continuum robots exhibit large, nonlinear deformations in their legs to achieve multi-DOF end effector articulation, but excess leg bowing can limit their reachable workspace, especially for long slender designs. In this paper, we investigate a parallel continuum robot design with a passive spring backbone carrying disks that constrain the legs at intermediate points. The constraints route the legs in helical paths around the backbone and prevent large divergence of the legs, expanding the reachable workspace for slender form factors while preserving the manipulator's six degrees of freedom. We present a novel forward and inverse kinematics model, based on Cosserat rod theory, that accommodates general leg routing paths and any number of intermediate constraint disks. We also explore manipulator workspace with experiments and simulations, demonstrating that intermediate constraints expand the reachable workspace of slender parallel continuum robots.
keywords: {Legged locomotion;Manipulators;Springs;Routing;Load modeling;Shape},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989728&isnumber=7988677

F. Campisano et al., "Towards a soft robotic skin for autonomous tissue palpation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6150-6155.
doi: 10.1109/ICRA.2017.7989729
Abstract: Manual palpation is commonly used to localize tumors and other features buried deep inside organs during open surgery. This approach is not feasible in minimally invasive or robotic surgery, as the contact with the tissue is mediated by instruments. To address this problem, we propose a soft robotic skin (SRS) that can be deployed from a small incision and create a stiffness map in a single step. Such a skin is composed of a matrix of soft robotic tactile elements (SRTEs), each one able to expand and record the tissue response during expansion. In this paper, we firstly prove the feasibility of palpation using a single SRTE. Then, we present and test a soft-suction based anchoring mechanism able to keep the SRS in the desired position in contact with the tissue, allowing surgeons to palpate different sides of the organ. Finally, we detail a calibration method for the SRTE, and assess the feasibility of identifying lumps buried inside a soft tissue phantom, and then inside a chicken liver during an ex-vivo trial. Experimental results show that the SRTE was able to differentiate simulated lumps (up to 3.25 mm deep) from healthy tissue in both the phantom and the ex-vivo trials. These results, added to the ability of the suction gripper to compensate for the expansion forces of each SRTE, are paving the way for soft robotic autonomous tools that can be used for intraoperative mapping of tissue cancers.
keywords: {Surgery;Rubber;Soft robotics;Grippers;Calibration;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989729&isnumber=7988677

S. Scheggi et al., "Magnetic motion control and planning of untethered soft grippers using ultrasound image feedback," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6156-6161.
doi: 10.1109/ICRA.2017.7989730
Abstract: Soft miniaturized untethered grippers can be used to manipulate and transport biological material in unstructured and tortuous environments. Previous studies on control of soft miniaturized grippers employed cameras and optical images as a feedback modality. However, the use of cameras might be unsuitable for localizing miniaturized agents that navigate within the human body. In this paper, we demonstrate the wireless magnetic motion control and planning of soft untethered grippers using feedback extracted from B-mode ultrasound images. Results show that our system employing ultrasound images can be used to control the miniaturized grippers with an average tracking error of 0.4±0.13 mm without payload and 0.36±0.05 mm when the agent performs a transportation task with a payload. The proposed ultrasound feedback magnetic control system demonstrates the ability to control miniaturized grippers in situations where visual feedback cannot be provided via cameras.
keywords: {Grippers;Magnetic resonance imaging;Tracking;Magnetic moments;Saturation magnetization;Ultrasonic imaging;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989730&isnumber=7988677

L. Palmieri, T. P. Kucner, M. Magnusson, A. J. Lilienthal and K. O. Arras, "Kinodynamic motion planning on Gaussian mixture fields," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6176-6181.
doi: 10.1109/ICRA.2017.7989731
Abstract: We present a mobile robot motion planning approach under kinodynamic constraints that exploits learned perception priors in the form of continuous Gaussian mixture fields. Our Gaussian mixture fields are statistical multi-modal motion models of discrete objects or continuous media in the environment that encode e.g. the dynamics of air or pedestrian flows. We approach this task using a recently proposed circular linear flow field map based on semi-wrapped GMMs whose mixture components guide sampling and rewiring in an RRT* algorithm using a steer function for non-holonomic mobile robots. In our experiments with three alternative baselines, we show that this combination allows the planner to very efficiently generate high-quality solutions in terms of path smoothness, path length as well as natural yet minimum control effort motions through multi-modal representations of Gaussian mixture fields.
keywords: {Planning;Heuristic algorithms;Trajectory;Dynamics;Robots;Vehicle dynamics;Gaussian mixture model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989731&isnumber=7988677

J. Modares, F. Ghanei, N. Mastronarde and K. Dantu, "UB-ANC planner: Energy efficient coverage path planning with multiple drones," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6182-6189.
doi: 10.1109/ICRA.2017.7989732
Abstract: Advancements in the design of drones have led to their use in varied environments and applications such as battle field surveillance. In such scenarios, swarms of drones can coordinate to survey a given area. We consider the problem of covering an arbitrary area containing obstacles using multiple drones, i.e., the so-called coverage path planning (CPP) problem. The goal of the CPP problem is to find paths for each drone such that the entire area is covered. However, a major limitation in such deployments is drone flight time. To most efficiently use a swarm, we propose to minimize the maximum energy consumption among all drones' flight paths. We perform measurements to understand energy consumption of a drone. Using these measurements, we formulate an Energy Efficient Coverage Path Planning (EECPP) problem. We solve this problem in two steps: a load-balanced allocation of the given area to individual drones, and a minimum energy path planning (MEPP) problem for each drone. We conjecture that MEPP is NP-hard as it is similar to the Traveling Salesman Problem (TSP). We propose an adaptation of the well-known Lin-Kernighan heuristic for the TSP to efficiently solve the problem. We compare our solution to the recently proposed depth-limited search with back tracking algorithm, the optimal solution, and rastering as a baseline. Results show that our algorithm is more computationally efficient and provides more energy-efficient solutions compared to the other heuristics.
keywords: {Drones;Path planning;Energy consumption;Energy measurement;Power demand;Planning;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989732&isnumber=7988677

D. A. Sinyukov and T. Padir, "CWave: High-performance single-source any-angle path planning on a grid," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6190-6197.
doi: 10.1109/ICRA.2017.7989733
Abstract: Path planning on a 2D-grid is a well-studied problem in robotics. It usually involves searching for a shortest path between two vertices on a grid. Single-source path planning is a modified problem which asks to find distances from a given point to all other points on the map. A high-performance algorithm for single-source any-angle path planning on a grid that we named CWave is proposed in this work. “Any-angle” attribute of a path planning algorithm implies that such algorithm can find paths which may include any angle segments, as opposed to standard A* on an 8-connected graph, the path can turn with 45°-increments only. The key idea of the presented algorithm is that it does not represent the grid as a graph and uses discrete geometric primitives to define the wave front. In its purest form, CWave requires for computation only integer arithmetics and multiplication by two, but can accumulate the distance error at turning points. A modified version of CWave with minimal usage of floating-point calculations is also developed. It allows to eliminate any accumulative errors which is proven mathematically and experimentally on several maps. The performance of the algorithm on three maps is demonstrated to be significantly faster than that of Theta*, Lazy Theta* and Field A* adapted for single-source planning. The limitations of the current implementations of the algorithm as well as potential improvements are discussed.
keywords: {Path planning;Algorithm design and analysis;Two dimensional displays;Navigation;Planning;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989733&isnumber=7988677

W. Afzal and A. A. Masoud, "Harmonic potential based communication-aware navigation and beamforming in cluttered spaces with full channel-state information," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6198-6203.
doi: 10.1109/ICRA.2017.7989734
Abstract: In this paper, we introduce a communication-aware algorithm to navigate mobile agents with non-trivial dynamics in cluttered environments. The navigation technique is based on the Harmonic Potential Field (HPF) approach to motion-planning. The proposed approach employs beamforming at the Base-Station (BS) simultaneously with the robot's motion to increase the Channel Spectral Efficiency (CSE). The approach is developed and basic proofs of performance are provided. Realistic simulations using the WINNER-II wireless channel model are used to demonstrate the navigation algorithm.
keywords: {Signal to noise ratio;Trajectory;Navigation;Wireless communication;Heuristic algorithms;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989734&isnumber=7988677

J. S. Smith and P. Vela, "PiPS: Planning in perception space," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6204-6209.
doi: 10.1109/ICRA.2017.7989735
Abstract: Path planning for mobile robots requires rapidly finding collision-free trajectories in an uncertain and changing environment. Full collision checking with detailed, online-revised representations of the robot and world imposes a delay that undermines reactive obstacle avoidance. As a result, reactive vision-based approaches make various assumptions to arrive at simplified representations, such as circular or spherical robot shapes reducible to point masses, or obstacles that always rise from the ground. We seek to avoid these problems by modeling the robot directly in perception space so that collisionfree trajectories can be sought in a consistent representation with minimal processing needs. Here perception space refers to the depth space image measurements available by modern consumer range sensors. We hallucinate a robot navigating through the world and synthesize depth images of its path for comparison against the directly sensed depth images of the local world. The approach performs collision checking in a 3D volume but only requires 2D image comparisons. Experiments show that an implementation is able to negotiate an obstacle course consisting of miscellaneous objects in real-time.
keywords: {Robot kinematics;Collision avoidance;Trajectory;Cameras;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989735&isnumber=7988677

D. Mehta, G. Ferrer and E. Olson, "Fast discovery of influential outcomes for risk-aware MPDM," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6210-6216.
doi: 10.1109/ICRA.2017.7989736
Abstract: In the Multi-Policy Decision Making (MPDM) framework, a robot's policy is elected by sampling from the distribution of current states, predicting future outcomes through forward simulation, and selecting the policy with the best expected performance. Electing the best plan depends on sampling initial conditions with influential (very high costs) outcomes. Discovering these configurations through random sampling may require drawing many samples, which becomes a performance bottleneck. In this paper, we describe a risk-aware approach which augments this sampling with an optimization process that helps discover those influential outcomes. We describe how we overcome several practical difficulties with this approach, and demonstrate significant performance improvements on a real robot platform navigating a semi-crowded, highly dynamic environment.
keywords: {Robots;Cost function;Trajectory;Decision making;Navigation;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989736&isnumber=7988677

S. Song and S. Jo, "Online inspection path planning for autonomous 3D modeling using a micro-aerial vehicle," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6217-6224.
doi: 10.1109/ICRA.2017.7989737
Abstract: In this paper, we propose a novel algorithm for planning exploration paths to generate 3D models of unknown environments by using a micro-aerial vehicle (MAV). Our algorithm initially determines a next-best-view (NBV) that maximizes information gain and plans a collision-free path to reach the NBV. Along the path, the MAV explores the greatest unknown area although it sometimes misses minor unreconstructed region, such as a hole or a sparse surface. To cover such a region, we propose an online inspection algorithm that consistently provides an optimal coverage path toward the NBV in real time. The algorithm iteratively refines an inspection path according to the acquired information until the modeling of a specific local area is complete. We evaluated the proposed algorithm by comparing it with other state-of-the-art approaches through simulated experiments. The results show that our algorithm outperforms the other approaches in both exploration and 3D modeling scenarios.
keywords: {Inspection;Three-dimensional displays;Solid modeling;Computational modeling;Path planning;Mobile robots;Planning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989737&isnumber=7988677

D. Withers and P. Newman, "Modelling scene change for large-scale long term laser localisation," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6233-6239.
doi: 10.1109/ICRA.2017.7989738
Abstract: This paper addresses a difficulty in large-scale long term laser localisation - how to deal with scene change. We pose this as a distraction suppression problem. Urban driving environments are frequently subject to large dynamic outliers, such as buses, trucks etc. These objects can mask the static elements of the prior map that we rely on for localisation. At the same time some objects change shape in a way that is less dramatic but equally pernicious during localisation - for example trees over seasons and in wind, shop fronts and doorways. In this paper, we show how we can learn in high resolution, the areas of our map that are subject to such distractions (low value data) in a place-dependent approach. We demonstrate how to utilise this model to select individual laser measurements for localisation. Specifically, by leveraging repeated operation over weeks and months, for each point in our map pointcloud we build distributions of the errors associated with that point for multiple localisation passes. These distributions are then used to determine the legitimacy of laser measurements prior to their use in localisation. We demonstrate distraction suppression as a front-end process to large scale localiser by incrementally adding 50km of error data to our base map and show that robustness is improved over the base system with a further 10km of urban driving.
keywords: {Histograms;Sensors;Three-dimensional displays;Robustness;Laser radar;Measurement by laser beam;Mathematical model},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989738&isnumber=7988677

W. Zhen, S. Zeng and S. Soberer, "Robust localization and localizability estimation with a rotating laser scanner," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6240-6245.
doi: 10.1109/ICRA.2017.7989739
Abstract: This paper presents a robust localization approach that fuses measurements from inertial measurement unit (IMU) and a rotating laser scanner. An Error State Kalman Filter (ESKF) is used for sensor fusion and is combined with a Gaussian Particle Filter (GPF) for measurements update. We experimentally demonstrated the robustness of this implementation in various challenging situations such as kidnapped robot situation, laser range reduction and various environment scales and characteristics. Additionally, we propose a new method to evaluate localizability of a given 3D map and show that the computed localizability can precisely predict localization errors, thus helps to find safe routes during flight.
keywords: {Robot sensing systems;Measurement uncertainty;Robustness;Three-dimensional displays;Atmospheric measurements;Particle measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989739&isnumber=7988677

Y. Sung and P. Tokekar, "Algorithm for searching and tracking an unknown and varying number of mobile targets using a limited FoV sensor," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6246-6252.
doi: 10.1109/ICRA.2017.7989740
Abstract: We study the problem of searching and tracking a collection of moving targets using a robot with a limited Field-of-View (FoV) sensor. The actual number of targets present in the environment is not known a priori. We propose a search and tracking framework based on the concept of Bayesian Random Finite Sets (RFSs). Specifically, we generalize the Gaussian Mixture Probability Hypothesis Density (GM-PHD) filter which was previously applied for only tracking problems to allow for simultaneous search and tracking. The proposed framework can extract individual target tracks as well as estimate the number and spatial density of the targets. We also show how to use Gaussian Process (GP) regression to extract and predict nonlinear target trajectories in this framework. We demonstrate the efficacy of our techniques through representative simulations where we also compare the performance of two active control strategies.
keywords: {Target tracking;Robot sensing systems;Radio frequency;Mathematical model;Search problems;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989740&isnumber=7988677

R. C. DuToit, J. A. Hesch, E. D. Nerurkar and S. I. Roumeliotis, "Consistent map-based 3D localization on mobile devices," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6253-6260.
doi: 10.1109/ICRA.2017.7989741
Abstract: In this paper, we seek to provide consistent, real-time 3D localization capabilities to mobile devices navigating within previously mapped areas. To this end, we introduce the Cholesky-Schmidt-Kalman filter (C-SKF), which explicitly considers the uncertainty of the prior map, by employing the sparse Cholesky factor of the map's Hessian, instead of its dense covariance-as is the case for the Schmidt-Kalman filter. By doing so, the C-SKF has memory requirements typically linear in the size of the map, as opposed to quadratic for storing the map's covariance. Moreover, and in order to bound the processing needs of the C-SKF (between linear and quadratic in the size of the map), we introduce two relaxations of the C-SKF algorithm: (i) The sC-SKF, which operates on the Cholesky factors of independent sub-maps resulting from dividing the map into overlapping segments. (ii) We formulate an efficient method for sparsifying the Cholesky factor by selecting and processing a subset of loop-closure measurements based on their temporal distribution. Lastly, we assess the processing and memory requirements of the proposed algorithms, and compare their positioning accuracy against other inconsistent map-based localization approaches that employ measurement-noise-covariance inflation to compensate for the map's uncertainty.
keywords: {Noise measurement;Measurement uncertainty;Mobile handsets;Time measurement;Uncertainty;Cameras;Q measurement},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989741&isnumber=7988677

Y. Zhou, L. Kneip and H. Li, "Semi-dense visual odometry for RGB-D cameras using approximate nearest neighbour fields," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6261-6268.
doi: 10.1109/ICRA.2017.7989742
Abstract: This paper presents a robust and efficient semidense visual odometry solution for RGB-D cameras. The core of our method is a 2D-3D ICP pipeline which estimates the pose of the sensor by registering the projection of a 3D semidense map of a reference frame with the 2D semi-dense region extracted in the current frame. The processing is speeded up by efficiently implemented approximate nearest neighbour fields under the Euclidean distance criterion, which permits the use of compact Gauss-Newton updates in the optimization. The registration is formulated as a maximum a posterior problem to deal with outliers and sensor noise, and the equivalent weighted least squares problem is consequently solved by iteratively reweighted least squares method. A variety of robust weight functions are tested and the optimum is determined based on the probabilistic characteristics of the sensor model. Extensive evaluation on publicly available RGB-D datasets shows that the proposed method predominantly outperforms existing state-of-the-art methods.
keywords: {Iterative closest point algorithm;Cameras;Three-dimensional displays;Robustness;Robot sensing systems;Two dimensional displays;Euclidean distance},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989742&isnumber=7988677

M. G. Jadidi, M. Patel and J. V. Miro, "Gaussian processes online observation classification for RSSI-based low-cost indoor positioning systems," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6269-6275.
doi: 10.1109/ICRA.2017.7989743
Abstract: In this paper, we propose a real-time classification scheme to cope with noisy Radio Signal Strength Indicator (RSSI) measurements utilized in indoor positioning systems. RSSI values are often converted to distances for position estimation. However due to multipathing and shadowing effects, finding a unique sensor model using both parametric and non-parametric methods is highly challenging. We learn decision regions using the Gaussian Processes classification to accept measurements that are consistent with the operating sensor model. The proposed approach can perform online, does not rely on a particular sensor model or parameters, and is robust to sensor failures. The experimental results achieved using hardware show that available positioning algorithms can benefit from incorporating the classifier into their measurement model as a meta-sensor modeling technique.
keywords: {Robot sensing systems;Gaussian processes;Estimation;Receivers;Nonlinear optics;Noise measurement;Feature extraction},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989743&isnumber=7988677

W. -C. Ma, S. Wang, M. A. Brubaker, S. Fidler and R. Urtasun, "Find your way by observing the sun and other semantic cues," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6292-6299.
doi: 10.1109/ICRA.2017.7989744
Abstract: In this paper we present a robust, efficient and affordable approach to self-localization which requires neither GPS nor knowledge about the appearance of the world. Towards this goal, we utilize freely available cartographic maps and derive a probabilistic model that exploits semantic cues in the form of sun direction, presence of an intersection, road type, speed limit and ego-car trajectory to produce very reliable localization results. Our experimental evaluation shows that our approach can localize much faster (in terms of driving time) with less computation and more robustly than competing approaches, which ignore semantic information.
keywords: {Sun;Roads;Semantics;Visualization;Global Positioning System;Cameras;Automobiles},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989744&isnumber=7988677

J. Surber, L. Teixeira and M. Chli, "Robust visual-inertial localization with weak GPS priors for repetitive UAV flights," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6300-6306.
doi: 10.1109/ICRA.2017.7989745
Abstract: Agile robots, such as small Unmanned Aerial Vehicles (UAVs) can have a great impact on the automation of tasks, such as industrial inspection and maintenance or crop monitoring and fertilization in agriculture. Their deploy-ability, however, relies on the UAV's ability to self-localize with precision and exhibit robustness to common sources of uncertainty in real missions. Here, we propose a new system using the UAV's onboard visual-inertial sensor suite to first build a Reference Map of the UAV's workspace during a piloted reconnaissance flight. In subsequent flights over this area, the proposed framework combines keyframe-based visual-inertial odometry with novel geometric image-based localization, to provide a real-time estimate of the UAV's pose with respect to the Reference Map paving the way towards completely automating repeated navigation in this workspace. The stability of the system is ensured by decoupling the local visual-inertial odometry from the global registration to the Reference Map, while GPS feeds are used as a weak prior for suggesting loop closures. The proposed framework is shown to outperform GPS localization significantly and diminishes drift effects via global image-based alignment for consistently robust performance.
keywords: {Global Positioning System;Estimation;Cameras;Robots;Three-dimensional displays;Optimization;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989745&isnumber=7988677

S. Agarwal, V. Shree and S. Chakravorty, "RFM-SLAM: Exploiting relative feature measurements to separate orientation and position estimation in SLAM," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6307-6314.
doi: 10.1109/ICRA.2017.7989746
Abstract: The SLAM problem is known to have a special property that when robot orientation is known, estimating the history of robot poses and feature locations can be posed as a standard linear least squares problem. In this work, we develop a SLAM framework that uses relative feature-to-feature measurements to exploit this structural property of SLAM. Relative feature measurements are used to pose a linear estimation problem for pose-to-pose orientation constraints. This is followed by solving an iterative non-linear on-manifold optimization problem to compute the maximum likelihood estimate for robot orientation given relative rotation constraints. Once the robot orientation is computed, we solve a linear problem for robot position and map estimation. Our approach reduces the computational complexity of non-linear optimization by posing a smaller optimization problem as compared to standard graph-based methods for feature-based SLAM. Further, empirical results show our method avoids catastrophic failures that arise in existing methods due to using odometery as an initial guess for non-linear optimization, while its accuracy degrades gracefully as sensor noise is increased. We demonstrate our method through extensive simulations and comparisons with an existing state-of-the-art solver.
keywords: {Simultaneous localization and mapping;Estimation;Optimization;Position measurement;Correlation;Standards;SLAM;graph-based SLAM;non-linear optimization;relative measurements},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989746&isnumber=7988677

R. Lukierski, S. Leutenegger and A. J. Davison, "Room layout estimation from rapid omnidirectional exploration," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6315-6322.
doi: 10.1109/ICRA.2017.7989747
Abstract: A new generation of practical, low-cost indoor robots is now using wide-angle cameras to aid navigation, but usually this is limited to position estimation via sparse feature-based SLAM. Such robots usually have little global sense of the dimensions, demarcation or identities of the rooms they are in, information which would be very useful to enable behaviour with much more high level intelligence. In this paper we show that we can augment an omni-directional SLAM pipeline with straightforward dense stereo estimation and simple and robust room model fitting to obtain rapid and reliable estimation of the global shape of typical rooms from short robot motions. We have tested our method extensively in real homes, offices and on synthetic data. We also give examples of how our method can extend to making composite maps of larger rooms, and detecting room transitions.
keywords: {Cameras;Estimation;Robot vision systems;Three-dimensional displays;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989747&isnumber=7988677

B. E. Nemsick, A. D. Buchan, A. Nagabandi, R. S. Fearing and A. Zakhor, "Cooperative inchworm localization with a low cost team," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6323-6330.
doi: 10.1109/ICRA.2017.7989748
Abstract: In this paper we address the problem of multi-robot localization with a heterogeneous team of low-cost mobile robots. The team consists of a single centralized observer with an inertial measurement unit (IMU) and monocular camera, and multiple picket robots with only IMUs and Red Green Blue (RGB) light emitting diodes (LED). This team cooperatively navigates a visually featureless environment while localizing all robots. A combination of camera imagery captured by the observer and IMU measurements from the pickets and observer are fused to estimate motion of the team. A team movement strategy, referred to as inchworm, is formulated as follows: Pickets move ahead of the observer and then act as temporary landmarks for the observer to follow. This cooperative approach employs a single Extended Kalman Filter (EKF) to localize the entire heterogeneous multi-robot team, using a formulation of the measurement Jacobian to relate the pose of the observer to the poses of the pickets with respect to the global reference frame. An initial experiment with the inchworm strategy has shown localization within 0.14 m position error and 2.18° orientation error over a path-length of 5 meters in an environment with irregular ground, partial occlusions, and a ramp. This demonstrates improvement over a camera-only localization technique that was adapted to our team dynamic which produced 0.18m position error and 3.12° orientation error over the same dataset. In addition, we demonstrate improvement in localization accuracy with an increasing number of picket robots.
keywords: {Observers;Robot kinematics;Cameras;Robot vision systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989748&isnumber=7988677

D. Fourie, S. Claassens, S. Pillai, R. Mata and J. Leonard, "SLAMinDB: Centralized graph databases for mobile robotics," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6331-6337.
doi: 10.1109/ICRA.2017.7989749
Abstract: Robotic systems typically require memory recall mechanisms for a variety of tasks including localization, mapping, planning, visualization etc. We argue for a novel memory recall framework that enables more complex inference schemas by separating the computation from its associated data. In this work we propose a shared, centralized data persistence layer that maintains an ensemble of online, situationally-aware robot states. This is realized through a queryable graph-database with an accompanying key-value store for larger data. In turn, this approach is scalable and enables a multitude of capabilities such as experience-based learning and long-term autonomy. Using multi-modal simultaneous localization and mapping and a few example use-cases, we demonstrate the versatility and extensible nature that centralized persistence and SLAMinDB can provide. In order to support the notion of life-long autonomy, we envision robots to be endowed with such a persistence model, enabling them to revisit previous experiences and improve upon their existing task-specific capabilities.
keywords: {Simultaneous localization and mapping;Computer architecture;Relational databases;Navigation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989749&isnumber=7988677

F. Gao and S. Shen, "Quadrotor trajectory generation in dynamic environments using semi-definite relaxation on nonconvex QCQP," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6354-6361.
doi: 10.1109/ICRA.2017.7989750
Abstract: In this paper, we present an optimization-based framework for generating quadrotor trajectories which are free of collision in dynamic environments with both static and moving obstacles. Using the finite-horizon motion prediction of moving obstacles, our method is able to generate safe and smooth trajectories with minimum control efforts. Our method optimizes trajectories globally for all observed moving and static obstacles, such that the avoidance behavior is most unnoticeable. This method first utilizes semi-definite relaxation on a quadratically constrained quadratic programming (QCQP) problem to eliminate the nonconvex constraints in the moving obstacle avoidance problem. A feasible and reasonably good solution to the original nonconvex problem is obtained using a randomization method and convex linear restriction. We detail the trajectory generation formulation and the solving procedure of the nonconvex quadratic program. Our approach is validated by both simulation and experimental results.
keywords: {Trajectory;Planning;Collision avoidance;Dynamics;Quadratic programming;Automobiles;Vehicle dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989750&isnumber=7988677

H. Seo, S. Kim and H. J. Kim, "Aerial grasping of cylindrical object using visual servoing based on stochastic model predictive control," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6362-6368.
doi: 10.1109/ICRA.2017.7989751
Abstract: This paper concentrates on design of a vision-based guidance command for aerial manipulation of a cylindrical object, using a stochastic model predictive approach. We first develop an image-based cylinder detection algorithm that utilizes a geometric characteristic of perspectively projected circles in 3D space. To enforce the object to be located inside sight of a camera, we formulate a visual servoing problem as a stochastic model predictive control (MPC) framework. By regarding x and y axes rotational velocities as stochastic variables, we guarantee the visibility of the camera considering underactuation of the system. We also provide experimental results that validate effectiveness of the proposed algorithm.
keywords: {Cameras;Visual servoing;Stochastic processes;Manipulator dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989751&isnumber=7988677

P. Chakravarty, K. Kelchtermans, T. Roussel, S. Wellens, T. Tuytelaars and L. Van Eycken, "CNN-based single image obstacle avoidance on a quadrotor," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6369-6374.
doi: 10.1109/ICRA.2017.7989752
Abstract: This paper demonstrates the use of a single forward facing camera for obstacle avoidance on a quadrotor. We train a CNN for estimating depth from a single image. The depth map is then fed to a behaviour arbitration based control algorithm that steers the quadrotor away from obstacles. We conduct experiments with simulated and real drones in a variety of environments.
keywords: {Drones;Collision avoidance;Cameras;Training;Indoor environments;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989752&isnumber=7988677

M. Tognon, B. Yüksel, G. Buondonno and A. Franchi, "Dynamic decentralized control for protocentric aerial manipulators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6375-6380.
doi: 10.1109/ICRA.2017.7989753
Abstract: We present a control methodology for underactuated aerial manipulators that is both easy to implement on real systems and able to achieve highly dynamic behaviors. The method is composed by two parts: i) a nominal input/state trajectory generator that takes into account the full-body dynamics of the system exploiting its differential flatness property; ii) a decentralized feedback controller acting on the actuated degrees of freedom that confers the needed robustness to the closed-loop system. We demonstrate that the proposed controller is able to precisely track dynamic trajectories when implemented on a standard hardware. Comparative experiments clearly show the benefit of using the nominal input/state generator.
keywords: {Manipulator dynamics;Torque;Trajectory;Actuators;System dynamics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989753&isnumber=7988677

P. Morere, R. Marchant and F. Ramos, "Sequential Bayesian optimization as a POMDP for environment monitoring with UAVs," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6381-6388.
doi: 10.1109/ICRA.2017.7989754
Abstract: Bayesian Optimization has gained much popularity lately, as a global optimization technique for functions that are expensive to evaluate or unknown a priori. While classical BO focuses on where to gather an observation next, it does not take into account practical constraints for a robotic system such as where it is physically possible to gather samples from, nor the sequential nature of the problem while executing a trajectory. In field robotics and other real-life situations, physical and trajectory constraints are inherent problems. This paper addresses these issues by formulating Bayesian Optimization for continuous trajectories within a Partially observable Markov Decision Process (POMDP) framework. The resulting POMDP is solved using Monte-Carlo Tree Search (MCTS), which we adapt to using a reward function balancing exploration and exploitation. Experiments on monitoring a spatial phenomenon with a UAV illustrate how our BO-POMDP algorithm outperforms competing techniques.
keywords: {Trajectory;Robots;Planning;Optimization;Monitoring;Uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989754&isnumber=7988677

J. E. Low, L. T. S. Win, D. S. B. Shaiful, C. H. Tan, G. S. Soh and S. Foong, "Design and dynamic analysis of a Transformable Hovering Rotorcraft (THOR)," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6389-6396.
doi: 10.1109/ICRA.2017.7989755
Abstract: This paper describes the Transformable HOvering Rotorcraft (THOR), a prototype Unmanned Aerial Vehicle (UAV) that explores a novel approach in combining the range and speed of a horizontal flying platform with the hovering and maneuverability of a rotor-wing. This is achieved by integrating a tailless flying wing configuration with a single-axis rotor, or monocopter. By maintaining full utilization of all aerodynamic surfaces and propulsion sources in both flight modes, this method represents the most structurally efficient approach to achieving a cruising mode and a hovering mode on the same frame. Using a dual servo and motor configuration, we propose an under-actuated system that is able to achieve controllability in 4 degrees of freedom while in its horizontal cruising mode and in 5 degrees of freedom while in its hovering mode. In both indoor and outdoor experiments, the UAV is able to transition between either flight modes seamlessly and repeatedly without the need for any additional mechanisms and actuators.
keywords: {Aerodynamics;Blades;Unmanned aerial vehicles;Propulsion;Drag;Torque;Force},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989755&isnumber=7988677

H. Kato, N. Tanishima, K. Yanagase, T. Tsumaki and S. Mitani, "Distance control of rocket-propelled miniature exploration robot," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6397-6403.
doi: 10.1109/ICRA.2017.7989756
Abstract: A rocket-propelled miniature robot is capable to explore sites that planetary rovers cannot reach with efficiency in locomotion distance per mass. The technical difficulty is the significant variance in its flight distance because of two factors: sensitivity of error in the center of gravity with respect to the thrust axis, and solid rocket engines deviance in thrusting force. To overcome the issue, our flight distance control strategy includes flight trajectory forming, and the flight trajectory prediction including the opposing shot. With our method, we experimentally showed the flight distance to the forward direction improved by a factor of four in variance reduction.
keywords: {Mobile robots;Engines;Wheels;Rockets;Force;Robot kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989756&isnumber=7988677

T. Funatomi, M. Iiyama, K. Kakusho and M. Minoh, "Regression of 3D rigid transformations on real-valued vectors in closed form," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6412-6419.
doi: 10.1109/ICRA.2017.7989757
Abstract: In this paper, we present a regression for predicting 3D rigid transformations from real-valued vectors. We use a unit dual quaternion to represent the transformation. The regression is formulated as blending unit dual quaternions. To formulate it in a closed form, we introduce an approximation based on error metrics according to geometric algebra. Finally, we take an articulated motion and an elastic deformation as examples to present the descriptive power of our method in modeling the motion and the deformation.
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989757&isnumber=7988677

W. Sun, N. Sood, D. Dey, G. Ranade, S. Prakash and A. Kapoor, "No-regret replanning under uncertainty," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6420-6427.
doi: 10.1109/ICRA.2017.7989758
Abstract: This paper explores the problem of path planning under uncertainty. Specifically, we consider online receding horizon based planners that need to operate in a latent environment where the latent information can be modelled via Gaussian Processes. Online path planning in latent environments is challenging since the robot needs to explore the environment to get a more accurate model of latent information for better planning later and also achieves the task as quick as possible. We propose UCB style algorithms that are popular in the bandit settings and show how those analyses can be adapted to the online robotic path planning problems. The proposed algorithm trades-off exploration and exploitation in near-optimal manner and has appealing no-regret properties. We demonstrate the efficacy of the framework on the application of aircraft flight path planning when the winds are partially observed.
keywords: {Robots;Trajectory;Uncertainty;Planning;Libraries;Algorithm design and analysis;Computational modeling},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989758&isnumber=7988677

J. Umlauft, Y. Fanger and S. Hirche, "Bayesian uncertainty modeling for programming by demonstration," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6428-6434.
doi: 10.1109/ICRA.2017.7989759
Abstract: Programming by Demonstration allows to transfer skills from human demonstrators to robotic systems by observation and reproduction. One aspect that is often overlooked is that humans show different trajectories over multiple demonstrations for the same task. Observed movements may be more precise in some phases and more diverse in others. It is well-known that the variability of the execution carries important information about the task. Therefore, we propose a Bayesian approach to model uncertainties from training data and to infer them in regions with sparse information. The approach is validated in simulation, where it shows higher precision than existing methods, and a robotic experiment with variance based impedance adaptation.
keywords: {Uncertainty;Training data;Training;Covariance matrices;Robots;Optimization;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989759&isnumber=7988677

A. Gabriel, R. Akrour, J. Peters and G. Neumann, "Empowered skills," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6435-6441.
doi: 10.1109/ICRA.2017.7989760
Abstract: Robot Reinforcement Learning (RL) algorithms return a policy that maximizes a global cumulative reward signal but typically do not create diverse behaviors. Hence, the policy will typically only capture a single solution of a task. However, many motor tasks have a large variety of solutions and the knowledge about these solutions can have several advantages. For example, in an adversarial setting such as robot table tennis, the lack of diversity renders the behavior predictable and hence easy to counter for the opponent. In an interactive setting such as learning from human feedback, an emphasis on diversity gives the human more opportunity for guiding the robot and to avoid the latter to be stuck in local optima of the task. In order to increase diversity of the learned behaviors, we leverage prior work on intrinsic motivation and empowerment. We derive a new intrinsic motivation signal by enriching the description of a task with an outcome space, representing interesting aspects of a sensorimotor stream. For example, in table tennis, the outcome space could be given by the return position and return ball speed. The intrinsic motivation is now given by the diversity of future outcomes, a concept also known as empowerment. We derive a new policy search algorithm that maximizes a trade-off between the extrinsic reward and this intrinsic motivation criterion. Experiments on a planar reaching task and simulated robot table tennis demonstrate that our algorithm can learn a diverse set of behaviors within the area of interest of the tasks.
keywords: {Robot sensing systems;Entropy;Optimization;Predictive models;Trajectory;Standards},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989760&isnumber=7988677

F. End, R. Akrour, J. Peters and G. Neumann, "Layered direct policy search for learning hierarchical skills," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6442-6448.
doi: 10.1109/ICRA.2017.7989761
Abstract: Solutions to real world robotic tasks often require complex behaviors in high dimensional continuous state and action spaces. Reinforcement Learning (RL) is aimed at learning such behaviors but often fails for lack of scalability. To address this issue, Hierarchical RL (HRL) algorithms leverage hierarchical policies to exploit the structure of a task. However, many HRL algorithms rely on task specific knowledge such as a set of predefined sub-policies or sub-goals. In this paper we propose a new HRL algorithm based on information theoretic principles to autonomously uncover a diverse set of sub-policies and their activation policies. Moreover, the learning process mirrors the policys structure and is thus also hierarchical, consisting of a set of independent optimization problems. The hierarchical structure of the learning process allows us to control the learning rate of the sub-policies and the gating individually and add specific information theoretic constraints to each layer to ensure the diversification of the sub-policies. We evaluate our algorithm on two high dimensional continuous tasks and experimentally demonstrate its ability to autonomously discover a rich set of sub-policies.
keywords: {Optimization;Estimation;Entropy;Mixture models;Robots;Learning (artificial intelligence);Complexity theory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989761&isnumber=7988677

S. Park, J. Wang and S. Kenji, "On-line Bayesian regression mixture model for robot model learning," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6449-6454.
doi: 10.1109/ICRA.2017.7989762
Abstract: The performance of a robot system heavily relies on its model. The present paper proposes an efficient online Bayesian regression algorithm based on Gaussian Mixture Model. By using the mixture model of local Gaussian experts, the algorithm decouples global correlation of data and achieves linear computational cost to the size of the local model set. The proposed algorithm also realizes on-line implementation. To manage the size of local model on-the-fly, a strategy of adding and pruning local model based on a probabilistic criteria is proposed. Additionally, a forgetting strategy to treat outliers and non-stationary system is suggested. In the end, the algorithm achieved comparable results to other on-line regression algorithms.
keywords: {Data models;Computational modeling;Bayes methods;Mixture models;Robots;Adaptation models;Ground penetrating radar},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989762&isnumber=7988677

T. Wilson and S. B. Williams, "Active sample selection in scalar fields exhibiting non-stationary noise with parametric heteroscedastic Gaussian process regression," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6455-6462.
doi: 10.1109/ICRA.2017.7989763
Abstract: This paper considers the modelling of scalar fields exhibiting non-stationary noise in the context of Gaussian Process (GP) regression. We show how a Heteroscedastic GP produces more accurate predictions of the variance of a process of this type compared to the standard Homoscedastic model. We present a parametric model for the noise process and derive analytical solutions to the Log Marginal Likelihood of the data and its gradients with respect to Hyper Parameters of the kernel and the noise process. We compare our parametric model to one which estimates a full GP for the noise and show analogous predictive performance with a model which has greater computational efficiency and is less complex to implement. We also discuss active sample selection in this framework and show through the numerical simulation of an arrested bathymetric front in an estuary, the superiority of using Mutual Information to Fisher Information, Entropy or Random sampling in terms of errors in the first two moments of the predicted distributions.
keywords: {Computational modeling;Kernel;Predictive models;Standards;Biological system modeling;Gaussian processes;Data models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989763&isnumber=7988677

N. Hirose and R. Tajima, "Modeling of rolling friction by recurrent neural network using LSTM," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6471-6478.
doi: 10.1109/ICRA.2017.7989764
Abstract: The modeling and identification of a mechanical system is the most important issue for many control systems in order to realize the desired control specifications. In particular, the friction characteristics often deteriorate the control performance, such as in the fast and precise positioning performance in industrial robots, the force estimation accuracy based on a disturbance observer, and the posture control performance of an inverted pendulum robot. Rolling friction tends to cause overshoot, undershoot, or limit cycles of the target value in positioning systems. In previous research, some model structures for rolling friction have been proposed to express the hysteresis characteristics in order to overcome these control issues. However, it is difficult to identify the correct parameters for precise modeling. In this paper, the modeling of rolling friction based on a Recurrent Neural Network (RNN) using Long Short-Term Memory (LSTM) is proposed to precisely express the rolling friction characteristics. The initial value design of the RNN during supervised learning is also presented to achieve a better model. The effectiveness of the proposed approach is verified by comparison with conventional friction models using an actual experimental setup.
keywords: {Friction;Training;Torque;Hysteresis motors;Recurrent neural networks;Hysteresis;Supervised learning},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989764&isnumber=7988677

J. Rehder, J. Nikolic, T. Schneider and R. Siegwart, "A direct formulation for camera calibration," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6479-6486.
doi: 10.1109/ICRA.2017.7989765
Abstract: Conventional camera calibration techniques rely on discrete reference points extracted from a set of input images. While these approaches have been applied successfully for a long time, omitting all image information apart from reference point positions at the initial stage of the calibration pipeline renders correct treatment of uncertainties difficult and gives rise to complications in timestamping measurements in applications where exposure time cannot be neglected. Drawing inspiration from visual state estimation, we employ a direct formulation of the camera measurement model. To this end, we render a view of the target given all calibration parameters, enabling a maximum likelihood estimator formulated on image intensities as measurements. We demonstrate the advantages of avoiding abstraction from image measurements for determining the line delay of a rolling shutter camera and by estimating camera exposure time from motion blur.
keywords: {Cameras;Calibration;Measurement uncertainty;Visualization;Uncertainty;Radiometry;Optimization},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989765&isnumber=7988677

T. Schneider, M. Li, M. Burri, J. Nieto, R. Siegwart and I. Gilitschenski, "Visual-inertial self-calibration on informative motion segments," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6487-6494.
doi: 10.1109/ICRA.2017.7989766
Abstract: Environmental conditions and external effects, such as shocks, have a significant impact on the calibration parameters of visual-inertial sensor systems. Thus long-term operation of these systems cannot fully rely on factory calibration. Since the observability of certain parameters is highly dependent on the motion of the device, using short data segments at device initialization may yield poor results. When such systems are additionally subject to energy constraints, it is also infeasible to use full-batch approaches on a big dataset and careful selection of the data is of high importance. In this paper, we present a novel approach for resource efficient self-calibration of visual-inertial sensor systems. This is achieved by casting the calibration as a segment-based optimization problem that can be run on a small subset of informative segments. Consequently, the computational burden is limited as only a predefined number of segments is used. We also propose an efficient information-theoretic selection to identify such informative motion segments. In evaluations on a challenging dataset, we show our approach to significantly outperform state-of-the-art in terms of computational burden while maintaining a comparable accuracy.
keywords: {Calibration;Cameras;Motion segmentation;Gyroscopes;Accelerometers;Sensor systems;Trajectory},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989766&isnumber=7988677

A. Khosravian, T. Chin and I. Reid, "A branch-and-bound algorithm for checkerboard extraction in camera-laser calibration," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6495-6502.
doi: 10.1109/ICRA.2017.7989767
Abstract: We address the problem of camera-to-laserscanner calibration using a checkerboard and multiple imagelaser scan pairs. Distinguishing which laser points measure the checkerboard and which lie on the background is essential to any such system. We formulate the checkerboard extraction as a combinatorial optimization problem with a clear cut objective function. We propose a branch-and-bound technique that deterministically and globally optimizes the objective. Unlike what is available in the literature, the proposed method is not heuristic and does not require assumptions such as constraints on the background or relying on discontinuity of the range measurements to partition the data into line segments. The proposed approach is generic and can be applied to both 3D or 2D laser scanners as well as the cases where multiple checkerboards are present. We demonstrate the effectiveness of the proposed approach by providing numerical simulations as well as experimental results.
keywords: {Lasers;Cameras;Calibration;Measurement by laser beam;Two dimensional displays;Three-dimensional displays;Linear programming},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989767&isnumber=7988677

R. Khanna, I. Sa, J. Nieto and R. Siegwart, "On field radiometric calibration for multispectral cameras," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6503-6509.
doi: 10.1109/ICRA.2017.7989768
Abstract: Perception systems for outdoor robotics have to deal with varying environmental conditions. Variations in illumination in particular, are currently the biggest challenge for vision-based perception. In this paper we present an approach for radiometric characterization of multispectral cameras. To enable spatio-temporal mapping we also present a procedure for in-situ illumination estimation, resulting in radiometric calibration of the collected images. In contrast to current approaches, we present a purely data driven, parameter free approach, based on maximum likelihood estimation which can be performed entirely on the field, without requiring specialised laboratory equipment. Our routine requires three simple datasets which are easily acquired using most modern multispectral cameras. We evaluate the framework with a cost-effective snapshot multispectral camera. The results show that our method enables the creation of quatitatively accurate relative reflectance images with challenging on field calibration datasets under a variety of ambient conditions.
keywords: {Cameras;Calibration;Lighting;Lenses;Optical attenuators;Optical imaging;Optical sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989768&isnumber=7988677

J. J. Park, S. Lee and B. Kuipers, "Discrete-time dynamic modeling and calibration of differential-drive mobile robots with friction," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6510-6517.
doi: 10.1109/ICRA.2017.7989769
Abstract: Fast and high-fidelity dynamic model is very useful for planning, control, and estimation. Here, we present a fixed-time-step, discrete-time dynamic model of differential-drive vehicle with friction for reliable velocity prediction, which is fast, stable, and easy to calibrate. Unlike existing methods which are predominantly formulated in the continuous-time domain (very often ignoring dry friction) that require numerical solver for digital implementation, our model is formulated directly in a fixed-time-step discrete-time setting, which greatly simplifies the implementation and minimizes computational cost. We also explicitly take into account friction, using the stable formulation developed by Kikuuwe [1]. Friction model, while non-trivial to implement, is necessary for predicting wheel locks and velocity steady-states which occur in real physical systems. In this paper, we present our dynamic model and evaluate it on a physical platform, a commercially-available electric powered wheelchair. We show that our model, which can run over 105 times faster than real-time on a typical laptop, can accurately predict linear and angular velocities without drift. The calibration of our model requires only a time-series of wheel speed measurements (via encoders) and command inputs, making it readily deployable to physical mobile robots.
keywords: {Friction;Wheels;Vehicle dynamics;Numerical models;Load modeling;Steady-state;DC motors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989769&isnumber=7988677

K. Ayusawa, A. Rioux, E. Yoshida, G. Venture and M. Gautier, "Generating persistently exciting trajectory based on condition number optimization," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6518-6524.
doi: 10.1109/ICRA.2017.7989770
Abstract: This paper presents a novel optimization method for generating persistently exciting trajectories for inertial parameters identification of a robot. The exciting performance of the trajectories is usually evaluated by the condition number of the regressor matrix, which appears in the linear regression model for identification. In this paper, the efficient formulation is presented to directly compute the gradient of the condition number with respect to joint trajectory parameters, by deriving the derivative of the singular values and regressor matrices. Direct gradient computation can enhance computational performance of optimization, which is essential for large DOF systems under many physical consistent conditions such as humanoid robots. The proposed method is validated by generating several trajectories for the humanoid robot HRP-4.
keywords: {Trajectory;Humanoid robots;Cost function;Matrix decomposition;Symmetric matrices},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989770&isnumber=7988677

F. Nobre, M. Kasper and C. Heckman, "Drift-correcting self-calibration for visual-inertial SLAM," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6525-6532.
doi: 10.1109/ICRA.2017.7989771
Abstract: We present a solution for online simultaneous localization and mapping (SLAM) self-calibration in the presence of drift in calibration parameters in order to support accurate long-term operation. Calibration parameters such as the camera focal length or camera-to-IMU extrinsics are frequently subject to drift over long periods of operation, inducing cumulative error in the reconstruction. The key contributions are modeling calibration parameters as a spatiotemporal quantity: sensor-to-sensor spatial calibration and sensor intrinsic parameters are continuously time-varying, with statistical tests for change detection and regression. An analysis of the long term effects of inappropriately modeling time-varying sensor calibration is also provided. Constant-time operation is achieved by selecting only a fixed number of informative segments of the trajectory for calibration parameter estimation, giving the added benefit of avoiding early linearization errors by not rolling past measurements into a prior distribution. Our approach is validated with simulated and real-world data.
keywords: {Calibration;Cameras;Trajectory;Simultaneous localization and mapping;Two dimensional displays;Measurement uncertainty},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989771&isnumber=7988677

H. -C. Wang, R. K. Katzschmann, S. Teng, B. Araki, L. Giarré and D. Rus, "Enabling independent navigation for visually impaired people through a wearable vision-based feedback system," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6533-6540.
doi: 10.1109/ICRA.2017.7989772
Abstract: This work introduces a wearable system to provide situational awareness for blind and visually impaired people. The system includes a camera, an embedded computer and a haptic device to provide feedback when an obstacle is detected. The system uses techniques from computer vision and motion planning to (1) identify walkable space; (2) plan step-by-step a safe motion trajectory in the space, and (3) recognize and locate certain types of objects, for example the location of an empty chair. These descriptions are communicated to the person wearing the device through vibrations. We present results from user studies with low- and high-level tasks, including walking through a maze without collisions, locating a chair, and walking through a crowded environment while avoiding people.
keywords: {Navigation;Three-dimensional displays;Vibrations;Cameras;Legged locomotion;Robot sensing systems;Haptic interfaces},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989772&isnumber=7988677

T. M. Benz and V. Nitsch, "Using multisensory cues for direction information in teleoperation: More is not always better," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6541-6546.
doi: 10.1109/ICRA.2017.7989773
Abstract: When full automation of mobile robots is not possible or desirable, teleoperation constitutes an alternative. The human operator can be supported with direction cues to facilitate localization or navigation. These cues are presented typically in the auditory, haptic and/or visual modality. An experiment was conducted to evaluate systematically and empirically the (uni-modal and multi-modal) effects of auditory and haptic feedback compared to visual feedback on target localization accuracy. Results show that haptic as well as auditory direction cues lead to significantly lower accuracy than visual cues. Moreover, combining feedback cues does not necessarily lead to better performance and can even reduce accuracy. Based on the results, possible implications for multi-modal human machine interface design are discussed.
keywords: {Haptic interfaces;Visualization;Navigation;Force;Robots;Spatial resolution;Analytical models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989773&isnumber=7988677

L. Marchegiani and I. Posner, "Leveraging the urban soundscape: Auditory perception for smart vehicles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6547-6554.
doi: 10.1109/ICRA.2017.7989774
Abstract: Urban environments are characterised by the presence of distinctive audio signals which alert the drivers to events that require prompt action. The detection and interpretation of these signals would be highly beneficial for smart vehicle systems, as it would provide them with complementary information to navigate safely in the environment. In this paper, we present a framework that spots the presence of acoustic events, such as horns and sirens, using a two-stage approach. We first model the urban soundscape and use anomaly detection to identify the presence of an anomalous sound, and later determine the nature of this sound. As the audio samples are affected by copious non-stationary and unstructured noise, which can degrade classification performance, we propose a noise-removal technique to obtain a clean representation of the data we can use for classification and waveform reconstruction. The method is based on the idea of analysing the spectrograms of the incoming signals as images and applying spectrogram segmentation to isolate and extract the alerting signals from the background noise. We evaluate our framework on four hours of urban sounds collected driving around urban Oxford on different kinds of road and in different traffic conditions. When compared to traditional feature representations, such as Mel-frequency cepstrum coefficients, our framework shows an improvement of up to 31% in the classification rate.
keywords: {Acoustics;Spectrogram;Noise measurement;Image reconstruction;Hidden Markov models;Training;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989774&isnumber=7988677

H. Chang, Y. Na, S. J. Kim and J. Kim, "Stochastic sEMG processor based manipulator control toward man-machine interface with minimal electro-mechanical delay," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6555-6561.
doi: 10.1109/ICRA.2017.7989775
Abstract: Inspired from Hogan's myoelectric processor in 1980, this study presents a stochastic sEMG processing method to estimate the muscle activation level for manipulator control. Hogan's previous study showed the feasibility to estimate the muscle activation level with multi-channel sEMG under static force condition. However, it is difficult to continuously estimate muscle activation during dynamic contraction because of the nonlinear effects by the time-varying nature of sEMG. To enhance the performance of high SNR and rapid response in force-varying contraction, we propose a new method with statistical analysis extended from a whitening method of Hogan's study. The signals from eight sEMG channels were used to estimate the muscle activation level during isometric force-varying contractions. Experimentally, a two-DoF manipulator was controlled by input signals from the estimated muscle activation signal.
keywords: {Muscles;Electrodes;Force;Sociology;Statistics;Estimation;Manipulators},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989775&isnumber=7988677

K. Li and J. W. Burdick, "Clinical patient tracking in the presence of transient and permanent occlusions via geodesic feature," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6562-6569.
doi: 10.1109/ICRA.2017.7989776
Abstract: This paper develops a method to use RGB-D cameras to track the motions of a human spinal cord injury patient undergoing spinal stimulation and physical rehabilitation. Because clinicians must remain close to the patient during training sessions, the patient is usually under permanent and transient occlusions due to the training equipment and the movements of the attending clinicians. These occlusions can significantly degrade the accuracy of existing human tracking methods. To improve the data association problem in these circumstances, we present a new global feature based on the geodesic distances of surface mesh points to a set of anchor points. Transient occlusions are handled via a multi-hypothesis tracking framework. To evaluate the method, we simulated different occlusion sizes on a data set captured from a human in varying movement patterns, and compared the proposed feature with other tracking methods. The results show that the proposed method achieves robustness to both surface deformations and transient occlusions.
keywords: {Tracking;Transient analysis;Training;Cameras;Three-dimensional displays;Robustness;Sensors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989776&isnumber=7988677

A. F. Salazar-Gomez, J. DelPreto, S. Gil, F. H. Guenther and D. Rus, "Correcting robot mistakes in real time using EEG signals," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6570-6577.
doi: 10.1109/ICRA.2017.7989777
Abstract: Communication with a robot using brain activity from a human collaborator could provide a direct and fast feedback loop that is easy and natural for the human, thereby enabling a wide variety of intuitive interaction tasks. This paper explores the application of EEG-measured error-related potentials (ErrPs) to closed-loop robotic control. ErrP signals are particularly useful for robotics tasks because they are naturally occurring within the brain in response to an unexpected error. We decode ErrP signals from a human operator in real time to control a Rethink Robotics Baxter robot during a binary object selection task. We also show that utilizing a secondary interactive error-related potential signal generated during this closed-loop robot task can greatly improve classification performance, suggesting new ways in which robots can acquire human feedback. The design and implementation of the complete system is described, and results are presented for realtime closed-loop and open-loop experiments as well as offline analysis of both primary and secondary ErrP signals. These experiments are performed using general population subjects that have not been trained or screened. This work thereby demonstrates the potential for EEG-based feedback methods to facilitate seamless robotic control, and moves closer towards the goal of real-time intuitive interaction.
keywords: {Electroencephalography;Real-time systems;Collaboration;Training;Visualization;Mobile robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989777&isnumber=7988677

B. Hayes and J. A. Shah, "Interpretable models for fast activity recognition and anomaly explanation during collaborative robotics tasks," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6586-6593.
doi: 10.1109/ICRA.2017.7989778
Abstract: In this paper, we present Rapid Activity Prediction Through Object-oriented Regression (RAPTOR), a scalable method for performing rapid, real-time activity recognition and prediction that achieves state-of-the-art classification accuracy on both a generic human activity dataset and two domain-specific collaborative robotics manufacturing datasets. Our approach is designed to be human-interpretable: able to provide explanations for its reasoning such that non-experts can better understand and improve its activity models. We incorporate methods to increase RAPTOR's resilience against confusion due to temporal variations, as well as against learning false correlations between features. We report full and partial trajectory classification results across three datasets and conclude by demonstrating our model's ability to provide interpretable explanations of its reasoning using outlier detection techniques.
keywords: {Trajectory;Object oriented modeling;Activity recognition;Hidden Markov models;Robots;Collaboration;Training},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989778&isnumber=7988677

J. Yu, D. Jin and L. Zhang, "Mobile paramagnetic nanoparticle-based vortex for targeted cargo delivery in fluid," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6594-6599.
doi: 10.1109/ICRA.2017.7989779
Abstract: Microrobots are considered as potential candidates for targeted delivery of cargos, drugs and even energy with high precision. One interesting phenomenon is their collective behaviour actuated by dynamic fields, which is yet to be adequately studied. Herein, we report a novel method of using millions of magnetic nanoparticles to generate a dynamic-equilibrium particle-based vortex, which can manipulate multiple cargos simultaneously at the microscale. The governing physical laws of the generation of a particle-based vortex are explained and the experimental results are presented. The high effectiveness of this micro-vortex-based method of particle gathering is testified. Moreover, the vortex can be navigated near a solid surface in a controlled manner. The velocity and morphology of the mobile vortices with different pitch angles are investigated, showing that the vortex moving with small pitch angles is capable of maintaining the original shape and coverage area. Collecting and transporting multiple polystyrene (PS) microbeads into a channel using the vortex are also demonstrated. This method allows us to perform micromanipulation using the collective behaviour of nanoparticles and to develop new strategies for the formation and control of the microrobotic swarm.
keywords: {Magnetic resonance imaging;Magnetic susceptibility;Magnetosphere;Force;Magnetic nanoparticles;Mobile communication;microrobot;vortex;collective behaviour;targeted delivery;magnetic nanoparticle},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989779&isnumber=7988677

X. Wang et al., "Three-dimensional robotic control of a 5-micrometer magnetic bead for intra-embryonic navigation and measurement," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6600-6605.
doi: 10.1109/ICRA.2017.7989780
Abstract: Magnetic micromanipulation has the advantage of untethered control, high precision, and biocompatibility and has recently undergone great advances. The magnetic micromanipulation task to tackle in this work is to three-dimensionally navigate a 5-micrometer magnetic bead inside a mouse embryo and perform mechanical measurements at multiple locations. Existing technologies are not able to achieve these navigation and measurement goals because of poor magnetic force scaling and/or lacking the capability of applying an accurately controlled force. This paper reports a robotic magnetic tweezer system that enables, for the first time, intra- embryonic magnetic navigation and force application. A single magnetic bead was introduced into a mouse embryo via robotic microinjection. The robotic magnetic tweezer system accurately controls the position of the magnetic bead via visually servoed magnetic control. The system is also capable of applying forces up to 120 pN with a resolution of 1.78 pN for performing mechanical measurements on the cellular structures inside the mouse embryo, revealing that the middle region is more deformable than the side regions of the inner cell mass.
keywords: {Magnetosphere;Magnetic resonance imaging;Force;Embryo;Magnetic noise;Magnetic shielding;Magnetic levitation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989780&isnumber=7988677

S. Liang, M. Boudaoud, B. Cagneau and S. Régnier, "Velocity characterization and control strategies for nano-robotic systems based on piezoelectric stick-slip actuators," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6606-6611.
doi: 10.1109/ICRA.2017.7989781
Abstract: Nano-robotic systems based on Piezoelectric StickSlip (PSS) actuators have become increasingly popular in research and industry for semi-automated and automated tasks at small scales. For an efficient use of PSS actuators, a series of research have been fulfilled on design process, dynamic modeling, driving methods and position control. However, there have been very few investigations on velocity control of PSS actuators. Velocity control is important to enable the nano-robotic system to generate a smooth and efficient motion and to avoid the undesired inertial shock of the end effector. This paper deals with velocity characterization and control strategies for nano-robotic systems based on PSS actuators. The range of achievable velocities on PSS actuators is studied in air and vacuum environments. This analysis allows the definition of a detailed map of the velocity characteristics in forward and backward directions of motion. Velocity control strategies are then studied based on an instantaneous velocity feedback and an average velocity feedback. Results of the proposed method show the first experimental demonstration of velocity control for PSS actuators in medium and high speed configurations opening new perspectives on the use of nano-robotic systems in dynamic automated tasks.
keywords: {Actuators;Velocity control;Friction;Voltage control;Dynamics;Frequency control},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989781&isnumber=7988677

X. Dong and M. Sitti, "Planning spin-walking locomotion for automatic grasping of microobjects by an untethered magnetic microgripper," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6612-6618.
doi: 10.1109/ICRA.2017.7989782
Abstract: Most demonstrated mobile microrobot tasks so far have been achieved via pick-and-placing and dynamic trapping with teleoperation or simple path following algorithms. In our previous work, an untethered magnetic microgripper has been developed which has advanced functions, such as gripping objects. Both teleoperated manipulation in 2D and 3D have been demonstrated. However, it is challenging to control the magnetic microgripper to carry out manipulation tasks, because the grasping of objects so far in the literature relies heavily on teleoperation, which takes several minutes with even a skilled human expert. Here, we propose a new spin-walking locomotion and an automated 2D grasping motion planner for the microgripper, which enables time-efficient automatic grasping of microobjects that has not been achieved yet for untethered microrobots. In its locomotion, the microgripper repeatedly rotates about two principal axes to regulate its pose and move precisely on a surface. The motion planner could plan different motion primitives for grasping and compensate the uncertainties in the motion by learning the uncertainties and planning accordingly. We experimentally demonstrated that, using the proposed method, the microgripper could align to the target pose with error less than 0.1 body length and grip the objects within 40 seconds. Our method could significantly improve the time efficiency of micro-scale manipulation and have potential applications in microassembly and biomedical engineering.
keywords: {Grippers;Planning;Grasping;Magnetic heads;Micromagnetics;Two dimensional displays;Torque},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989782&isnumber=7988677

T. Hayakawa and F. Arai, "On-chip micromanipulation method based on mode switching of vibration-induced asymmetric flow," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6631-6636.
doi: 10.1109/ICRA.2017.7989783
Abstract: We propose an on-chip micromanipulation method based on mode switching of vibration-induced asymmetric flow. The asymmetric flow can be induced around rotationally asymmetric structures on a microfluidic chip by applying a circular vibration to the chip. Thus, the flow pattern can be switched by changing directions of applied vibrations as clockwise or counter-clockwise. In this study, we applied the switching of flow patterns (e. g., trap mode and transport mode, or trap mode and alignment mode) to change the manipulation modes of microobjects. Furthermore, we demonstrated the proposed method for two applications, local cell concentration and single particle loading. These demonstrations show that the proposed manipulation method can realize versatile on-chip micromanipulations and will contribute to high-throughput and high-reliability cell analysis or diagnosis.
keywords: {Vibrations;Switches;System-on-chip;Loading;Microscopy;Biomedical optical imaging;Optical device fabrication},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989783&isnumber=7988677

T. Proietti, G. Morel, A. Roby-Brami and N. Jarrassé, "Comparison of different error signals driving the adaptation in assist-as-needed controllers for neurorehabilitation with an upper-limb robotic exoskeleton," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6645-6650.
doi: 10.1109/ICRA.2017.7989784
Abstract: Assist-as-needed control aims at maximizing stroke survivors involvement during robotic-led therapies of neurorehabilitation. Besides the specific characteristics of the designed adaptive control strategy, a fundamental property of this control architecture is the choice of the error signal which will drive the adaptation process. This driving source is a necessary control parameter to be chosen, although often sidelined in the control design, and several solutions already exist in the state-of-the-art. For this reason, we wanted to compare three different strategies to guide the adaptation, respectively based on the local joint performances, on the end-effector only behaviour, or on the performance of one specific joint in the kinematic chain of the robot. The resulting analysis evaluates the possibilities offered by simply changing from one source to another with respect to the specific stage of the motor recovery of the patients, potentially extending the capabilities of current exoskeleton controllers for neurorehabilitation.
keywords: {Exoskeletons;Robot kinematics;Medical treatment;Feedforward neural networks;Elbow;Adaptation models},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989784&isnumber=7988677

C. S. Simpson, A. M. Okamura and E. W. Hawkes, "Exomuscle: An inflatable device for shoulder abduction support," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6651-6657.
doi: 10.1109/ICRA.2017.7989785
Abstract: Stroke is the leading cause of adult disability. Many robots have been developed to administer movement therapies or provide physical assistance to stroke survivors suffering from movement deficits. One effective approach has been to support the weight of the arm, offloading shoulder abductor muscles that have become coupled to elbow muscles. However, patients have limited access to such robots due to the robots' complexity, cost, and bulk. To counter this problem, we developed a lightweight (350 g), inexpensive external actuator, which we call an exomuscle. We constructed a prototype exomuscle by reinforcing a plastic bladder with a fabric bag that is sewn to supporting straps. The bladder can then be inflated with pressurized air to provide expansive forces between the user's torso and arm, supporting shoulder abduction. A seam acting as a hinge joint connects the exomuscle to the torso. We demonstrate that our exomuscle reduces muscular effort by 74% in isometric tasks and 72% in dynamic reaching tasks while minimally affecting the range of motion of the shoulder and elbow (average 4% reduction) on three users ranging from 165 to 188 cm tall. Future studies will evaluate the exomuscle with users who have post-stroke motor impairments.
keywords: {Shoulder;Robots;Muscles;Couplings;Torso;Elbow;Bladder},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989785&isnumber=7988677

E. M. Ficanha, G. A. Ribeiro, L. Knop and M. Rastgaar, "Time-varying human ankle impedance in the sagittal and frontal planes during stance phase of walking," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6658-6664.
doi: 10.1109/ICRA.2017.7989786
Abstract: This paper, for the first time, describes the estimation of the time-varying impedance of the human ankle in the sagittal (SP) and frontal (FP) planes during the stance phase of walking. The result of this work is aimed to provide design parameters for the development of 2-DOF powered ankle-foot prostheses capable of mimicking the time-varying impedance of the human ankle. Sixteen axes of rotations combining different amounts of SP and FP rotations were studied. For each axis, positive and negative rotations were considered separately. Four unimpaired male subjects walked on an instrumented vibrating platform that applied combined torque perturbations in the SP and FP simultaneously, while the ankle angles and torques were recorded. Based on the recorded data, the ankle impedance was estimated with a time resolution of 20 ms from 7% to 93% of the stance length (SL). The ankle stiffness and damping showed great variability through the SL and across axes of rotation. The maximum stiffness was 4.7±0.5 Nm/rad/kg at 0.21 s of the SL when the ankle rotated at an axis 22.5° from the SP combining Dorsiflexion (D) and Inversion (I). The minimum stiffness was 1.4±0.6 Nm/rad/kg at 0.05 s of the SL at an axis 45° from the SP combining D and Eversion (E). The maximum damping was 0.09±0.02 Nms/rad/kg at 0.21 s of the SL combining D and I at an axis 25° from the SP. The minimum was 0.02±0.01 Nms/rad/kg at 0.05 s of the SL combining P and I at an axis 45° from the SP.
keywords: {Impedance;Force;Legged locomotion;Torque;Foot;Estimation;Cameras},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989786&isnumber=7988677

T. Lenzi, M. Cempini, L. J. Hargrove and T. A. Kuiken, "Actively variable transmission for robotic knee prostheses," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6665-6671.
doi: 10.1109/ICRA.2017.7989787
Abstract: We present a novel powered knee prosthesis with an active variable transmission (AVT) that adapts motor torque and speed output based on the requirements of different ambulation activities. The AVT works in combination with a spring/damper system to allow for both active and passive operation modes. Preliminary tests performed by an able-bodied subject wearing a bypass orthosis show that the proposed knee can support walking on level ground in passive mode, as well as ambulating on stairs with a reciprocal gait pattern in active mode.
keywords: {Prosthetics;Knee;Torque;Actuators;Kinematics;Brushless DC motors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989787&isnumber=7988677

M. K. Shepherd and E. J. Rouse, "Design of a quasi-passive ankle-foot prosthesis with biomimetic, variable stiffness," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6672-6678.
doi: 10.1109/ICRA.2017.7989788
Abstract: Modern passive ankle-foot prostheses do not exhibit appropriate biomechanics during walking, and are unable to adjust their mechanics for other mobility tasks, such as stair traversal or quiet standing. In this paper, we introduce a quasi-passive ankle-foot prosthesis that addresses these challenges; the ankle has a customizable, nonlinear torque-angle curve, and the overall stiffness can be varied continuously between mobility tasks. The variation in mechanics is accomplished by integrating two mechanisms: a cam-based transmission, in which rotation of the ankle joint causes deflection of a leaf spring, and an active sliding support beneath the leaf spring, which can modify the spring's effective stiffness. In addition to introducing the design, we present the mathematics to calculate the cam profile for any arbitrary torque-angle curve, and experimentally characterize the system for a desired curve based on human walking. Lastly, we demonstrate the full range of stiffness levels available and stiffness transition time.
keywords: {Springs;Prosthetics;Foot;Legged locomotion;Torque;Modulation;DC motors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989788&isnumber=7988677

S. Casini et al., "Design of an under-actuated wrist based on adaptive synergies," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6679-6686.
doi: 10.1109/ICRA.2017.7989789
Abstract: An effective robotic wrist represents a key enabling element in robotic manipulation, especially in prosthetics. In this paper, we propose an under-actuated wrist system, which is also adaptable and allows to implement different under-actuation schemes. Our approach leverages upon the idea of soft synergies — in particular the design method of adaptive synergies — as it derives from the field of robot hand design. First we introduce the design principle and its implementation and function in a configurable test bench prototype, which can be used to demonstrate the feasibility of our idea. Furthermore, we report on results from preliminary experiments with humans, aiming to identify the most probable wrist pose during the pre-grasp phase in activities of daily living. Based on these outcomes, we calibrate our wrist prototype accordingly and demonstrate its effectiveness to accomplish grasping and manipulation tasks.
keywords: {Wrist;Prosthetics;Prototypes;Springs;Shoulder;Robot sensing systems},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989789&isnumber=7988677

L. H. Blumenschein, C. G. McDonald and M. K. O'Malley, "A cable-based series elastic actuator with conduit sensor for wearable exoskeletons," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6687-6693.
doi: 10.1109/ICRA.2017.7989790
Abstract: There is currently a scarcity of wearable robotic devices that can practically provide physical assistance in a range of real world activities. Soft wearable exoskeletons, or exosuits, have the potential to be more portable and less restrictive than their rigid counterparts. In this paper, we present the design of an actuation system that has been optimized for use in a soft exosuit for the human arm. The selected design comprises a DC motor and gearbox, a flexible cable conduit transmission, and a custom series elastic force sensor. Placed in series with the transmission conduit, the custom compliant force sensor consists of a translational steel compression spring with a pair of Hall effect sensors for measuring deflection. The custom sensor is validated as an accurate means of measuring cable tension, and it is shown that it can be used in feedback to control the cable tension with high bandwidth. The dynamic effect of the cable-conduit transmission on the force felt at the user interface is characterized by backdriving the system as it renders a range of virtual impedances to the user. We conclude with recommendations for the integration of such an actuation system into a full wearable exosuit.
keywords: {Actuators;Exoskeletons;Force;Impedance;Magnetic flux;Robots;DC motors},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989790&isnumber=7988677

K. Y. Choi, A. Akhtar and T. Bretl, "A compliant four-bar linkage mechanism that makes the fingers of a prosthetic hand more impact resistant," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6694-6699.
doi: 10.1109/ICRA.2017.7989791
Abstract: Repeated mechanical failure due to accidental impact is one of the main reasons why people with upper-limb amputations abandon commercially-available prosthetic hands. To address this problem, we present the design and evaluation of a compliant four-bar linkage mechanism that makes the fingers of a prosthetic hand more impact resistant. Our design replaces both the rigid input and coupler links with a monolithic compliant bone, and replaces the follower link with three layers of pre-stressed spring steel. This design behaves like a conventional four-bar linkage but adds lateral compliance and eliminates a pin joint, which is a main site of failure on impact. Results from free-end and fixed-end impact tests show that, compared to those made with a conventional four-bar linkage, fingers made with our design absorb up to 11% more energy on impact with no mechanical failure. We also show the integration of these fingers in a prosthetic hand that is low-cost, light-weight, and easy to assemble, and that has grasping performance comparable to commercially-available hands.
keywords: {Couplings;Pins;Prosthetic hand;Bones;Springs;Steel;Immune system},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989791&isnumber=7988677

R. F. Natividad, M. R. Del Rosario, P. C. Y. Chen and C. -H. Yeow, "A hybrid plastic-fabric soft bending actuator with reconfigurable bending profiles," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6700-6705.
doi: 10.1109/ICRA.2017.7989792
Abstract: Rigid actuators that accompany traditional robotic systems allow them to perform tasks with unmatched precision and efficiency. However, such systems are inapt when flexibility and suppleness are required. Inversely, soft robotic actuators are constructed out of naturally compliant materials. This compliance allows them to execute complex motions while their inherent lack of hardness removes the dangers that commonly accompany traditional robots. One archetype of the soft robot is the pneumatic bending actuator. The actuators convert the flow of pressurized air into bending outputs; however, most bending actuators are only limited to one bending trajectory. A new bending actuator, capable of active reconfiguration, is realized through the combination of a non-inflating, flexible, plastic spine and multiple, inflatable, fabric modules. The spine acts as the primary conduit and is responsible for distributing the pressurized flow to the modules. Modules can be removed and replaced seamlessly. The combination of varying module geometries can produce a heterogenic bending trajectory. Blockages located along the spine can separate flow, allowing more customization of the trajectory. A physical model predicting the pressure-bending relationship was conceptualized and verified. When pressurized to 100kPa, the 5-module and 10-module actuators achieved bending angles of 48.76° and 137.65° respectively. The actuators behave as a first-order system when supplied with a step input.
keywords: {Actuators;Fabrics;Force;Resistance;Soft robotics;Interference},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989792&isnumber=7988677

Y. Liu and Q. Xu, "Design of a 3D-printed polymeric compliant constant-force buffering gripping mechanism," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6706-6711.
doi: 10.1109/ICRA.2017.7989793
Abstract: This paper reports on a novel 3D-printed polymeric compliant constant-force buffering gripping mechanism. The motivation of this work is to develop a buffering gripping mechanism to avoid the damage of manipulated biological object induced by excessive displacement output. The presented zero-stiffness mechanism is realized by connecting the negative-stiffness part and positive-stiffness part in parallel. The negative stiffness is obtained by a bistable buckled fixed-guided beam mechanism. Analytical modeling and simulation study are carried out before the prototype fabrication with 3D printing. Experimental results show that the proposed gripping mechanism can provide a constant output force of 780 mN in 500 μm motion range. Results also reveal that the manipulated object bears no deformation in the constant-force range, which is enabled as the excessive displacement output is buffered by the mechanism. The proposed design can be used to replace the existing combined force-displacement control strategy for fragile object manipulation.
keywords: {Force;Prototypes;Grippers;Young's modulus;Polymers;Analytical models;Manganese},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989793&isnumber=7988677

G. Tibi, E. Sachyani, M. Layani, S. Magdassi and A. Degani, "Analytic modeling and experiments of tri-layer, electro-thermal actuators for thin and soft robotics," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6712-6717.
doi: 10.1109/ICRA.2017.7989794
Abstract: By bonding micron-thin polymer layers with an electrically conductive layer, we can utilize the bi-metal effect to create a soft, thin, electrically-activated thermal actuator (ETA), which can be used in printed soft robots. Using ETAs have shown quite remarkable potential in previous works. However, to reveal their true capabilities, we propose to utilize a multi-layered ETA. In this research, we analytically model the actuator for both the bi-, and more importantly, tri-layer ETAs and analyze their behavior. We develop a simple intuitive model to better explain the benefits of the tri-layer actuation and to estimate the optimal design parameters. We verify the models by conducting an experiment to measure the curvature change for different third layer thicknesses. The experiments show a significant improvement in performance of the tri-layer actuators and display a good fit between the simplified analytic model and the full model.
keywords: {Actuators;Analytical models;Robot sensing systems;Polymers;Elasticity;Springs},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989794&isnumber=7988677

Y. She, D. Meng, J. Cui and H. Su, "On the impact force of human-robot interaction: Joint compliance vs. link compliance," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6718-6723.
doi: 10.1109/ICRA.2017.7989795
Abstract: In this paper, we study the effect of mechanical compliance on the impact force of human-robot interactions, more specifically the maximum impact force during a collision. Here we consider two methods of introducing compliance to industrial manipulators: joint compliance and link compliance. To compare their effect on the maximum impact force, we study two designs of a 2D robot link: a rigid link with torsion spring at the joint and a uniform compliant link. The dynamic impact model is based on the Hertz contact model. The results show that the compliant joint solution could produce a larger impact force than that of the compliant link solution if the arm mass is larger than that of the end mass, given the same lateral stiffness and all other inertial parameters (e.g. mass). Simulations and experiment have been done and verified this conclusion. The research demonstrates that the compliant link solution could be a promising approach for addressing safety concerns of human robot interactions.
keywords: {Force;Human-robot interaction;Springs;Aluminum;Manipulators;Safety},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989795&isnumber=7988677

J. Song, B. Gonenc, J. Guo and I. Iordachita, "Intraocular snake integrated with the steady-hand eye robot for assisted retinal microsurgery," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6724-6729.
doi: 10.1109/ICRA.2017.7989796
Abstract: Due to the confined intraocular space and physical constraints in tool manipulation, snake-like robots have a significant potential for use in retinal microsurgery. By enhancing the dexterity at the tool tip, not only the operable space on the retina can be enlarged, but also the delicate target tissues can be reached at an optimal angle minimizing the damage and making the operation much easier. In this study, we present an improved version of our earlier integrated intraocular snake (IRIS) robot, and combine it with another robotic assistant: the cooperatively controlled Steady-Hand Eye Robot (SHER). SHER is used to drive IRIS close to the retina with precision, while IRIS makes omnidirectional bends by combining its yaw and pitch motions and provides a significantly enhanced intraocular dexterity while holding the sclerotomy port fixed. For precise control of IRIS, its snake-like tip actuation has been characterized through experiments considering both a free tool tip and external loading at the tool tip. The workspace analysis showed ±45° yaw and pitch with excellent repeatability (±1°) despite the highly miniaturized articulated segment length (3 mm) and very thin shaft (0 0.9 mm). Our preliminary experiments in an artificial eye model have shown feasibility in reaching targets requiring bends up to 55° accurately.
keywords: {Iron;IP networks;Finite element analysis;Conferences;Automation;Frequency modulation},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989796&isnumber=7988677

J. Ha and P. E. Dupont, "Incorporating tube-to-tube clearances in the kinematics of concentric tube robots," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6730-6736.
doi: 10.1109/ICRA.2017.7989797
Abstract: Mechanics-based formulations of concentric tube robots incorporate tube bending and twisting, but do not include other phenomena that could model observed hysteretic behavior in which tube configurations reached by rotating tubes in different directions achieve different tip positions. As a step toward incorporating hysteretic tube-on-tube friction, this paper derives a model that enables computation of the contact forces applied by the tubes on each other along their lengths. To do so, it is necessary to include the small, but finite clearances between the tubes. Recasting the constrained energy minimization problem as its dual problem enables numerically efficient solution for the clearance-constrained centerlines of each tube as well as their contact forces. These variables are investigated through numerical examples and it is shown that, even without considering friction, the assumption of zero clearance can introduce tip position errors of several millimeters for clinically relevant robot lengths.
keywords: {Electron tubes;Robots;Kinematics;Optimization;Computational modeling;Friction;Nickel},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989797&isnumber=7988677

Y. Zhu, M. Xu, H. Jin, J. Yang and E. Dong, "Chromatic surface microstructures on bionic soft robots for non-contact deformation measurement," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 6737-6742.
doi: 10.1109/ICRA.2017.7989798
Abstract: This paper presents a bionic soft robot with chromatic surface micro-structure (CSM), as a new approach for the measurement of body deformation of the soft robots. Firstly, the CSM films are fabricated by diffraction gratings mold using material polydimethylsiloxane (PDMS). Then, the CSM films are attached to the surface of the soft actuators based on shape memory alloy (SMA) wires. By recording and matching the pattern through two cameras, the continuous deformation curvature degrees of SMA soft actuators are attained. Finally, by integrating three actuators mentioned previously, a bio-inspired prototype of three-legged soft robot is manufactured to carry out motions of both freely and grasp obstacles. By recording and matching the pattern of the robot, we demonstrated a non-contact deformation measurement for flexible devices. As a new non-contact measurement method for body deformation of soft robots, it may shed some light on the issues of the soft robots' sensing and controlling in the future.
keywords: {Actuators;Diffraction;Diffraction gratings;Films;Robot sensing systems;Color},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7989798&isnumber=7988677

M. Mujahed and B. Mertsching, "The admissible gap (AG) method for reactive collision avoidance," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1916-1921.
doi: 10.1109/ICRA.2017.8071093
Abstract: This paper presents a new concept, the Admissible Gap, for collision avoidance. An admissible gap AG is defined as the gap that a robot may safely pass through, while obeying the shape and motion constraints. By employing this concept, a new obstacle avoidance approach was developed, improving the navigation performance in unknown cluttered environments. Unlike most state-of-the-art methods, our approach explicitly considers the robot shape and kinematic constraints rather than adapting a method originally designed for a holonomic pointlike robot. Experimental results demonstrated the power of the proposed AG approach. Moreover, a comparison with state-of-the-art methods showed that the AG approach generates more efficient, safer, and smoother trajectories.
keywords: {Robot kinematics;Collision avoidance;Robot sensing systems;Shape;Navigation;Kinematics},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8071093&isnumber=7988677

R. Andre and U. Thomas, "Error robust and efficient assembly sequence planning with haptic rendering models for rigid and non-rigid assemblies," 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017, pp. 1-7.
doi: 10.1109/ICRA.2017.8262698
Abstract: This paper presents a new approach for error robust assembly sequence planning which uses haptic rendering models (HRMs) for the representation of assemblies. Our assembly planning system uses HRMs for collision test along mating vectors, which are generated by stereographic projection. The planner stores the vectors in 2 1/2D distance maps providing fast and efficient access for the later evaluation while AND/OR-graphs contain possible sequences. Haptic rendering models facilitate the processing compared to faulty triangle meshes providing fast and geometry independent collision tests as colliding parts can easily be identified and handled accordingly. In addition, part and material related properties can be annotated. We present a fast and simple approach handling approximation inconsistencies, which occur due to discretization errors, based only on the properties of the haptic rendering models. The paper concludes with feasible results for various assemblies and detailed calculation times underlining the effectiveness of our approach.
keywords: {Solid modeling;Planning;Haptic interfaces;Rendering (computer graphics);Three-dimensional displays;Robustness;Robots},
URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8262698&isnumber=7988677
